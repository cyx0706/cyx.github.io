{"pages":[{"title":"about","text":"This is an about document about me","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"start up","text":"","link":"/start-up/index.html"}],"posts":[{"title":"100-percent-sunny-girl","text":"停更说明 马上进入期中考试，自认为自己课内的东西学的不行，需要再补一补，估计2周内不会更新 在停更前 修正一些前面写的错误 可以配置一个评论系统出来 过日子 这一阵子过得感觉很不好，记录一下生活的点滴反而给我很多的幸福感 11.3 去看《天气之子》（Weathering With You） 好喜欢新海诚的风格，这次比起《你的名字》更加像新海诚自己的风格，有遗憾，懵懂，坚定和不顾一切。感谢在全是阴霾的日子里遇见了这样一部好的作品。 11.3 社团里检查新生的项目 总会有人给我惊喜，我也总会感叹后浪推前浪，比我小一级的新生们在努力，自己也要更加的努力才行 11.4 给新生做经验分享 本来我不太愿意，而且赶时间，但最后还是去了并且拖了原本预定在11.4晚上要做的一个东西。我想我就是一个愿意多说的，也害怕没人聊天。每天想装高冷，确是最最希望有人和我畅聊的人 11.8 准备买一只小黄鸭毛绒玩具 放在自己社团的桌子上，感觉自己每天坐的地方就不那么的冷清了（原本只有书） 喜提大二 夏季学期结束了, 我也学习计算机一年了 过去的一年里，更多的是磨练自己的coding能力，现在是时候把这些能力转化为高技术能力了，去学习web安全和算法，扩充自己的知识 另一方面，学习更多的Python的特性，学习更多的web技术 一定要学js和css等前端技术，后面的课程设计要用 我大二上的最终目标是学习建模和科学计算，准备进发人工智能方向，可能前面学的有点偏，但无所谓，我喜欢而且现在的数学基础太差了，根本没法学人工智能方向的任何一个（/ 幽灵） 总之菜如我，大二也要好好努力 博客更新基本1周1篇吧，课业也不轻 没啥了 “现在开始放晴了哦” “比起晴空，我更需要你”","link":"/2019/11/08/100-percent-sunny-girl/"},{"title":"汇编语言语法-1","text":"汇编语言 前言 声明： 个人学习的是基于x86和Intel64处理器的汇编语言编程与架构 主要分两部分，语法和实验/实操 语法部分学习书籍：《汇编语言——基于x86处理器》（机械工业出版社）（对，就是那一套外国书里的一本），我尝试采用问答的方式写这一系列的博客，问题选自书上的问题 实验部分为课后习题或者是有意思的东东 汇编语言基础 基本语言元素 Q: 使用数值-35，按照MASM语法，写出10进制，16进制，8进制，2进制格式 K：MASM（Microsoft宏汇编器，Microsoft Macro Assembler）规则下，整数常量由一个可选前置符，数字和基数构成 [{ + | - }] digits [ radix ] 后缀 基数 h 十六进制 q//o 八进制 d 十进制 b 二进制 当进行有符号的十进制向别的进制转换时，先取绝对值，将绝对值转成对应进制，再取补码。 如题中-35转2进制： 35 -&gt; 00100011(不足高位补0) -&gt; 11011101（补码） A：-35d； DDh； 335o； 11011101b Q：A5h是一个有效的十六进制常量吗 A：不是，以字母为开头的十六进制数必须加一个前置0，防止汇编器解释称标识符 Q：安照MASM语法写出实数-62000的实数常量 K：（就和C很像） [ sign ] interger.[ interger ][ exponent ] A: -6.2E+04 Q: 字符常量是什么，字符串常量必须包含在单引号中吗？ A：字符常量是指用单引号或双括号包含的一个字符，汇编语言在内存中保存该字符的ASCII码数值；字符串常量允许被包含单/双引号中，其在内存中保存形式为整数字节数值序列 Q：保留字可以用作助记符，属性，运算符，预定义符号和______ A：伪指令 K： 标识符，可以理解为变量，用于标识变量，常量，子程序，代码标签。最多247个字符，不区分大小写 伪指令，命令，由汇编器识别执行 定义段（segment），即定义程序区段，如.data数据段, .code程序段 指令助记符，标记指令的短单词 助记符 说明 MOV 传值 ADD 数值相加 SUB 数值相减 MUL 数值相乘 JMP 跳转到一个新位置 CALL 调用子程序 补充： 注释，单行以；开头， 块，COMMENT 和一个用户定义的符号，汇编器会忽略其代码直到和用户定义的符号相同的符号出现时 如： COMMENT！ 2333333 ！ NOP，空操作指令 第一个汇编程序：整数加减 1234567891011121314151617; AddTwo.asm - adds two 32-bit integers.; Chapter 3 example.386.model flat,stdcall.stack 4096ExitProcess proto,dwExitCode:dword.codemain proc mov eax,5 add eax,6 invoke ExitProcess,0main endpend main 目前不用完全看懂 .386表明这是32位程序，可以访问32位的寄存器和地址 .flat指定内存模式 stdcall确定了子程序调用规范 .stack 4096 运行时堆栈保留了4096字节存储空间 Exit行，声明ExitProcess原型，原型包括函数名，PROTO关键字，一个逗号，一个输入参数表 end伪指令标记一个程序的结束，并要引入程序入口 main 标识程序入口，即程序要执行的第一条指令的位置 endp用于标识一个进程的结束，这里为main的结束 汇编，链接与运行 源文件-（汇编器-目标文件-(链接器)-可执行文件-(OS加载器)-结果 Q：汇编器生成什么类型的文件 A：汇编器读取源文件，目标文件，即对程序的机器语言翻译。或者它也会生成列表文件 Q：链接器从链接库中抽取已汇编的程序，并将其插入到可执行程序中？ A：错，链接器读取并检查项目目标文件，检查是否有对链接库的调用，链接器从链接库里复制任何被请求的过程，将它们与目标文件组合生成可执行文件 Q：操作系统的那一部分来读取执行程序？ A：操作系统加载程序可以将可执行文件读入内存，并使cpu分支到该程序的起始地址，然后执行程序 定义数据 BYTE和SBYTE定义8位变量 WORD和SWORD定义16位变量 DWORD和SDWORD定义32位变量 QWORD和TBYTE分别定义8字节和10字节的变量 REAL4，REAL8，REAL10分别定义4字节，8字节，10字节变量 Q：为一个16位有符号整数创建未初始化数据声明 K：问号（？）初始值使得变量未初始化，这意味着运行时分配数值 A：var1 SWORD ？ Q：为一个8位无符号整数创建未初始化数据声明 K：BYTE和SBYTE由于是8位，可以表示字符常量，如var1 BYTE ‘A’ 但在定义字符串时，需要注意，需要空字节（0）作为结尾 如： greeting BYTE “Hello World”，0， 也可以这样： greeting BYTE “Welcome”，0dh，0ah BYTE “Hello World”，0 ps：若同一数据定义多个初始值，那么他们的位置只指出偏移量，在内存中相连 如 list BYTE 10,20,30,40 则偏移量为0000， 0001， 0002， 0003，这样是由于x86处理器内存按小端（little-endian）顺序，即从低到高存放检索数据 A：var1 BYTE ？ Q：假设有数值456789AB，按小端序列列出其字节内容 A：从小到大，0000 AB；0001 89；0002 67； 0003 45 ##符号常量 Q：使用等号伪指令定义一个符号常量，使其包含Backspace键的ASCII码（08h） K：很好理解，=就是把一个符号和一个整数表达式关联起来 A：backSpace = 08h Q： (1)编写一条语句使汇编器计算下列数组的字节数，并将结果赋给符号常量ArraySize myArray WORD 20 DUP(?) (2)编写一条语句使汇编器计算下列数组元素的个数，并将结果赋给符号常量ArraySize myArray DWORD 20 DUP(?) K: DUP用于给多个数据项复制，如 BYTE 20 DUP(?) ;20个字节，无初始化 BYTE 4 DUP(“STACK”) ;20个字节，4个字符串，每个都是“STACK” 我们使用 $ 作为当前地址的计数器, $ - array就能得到语句偏移量，即数组字节数，而要计算数组元素，需要用字节数除以每个元素的大小（字数组WORD（每个2字节，16位），双字数组DWORD（每个4字节，32位）） 注意下面情况： list BYTE 1,2,3,4 var BYTE 20 DUP（？） size = （$ - list） size最终为24，别忘了存储地址是连续的，中间插入了20个BYTE A: 1）ArraySize = $-myArray 2）ArraySize = ($-myArray)/2 Q:使用TEXTEQU将下面代码行赋值给setupESI mov esi, OFFSET myArray K：TEXTEQU用于创建文本宏（text macro）分三种情况： name TEXTEQU ;分配文本 name TEXTEQU textmacro ;分配已有的文本宏 name TEXTEQU %constExpr ;分配整数常量表达式(注意有个%号) A：setupESI = &lt;mov esi, OFFSET myArray&gt; 写在后面 这章编程题太简单了，没啥东西值得放上来，就去掉对应实验的博客了 这么简单的一章看了好几天，以后要加快速度了 配置环境参考：参考博客 ps：配置生成列表文件： 两个$之间 就可能被转为数学表达式","link":"/2019/07/12/AssemblyLanguageBasis-1/"},{"title":"汇编基础","text":"高级语言接口 大多数程序员不会用汇编语言写大的程序，因为这相当的花费时间。反之，高级语言会隐藏一些细节，开发效率更高。汇编语言广泛用于配置硬件驱动器，以优化程序速度和代码量 通用规范 调用规范（call convention）是指调用过程的底层细节。下面列出需要考虑的细节信息： 调用过程需要保存哪些寄存器 传递参数的方法：用寄存器，用堆栈，共享内存或其他方法 主调程序调用过程时参数传递的顺序 参数传值还是传引用 过程调用后，如何恢复堆栈指针 函数如何向主调程序返回结果 命名规范与外部标识符 当从其他语言程序中调用汇编过程时，外部标识符必须与命名规范兼容。外部标识符（external identifier）是放在模块目标文件中的名称，链接器使得这些名称能被其他程序模块使用。 段名称 汇编语言过程与高级语言程序连接时，段名称必须是兼容的。本章使用的简化段指令都与Microsoft C++编译器生成的段名称兼容 内存模式 主调程序与被调程过程使用的内存模式必须相同 Q：实地址模式下可以选择那些内存模式？ K：.model伪指令确定若干重要的程序特性：内存模式类型，过程命名模式，参数传递规则 A：有微模式，小模式，中模式，大模式，紧凑模式，巨模式，平坦模式，值得一提的是：平坦模式也是保护模式，代码与数据使用32位偏移量。所有的数据和代码（包括系统资源）都在一个32位段内。 Q：使用STDCALL语言说明符的汇编语言过程可以与C++程序链接 A：F，STDCALL用于Windows的系统函数调用，C语言说明符才是可以与C/C++链接的过程 K：需要注意，C说明符将从堆栈中移除参数的任务交给了主调方，C语言说明符在外部过程名的前面添加前导下滑线，如_AddTwo 内嵌汇编代码 Q：内嵌汇编代码与内嵌C++过程有什么不同之处？ A：内嵌汇编代码是指的直接插入高级语言程序的汇编源代码，而C++内嵌限定符则要求C++汇编器直接把函数体插入程序的编译代码，以便清除函数调用和返回时所耗费的时间。 Q：与使用外部汇编过程相比，内嵌汇编代码有什么优势？ A：简单，因为不需要考虑外部链接，命名以及参数传递协议 Q：请至少给出两种在内嵌汇编代码中添加注释的方法 A：建议不要使用汇编风格的注释，选择使用 / xxxx / /* xxxxx */ Q:内嵌语言是否可以引用__asm模块外的代码 A:可以 K： 编写内嵌汇编代码时允许： 使用x86指令集的大多数指令 使用寄存器名作为操作数 通过名字引用函数参数 引用asm块外定义的代码标号和变量。（这点很重要，因为局部变量必须在asm块的外面） 在语句中使用PTR，EVEN（使下一个变量或指令开始于偶数字节地址），ALIGN（双字对齐） 不允许： 使用数据定义伪指令，如DB（BYTE）和DW（WORD） 使用汇编运算符（PTR除外） 使用STRUCT，RECORD，WIDTH，MASK 使用宏伪指令，以及宏运算符（&lt;&gt;,!,&amp;,%） 虽然不能使用OFFSET运算符，但可以用lea指令获取变量的偏移值 lea esi, buffer 实例： 使用汇编加密 encode.cpp1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;fstream&gt;#include &quot;translat.h&quot;using namespace std;int main(int argcount, char *args[]){ if (argcount &lt; 3) { cout &lt;&lt; &quot;Usage:encode infile outfile&quot; &lt;&lt; endl; return -1; } const int BUFSIZE = 2000; char buffer[BUFSIZE]; unsigned int count; //字符计数 unsigned char encryptCode; cout &lt;&lt; &quot;Encryption code[0-255]?&quot;; cin &gt;&gt; encryptCode; ifstream infile(args[1], ios::binary); ofstream outfile(args[2], ios::binary); cout &lt;&lt; &quot;Reading &quot; &lt;&lt; args[1] &lt;&lt; &quot; and creating &quot; &lt;&lt; args[2] &lt;&lt; endl; while (!infile.eof()){ infile.read(buffer, BUFSIZE); count = infile.gcount(); TranslateBuffer(buffer, count, encryptCode); outfile.write(buffer, count); } return 0;} 嵌入的汇编语言写在头文件里,加密方法就是让字符每一位与输入的数字异或 translat.h12345678910111213void TranslateBuffer(char *buf, unsigned count, unsigned char eChar) { __asm { mov esi, buf mov ecx, count mov al, eChar L1: xor [esi], al inc esi loop L1 } // asm} 我们在命令行里运行 encode infile.txt encoded.txt 我们反汇编看到一些东西 123456789101112131415161718192021222324252627000D7D80 push ebp 000D7D81 mov ebp,esp 000D7D83 sub esp,0C0h 000D7D89 push ebx 000D7D8A push esi 000D7D8B push edi;内嵌代码开始 000D7D8C lea edi,[ebp-0C0h] 000D7D92 mov ecx,30h 000D7D97 mov eax,0CCCCCCCCh 000D7D9C rep stos dword ptr es:[edi] 000D7D9E mov esi,dword ptr [buf] 000D7DA1 mov ecx,dword ptr [count] 000D7DA4 mov al,byte ptr [eChar] 000D7DA7 xor byte ptr [esi],al 000D7DA9 inc esi 000D7DAA loop L1 (0D7DA7h) ；这里汇编结束000D7DAC pop edi 000D7DAD pop esi 000D7DAE pop ebx 000D7DAF add esp,0C0h 000D7DB5 cmp ebp,esp 000D7DB7 call __RTC_CheckEsp (0D15AFh) 000D7DBC mov esp,ebp 000D7DBE pop ebp 000D7DBF ret 编译器自动插入了一些语句用于设置EBP以及保存标志寄存器集合，集合内的寄存器不论是否被修改，总是会被保存 32位汇编程序与C/C++的链接 要想调用，需要在汇编源码中.MODEL伪指令中指定调用C的规范，而且要为每个调用外部的过程创建一个原型 1234.586.model flat,CIndexOf PROTO, srchVal:DWORD, arrayPtr:DWORD, count:DWORD 在C程序中，声明外部汇编过程时要使用extern限定符，如果过程会被C++调用，则要添加“C”限定符，防止C++的名称修饰 12extern long IndexOf(long n, long array[], unsigned count);extern &quot;C&quot; long IndexOf(long n, long array[], unsigned count); 名称修饰（name decoration）就是一种标志C++编译技术，通过添加字符来修改函数名，添加的字符指明了每个函数参数的确切类型 详细的配置可以看我们的实验 调用C和C++的函数 函数原型 可以编写程序来调用C和C++函数，这样做的理由至少有： C和C++有丰富的输入输出库，因此有更大的灵活性，处理浮点数时，这相当有用 两种语言都有丰富的数学库 需要注意：调用标准C库或C++库，必须从C或C++的main()过程启动程序，以便运行库初始化代码 汇编语言调用的C++函数必须使用“C”和关键字extern，推荐不是修改每个函数的定义，而是把多个函数原型放在一个块中显得更容易 1234extern &quot;C&quot;{ int askForInteger(); int showInt(int value, unsigned outWidth)} 汇编语言模块 如果汇编语言模块要调用Irvine32链接库，就要使用.model flat, stdcall，但这和c的调用规范不符（要用c规范），这时声明原型必须给PROTO伪指令加上C限定符 123INCLUDE Irvine32.incaskForInteger PROTO CshowInt PROTO C, value:SDWORD, outWidth:DWORD 当然如果不调用Irvine库，则全局声明为C规范即可.model flat, C,PROTO就不用再添加C限定符 仍需要知道，Microsoft Visual C++函数怎样返回数值： bool和char的值用AL返回 short，int值用AX返回 int和long int值用EAX返回 指针用EAX返回 float，double，long double的值分别以4,8,10字节值压入浮点堆栈 调用C库（Standard Library）函数 printf C的原型 123int printf( const char *format [, argument]...) 汇编的等效原型 1printf PROTO C,format:PTR BYTE, args:VARARG 可变长度参数类型为vararg 如何调用printf？ 1234567891011121314;显示双精度.datadouble1 REAL8 1234567.890123formatStr BYTE &quot;%3.f&quot;, 0dh, 0ah, 0.codeINVOKE printf, ADDR formatStr, double1 ;结果=1234567.890;多参数TAB=9.dataformatTwo BYTE &quot;%.2f&quot;, TAB, &quot;%.3f&quot;, 0dh, 0ah, 0val1 REAL8 111.111val2 REAL8 456.789.codeINVOKE printf, ADDR formatTwo, val1, val2 需要注意的是：格式化字符串不是插入转义字符，如\\n，必须插入ASCII字符（0dh，0ah） 写在后面 至此，基础基本完成，庆祝一下自己坚持看完了这本400+的书，习题会补上。","link":"/2019/08/10/AssemblyLanguageBasis-10/"},{"title":"汇编基础","text":"64位编程 之前介绍的一直都是32位的程序，64位和32位有很多相似的地方，但仍有许多的不同： 比如64位MASM 11.0不支持INVOKE伪指令，而且不需要在程序前写出.model,.stack,.386的 寄存器 64位模式下，操作数的默认大小是32位，并且有8个通用的寄存器。但是给每条指令加上REX（寄存器扩展）前缀后，操作数也可达64位。通用寄存器的数量也增加到了16个：32位模式下的寄存器再加上8个有标号的寄存器，R8~R15 64位模式下，单条指令不能同时访问寄存器的高字节，如AH，BH，CH以及新寄存器的低字节DIL 64模式下，32位的EFLAGS被64位的RFLAGS取代。这两个寄存器共享低32位，而RFLAGS的高32位是不使用的 32位和64位拥有相同的状态标志位 加法减法 SumArray_64.asm123456789101112131415161718;数组求和ExitProcess PROTO.dataintArray QWORD 1000000000000h, 20000000000000h QWORD 3000000000000h, 40000000000000h.codemain PROC mov rdi, OFFSET intArray mov rcx, LENGTHOF intArray mov rax, 0L1: add rax, [rdi] add rdi, TYPE intArray loop L1 mov ecx, 0 ;ExitProcess的返回值 call ExitProcessmain ENDPEND 需要注意的是操作数的大小，当操作数只使用部分寄存器的时候，其余位置不会被修改 同时，使用OFFSET运算符将产生64位地址，必须用64位寄存器或者变量来保存 64位调用规范 如果想要调用自己写的子程序或者Irvine64链接库的子程序，则程序员需要在自己的程序顶部用PROTO伪指令来指定所有在本程序外同时又会被调用的过程 12ExitProcess PROTO ;Windows APIWriteHex64 PROTO ;Irvine64链接库 由于地址长为64位，因此CALL指令把RSP（堆栈指针）寄存器的值减去8 长度不足64位的参数不进行零扩展，因此其高位的值是不确定的 如果返回值的长度小于或者等于64位，那么它必须放在RAX寄存器中 主调者要负责在堆栈中分配至少32字节的影子空间，以便被调用的子程序可以选择将寄存器保存在这个区域中 调用子程序时，堆栈指针（RSP）必须对齐16字节边界。CALL指令将8字节的返回地址压入堆栈，因此，主调程序出了把堆栈指针减去32以便存放寄存参数之外，还要减去8 大于64的返回值存放于运行时的堆栈，由RCX指出其位置 123456789101112131415161718192021222324252627ExitProcess PROTOWriteInt64 PROTOCrlf PROTO.codemain PROC sub rsp, 8 ;对准堆栈指针 sub rsp, 20h ;影子参数 mov rcx, 1 mov rdx, 2 mov r9, 3 mov r8, 4 call AddFour ;RAX中返回值 call WriteInt64 call Crlf mov ecx, 0 call ExitProcessmain ENDPAddFour PROC mov rax, rcx add rax, rdx add rax, r8 add rax, 19 retAddFour ENDPEND 64位模式下的布尔指令 大多数情况下，64位模式中的64位指令与32位模式中的操作是一样的。比如，如果源操作数是常数，长度小于32位，而目的操作数使一个64位的寄存器或者内存操作数，那么目的操作数的所有位都会受到影响 1234567891011.dataallones QWORD 0FFFFFFFFFFFFFFFFh.code mov rax, allones ;RAX=FFFFFFFFFFFFFFFF and rax, 80h ;RAX=0000000000000080 mov rax, allones and rax, 8080h ;RAX=0000000000008080 mov rax, allones and rax, 808080h ;RAX=0000000000808080 mov rax, allones and rax, 80808080h ;RAX=FFFFFFFF80808080 我们发现如果操作数是32位常数或寄存器，那么目的操作数，只有低32位会受到影响 这个同样适用于内存操作数，显然32位操作数是一种特殊的情况，需要和其他大小的操作数分开考虑","link":"/2019/08/12/AssemblyLanguageBasis-11/"},{"title":"汇编基础","text":"字符串和数组 如果可以有效的处理字符串和数组，就能掌握代码优化中的最常见情况。研究表明，绝大多数程序用90%的运行时间执行其10%的代码。毫无疑问，这10%通常发生在循环中，而循环正是处理字符串和数组所要求的结构。本节以编写高效代码为目的，阐释字符串和数组的处理技术 串处理 字符串操作指令的实质是对一片连续存储单元进行处理，这片存储单元是由隐含指针DS:SI或ES:DI来指定的。字符串操作指令可对内存单元按字节或字进行处理，并能根据操作对象的字节数使变址寄存器SI（和DI）增减1或2。 字符串基本指令 x86指令集有5组指令用于处理字节，字，双字数组。虽然他们被称为字符串原语（string primitives），但它们并不局限于字符数组。 指令 说明 MOVSB，MOVSW，MOVSD 传送字符串数据：将ESI寻址的内存复制到EDI寻址的内存位置 CMPSB，CMPSW，CMPSD 比较字符串：比较分别由ESI和EDI寻址的内存数据 SCASB，SCASW，SCASD 扫描字符串：比较累加器（AL，AX，EAX）与EDI寻址的内存数据 STOSB，STOSW，STOSD 保存字符串：将累加器内容保存到EDI寻址的内存位置 LODSB，LODSW，LODSD 从字符串加载到累加器：将ESI寻址的内存数据加载到累加器 使用重复前缀 指令 说明 REP ECX&gt;0时重复 REPZ，REPE 零标志位置1且ECX＞0时重复 REPNZ，REPNE 零标志位清零且ECX＞0时重复 实例：复制字符串 12345cld ;清除方向标志位mov esi, OFFSET string1mov edi, OFFSET string2mov ecx, 10rep movsb 上面例子，MOVSB从string1传10字节到string2，每次rep前先测试ECX是不是0，若为0则跳过这句，若ECX&gt;0则将ECX减1执行MOVSB，而MOVSB会自动增加ESI和EDI，这个操作由CPU的方向标志位控制。 MOVSB减1，MOVSW减2，MOVSD减4 方向标志位 方向标志位的值 对ESI和EDI的影响 地址顺序 0 增加 低到高 1 减少 高到低 可以使用CLD和STD显示修改方向标志位 CLD ;方向标志位清零（正向） STD ;方向标志位置1（反向） 比较 CMPSB， CMPSW，SMPSD用于比较字节，字，双字，同样方向标志位决定EDI和ESI增加还是减少 实例：比较双字 123456789101112131415.datasource DWORD 1234htarget DWORD 5678h.codemov esi, OFFSET sourcemov edi, OFFSET targetcmpsd ;比较双字ja L1 ;大于跳转;比较多个的时候mov esi, OFFSET sourcemov edi, OFFSET targetcldmov ecx, LENGTHOF sourcerepe cmpsd ;相等则重复 REPE前缀重复比较操作，自动增加ESI和EDI直到ECX=0或者发现了一对不相等的双字 扫描 SCASB，SCASW，SCASD指令分别将AL，AX，EAX中的值与EDI寻址的一个字节，字，双字进行比较。这些指令可以用于在字符串或数组中寻找一个数值，结合REPE。 实例：扫描是否有匹配字符 12345678910.dataalpha BYTE &quot;ABCDEFGH&quot;, 0.codemov edi, OFFSET alphamov al, 'F' ;检索字符Fmov ecx, LENGTHOF alphacld ;标志位正向repne scasb ;不相等就重复jnz quit ;未发现字符，退出dec edi ;发现字符，EDI-1指向该位 需要记得减1才是F的位置，不然指向的是后一位，循环之后添加了JNZ，以避免出现由于ECX=0而没有找到AL中的字符结束循环的可能性 填充 LODSB，LODSW，LODSD指令分别从ESI指向的内存地址加载一个字节或一个字到AL，AX，EAX。ESI按照方向标志位的状态递增或递减。LODS很少与REP前缀一起使用。原因是，加载到累加器的新值会覆盖其原先的内容。所以LODS常常被用于加载单个数值 实例：数组乘法 1234567891011121314151617INCLUDE Irvine32.inc.dataarray DWORD 1,2,3,4,5,6,7,8,9,10multiplier DWORD 10.codemain PROC cld mov esi, OFFSET array mov edi, esi mov ecx, LENGTHOF arrayL1: lodsd ;[ESI]加载到EAX mul multipier stosd ;EAX保存到[EDI] loop L1main ENDPEND main 部分字符串过程 用Irvine32链接库中的几个过程来处理空字节结束的字符串。这些过程和标准C库有明显的相似性： 12345678910111213141516;将源串复制到目的串Str_copy PROTO, source: PTR BYTE, target: PTR BYTE;用EAX返回串长度(包括0字节)Str_length PROTO, string1:PTR BYTE string2:PTR BYTE;从字符串尾部去除特定的字符;第二个参数是要去除的字符Str_trim PROTO, pString:PTR BYTE char:BYTE;将字符串转为大写Str_ucase PROTO, pString:PTR BYTE Irvine64库中的字符串过程 Str_compare 比较两个字符串 输入参数：RSI为源指针，RDI为目的指针 返回值：若源串＜目的串，进位标志位CF=1，若源串=目的串，ZF=1，若源串＞目的串，ZF=0且CF=0 Str_copy 将源串复制到目的指针指向的位置 输入参数：RSI为源串指针，RDI指向被复制串将要存储的位置 Str_length 返回以空字节结束字符串的长度 输入参数：RCX为字符串指针 返回值：RAX为该字符串的长度 二维数组 在汇编语言的程序员看来，二维数组是一维数组的高级抽象。高级语言有两种方法在内存中存放数组的行和列：行主序和列主序，就是按行的顺序来排列或者按列的顺序来排列 二维数组的定义和访问 12345678910111213.datatableB BYTE 10h, 20h, 30h, 40h, 50hRowsize = ($-tableB) BYTE 60h, 70h, 80h, 90h, 0Ah BYTE 0Bh, 0Ch, 0Dh, 0Eh, 0Fh;访问行1列2的80hrow_index = 1column_index = 2.code mov ebx, OFFSET tableB add ebx, RowSize * row_index mov esi, column_index mov al, [ebx+esi*TYPE tableB] 64位模式下的基址-变址操作数 123456789101112131415161718192021222324252627282930313233Crlf PROTOWriteInt64 PROTOExitProcess PROTO.datatable QWORD 1,2,3,4,5RowSize = ($ - table) QWORD 6,7,8,9,10 QWORD 11,12,13,14,15.codemain PROC mov rax, 1 mov rsi, 4 call get_tableVal call WriteInt64 call Crlf mov ecx, 0 call ExitProcessmain ENDPget_tableVal PROC USES rbx;--------------------------------;返回四字二维数组中给定的行列的值的元素;参数:RAX=行数,RSI=列数;返回:RAX存储找到的元素;-------------------------------- mov rbx, RowSize mul rbx mov rax, table[rax+rsi*TYPE table] retget_tableVal ENDPend 需要注意的是，如果使用寄存器索引操作数，就必须使用64位寄存器","link":"/2019/08/13/AssemblyLanguageBasis-12/"},{"title":"汇编基础-13","text":"对之前学过的内容的补充(结合专业课) 11.14更新 关于NASM和MASM NASM全称The Netwide Assembler，是一款基于80x86和x86-64平台的汇编语言编译程序，其设计初衷是为了实现编译器程序跨平台和模块化的特性。NASM支持大量的文件格式，包括Linux，*BSD，a.out，ELF，COFF，Mach−O，Microsoft 16−bit OBJ，Win32以及Win64，同时也支持简单的二进制文件生成。它的语法被设计的简单易懂，相较Intel的语法更为简单，支持目前已知的所有x86架构之上的扩展语法，同时也拥有对宏命令的良好支持。 摘自百度百科 宏汇编程序(MASM)是具有宏加工功能的汇编程序。可以用它定义含参数的程序段，在使用的位置上调用它们，汇编时将进行宏(指令)展开，把宏定义所预先定义的指令目标代码插在该位置上。 前面的学习都用到的是MASM，而学校实验用的是NASM，什么DOSBOX，DEBUG，用着非常的不舒服 但是这不影响对于一些共性的东西的学习，写这篇博客的存在意义就是补充这些我遗漏的东西 跨段前缀寻址 对于常规的寻址方式，我们都知道我们汇编的所谓地址就是一个偏移量，是相对于隐含段DS（数据段）的偏移量，对于正常的mov语句，如mov ax, [bx]，其实为mov ax, ds:[bx] 物理地址 PA = 16 * DS + 偏移量 in&amp;out IN AL,21H ;表示从21H端口读取一字节数据到AL OUT 21H,AL ;将AL的值写入21H端口 lea lea(Load effective address)表示取有效地址，也就是取偏移地址,看下面一段程序就足以说明它的含义 12345678910111213141516.datatest1 DWORD 100address DWORD $.codemain PROC mov eax, 0 lea eax, test1 mov eax, 0 mov eax, address mov eax, 0 mov eax, OFFSET test1 mov eax, 0main endp 我们发现它一定程度上和offset指令和$符效果相同,不过这两个是masm独有的符号，在别的架构里说不定就没有了 当然，在涉及堆栈时，就需要它来运行时计算，详细参考汇编基础6 LOOP指令补充 12345678910111213循环指令：LOOP OPR测试条件：(CX) != 0为零或相等时循环指令：LOOPZ(LOOPE) OPR测试条件：ZF=1 且 (CX) != 0不为零或不相等时循环指令：LOOPNZ(LOOPNE) OPR测试条件：ZF=0 且 (CX) != 0如:loop again等价于:dec ecxjnz again 11.23更新 伪操作 伪操作是汇编程序对源程序进行汇编时处理的操作，完成处理器的选择，存储模式的定义，数据定义，存储器分配，指示程序开始和结束等功能 处理器选择 伪指令 含义 .8086 选择8086指令系统 .286 选择80286指令系统 .286P 选择保护模式下的80286指令系统 .386 选择80386指令系统 .386P 选择保护模式下的80386指令系统 … … 段定义伪操作 1234段名 SEGMENT [定位类型][组合类型][使用类型][类别] .... ....段名 ENDS 定位方式默认为PARA，表示本段必须从能被16整除的地址开始存放，除此之外还有WORD，BYTE，PAGE 组合方式决定在连接时是否合并同名段，如STACK将不同模块的同名段组合成一个堆栈段，默认为PRIVATE，表示连接时不组合 USE使用类型，USE16/32 表示用用16或32位寻址方式 当然这些可以被简化，就是我们常用的.data，.code等 MODEL伪操作指定存储模式 1.MODEL 存储模式 [,语言类型][,操作系统类型][,堆栈选项] 我们常用的flat就是存储模式，除此之外还有TINY，SMALL，LARGE，HUGE等 ORG伪操作 ORG是Origin的缩写，表示起始地址或源。在汇编语言源程序的开始通常都用一条ORG伪指令来实现规定程序的起始地址。如果不用ORG规定则汇编得到的目标程序将从0000H开始。如下： 12 ORG 100HSTART: ...... 汇编语言源程序中若没有ORG伪指令，则程序执行时，指令代码被放到自由内存空间的CS:0处；若有ORG伪指令，编译器则把其后的指令代码放到ORG伪指令指定的偏移地址。两个ORG伪指令之间，除了指令代码，若有自由空间，则用0填充。 基数控制伪操作 .RADIX 表达式 用于规定以下的无标记数的默认基数，如果不设置默认为10 1234567.RADIXmov bx, 0FFmov bx, 178;等价写法mov bx, 0FFHmov bx, 178H","link":"/2019/11/14/AssemblyLanguageBasis-13/"},{"title":"汇编语言语法-2","text":"数据传送，寻址和算数运算 写在前面的补充(32位x86处理器)： 基本程序执行寄存器 通用寄存器：主要用于算数运算和数据传输 一些寄存器的组成部分可以处理8位的值，如AX寄存器的高8位被称为AH，低8位被称为AL 32位 16位 8位(高) 8位(低) EAX AX AH AL EBX BX BH BL ECX CX CH CL EDX DX DH DL 其他通用寄存器只能用32或16位访问 32位 16位 32位 16位 ESI SI EBP BP EDI DI ESP SP 特殊用法： 乘除指令默认使用EAX（extended accumulator） CPU默认使用ECX为循环计数器 ESP（extended stack accumulator）用于寻址堆栈数据，极少用于数据传输和算数运算 ESI（extended source index）和EDI（extended destination index）用于高速存储传输指令 高级语言通过EBP（extended frame pointer）来引用堆栈中的函数参数和局部变量 段寄存器 实地址模式中，16位段寄存器表示的是预先分配的内存区域的基址，这个内存区域称为段。一些段中存放程序指令（代码），其他段中存放变量（数据），还有一个堆栈段存放的局部变量和函数参数 指令指针 EIP寄存器中包含下一条要执行指令的地址。某些机器指令可以控制EIP，使程序分支转向另一个新位置 数据传送指令 Q: 操作数的三种类型是什么 A：操作数有3种基本形式： 立即数——————使用数字文本表达式 寄存器操作数————————使用CPU内已经命名的寄存器 内存操作数————————引用内存位置 Q：Intel使用的操作数符号中reg/mem32的含义是什么？ K：不用死记： reg表示通用寄存器（register）：reg8，8位的（AH，AL，BH，BL，CH，CL，DH，DL）；reg16，16位的 sreg表示16位段寄存器（stack reg）：CS，DS，SS，ES，GS，FS imm立即数（immediate）：imm8,8位立即数；imm32,32位立即数（DWORD型） reg/mem8:8位操作数，可以是8位通用寄存器或者内存字节 reg/mem16:16位立即数，可以是16位通用寄存器或者内存字 reg/mem32:32位立即数，可以是32位通用寄存器或者内存双字 mem 内存操作数（8位，16位，32位） A：略… Q：（判断） 1.MOV指令的目的操作数不能为段寄存器 2.MOV指令中的第二个操作数是目的操作数 3.EIP寄存器不能作为MOV指令的目的操作数 K： MOV用于数据传送 MOV destination,source MOV操作要满足如下规则： 两个操作数必须是同样的大小 两个操作数不能同时为内存操作数 指令指针寄存器（IP，EIP，RIP）不能作为目标操作数 MOV不能内存到内存，要先入寄存器 由于MOV不能直接将较小的操作数复制到较大的操作数中便有了： MOVZX指令将一个较小的操作数（无符号）0扩展为较大的操作数再移动 MOVSX指令将一个较小的操作数（有符号）符号扩展为较大的操作数再移动 A：F F T 实例 XCHG指令交换两个操作数的内容，指令中至少有一个操作数是寄存器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748.386.model flat,stdcall.stack 4096ExitProcess proto,dwExitCode:dword.dataval1 WORD 1000hval2 WORD 2000harrayB BYTE 10h,20h,30h,50harrayW WORD 100h, 200h, 300harrayD DWORD 10000h, 20000h.codemain proc ;演示MOVZS指令 mov bx, 0A69Bh movzx eax, bx ; EAX = 0000A69Bh movzx edx, bl ; EDX = 0000009Bh movzx cx, bl ; CX = 009Bh ;演示MOVSX指令 mov bx, 0A69Bh movsx eax, bx ; EAX = FFFFA69Bh movsx edx, bl ; EDX = FFFFFF9Bh mov bl, 7Bh movsx cx, bl ; CX = 007Bh ;内存-内存的交换 mov ax, val1 ; AX = 1000h xchg ax, val2 ; AX = 2000h, val2 = 1000h mov val1, ax ; val1= 2000h ;直接-偏移量寻址 mov al, arrayB ; AL = 10h mov al, [arrayB+1] ; AL = 20h mov al, [arrayB+2] ; AL = 30h mov ax, arrayW ; AX = 100h mov ax, [arrayW+2] ; AX = 200h mov eax, arrayD ; EAX = 10000h mov eax, [arrayD+4] ; EAX = 20000h invoke ExitProcess,0main endpend main 加减法 算数指令 INC指令实现操作数加1 DEC指令实现操作数减1 ADD指令实现源操作数和目的操作数相加 SUB指令实现目的操作数减去源操作数 NEG指令实现操作数符号翻转 状态标志 表示受算数影响的CPU状态标志： 算数结果为负，符号标志位（SF）为1 与目标操作数相比，无符号算术运算操作结果太大，进位标志位（CF）为1 执行算术或布尔指令后，奇偶标志位（PF）能反映出目标操作数最低有效字节中1的个数为奇数还是偶数 目的操作数位3有进位或借位，辅助进位标志位（AC）为1，主要用于二进制编码的十进制数（BCD）运算，如1+0Fh，和数在位4上为1，这是位3的进位，AC=1 算术操作结果为0,零标志位（ZF）为1 有符号算术操作结果超过目标操作数范围时，溢出标志位（OF）为1，典型的就是两个正数相加得到了一个负数，两个负数相加得到了一个正数 ps：若NEG求反后原寄存器无法装下，则OF置1，寄存器内结果不变，如： 12mov al，-128 ；AL=10000000bneg al ；AL=10000000b， OF=1 Q：写一个汇编程序实现a=R = -X + （Y - Z）,其中abcd均为变量，为结果，26， 30， 40 A： 12345678910111213141516171819202122232425.386.model flat,stdcall.stack 4096ExitProcess proto, dwExitcode:dword.dataRval SDWORD ?Xval SDWORD 26Yval SDWORD 30Zval SDWORD 40.codemain PROC ; 执行运算Rval = -Xval + （Yval - Zval） mov eax, Xval neg eax mov ebx, Yval sub ebx, Zval add eax, ebx mov Rval, eax INVOKE ExitProcess,0main ENDPEND main 与数据相关的运算符和伪指令 OFFSET运算符返回的是一个变量与其所在段起始地址之间的距离 PTR可以重写操作数的默认大小类型 TYPE返回的是一个操作数或者数组中每个元素的大小 LENGHOF返回数组中元素的个数 SIZEOF返回数组初始化时使用的字节数 Q：假如有如下定义： 1234567891011;Q1.datamyArray BYTE 10,20,30,40,50 BYTE 60,70,80,90,100;Q2.data myDouble DWORD 12345678h.codemov ax,WORD PTR myDouble Q1: TYPE，LENGHOF，SIZEOF结果为多少？ Q2：AX=？ K： 如果数组定义占多行，LENGHOF只针对第一行，故为5，而SIZEOF返回值等于TYPE与LENGHOF的乘积，但如果该定义多行数组第一行结尾加上一个逗号，LENGHOF就为10 操作数大小不匹配，则我们无法直接让myDouble的后四位5678h移动到AX中，但使用PTR修改大小即可。为啥是后四位？想想x86处理器的小端存储 A1：1,5,5 A2：5678h 间接寻址 直接寻址很少用于数组的处理，反之，会用寄存器作为指针（称为间接寻址）并控制该寄存器的值。如果一个操作数使用的是间接寻址，就称之为间接操作数 Q：（判断） 1.任何一个32位寄存器都可以用作间接操作数 2.指令inc[esi]非法 3.array[esi]是变址操作数 A:T T T K： 保护模式 任何一个32位通用寄存器（EAX,EBX,ECX,EDX,ESI,EDI,EBP,ESP）加上括号就是一个间接操作数。寄存器中存放的是数据的地址。 123456.databyteVal BYTE 10h.codemov esi,OFFSET byteValmov al,[esi] 上面代码就是常见用法，MOV指令使用间接操作数作为源操作数，解析ESI中的偏移量，并将该内存的值送入AL，当然也可以mov [esi],bl 即将BL内容复制到ESI寻址的内存地址中 使用PTR inc [esi]会产生operand must have size的错误，汇编器不知道ESI指针的类型是啥，我们需要使用PTR 1inc BYTE PTR [esi] 变址操作数 变址操作数是指，在寄存器上加上常数产生一个有效地址。每个32位通用寄存器都可以作为变址寄存器。 constant[reg] [constant + reg] 变址操作非常适合数组处理，在访问第一个元素前，变址寄存器需要初始化为0 12345.dataarrayB BYTE 10h,20h,30h.codemov esi,0mov al,arrayB[esi] ;AL=10h 需要注意，arrayB为BYTE型时，下一个为[esi+1],arrayB为WORD型时，下一个为[esi+2],这同样和数组元素大小有关,简化这一步骤，可以使用比例因子 123456789.data arrayB DWORD 1,2,3,4.codemov esi,3mov eax,array[esi*4];使用TYPE使程序更加灵活mov esi,3mov eax,array[esi*TYPE arrayB] Q:分析下面程序填结果: 123456789101112131415.datamyBytes BYTE 10h,20h,30h,40hmyWords WORD 8Ah,3Bh,72h,44h,66h,myDoubles DWORD 1,2,3,4myPointer DWORD myDoubles.codemov esi,OFFSET myBytesmov ax, [esi] ;a. AX =mov eax, DOWRD PTR myWord ;b. EAX = mov esi, myPointermov ax, [esi+2] ;c.AX = mov ax, [esi+6] ;d.AX = mov ax, [esi-4] ;e.AX = K: myPointer DWORD myDoubles为定义一个指向双字的指针，值为myDoubles(地址),可以联想求数组大小时x = $ - array 中的array就是首地址 TYPEDEF可以创建用户定义类型，如：PBYTE TYPEDEF PTR BYTE创建了自定义的PBYTE，一个字节的指针 A：a:0010h; b:003B008Ah; c:0; d:0; e:0044h 将字类型重定义为双字，则接下来的2字节的内存和该2字节的内存的值一起组成一个双字（小端顺序），自然b就是003B008Ah 双字在内存里4个字节存一个数，则该部分排列为00h,00h,00h,01h,00h,00h,00h…，自然[esi+2]得到0，[esi+4]也为0 .data的数据都是连续存储的,减4得到向前4字节，是44h JMP&amp;LOOP Q(判断)：1.JMP指令只能跳转到当前过程中的标号。2.JMP是条件跳转指令 A：T F K：JMP为无条件跳转，目标地址的偏移量直接送入指令指针寄存器，从而从新的地址开始 Q：循环开始时，如果ECX初始化为0，则LOOP指令要循环多少次（假设循环中没有其他指令修改ECX） A：FFFFFFFFh次 K：LOOP使用ECX计数器循环。LOOP指令为条件跳转，每次执行到LOOP语句时，先使ECX-1，然后判断是否为0,0就结束LOOP，非0跳转到目标给出标号。若循环前初始化ECX=0，则减1变成FFFFFFFFh，真就跑死CPU了。 Q：实地址模式中LOOP和LOOPD分别使用哪个寄存器作为计数器？ A：LOOP–CX; LOOPD–ECX 另外还需注意一点，LOOP指令运行跳转目标的范围为-128~127字节内，内存中地址超出跳转范围会报错 Q:分析下面程序：求EAX的最后值 123456789 mov eax,0 mov ecx,10 ;外层循环计数器L1: mov eax,3 mov ecx,5 ;内层循环计数器L2: add eax,5 loop L2 loop L1 A:你以为是28（3+5*5）?，是死循环哒!L2循环结束时ecx为0，接着执行loop L1，ecx-1，每次循环结束时ecx都会被置成FFFFFFFFh，gg K：更正方法：循环嵌套时最好使用变量保存进入内层时ecx的值，内层结束后再恢复，模板如下： 123456789101112131415.data count DWORD ?.code mov ecx,100 ;设置外层循环计数值L1: mov count,ecx mov ecx,20 ;设置内层循环计数值L2: . . . loop L2 mov ecx, count ;恢复外层循环计数值 loop L1 写在后面 写loop时一定要注意: 我就是学习汇编语言时长1周的个人练习生，喜欢top：jmp top，loop死循环 练习题会随后更","link":"/2019/07/19/AssemblyLanguageBasis-2/"},{"title":"汇编基础","text":"过程 如何在汇编语言中定义一个过程？编写一个&quot;函数&quot;？ 堆栈操作 Q：运行时堆栈与抽象数据类型有什么不同？ A：运行时堆栈是内存数组，CPU用ESP寄存器对其进行直接管理，该寄存器被称为堆栈指针寄存器，在32位模式下，ESP及寄存器存放的是堆栈中某个位置的32位偏移量。ESP基本不会被程序员控制，它用的是CALL，POP，PUSH，RET等指令进行修改。 Q：32位模式中哪个寄存器管理堆栈？如何管理？ K：ESP，顺便一提，EIP寄存器为指令指针寄存器 A：ESP（extended stack pointer），32位入栈操作是：先把栈顶指针减4，再将数值复制到栈顶指针指向的堆栈的位置，所有，该栈是“向下”生长的，从高地址向低地址扩展 Q：（判断）过程中的局部变量是在堆栈中新建的 A：T K： 堆栈的应用 当寄存器用于多个目的时，堆栈可以作为寄存器的一个方便的临时保存区域。在寄存器被修改后还能保存其初始值 执行CALL指令时，CPU在堆栈中保存了当前过程的返回值 调用过程时，输入数值（参数），通过其压栈实现参数传递 堆栈也为过程局部变量提供了临时存储区域 PUSH &amp; POP PUSH指令就是压栈操作，首先减少堆栈指针，然后复制源操作数，POP首先把ESP指向的内容复制到寄存器或者变量，然后增加ESP的值 PUSHAD把32位通用寄存器都压入栈，POPAD指令把堆栈中的数据弹出到32位通用寄存器 PUSHA则是把16位通用寄存器压入栈，POPA指令把堆栈中的数据弹出到16位通用寄存器 PUSHFD指令将32位EFLAGS寄存器压入栈，POPFD弹出，PUSHF和POPF对应16位 1234567891011121314151617181920212223242526272829303132333435.386.model flat, stdcall.stack 4096ExitProcess PROTO, dwExitCode:DWORD.dataaName BYTE &quot;Abraham Lincoln&quot;, 0nameSize = ($ - aName) - 1;字符串翻转.codemain PROC; 将名字压入栈 mov ecx, nameSize mov esi, 0L1: mov al, aName[esi] ; 获取字符 push eax ; 压入栈 inc esi loop L1 mov esi, 0 mov ecx, nameSizeL2: pop eax ; 出栈 mov aName[esi], al ; 保存 inc esi loop L2INVOKE ExitProcess, 0main ENDPEND main 定义并使用过程 Q：(判断) PROC伪指令标识过程的开始，ENDP伪指令标识过程的结束 A：T K：所有的程序都需要含有一个main过程，当在程序之外创建一个过程时，就用RET指令来结束它。RET强制CPU返回到被调用的位置 Q：（判断）CALL指令把自身指令的偏移量压入栈 A：F K： CALL指令调用一个过程，指挥处理器从新的内存地址开始执行，使用RET指令将处理器转回到被调用过程的程序点上。从物理上来说，CALL将其返回地址（运行的下一行）压入堆栈，再把被调用的过程的地址给EIP，RET从堆栈把返回地址弹回EIP。 当存在过程嵌套时，每次调用CALL就会把下一行位置压栈，然后遇见一个RET就弹出一个，直到返回main 例子：求和数组 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.386.model flat, stdcall.stack 4096ExitProcess PROTO, dwExitCode:DWORD.dataarray DWORD 100h, 200h, 300h, 400h, 500htheSum DWORD ?.codemain PROC; 将名字压入栈 mov esi, OFFSET array mov ecx, LENGTHOF array call ArraySum mov sum, eaxINVOKE ExitProcess, 0main ENDP; 良好的过程注释风格如下:;-------------------;ArraySum;计算32位整数数组元素的和;接受：ESI = 数组偏移量，ECX = 数组元素的个数;返回: EAX = 数组元素的和;-----------------;把寄存器作为参数和返回值的载体ArraySum PROC push esi push exc mov eax， 0 L1： add eax, [esi] ;相加 add esi, TYPE DWORD ;指向下一个整数 loop L1 ;按数组大小重复 pop ecx pop esi ;顺序别反了 ret ;结果放在了eax中ArraySum ENDP END main 过程中的push和pop可以省略，在PROC后加上 USES esi, ecx，可以让汇编器自己生成 链接到外部库 Q: （判断）链接库由汇编语言源代码组成 A：F K：链接库是一种文件，包含了已经汇编为机器代码的过程。链接库开始时是一个或多个源文件，这些文件再被汇编为目标文件。目标文件插入到一个特殊格式文件，该文件由链接器工具识别。 Q：在一个外部链接库中，用PROTO伪指令声明过程MyProc并调用 A： Myproc proto call Myproc 当程序进行汇编时，汇编器不指定call的地址，链接器在链接库中寻找Myproc，并把库中适当的机器指令复制到程序可执行文件中，同时给call一个地址 .dll文件（dynamic link library） 写在后面 在对应实验的博客中，我们会使用Irvine32链接库，再更往后的内容中，我们会学习如何实现库的功能 我就是鸽子精,咕咕咕","link":"/2019/07/22/AssemblyLanguageBasis-3/"},{"title":"汇编基础","text":"写在前面 拖更说明: 本人是鸽子精 前一段出去玩了,现在回来了要好好学习了 条件处理 复习-CPU标志位 情况 描述 操作结果为0 零标志位1 操作导致最高位进位 进位标志位1 符号标志位是操作数的最高位的副本,表示负数 符号标志位1 操作超出有符号目的操作数的范围 溢出标志位1 指令使目标操作数低字节中有偶数个1 奇偶标志位1 VS中PE=1表示偶校验，PE=0表示奇校验 布尔和比较指令 符号 逻辑运算 AND 按位与 OR 按位或 XOR 按位异或 NOT 按位非(反码) Q：编写一条指令，用16位操作数清除AX的高8位而低8位不变 K：这个是and的常见用处之一，我们不想要那些位置可以让其和0与，结果就是0，保留哪一位就与1与 A：and ax, 00FFh AND会清除溢出和进位标志位，并根据目标操作数的值来修改符号标志位，零标志位，奇偶标志位 Q：编写一条指令，用16位操作数使AX得高8位置1，低8位不变 K：类似AND，我们想置1就与1或，想保留就与0或 A：or ax, FF00h OR指令总是清除进位和溢出标志位，并根据目标操作数的值来修改符号标志位，零标志位，奇偶标志位。我们可以将一个数和自己（或0）OR, 来获取该数值的信息 or al, al 可能结果: 零标志位 符号标志位 AL中的值 清0 清0 大于0 置1 清0 等于0 清0 置1 小于0 Q：编写一条指令，不使用NOT，使eax中的所有位取反 A: xor eax, 0FFFFFFFFh K:在x86处理器中，当按位操作或者算数操作的目标操作数最低字节为偶校验时，奇偶标志位置1（即结果中1的个数为偶数时置1），我们让一个数和0异或既不会改变该数的值，又能通过观察标志位获取该数是奇校验还是偶校验 Q:编写指令实现如下功能：当EAX的32位值为偶数时将零标志位置1，反之置0 K：TEST指令用于两个操作数的对应位AND, 并根据结果设置标志位,TEST不修改目的操作数 A：test eax, 00000001h Q:编写一条指令将AL中的大写字母转换为小写字母，如果AL包含小写字母，不修改AL K：大小写的字母的ASCII码只有位5不同 A：or al, 00100000b 置位和清除标志位 CMP指令执行从目的操作数中减去源操作数的隐含减法操作，而且不修改任何操作数 123456789mov ax, 5cmp ax, 10 ; ZF=0,CF=1（借位）mov ax, 1000mov cx, 1000cmp cx, ax ; ZF=1,CF=0mov si, 105cmp si, 0 ; ZF=0,CF=0 当比较的是有符号数，SF≠CF时为小于（目标数小于源操作数），SF=CF时为大于 下面是一些修改标志位的操作 1234567891011121314test al, 0 ; ZF=1and al, 0 ; ZF=1or al, 1 ; ZF=0or al, 80h ;(-128) SF=1and al, 7Fh ; SF=0stc ; CF=1clc ; CF=0mov al, 7Fhinc al ; 溢出标志位为1,就把两个正数相加得到负数,OF=1or eax, 0 ; OF=0 条件跳转 Q:下面代码会跳转到target吗？ 123mov ax, 8109hcmp ax, 26hjg target A：不会, 8109h为负数 K：关于跳转指令，下面列出全部: 特定标志位 助记符 说明 标志位或寄存器 JZ 为0跳转 ZF=1 JNZ 非0跳转 ZF=0 JC 进位跳转 CF=1 JNC 无进位跳转 CF=0 JO 溢出跳转 OF=1 JNO 无溢出跳转 OF=0 JS 有符号跳转 SF=1 JNS 无符号跳转 SF=0 JP 偶跳转 PF=1 JNP 奇跳转 PF=0 比较跳转 相等 助记符 说明 JE 相等跳转 JECX ECX=0跳转 无符号数 助记符 说明 JA 大于跳转 JAE 大于等于跳转 JB 小于跳转 JBE 小于等于跳转 有符号数 助记符 说明 JG 大于跳转 JGE 大于等于跳转 JL 小于跳转 JLE 小于等于跳转 例子：循环直到按下按键 123456789.datachar BYTE ?.codeL1: mov eax, 10 call Delay ; 创建10s延迟 call ReadKey ; 检查按键,ReadKey只有在发现有按键时才清除0标志位 jz L1 ; 没按键时循环 mov char, AL ; 有按键时读入AL(以ASCII码) 条件循环指令 Q:(判断) 1.当且仅当零标志位被清除时，LOOPE指令会跳转到标号 2.32位模式下，当ECX大于零且零标志位被清除时LOOPNZ指令才会跳转 3.LOOPZ指令的标号必须在距离其后-128~127字节范围之内 A：F T T K： LOOPZ和LOOPE与LOOP基本相同，但需要零标志位为1才会跳转（ZF=1），同时其不影响标志位 LOOPNZ和LOOPNE完全一样，当ECX中无符号值大于l零（减1操作后）且零标志位为0时才跳转 Q:看下面一段代码 12345678910111213141516.dataarray SWORD -3, -6, -1, -10, 10, 30, 40, 4sentinel SWORD 0.codemov esi, OFFSET arraymov ecx, LENGTHOF arrayL1: test WORD PTR [esi], 8000h pushfd add esi, TYPE array popfd loopnz L1 jnz quit sub esi, TYPE arrayquit: 这个程序如果找到一个非负数，ESI会指向该负数 popfd，pushfd用于将EFLAG寄存器（保存cpu标志位）压栈 未找到时ESI指向sentinel，为数组的下一块内存 Q1：修改代码实现寻找第一个负数 A1: 123456789101112131415.dataarray SWORD 3, 6, 1, 10, -10, -30, -40, -4sentinel SWORD 0.codemov esi, OFFSET arraymov ecx, LENGTHOF arrayL1: test WORD PTR [esi], 8000h ; 和1000000000000000b AND pushfd ; 负数的时候ZF=0 add esi, TYPE array popfd loopz L1 jz quit ; ZF=1跳转,未找到负数 sub esi, TYPE arrayquit: Q2: 紧靠一个标志记值来处理能不能发现正数？如果去掉会咋样？ A2：紧靠一个不够，仅能判断非负；去掉的话循环不会中间结束，会一直转到最后一位，因为add esi这句会影响cpu的标志位 条件结构 if 单ifs if(op1==op2){x=1;y=2;} 123456mov eax, op1cmp eax, op2jne L1 ;不相等,跳过后续指令mov x, 1mov y, 2L1: 分支if if (op1 &gt; op2) call routine1 else call rountine2 12345678mov eax, op1cmp eax, op2jg A1call rountine2jmp A2A1: call rountine1A2: ;后面的语句 嵌套if if (op1 == op2){ if (X&gt;Y) call rountine1 else call routine2 else call rountine3 } 1234567891011121314151617mov eax, op1cmp eax, op2jne L2; 处理内层mov eax, xcmp eax, yjg L1call rountine2jmp L3L1: call rountine1 jmp L3L2: call rountine3L3: while while( val1 &lt; val2 ){ val1++ } 123456789mov eax, val1beginWhile: cmp eax, val2 jnl endWhile inc eax jmp beginWhileendWhile: mov val1, eax ; 保存新的值 有限状态机 Q：有限状态机是哪种数据结构类型的特殊应用？其示意图中的节点和边分别表示什么？ A：有限状态机（FSM）是有向图的更一般结构的特例，每个节点表示一个程序的状态，每个边表示从一个状态到另一个状态 例子：验证有符号整数的输入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970;Finite.asmINCLUDE Irvine32.incenter_key = 13.dataInvalidInputMsg BYTE &quot;Invalid Input&quot;, 13, 10, 0.codemain PROC call Clrscr ; 清除控制台窗口StateA: call Getnext ; 读取下一个字符,送入AL cmp al, '+' ; 前置&quot;+&quot; je StateB cmp al, '-' ; 前置&quot;-&quot; je StateB call IsDigit ; 如果AL包含数字, 则ZF=1 jz StateC call DisplayErrorMsg ; 提示非法输入 jmp Quit StateB: call Getnext call IsDigit jz StateC call DisplayErrorMsg jmp QuitStateC: call Getnext call IsDigit jz StateC cmp al, enter_key ; 是否按下Enter键 je Quit ; 是,退出 call DisplayErrorMsg ; 否,提示非法输入 jmp QuitQuit: call Crlf ; 将光标移到到下一行 call WaitMsg exitmain ENDPGetnext PROC;------------------------; 从标准输入获取一个字符; 无参数; 字符保存在AL中;------------------------ call ReadChar call WriteChar retGetnext ENDPDisplayErrorMsg PROC;----------------------; 显示一个错误消息; 无参数; 无返回值;---------------------- push edx ; 保存一下原来的值 mov edx, OFFSET InvalidInputMsg call WriteString pop edx retDisplayErrorMsg ENDPEND main 其中IsDigit的源码如下： 相当简洁的写法, 可以供参考学习 1234567891011121314IsDigit PROC;---------------------------------- ; 确定AL中是否为10进制数; 参数: AL=字符; 返回: 若AL为有效十进制数, ZF=1;否则ZF=0;----------------------------------cmp al, '0'jb ID1 ; 比0小结束cmp al, '9'ja ID1 ; 比9大也结束test ax, 0 ; 设置ZF=1ID1:retIsDigit ENDP 条件控制流伪指令 32位模式下，MASM包含一些高级条件控制流伪指令，这有助于简化编写条件语句，但这些伪指令不能用于64位，这些伪指令有**.IF**, .ELSE, .ELSEIF, .ENDIF，.WHILE,.REPEAT","link":"/2019/07/29/AssemblyLanguageBasis-4/"},{"title":"汇编基础","text":"整数运算 本章将学习汇编语言的最大优势之一:基本二进制位移和循环位移技术。实际上，位操作是计算机图形学，数据加密和硬件控制的固有部分。 位移动(bit shifting) 移动操作数的位有两种方法， 第一种: 逻辑位移(logic shift)，空出的位用0填充 第二种：算数位移(arithmetic shift)，空出的位用原数据的符号位填充 符号 说明 SHL 左移 SHR 右移 SAL 算数左移 SAR 算数右移 位移操作的最高位或最低位都会被复制到CF(进位标志位) 当一个数多次右移时，进位标志位保存的是最后移出最低有效位的数值 最高有效位(MSB),最低有效位(LSB) 例子: 有符号除法 12mov dl, -128 ;DL=10000000bsar dl, 3 ;DL=11110000b 即用SAR实现有符号数除以2的整数次幂 AX符号扩展到EAX 123mov ax, -128 ;EAX=????FF80hshl eax, 16 ;EAX=FF800000hsar eax, 16 ;EAX=FFFFFF80h 先左移16位然后算数右移16位就完成了将AX符号扩展到EAX 位元循环(Bitwise Rotation) 以循环的方式来移位，不会弃位，从数的一段循环出去的位会在该数的另一端出现 符号 说明 ROL 循环左移 ROR 循环右移 RCL 带进位的循环左移 RCR 带进位的循环右移 ROL和ROR同样最高位和最低位会被复制到CF中 RCL和RCR会将最高位或最低位移动到CF中，CF移动到最低位或最高位 例子: 循环多次 12mov al, 00100000brol al,3 ;CF=1,AL=0000001b 位组交换 12mov al, 26hrol al, 4 ;AL=62h 利用ROL可以交换一个字节的高四位和低四位 从进位标志位恢复位 123456.dataval BYTE 01101010b.codeshr val, 1 ;LSB(最低有效位)移入标志位jc exit ;为1退出rcl val, 1 ;否则恢复 有符号数溢出 如果有符号数循环移动1位生成的结果超过了目的操作数的有符号数范围，就发生了溢出 12mov al, +127rol al, 1 ;OF=1,溢出al变为负数-2 如果循环次数大于1，则溢出标志位无定义 SHLD/SHRD SHLD(双精度左移)指令将目的操作数向左移动指定位数，形成的空位由源操作数的高位填充，最高位移动到CF。同理SHRD。 Q:编写一组指令不使用SHRD将AX的最低位移入BX的最高位 A： 12ror ax, 1rcr bx, 1 K：即借用CF作为中转站，我们若想对数组进行移位操作，思路和该方法一样 Q：计算EAX中32位数奇偶性的方法之一是利用循环把该数的每一位都移动进入进位标志位，然后计算进位标志位置1的次数，根据结果设置奇偶标志位 A： 123456789101112131415161718192021222324252627.386.model flat, stdcall.stack 4096ExitProcess PROTO,dwExitCode: DWORD.codemain PROC mov eax, 1111b mov ecx, 32 mov esi, 0L1: rol eax, 1 jnc L2 inc esiL2: loop L1 shr esi, 1 jc L4 mov ebx, 11 jmp L5L4: mov ebx, 1L5: xor ebx, 0main ENDPEND main 其实后面的代码意义不大,目的在于置奇偶标志位，若esi为偶数，则最低位一定是0，反之为奇数 乘除指令 Q:请说明执行MUL指令和单操作数的IMUL指令时，不会发生溢出的原因 A:MUL指令（无符号数乘法）中的单操作数是乘数，如下表列出了默认的被乘数和乘积。由于目的操作数是被乘数和乘数大小的2倍，所以不会溢出 被乘数 乘数 乘积 AL reg/mem8 AX AX reg/mem16 DX:AX EAX reg/mem32 EDX:EAX Q：生成乘积时，单操作数IMUL和MUL指令有何不同？ A：IMUL（有符号数乘法）执行有符号的整数乘法，与MUL不同的是IMUL会保留乘积的符号 Q：什么情况下单操作数IMUL会将进位标志位和溢出标志位置1？ A：与MUL指令一样，其乘积的存储大小使其不会发生溢出。同时，如果乘积的高半部分不是其低半部分的符号扩展，则进位标志位和溢出标志位置1 单操作数下，将乘积存放在AX，DX：AX，EDX：EAX中 双操作数下第一个操作数必须是寄存器，第二个可以是寄存器，内存操作数，立即数。会将结果放在第一个寄存器中 三操作数下第一个是结果保存的寄存器，第二个是reg/mem，第三个是imm，表示将立即数和寄存器/内存数相乘放入第一个寄存器中 注意：二三个操作数时若寄存器大小不够，会按大小低位截取，并将溢出和进位置1 Q：DIV指令中，若EBX为操作数，商保存在哪个寄存器？BX为操作数呢？ A： 被除数 除数 商 余数 AX reg/mem8 AL AH DX:AX reg/mem16 AX DX EDX:EAX reg/mem32 EAX EDX Q:有符号除法和无符号的区别是？ A：几乎完全相同，只有一个重要区别，在执行除法前，必须对被除数进行符号扩展（将一个数的最高位复制到包含该数的变量或寄存器的所有高位中） K：3种符号扩展指令CWD（字转双字），CBW（字节转字），CDQ（双字转四字） 例子： 1234567.datawordVal SWORD -101.codemov dx, 0mov ax, wordVal ;DX:AX=0000009Bh(+155)mov bx, 2idiv bx 结果并不是我们想要的，因为我们的DX和AX组合时忽略了符号问题 加上cwd即可，此时DX：AX=FFFFFF9Bh 关于CWD的更多说明(2019.11.14修改) 1234567891011121314CBW AL -&gt; AX执行操作： 若(AL)的最高有效位为0，则(AH)= 00H若(AL)的最高有效位为1，则(AH)= FFHCWD AX -&gt; (DX,AX)执行操作：若(AX)的最高有效位为0，则(DX)= 0000H若(AX)的最高有效位为1，则(DX)= FFFFH例子:(AX) = 0BA45HCBW ; (AX)=0045HCWD ; (DX)=0FFFFH (AX)=0BA45H 其主要作用之一就是将我们的数据进行符号扩展或截断，就想题目中一样，我们想要用dx:ax做除法的除数，但我们的数仅仅有16位，对dx清零后直接用dx和ax组合会有符号的问题，这时候进行一下符号的扩展就能解决符号的问题 扩展加减法 扩展精度加减法（extended precision addition and subtraction）是对基本没有大小限制的数进行加减法。比如在C++中，没有标准运算符会允许两个1024位整数相加，但在汇编中，ADC（带进位加法），SBB（带借位减法）就适合这样的操作。 例子：两组数的相加 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667INCLUDE Irvine32.inc.dataop1 BYTE 34h, 12h, 98h, 74h, 06h, 0A4h, 0B4h, 0A2hop2 BYTE 02h, 45h, 23h, 00h, 00h, 87h, 10h, 80hsum BYTE 9 DUP(0).codemain PROC mov esi, OFFSET op1 mov edi, OFFSET op2 mov ebx, OFFSET sum mov ecx, LENGTHOF op1 call ExtendedAdd ;显示和数 mov esi, OFFSET sum mov ecx, LENGTHOF sum call DisplaySum call Crlf call WaitMsg exitmain ENDPExtendedAdd PROC;------------------;计算两个以字节数组存放的扩展整数的和;参数：ESI和EDI存放两个加数数组的指针，EBX为和变量的指针，ECX为相加字节数;无返回;------------------ pushad clc ;清除标志位L1: mov al, [esi] adc al, [edi] pushfd ;保存进位标志位 mov [ebx], al ;保存部分和 add esi, 1 add edi, 1 add ebx, 1 popfd ;恢复标志位 loop L1 mov BYTE PTR [ebx], 0 ;清除和数高字节 adc BYTE PTR [ebx], 0 ;加上进位 popad retExtendedAdd ENDPDisplaySum PROC pushad ;指向最后一个数组元素 add esi, ecx sub esi, TYPE BYTE mov ebx, TYPE BYTEL1: mov al, [esi] call WriteHexB ;显示该字节 sub esi, TYPE BYTE loop L1 popad retDisplaySum ENDPEND main 注意我们的核心过程ExtendedAdd，每次循环使用adc并压栈进位标志位，为的是后面的add不影响我们的进位，循环前恢复就可以在下次做adc运算是加上了 最后一步是检查操作数的最高位是否产生了进位，有进位就放入sum的最高位 ASCII和非压缩10进制 BCD码 用二进制编码的十进制数，通过专门的十进制数运算指令进行处理。计算机中可有专门的逻辑线路支持BCD码运算 压缩BCD 用4位二进制数表示1位十进制数，如：( 59 )10 ＝( 0101 1001 )BCD 非压缩BCD 用8位二进制数表示1位十进制数，如：( 59 )10 ＝( 0000 0101 0000 1001 )BCD 数字的 ASCII 码是一种 非压缩的 BCD 码 十进制调整指令 对于两个十进制数求和： 1.我们可以都转成2进制然后求和再转回10进制 2.直接进行字符串加法，再进行调整 相较于第二种方法，第一种方法过于麻烦，我们不会使用 而第二种方法的误差是统一的： 所以可以设计指令来修正这个误差，当然也可以手动修正 非压缩的BCD码调整指令 命令 说明 AAA 执行加法后调整 AAS 执行减法后调整 AAM 执行乘法后调整 AAD 执行除法后调整 非压缩十进制数的最高位为0000b，而ASCII十进制数的最高位为0011b，任何情况下这两种类型的数字占一个字节 ASCII运算要比二进制运算慢的多，但在处理实数时不会出现浮点数运算的舍入误差的危险 12345mov ah, 0 ;记得清零mov al, '8' ;AX=0038hadd al, '2' ;AX=006Ahaaa ;AX=0100h（01 00）or ax, 3030h ;AX=3130h='10'（31 30） 我们发现经过调整，2+8得到了10，而不是16进制相加的结果。而or ax, 3030h把10转变为了字符串’10’ 压缩BCD码调整指令 仅用于32位模式 压缩十进制数的每个字节存放两个十进制数，每个数字用4位表示，如果数字个数为奇数，最高的半字节用0填充（有点像8421码的编码理念） 压缩十进制数的优势在于： 1.数据可以几乎包含含有任意数字的有效数字 2.与ASCII码的转换相对简单 DAA，DAS分别为调整压缩十进制数的加法和减法，我们会在练习题中使用它们解决问题 写在后面 果然返校后效率激增 充分证明在家里的学习环境没有学校好，或者是我太咕了 总共13章，加把劲在开学前看完","link":"/2019/08/03/AssemblyLanguageBasis-5/"},{"title":"汇编基础","text":"高级过程 本章将介绍子程序调用的底层结构，重点集中于运行时的堆栈操作。本讲内容对C和C++程序员也是很有价值的，因为在调试程序运行于操作系统或设备驱动程序层的底层子程序时，他们也必须检查运行时的堆栈内容 堆栈帧 前面的章节中，子程序接受寄存器参数。本章展示子程序如何用堆栈接受参数 Q（判断）： 1.子程序的堆栈帧总是包含主调程序的返回地址和子程序的局部变量 2.为了避免被复制到堆栈，数组通过引用来传递 3.子程序开始部分的代码总是将EBP入栈 4.堆栈指针加上一个正值即可创建局部变量 5.32位模式下，子程序调用中最后入栈的参数保存于EBP+8的位置 6.引用传递意味着将参数的地址保存在运行时的堆栈中 A：T T T F T T K： 堆栈参数 堆栈帧的创建步骤如下： 1）被传递的实际参数，若有，则压入堆栈 2）子程序被调用时，子程序返回值（下一行的地址）压入栈 3）子程序开始执行时，EBP被压入栈 4）设置EBP等于ESP，从这时开始，EBP就变成了该子程序所有参数的引用基址 5）若有局部变量，修改ESP以便在堆栈中为这些变量预留空间 6）如果需要保存寄存器，就将它们压入堆栈 当子程序被调用时，有两种常见类型的参数会被压入堆栈：值参数，引用参数 1234567.dataval1 DWORD 5val2 DWORD 6.codepush val2push val1call AddTwo 这段汇编等效于C++里的int sum = AddTwo(val1, val2) 123push OFFSET val2push OFFSET val1call Swap 这段等效于Swap(&amp;val1, &amp;val2) 而当传递数组时，通常汇编的写法是push OFFSET array将地址压入堆栈 访问堆栈参数 我们仍以一个简单的C语言程序为例 123int AddTwo(int x, int y){ return x+y;} 上述的汇编写法如下： 12345678AddTwo PROC push ebp ;EBP入栈保存当前值 mov ebp, esp ;堆栈帧基址 mov eax, [ebp+12] ;第二个参数 add eax, [ebp+8] ;第一个参数 pop ebp retAddTwo ENDP 另一种写法是显示的堆栈参数(explicit stack parameter) 1234567891011x_param EQU [ebp+12]y_param EQU [ebp+8]AddTwo PROC push ebp mov ebp, esp mov eax, x_param add eax, y_param pop ebp retAddTwo ENDP 我们使用了符号常量来定义，用EQU伪指令把一个符号和表达式链接起来，可读性更好 清除堆栈 子程序返回时，必须将参数清除，否则会导致内存泄露，堆栈遭到破坏 仍以上图为例，当我们循环调用该addtwo过程时，每次都会在堆栈中遗留两个参数，最终会导致溢出。更可怕的是如下： 1234567891011main PROC call Process1 ....main ENDPProcess1 PROC push 6 push 5 call AddTwo ret ;破坏堆栈Process1 ENDP 当Process1的ret指令执行时，ESP本该指向返回地址，却因为多压栈了5,6而指向了5，导致出现无法意料的情况 32位调用规范 C规范 C规范适用于C/C++子程序的参数按逆序入栈，而调用完后手动移动esp将参数从堆栈中移除，在上面的代码中ret前加上add esp, 8 STDCALL规范 STDCALL与C相似，参数逆序入栈，通过在ret处添加一个整数参数指定返回ret 8，不仅减少了程序调用生成的代码量，保证了程序永远不会忘记清除堆栈 保存和恢复寄存器 通常，子程序在修改寄存器之前要将它们的当前值保存到堆栈。相关寄存器的设置应该在EBP等于ESP之后，在为局部变量保留空间之前 1234567891011121314Mysub PROC push ebp ;保存基址指针 mov ebp, esp ;指向栈顶 push ecx push edx mov eax, [ebp+8] . . . pop edx ;恢复寄存器 pop ecx pop ebp ;恢复基址指针 ret ;清除堆栈Mysub ENDP EBP被初始化后，整个过程中值将不会改变！ECX和EDX的入栈不会影响EBP的位移量（栈向下方增长） 局部变量(local variable) 局部变量创建于运行时的堆栈，通常位于基址指针（EBP）之下。尽管不能再汇编时给他们分配初始值，但可以在运行时初始化他们。 仍以C/C++函数的反汇编来看看如何创建局部变量 1234void Mysub(){ int x = 10; int y = 20;} 变量 字节数 堆栈偏移量 x 4 EBP-4 y 4 EBP-8 12345678910Mysub PROC push ebp mov ebp, esp sub esp, 8 ;创建局部变量 mov DWORD PTR [ebp-4], 10 mov DWORD PTR [ebp-8], 20 mov esp, ebp ;删除局部变量,千万不要漏掉 pop ebp retMysub ENDP 同样也可以使用EQU来定义局部变量的符号x_local EQU DWORD PTR [ebp-4] LEA指令 LEA返回间接操作数的地址，以例子来看 123456void initArray(){ char myString[30]; for(int i = 0; i &lt; 30; i++){ myStirng[i] = '*'; }} 与之等效的汇编代码在堆栈中为myString分配空间，并将地址（间接操作数）赋给ESI。 12345678910111213initArray PROC push ebp mov ebp, esp sub esp, 32 lea esi, [ebp-30] mov ecx, 30L1: mov BYTE PTR [esi], '*' loop L1 add esp, 32 pop ebp retinitArray ENDP 虽然数组只有30个字节，但是ESP还是递减了32以对齐双字边界。 我们不能使用OFFSET来获取堆栈参数的地址，因为OFFSET只适用于编译时已知的地址 递归(recursive subrountine) 递归计算阶乘 123456789101112131415161718192021222324252627282930313233343536INCLUDE Irvine32.inc.codemain PROC push 3 ;计算3! call Factorial call WriteDec call Crlf exitmain ENDPFactorial PROC;-------------------------;计算阶乘;参数:[ebp+8]=需要计算的数;返回:EAX=结果;------------------------- push ebp mov ebp, esp mov eax, [ebp+8] cmp eax, 0 ;n&gt;0? ja L1 ;否,返回0!=1 mov eax, 1 jmp L2L1: dec eax ;n-1 push eax call Factorial;每次递归调用返回时都要执行下面的指令ReturnFact: mov ebx, [ebp+8] ;获取n mul ebx ;EDX:EAX = EAX * EBXL2: pop ebp ;返回EAX ret 4Factorial ENDPEND main 每次call Factorial时都会压栈返回地址和ebp，直到eax为0，此时执行L2，开始返回; 弹出EBP，此时EBP指向上一次EBP的位置，ESP指向了返回地址，ret 4将清除栈中保存的N=0，此时从call后开始执行ReturnFact，[EBP+8]就是N=1,mul ebx得到了1x1的结果，如此反复直到返回地址为main里call的下一句 INVOKE，ADDR，PROC，PROTO Q：（判断） 1.CALL指令不能包含过程参数 2.INVOKE伪指令最多包含3个参数 3.INVOKE伪指令只能传递内存操作数，不能传递寄存器值 4.PROC伪指令可以包含USES运算符，但PROTO不可以 A：T F F T K： INVOKE INVOKE只用于32位模式，将参数入栈并调用该过程，是call的一个方便的替代品 1234push TYPE arraypush LENGTHOF arraypush OFFSET arraycall DumpArray 等价写法，注意列表中的参数逆序排列 1234INVOKE DumpArray, OFFSET array, LENGTHOF array, TYPE array INVOKE使用的参数若小于32位，会扩展参数，常常会覆盖EAX和EDX，当需要时，记得在调用前保存EAX和EDX ADDR ADDR可以传递指针参数，且只能和INVOKE一起使用 INVOKE FillArray, ADDR array 但传递给ADDR的参数必须是汇编时的常数,下面为错误写法 INVOKE FillArray, ADDR [ebp+12] PROC label PROC [attribute] [USES reglist], parameter_list 实例：AddTwo过程接受两个双字数值，用EAX返回和数 1234567AddTwo PROC, val1:DWORD, val2:DWORD mov eax, val1 add eax, val2 retAddTwo ENDP 汇编时MASM生成的代码: 12345678AddTwo PROC push ebp mov ebp, esp mov eax, dword ptr [ebp+8] add eax, dword ptr [ebp+0Ch] leave ret 8AddTwo ENDP LEAVE 指令恢复被调用的ESP和EBP的值,执行mov esp, ebp和pop ebp 与之相对的ENTER则执行push ebp, mov ebp, esp, sub esp, xx来执行EBP入栈，设置EBP为基址，为局部变量保留空间 ENTER numbtyes, nestinglevel 当没有局部变量时enter 0,0，当保留8字节堆栈空间enter 8,0 PROTO PROTO声明过程原型，每个INVOKE调用的过程都需要有原型，PROTO必须在INVOKE之前出现，除了当过程实现在程序的前面出现时的情况，此时PROC就是自己的原型 编写原型的方法： 将关键字改为PROTO 如有UESE运算符，将其与寄存器列表一起删掉 其余形参不变的copy过去 写在后面 用汇编实现递归是真的困难，稍微疏忽就会出错… 模块的内容放在了实验部分，这一章的题目不多","link":"/2019/08/05/AssemblyLanguageBasis-6/"},{"title":"汇编基础","text":"结构和宏 结构 结构（structure）是一组逻辑相关变量的模板或模式。结构中的变量被称为字段（fields），程序语句可以把结构作为整体进行访问，也可以访问其中的单个字段。 使用结构包含三个连续的步骤： 1)定义结构 2)声明结构类型的一个或多个变量，称为结构变量（structure variables） 3)编写运行时指令访问结构字段 对齐结构字段 为了获得最好的内存I/O性能，结构成员应按其数据类型进行地址对齐。否则，CPU将会花更多时间访问成员。 使用ALIGN伪指令会试其后的字段或者变量按地址对齐 12345678Employee STRUCT IdNum LastName ALGIN WORD Years WORD 0 ALGIN DWORD SalaryHistory DWORD 0,0,0,0Employee ENDS 则TYPE Employee和SIZEOF Employee均为60 需要注意对齐：9+30+1（对齐2）+2+2（对齐4）+16 Q-A Q：根据下面代码回答问题 1234MyStruct STRUCT field1 WORD ? field2 DWORD 20 DUP(?)MyStruct ENDS Q1：使用默认值创建变量 Q2：声明变量，将其第一个字段初始化为0 Q3：声明变量，将第二个字段初始化为全零数组 K：使用&lt;&gt;来在声明变量的同时初始化结构 A1:struct1 &lt;&gt; A2:struct1 &lt;0&gt; A3:struct1 &lt;,20 DUP(0)&gt; Q4：一数组包含20个MyStruct，将该数组声明为变量 A4:array MyStruct 20 DUP(&lt;&gt;) Q5：对上一题的数组，把第一个数组元素的field1送入AX Q6：对上一题的数组，用ESI索引第三个数组元素，并将AX送入field1 K：使用变量加点来引用成员 A5： mov ax, array[0].field1 K:同样也可以用OFFSET运算符获取结构变量中一个字段的地址，间接操作数用寄存器对结构成员寻址（变址操作），但需要注意引用间接操作数时需要PTR运算符 A6： 123456;写法1mov esi, 2*TYPE MyStructmov array[esi].field1, ax;写法2mov esi, OFFSET array[2]mov (MyStruct PTR [esi]).field1, ax 例子 COORD结构：Windows API中定义的COORD结构确定了屏幕的X和Y坐标。相对于结构起始地址，字段X的偏移量为0，Y的偏移量为2 1234COORD STRUCT X WORD ? Y WORD ?COORD ENDS 用程序模拟一个不太清醒的教授从计算机科学假期聚会回家的路线，利用随机数生成器，选择该教授每一步行走的方向。使用COORD结构追踪这个人行走路径上的每一步。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788INCLUDE Irvine32.incWalkMax = 50 ;走的总步数StartX = 25StartY = 25DrunkardWalk STRUCT path COORD WalkMax DUP (&lt;0, 0&gt;) pathsUsed WORD 0DrunkardWalk ENDSDisplayPosition PROTO currX:WORD, currY:WORD.dataaWalk DrunkardWalk &lt;&gt;.codemain PROC mov esi, OFFSET aWalk call TakeDrunkenWalk call Crlf call WaitMsg exitmain ENDPTakeDrunkenWalk PROC LOCAL currX:WORD, currY:WORD;向随机方向行走;参数：ESI为DrunkardWalk结构的指针;返回：结构初始化为随机数;----------------------------------- pushad mov edi, esi add edi, OFFSET DrunkardWalk.path mov ecx, WalkMax mov currX, StartX mov currY, StartYAgain:;把当前位置插入数组 mov ax, currX mov (COORD PTR [edi]).X, ax mov ax, currY mov (COORD PTR [edi]).Y, ax INVOKE DisplayPosition, currX, currY mov eax, 4 ;选择一个方向 call RandomRange .IF eax == 0 ;北 dec currY .ELSEIF eax == 1 ;南 inc currY .ELSEIF eax == 2 ;西 dec currX .ELSE ;东 inc currX .ENDIF add edi, TYPE COORD ;指向下一个COORD loop AgainFinish: mov (DrunkardWalk PTR [esi]).pathsUsed, WalkMax popad retTakeDrunkenWalk ENDPDisplayPosition PROC currX:WORD, currY:WORD;-----------------------------;显示当前的X和Y的位置;参数：无;返回：无;-----------------------------.data commaStr BYTE &quot;,&quot;, 0.code pushad movzx eax, currX call WriteDec mov edx, OFFSET commaStr call WriteString movzx eax, currY call WriteDec call Crlf popad retDisplayPosition ENDPEND main 宏 概述 宏过程(macro procedure)是一个命名的汇编句快。一但定义好，它就可以在程序中被多次调用。在调用宏的过程时，其代码的副本将被直接插入到程序中该宏被调用的位置。这种自动插入代码也被称作内联展开（inline expansion） 宏定义一般出现在程序源代码开始的位置，或者是放在独立的文件中，再用INCLUDE伪指令复制到程序里。宏在汇编器预处理（preprocessing）阶段进行扩展。在这个阶段中，预处理程序读取宏定义并扫描程序剩余的代码。每到宏被调用的位置，汇编器就将宏的源代码复制插入到程序中。 Q（判断）: 1.当一个宏被调用时，CALL和RET指令将自动插入汇编程序中 2.宏展开由汇编器的预处理程序控制 3.只要宏定义在代码段中，它就能出现在宏调用语句之前，也能出现在宏调用语句之后 4.对一个长过程而言，若用包含这个过程代码的宏来代替它，则多次调用该宏通常就会增加程序的编译代码量 5.宏不能包含数据定义 A:F T F T F K： 定义并调用宏 定义宏使用MACRO和ENDM伪指令 macroname MACRO param1, param2… statement-list ENDM 在宏名前使用前缀m，形成易识别的名称 宏形参（marco parameter）是需传递给调用者的文本实参的命名占位符，该形参不包含类型信息，如下： 123456mPutchar MACRO char push eax mov al, char call WriteChar pop eaxENDM 调用时不需要call，仍以上例mPutchar 'A'就调用了宏 通常， 与过程相比，宏执行起来更快，其原因是过程的CALL和RET指令需要额外的开销 但是，宏也存在缺点：重复使用大型宏会增加程序的大小，因为每次调用都会插入代码 其他宏特性 规定形参 利用REQ限定符，可以指定必需的宏形参。如果被调用的宏没有实参与规定形参相匹配，那么汇编器将显示出错误消息 123456mPutchar MACRO char:REQ push eax mov al, char call WriteChar pop eaxENDM 注释 如果想忽略宏展开时的注释，需要使用双分号(;😉 ECHO 程序汇编时，ECHO伪指令写一个字符串到标准输出 1234567mPutchar MACRO char:REQ ECHO Expanding the mPutchar marco push eax mov al, char call WriteChar pop eaxENDM 在汇编时会显示消息“ECHO Expanding the mPutchar marco” LOCAL 宏定义中经常含有标号，并会在代码中对这些标号进行自引用， 1234makeString MACRO text .data string BYTE text, 0ENDM 但这存在一个问题，若调用两次宏，就生成了两个一样的标号，会出现错误 为了避免这种错误，对标号使用LOCAL指令，这样预处理程序就把标号名转换成唯一的标识符（生成??nnnn的形式，其中nnnn为具有唯一性的整数） 宏嵌套（nested macro） 当汇编器的预处理程序遇到对被嵌套宏的调用时，它就会展开该宏。传递给主调宏的形参也将直接传递给它的被嵌套宏 1234mWriteIn MACRO text mWrite text call CrlfmWriteIn ENDM 特殊运算符 运算符 说明 &amp; 替换运算符 &lt;&gt; 文字文本运算符 ! 文字字符运算符 % 展开运算符 &amp; 1234567;X，regName被当做字符串mShowRegister MACRO regName.datatempStr BYTE &quot;regName=&quot;, 0;√，使用替换运算符tempStr BYTE &quot;&amp;regName=&quot;, 0 % 展开运算符展开文本宏并将常量表达式转换为文本形式 123456789101112count = 10sumVal TEXTEQU %(5+count) ;=&quot;15&quot;;X，屏幕输出没有什么用.dataarray DWORD 1,2,3,4,5,.codeECHO The array contains (SIZEOF array) bytesECHO The array contain %(SIZEOF array) bytes;√，使用TEXTEQU编写文本宏TempStr TEXTEQU %(SIZEOF array)% ECHO The array contains TempStr bytes &lt;&gt; 文字文本（literal-text）运算符把一个或多个字符和符号组合成一个文字文本，以防预处理程序把列表中的成员解释为独立的参数 12345;mWrite接收一个字符串作为唯一实参;X，第一个括号后的文本会被丢弃mWrite &quot;Line Three&quot;, 0ah, 0dh;√mWrite &lt;&quot;Line Three&quot;, 0ah, 0dh&gt; ! 构造文字字符（literal-character）运算符的目的与文字文本运算符几乎完全一样：强制预处理程序把预先定义的运算符当做普通的字符。 1BadYValue TEXTEQU &lt;Warning:Y-coodinate is !&gt; 24&gt; 上例使用！防止&gt;被当做文本分隔符 写在后面 题目等等再更，一口气把基础过完","link":"/2019/08/07/AssemblyLanguageBasis-7/"},{"title":"汇编基础","text":"MS-Windows编程 Win32 控制台编程 链接库用了这么久了，汇编学了这么多了，HelloWorld还不会写。 本章介绍如何用32位Microsoft Windows API(application programming interface)进行控制台窗口编程。 虽然不建议用汇编语言进行扩展图形应用编程，但不影响我们从底层理解高级语言的GUI编程 背景知识 一个Windows应用程序开始的时候，要吗创建一个控制台窗口，要吗创建一个图形化窗口。这里我们一直使用SUBSYSTEAM:CONSOLE，告诉链接器创建一个基于控制台的应用程序 控制台程序的外观和操作就像MS-DOS窗口一样，控制台有一个输入缓冲区以及一个或多个屏幕缓冲区： 输入缓存区（input buffer）包含一组输入记录（input records），其中每个记录都是一个输入事件的数据。输入事件的例子包括键盘输入，鼠标点击，以及用户调整控制台窗口大小 屏幕缓冲区（screen buffer）是字符与颜色数据的二维数组，他会影响控制台窗口文本的外观 调用Win32 API函数时会使用两类字符集：8位的ASCII/ANSI字符集和16位的Unicode字符集 控制台存在访问级别，用于在简单控制和完全控制直接进行权衡 Win32 API ps：详细的内容请参考官网 以例子来简单了解如何使用 获取用户输入 1234567891011121314151617181920212223INCLUDE Irvine32.incBufSize = 80.databuffer BYTE BufSize DUP(?), 0, 0stdInHandle HANDLE ?bytesRead DWORD ?.codemain PROC ;获取标准输入句柄 INVOKE GetStdHandle ,STD_INPUT_HANDLE mov stdInHandle, eax ;等待用户输入 INVOKE ReadConsole, stdInHandle, ADDR buffer, BufSize, ADDR bytesRead, 0 ;显示缓冲区 mov esi, OFFSET buffer mov ecx, bytesRead mov ebx, TYPE buffer call DumpMem call WaitMSg exitmain ENDPEND main 几乎所有的Win32控制台函数都需要句柄（handle），其是一个32位无符号整数，用于唯一标识一个对象，例如一个位图，画笔或任何输入输出设备 输入abcdefg结果如下，发现插还有0Dh，0Ah,这是用户按下Enter产生的行结束符 Dump of offset 003B6000 ------------------------------- 61 62 63 64 65 66 67 0D 0A 输出 等待已久的Hello World程序 123456789101112131415161718192021222324252627INCLUDE Irvine32.inc.dataendl EQU &lt;0dh, 0ah&gt; ;行结尾message LABEL BYTE BYTE &quot;Hello World!&quot;, endlmessageSize DWORD ($ - message)consoleHandle HANDLE 0 ;标准输出设备句柄byteWritten DWORD ? ;输出字节数.codemain PROC ;获取标准输出句柄 INVOKE GetStdHandle ,STD_OUTPUT_HANDLE ;标号,已经被定义过 mov consoleHandle, eax ;向控制台写一个字符串 INVOKE WriteConsole, consoleHandle, ;控制台输出句柄 ADDR message, ;字符串指针 messageSize, ;字符串长度 ADDR byteWritten, ;返回输出字节数 0 ;未使用 call WaitMsg INVOKE ExitProcess, 0 main ENDPEND main 动态内存分配 动态内存分配（dynamic memory allocation）又被称为堆分配（heap allocation） C，C++，Java都有内置运行时堆管理器来处理程序请求的存储分配和释放。程序启动时，堆栈管理器常常从操作系统中分配一大块内存，并为存储块指针创建空闲列表（free list）。当接到一个分配请求时，堆管理器就把适当大小的内存标识为已预留，并返回指向该块的指针。 之后，当接收到对同一个快的删除请求时，对就会释放该内存块，并将其返回空闲列表。 例：使用动态内存分配创建并填充一个1000字节的数组 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071INCLUDE Irvine32.inc.dataARRAY_SIZE = 1000FILL_VAL EQU 0FFhhHeap HANDLE ? ;程序堆句柄pArray DWORD ? ;内存块指针newHeap DWORD ? ;新堆句柄strl BYTE &quot;Heap size is:&quot;, 0.codemain PROC INVOKE GetProcessHeap ;获取程序堆句柄(EAX返回) .IF eax == NULL call WriteWindowsMsg ;如果失败，显示消息 jmp quit .ELSE mov hHeap, eax .ENDIF call allocate_array jnc arrayOK call WriteWindowsMsg ;失败(CF=1)，显示消息 call Crlf jmp quitarrayOK: call fill_array call display_array call Crlf ;释放数组 INVOKE HeapFree, hHeap, 0, pArrayquit: call WaitMsg exitmain ENDPallocate_array PROC USES eax INVOKE HeapAlloc, hHeap, HEAP_ZERO_MEMORY, ARRAY_SIZE .IF eax == NULL stc ;进位标志置1 .ELSE mov pArray, eax ;保存指针 clc ;进位标志置0 .ENDIF retallocate_array ENDPfill_array PROC USES ecx edx esi mov ecx, ARRAY_SIZE mov esi, pArrayL1: mov BYTE PTR [esi], FILL_VAL inc esi loop L1 retfill_array ENDPdisplay_array PROC USES eax ebx ecx esi ;USES后面的寄存器不需要逗号隔开 mov ecx, ARRAY_SIZE mov esi, pArrayL1: mov al, [esi] mov ebx, TYPE BYTE call WriteHexB inc esi loop L1 retdisplay_array ENDPEND main 下面是一项原型 123456789HeapAlloc PROTO, hHeap:HANDLE ;现有堆内存块的句柄 dwFlags:DWORD, ;堆分配控制标志 dwBytes:DWORD, ;分配的字节数HeapFree PROTO, hHeap:HANDLE, dwFlags:DWORD, ;通常为0 lpMem:DWORD ;被释放内存块的指针 说明：hHeap通常由GetProcessHeap和HeapCreate初始化，dwFlags为标志值，常使用HEAP_ZERO_MEMORY将内存清0 X86 内存管理 我们重点关注的是存储管理的两个主要方面: 将逻辑地址转为线性地址 将线性地址转为物理地址（分页） 回顾 先回顾一下一些x86存储管理术语： 多任务处理（multitasking）允许多个程序或任务同时运行。处理器在所有运行程序中划分其时间 段（segment）是可变大小的内存区，用于让程序存放代码或数据 分段（segmentation）提供了分隔内存区段的方法。它允许多个程序同时运行又不会相互干扰 段描述符（segment descriptior）时一个64位的值，用于标识和描述一个内存段。它包含的信息有段基址，访问权限，段限长，类型和用法 段选择符（segment selector）是保存在段寄存器（CS，DS，SS，ES，FS或GS）中的一个16位数值 逻辑地址（logic address）就是段选择符加上一个32位的偏移量 我们一直忽略段寄存器，因为用户程序从来不会直接修改这些寄存器，所以只关注了32位数据偏移量，但是，从系统来看十分重要，因为它们包含了对内存段的直接引用 线性地址 线性地址是一个32位整数，其范围为0FFFFFFFFh，它表示一个内存位置。如果禁止分页功能，那么线性地址就是目标数据的物理地址 逻辑地址转为线性地址 多任务操作系统运行多个任务在内存中同时运行，每个程序都有自己的唯一数据区。那这样，每个程序里都有一个变量的偏移量地址为200h会咋样？怎么区分？ x86使用一步或两步处理将变量偏移量转换为唯一的内存地址 1.段值+变量偏移量形成线性地址（linear address） 2.页转换（page translation） 分页 分页是x86的一个重要功能。 处理器初始只装载部分程序到内存，其他仍留在硬盘里。程序使用的内存被分割成若干小区域，称为页（page），通常一页大小为4KB。当程序运行时，处理器会选择内存中不活跃的页面替换出去，而将立即会被请求的也加载到内存里 操作系统通过维护一个页目录（page directory）和一组页表（page table）来持续跟踪当前内存中所有程序使用过的页面。当程序试图访问线性地址空间内的一个地址时，处理器会自动将线性地址转为物理地址。这个过程称为页转换（page translation）。如果不存在内存中，处理器中断产生一个页故障（page fault）。操作系统将被请求的页从硬盘复制到内存，然后程序继续执行。从应用程序来看，页故障和页转换都是自动发生的","link":"/2019/08/08/AssemblyLanguageBasis-8/"},{"title":"汇编基础","text":"浮点数处理 浮点数二进制表示 十进制浮点数有三个组成部分：符号，有效数字，阶码。比如：\\(-1.23154*10^5\\)中，符号位负，有效数字为1.23154，阶码为5（虽然不太正确，有时用术语尾数（mantissa）来代替有效数字（significand）） IEEE二进制浮点数表示 x86处理器使用的三种浮点数二进制存储格式都是由IEEE标准754-1985所指定 单精度，32位：1位符号位，8位阶码，23位为有效数字的小数部分 双精度，64位：1位符号位，11位阶码，52位为有效数字的小数部分 符号位 如果符号位为1，该数为负。如果符号位为0，该数为正。零被认为是正数。 有效数字 二进制浮点数可以使用加权位计数法。 $$ 11.1011 = (121)+(1*20)+(12-1)+(0*2-2)+(1*2-3)+(1*2-4) $$ 需要注意的是小数点左面的阶为正，右面的为负 同样有效数字存在精度。例如假设一个简单的浮点数格式有5位有效数字，那么将无法表示范围在1.1111~10.000之间的数 阶码 单精度数用8位无符号整数存放阶码，引入的偏差为127，因此必须在数的实际阶码上再加127，实际都是这个偏移码被保存，偏移码总是正数，范围为1~254，实际阶码的范围是-126~127 规格化二进制浮点数 大多数二进制浮点数都以规格化格式（normalized form）存放，以便将有效数字的精度最大化。给定任意的二进制浮点数，都可以进行规格化，方法是： 将二进制小数点移位，直到小数点左边只有一个‘1’，阶码为二进制小数点向左（正阶码）或向右（负阶码）移动的位数 新建IEEE表示 实数 一旦符号位，阶码，有效数字字段完成规格化和编码后，生成一个完整的二进制IEEE段实数就很容易了。如\\(1.101x2^0\\)： 符号位：0 阶码：0111111（127） 小数部分：10100000000000000000000 无穷 和 NaN 任一无穷都可以表示浮点溢出条件，运算结果不能规格化的原因是，阶码太大而无法用有效的阶码位数来表示 NaN表示Not a Number。x86有两种NaN：quiet NaN可以通过大多数算术运算符来传递，不会引起异常；signaling NaN则被用于产生一个浮点无效操作异常 十进制小数转为二进制实数 1/2 – .1; 1/4 – .01; … 也可以使用长除法，将十进制的除数被除数全部转为二进制，再执行长除 如何转换回去呢，看下面的例子： 0 10000010 01011000000000000000000 1）该数为正数 2）无偏差阶码的二进制值为00000011，十进制为3 3）将符号阶码有效数字组合起来即得该二进制数为\\(+1.01011x2^3\\) 4）非格式化二进制数为+1010.11 5）十进制为10.75 浮点单元 Intel8086的处理器无法处理浮点运算，后来，Intel486出现时，浮点硬件就被集成到主CPU中，称为FPU FPU寄存器栈 FPU不使用通用寄存器，它有自己的一组寄存器，称为寄存器栈（register stack）。数值从内存加载到寄存器栈，然后执行运算，再将堆栈数值保存到内存 FPU使用后缀（postfix）表达式计算算术表达式，如： （A+B）* C --&gt; A B + C * 表达式堆栈： 在计算后缀表达式的过程中，用堆栈来保存中间结果。ST（0）表示堆栈指针通常所指的位置 A入栈 -&gt; B入栈 -&gt; 弹出A,B做加法，结果入栈 -&gt; C入栈 -&gt; 弹出C和后面的数做乘法 FPU数据寄存器 FPU有8个独立的，可寻址的80位数据寄存器R0~R7，FPU状态字中名为TOP的一个3位字段给出了当前出于栈顶的寄存器编号，如011表示栈顶为R3，这个位置也称为ST(0)，最后一个寄存器为ST(7) 入栈操作将TOP减1，并把操作数复制到表示为ST(0)的寄存器中。如果入栈前，TOP就是0了，那么会绕回到寄存器R7 FPU专用寄存器 FPU有6个专用（special-purpose）寄存器 操作码寄存器：保存最后执行的非控制指令的操作码 控制寄存器：执行运算时控制精度和FPU的舍入 状态寄存器：包含栈顶指针，条件码和异常警告 标识寄存器：指明FPU数据寄存器栈内每个寄存器的内容 最后指令指针寄存器：保存指向最后执行的非控制指令的指针 最后数据指针寄存器：保存指向数据操作数的指针 舍入 方法 精确结果 舍入结果 舍入到最接近的偶数 1.0111 1.100 向-∞舍入 1.0111 1.011 向+∞舍入 1.0111 1.100 向0舍入 1.0111 1.011 同时FPU控制字会指明使用的舍入方法，这两位被称为RC段 00：舍入到最近的偶数（默认） 01：向负无穷舍入 10：向正无穷舍入 11：向0舍入（截断） 浮点数指令集 初始化 FINT FINT指令对FPU进行初始化。将FPU控制字节设置为037Fh，即隐蔽了所有浮点异常，舍入模式设置为最近偶数，计算精度设置为64位 浮点数数据类型 REAL4 -&gt; 32位（4字节）IEEE短实数 REAL8 -&gt; 64位（8字节）IEEE长实数 REAL10 -&gt; 80位（10字节）IEEE扩展实数 加载浮点数值 FLD 指令将浮点数复制到FPU堆栈栈顶，即压入栈顶 保存浮点数值 FST FSTP FST将浮点操作数从FPU栈顶复制到内存，但并不出栈 FSTP将完成复制+弹出 算数指令 FCHS和FABS FCHS（修改符号）指令将ST（0）中的浮点数数值的符号取反。FABS（绝对值）指令清除ST（0）中数值的符号，这两条指令没操作数 FADD，FADDP， FIADD FADD没有操作数时，为ST（0）和ST（1）相加，结果暂存在ST（1），ST（0）弹出堆栈，加法保留到栈顶 寄存器操作数时就是相加，不进行弹出操作 内存操作数，会将操作数和ST（0）相加 FADDP相加并弹出 FIADD（整数加法），先将源操作数转换为扩展双精度浮点数，再与ST（0）相加 FSUB，FSUBP，FISUB 类似加法，不再赘述 对应的乘除版本也类似 FSQRT 对ST（0）中的数值求平方根，结果返回ST（0） FCOM，FCOMP，FCOMPP FCOM 指令 说明 FCOM 比较ST（0）和ST（1） FCOM m32fp 比较ST（0）和m32fp FCOM m64fp 比较ST（0）和m64fp FCOM ST（i） 比较ST（0）和ST（i） FCOMP会将ST（0）弹出 FCOMPP会弹出两次 FPU条件码标识有3个，C3，C2，C0分别对应ZF（零标志位），PF（奇偶标志位），CF（进位标志位） 在比较了两个数值并且设置了FPU条件码后，如何根据条件分支跳转呢？ 这就包括了两个步骤： 1.用FNSTSW指令把FPU状态字送入AX 2.用SAHF指令把AH复制到EFLAGS 123456double x = 1.2;double y = 3.0;int n = 0;if(x &lt; y){ n = 1;} 与之等效的汇编代码: 123456789101112.datax REAL8 1.2y REAL8 3.0n DWORD 0.code fld x ;ST(0)=x fcomp y ;比较ST(0)和y fnstsw ax ;状态字送入AX sahf ;AH复制到EFLAGS jnb L1 mov n,1L1: 需要注意的是，在相等比较的时候，不要使用浮点数相等来进行比较，因为会在计算中存在舍入误差，一般使用差的绝对值小于一个极小的数时就认为相等 12345678910111213.dataepsilon REAL8 1.0E-12val2 REAL8 0val3 REAL8 1.001E-13.code fld epsilon fld val2 fsub val3 fabs fcomi ST(0), ST(1) ;代替之前的三条指令 ja skip ...skip: 异常同步 整数（CPU）和FPU是相互独立的单元，因此在执行整数和系统指令的同时可以执行浮点指令，这被称为并行性（concurrency），当发生未屏蔽的浮点异常时，可能会是一个潜在的问题。 发生未屏蔽异常，中断当前的浮点指令，FPU发异常事件信号。当下一条浮点指令或FWAIT（WAIT）指令将要执行时，FPU检查待处理的异常。 123fild intVal ;整数加载到ST(0)fwait ;等待处理异常inc intVal 设置WAIT和FWAIT指令是为了在执行下一条指令前，强制处理器检查待处理且未屏蔽的浮点异常。直到异常处理结束，才执行INC 如果不设置，引发异常的浮点指令后跟的是整数指令或者系统指令，很遗憾，不会检查待处理的异常——会立即执行。第一条指令送入一个内存操作数，第二条指令又要修改它，异常处理的程序就无法正确执行","link":"/2019/08/09/AssemblyLanguageBasis-9/"},{"title":"汇编实验","text":"C/C++中调用汇编的函数 汇编实现搜索的IndexOf函数 对应第十基础篇 IndexOf.asm1234567891011121314151617181920212223242526272829303132333435.586.model flat, CIndexOf PROTO, searchVal: DWORD, arrayPtr: DWORD, count: DWORD.codeIndexOf PROC USES ecx esi edi, searchVal:DWORD, arrayPtr:DWORD, count:DWORD;;对32位整数数组执行线性搜索,;EAX返回该数值的索引位置，否则返回-1;-------------------------------------- NOT_FOUND = -1 mov eax, searchVal mov ecx, count mov esi, arrayPtr mov edi, 0L1: cmp [esi+edi*4], eax je found inc edi loop L1NotFound: mov eax, NOT_FOUND jmp short ExitFound: mov eax, ediExit: retIndexOf ENDPEND C++中调用该函数 main.cpp123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;time.h&gt;extern &quot;C&quot; long IndexOf(long n, long array[], unsigned count);using namespace std;int main(){ const unsigned ARRAY_SIZE = 100; const unsigned LOOP_SIZE = 10; const char* boolstr[] = { &quot;false&quot;, &quot;true&quot; }; long array[ARRAY_SIZE]; for (unsigned i = 0; i &lt; ARRAY_SIZE; i++){ array[i] = rand(); } long searchVal; time_t startTime, endTime; cout &lt;&lt; &quot;Enter an integer value to find: &quot;; cin &gt;&gt; searchVal; cout &lt;&lt; &quot;Please wait......\\n&quot;; //测试汇编函数 time(&amp;startTime); int count = 0; for (unsigned i = 0; i &lt; LOOP_SIZE; i++){ count = IndexOf(searchVal, array, ARRAY_SIZE); } bool found = (count != -1); time(&amp;endTime); cout &lt;&lt; &quot;Elapsed ASM time: &quot; &lt;&lt; long(endTime - startTime) &lt;&lt; &quot; seconds. Found = &quot; &lt;&lt; boolstr[found] &lt;&lt; endl; return 0;} 好了，我们的代码就绪了，那，咋链接起来呢？ 配置如下： 右键汇编的文件 打开属性页 命令行填写：ml /c /coff %(fileName).asm 输出填写：%(fileName).obj;%(OutPuts) 一个C的代码 12345678int sumarray(int array[], int count){ int i; int sum=0; for(i=0;i&lt;count;i++){ sum+=array[i]; } return sum;} 汇编代码如下： 1234567891011121314151617181920212223242526272829303132333435363738sumarray: push ebp mov ebp,esp sub esp,0D8h push ebx push esi push edi lea edi,[ebp-0D8h] mov ecx,36h mov eax,0CCCCCCCCh rep stos dword ptr es:[edi] mov ecx,offset _CAC8CD7F_consoleapplication2@cpp (013DC002h) call @__CheckForDebuggerJustMyCode@4 (013D1208h) mov dword ptr [sum],0 mov dword ptr [i],0 jmp sumarray+41h (013D1731h) mov eax,dword ptr [i] add eax,1 mov dword ptr [i],eax mov eax,dword ptr [i] cmp eax,dword ptr [count] jge sumarray+5Ah (013D174Ah) mov eax,dword ptr [i] mov ecx,dword ptr [array] mov edx,dword ptr [sum] add edx,dword ptr [ecx+eax*4] mov dword ptr [sum],edx jmp sumarray+38h (013D1728h) mov eax,dword ptr [sum] pop edi pop esi pop ebx add esp,0D8h cmp ebp,esp call __RTC_CheckEsp (013D1212h) mov esp,ebp pop ebp ret 调试方法: 调试 -&gt; 右键 -&gt;转到反汇编(go to disassembly) 注意：需要在设置里勾选一项：启用地址级调试 工具菜单 -&gt; 选项 -&gt; 调试","link":"/2019/08/10/AssemblyLanguageExp-10/"},{"title":"汇编实验","text":"最后一批有意思的练习题 写在前面 终于完成了Intel x86汇编的习题（我认为应该写的）+基础知识，基本上花了3周左右（除去假期中间的咕咕咕极长时间），可喜可贺，也该开学了。 不coding死路一条 不要停下来啊（指学习） 下一阶段的目标就是数学+算法+Python网络编程 不学数学读研死路一条 什么，你说假期里的前端学习？咕咕咕 汇编代码咋高亮啊，好像不支持… Str_find过程 编写过程Str_find在目的串中查找第一次出现的源串，并返回其位置。输入参数为源串指针和目的指针。如果查找成功，过程将零标志位ZF置1，用EAX返回指向目的的串的匹配位置。否则ZF清零，EAX无定义。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162.386.model flat,stdcall.stack 4096ExitProcess PROTO, dwExitCode:DWORDStr_find PROTO, source_str:PTR BYTE, target_str:PTR BYTE,source_len:DWORD,target_len:DWORD.datasource BYTE &quot;Life is short so I use Python&quot;, 0target BYTE &quot;hor&quot;, 0pos DWORD ?.codemain PROC INVOKE Str_find, ADDR source, ADDR target, LENGTHOF source, LENGTHOF target jnz notFound mov pos, eax ;保存notFound: INVOKE ExitProcess, 0main ENDPStr_find PROC USES ecx esi edi ebx edx, source_str:PTR BYTE, target_str:PTR BYTE, source_len:DWORD, target_len:DWORD mov edi, source_str mov esi, target_str mov dl, [esi] ;首字符 mov ecx, source_lenL1: cmp dl, [edi] je L3 add edi, 1 loop L1 jmp quit ;找了一轮没有匹配L3: push ecx mov ebx, ecx ;源字符串还剩余多少 mov ecx, target_len sub ecx, 2 ;只剩长度-1个字符需要比较 jz find ;只剩一个元素 cmp ecx, ebx ;比较所剩长度 ja L4 ;源串所剩长度小于子串,结束 mov ebx, 1L2: mov dl, [esi+ebx] ;Target_str中取下一个 cmp [edi+ebx], dl jne next inc ebx loop L2find: mov eax, edi ;找到子串 dec eax ;减1代表首元素 test edi, 0 ;ZF置0L4: pop ecx ;别忘恢复栈quit: retnext: pop ecx jmp L1Str_find ENDPEND main 链表 用汇编语言实现一个单项链表（课本例子） 12345678910111213141516171819202122232425262728293031323334353637383940414243INCLUDE Irvine32.incListNode STRUCT NodeData DWORD ? NextPtr DWORD ?ListNode ENDSTotalNodeCount = 15NULL = 0Counter = 0.dataLinkedList LABEL PTR ListNode ;定义一个标号,标识一下头,不分配内存REPEAT TotalNodeCount Counter = Counter + 1 ListNode &lt;Counter, $ + Counter*SIZEOF ListNode&gt;ENDMListNode&lt;0, 0&gt; ;尾节点.codemain PROC mov esi, OFFSET LinkedList;显示NodeData的值NextNode: ;检查是否是尾节点 mov eax, (ListNode PTR [esi]).NextPtr cmp eax, NULL je quit ;显示结点数据 mov eax, (ListNode PTR [esi]).NodeData call WriteDec call Crlf ;获取下一个节点的指针 mov esi, (ListNode PTR [esi]).NextPtr jmp NextNodequit: call WaitMsg exitmain ENDPEND main 需要注意： 先定义一个标识头，不然到最后没有办法找到链表的起始位置 使用REPEAT伪指令来重复执行一个代码块，其格式如下： REPEAT constExpression statement ENDM constExpression是一个无符号整数常量，用于确定重复的次数，这里我们重复执行 Counter = Counter + 1 ListNode &lt;Counter, $ + Counter*SIZEOF ListNode&gt; 来填充这个链表（将NextPtr指向下一块ListNode大小的地方，由于定义时存储连续的，使用$+偏移量来指向下一个） 无法直接[esi].NextPtr来访问，必须使用ListNode PTR [esi]，因为无法表明其所属的结构 Str_trim过程拓展 Irvine32链接库里的Str_trim过程从空字节结束的字符串中移除所有与选定的尾部字符匹配的字符，这个过程的逻辑很有意思，因为程序需要检查很多种情况，以#作为尾字符为例： 1）字符串为空 2）字符串一个或多个尾字符的前面有其他字符，如&quot;Hello#&quot; 3）字符串只有一个字符，且为尾字符，如&quot;#&quot; 4）字符串不含尾部字符，如&quot;Hello&quot; 5）字符串在一个或多个尾部字符跟随一个或多个尾部字符，如&quot;Hello##&quot; 现在我们先研究一下其源码,以例子来看: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071INCLUDE Irvine32.incShowString PROTO, string_addr:PTR BYTEStrTrim PROTO, pString:PTR BYTE, char: BYTEGetLength PROTO, ptrString:PTR BYTE.datatest_1 BYTE &quot;##Hello##&quot;, 0.codemain PROC INVOKE StrTrim, ADDR test_1, '#' INVOKE ShowString, ADDR test_1 call WaitMsgmain ENDPGetLength PROC USES edi, ptrString: PTR BYTE mov edi, ptrString mov eax, 0L1: cmp BYTE PTR [edi], 0 ;判断是否结束 je L2 inc edi inc eax ;eax返回长度 jmp L1L2: retGetLength ENDPShowString PROC USES eax edx, string_addr:PTR BYTE xor eax, eax ;清空eax mov al ,'[' call WriteChar mov edx, DWORD PTR string_addr call WriteString mov al, ']' call WriteChar call Crlf retShowString ENDPStrTrim PROC USES eax ecx edi, pString:PTR BYTE, char: BYTE mov edi, pString INVOKE GetLength, pString cmp eax, 0 ;长度是否为0 je L3 mov ecx, eax ;保存长度 dec eax add edi, eax ;指向最后一个字符L1: mov al, [edi] cmp al, char ;是否为匹配字符? jne L2 ;不是,跳转 dec edi ;是,向前一位再次比较 loop L1L2: mov BYTE PTR [edi+1], 0 ;插入一个空字节L3: retStrTrim ENDPEND main 为了防止和库中冲突，我修改了函数名 留意StrTrim过程，写的很巧妙，倒着匹配，匹配到就插入一个0表示结束，没有就接着比 裁剪前导字符 现在要求删去给定前导字符，如&quot;##Hello&quot; --&gt; “Hello” 123456789101112131415161718192021222324252627;只修改部分的StrTrim的代码StrTrim PROC USES eax ecx edi, pString:PTR BYTE, char: BYTE mov edi, pString INVOKE GetLength, pString cmp eax, 0 ;长度是否为0 je L3 mov ecx, eax ;保存长度L1: mov al, [edi] cmp al, char ;是否为匹配字符? jne L3 ;不是,跳转 push ecx push edimove: mov al, [edi+1] ;向前移动一位 mov [edi], al add edi, 1 loop move pop edi pop ecx loop L1L3: retStrTrim ENDP 我们只需要在匹配上后把后面的依次向前移位就行，注意带上结尾的’0’ 注意：mov [edi], [edi+1]是不行的，我竟然这么写了，无法内存到内存 去除一组字符 现在要求过滤一组字符串，使主调程序能从字符串末尾删除一组字符。 分析一下就是设置一个“指针”从后向前在过滤的字符串中寻找，有就将“指针”向前移一位，直到匹配不到，这个“指针”就是间接寻址的一个寄存器 12345678910111213141516171819202122232425262728293031323334StrTrim PROC USES eax ecx edi ebx esi, pString:PTR BYTE, pchar: PTR BYTE mov edi, pString INVOKE GetLength, pString cmp eax, 0 ;长度是否为0 je L3 mov ecx, eax ;保存长度 dec eax add edi, eax ;指向最后一个字符 INVOKE GetLength, pchar ;获取过滤字符串的长度 mov ebx, eax ;存在EBX里L1: mov al, [edi] push ecx mov ecx, ebx mov esi, pcharfiltration: cmp al, BYTE PTR [esi] ;是否为匹配字符? je L2 ;是,跳出循环 add esi, 1 loop filtration pop ecx ;别忘恢复ECX jmp L4 ;扫一周也没匹配到,直接在当前尾部加0结束L2: sub edi, 1 ;前移1位 pop ecx loop L1L4: mov BYTE PTR [edi+1], 0L3: retStrTrim ENDP","link":"/2019/08/16/AssemblyLanguageExp-12/"},{"title":"汇编实验","text":"说是实验，实际就是写一下书上的题罢了，对应标号的basis部分，下面直接上问题和代码 关于64位编程，之后会专门更相关的博客，目前是32位编程 整数数组求和 L2循环的方法我是想仿照C的写法写的 123456789101112131415161718192021222324252627282930.386.model flat,stdcall.stack 4096ExitProcess proto ,dwExitCode:DWORD.dataintArray DWORD 10000h,2000h,30000h,40000hi DWORD 0;.codemain proc mov edi, OFFSET intArray mov ecx, LENGTHOF intArray mov eax, 0L1: add eax, [edi] add edi, TYPE intArray loop L1 mov edi, OFFSET intArray mov ecx, LENGTHOF intArray mov eax, 0L2: mov ebx, i imul ebx, ebx ,TYPE intArray add eax, intArray[ebx] inc i loop L2 invoke ExitProcess,0main ENDPEND main 注意为了节省位置，下面的都不再添加程序的头尾内容，只有.data和.code 复制字符串 需要注意的是，无法直接内存复制过去，需要转经寄存器，逐位复制即可 12345678910111213.data source BYTE &quot;This is the source string&quot;,0target BYTE SIZEOF source DUP(0).code mov esi, 0 ;变址寄存器 mov ecx, LENGTHOF sourceL1: mov al, source[esi] mov target[esi], al inc esi loop L1 数组操作 12345678910111213141516171819202122232425262728293031323334353637383940.dataintarray DWORD 1,2,3,4,5,6,7,8,9,10myarray DWORD 1,2,3,4,5,6,7,8,9,10len DWORD LENGTHOF intarray.code;数组反向,intarray mov edi, OFFSET intarray mov ecx, len mov edi, ecx ; 尾部索引 mov esi, 0 ; 头部索引 dec edi ; 索引是数目-1L1: mov ecx, edi sub ecx, esi mov eax, intarray[esi * TYPE intarray] ;从头开始的数 mov ebx, intarray[edi * TYPE intarray] ;从尾开始的数 mov intarray[esi * TYPE intarray], ebx mov intarray[edi * TYPE intarray], eax dec edi ; 尾部向前 inc esi ; 头部向后 loop L1;数组元素移位,myarray;将32位整数数组元素的位置逐个向右移动一位，最后一个移动到第一个数 mov esi, LENGTHOF myarray dec esi mov ecx, esi ;移动过最后一个了，少循环一次 mov eax, myarray[esi * TYPE myarray] mov ebx, myarray[0] mov myarray[0], eax ;最后一个数移动到第一个 mov esi, 0 ;从零开始计数L2: inc esi ;目的位置 mov eax, myarray[esi * TYPE myarray] ;保存目的位置的数 mov myarray[esi * TYPE myarray], ebx ;移动 mov ebx ,eax loop L2 mov edi, OFFSET intarray这句话的目的是方便我调试的时候看到数组位置，在内存中找到，观察结果是否正确 数组反向我只想到了这个方法，有空借鉴一下网上的方法，目前还待优化，奇数次会进行一次没有意义的循环（自己和自己交换一下） 斐波那契数列求和 编写汇编程序，计算斐波那契数列前7项的和 12345678910111213141516.dataFibo1 DWORD 1Fibo2 DWORD 1.code mov eax, Fibo1 mov ebx, Fibo2 mov ecx, 7 mov esi, 0 ; 最终结果放入esifiboSum: add esi, eax ; 累加一项 mov edx, eax add edx, ebx ; 算出数列下一项 mov eax, ebx mov ebx, edx ; 后移 loop fiboSum 没啥困难的，我们每次加一个数，算出下一个数，重复7次就行 附录 调试方法： 打下断点后打开调试，在菜单栏调试中选择窗口，再选寄存器，内存，在寄存器的窗口出右击，可以控制显示什么，目前用到的可以调出来cpu标志位 对应 书上的 别名 别名 溢出标志OF(Over flow flag) OV(1) NV(0) 方向标志DF(Direction flag) DN(1) UP(0) 中断标志IF(Interrupt flag) EI(1) DI(0) 符号标志SF(Sign flag) NG(1) PL(0) 零标志ZF(Zero flag) ZR(1) NZ(0) 辅助标志AF(Auxiliary carry flag) AC(1) NA(0) 奇偶标志PF(Parity flag) PE(1) PO(0) 进位标志CF(Carry flag) CY(1) NC(0) 图示","link":"/2019/07/20/AssemblyLanguageExp-2/"},{"title":"汇编实验","text":"对应basis-3的内容 Irvine32链接库 配置 首先准备好一个配置好masm的项目（正常可以写汇编的），下载好Irvine32（我的在D盘Irvine目录下D:\\Irvine） 然后对project右键属性： 链接器附加库目录中加入你安装好的路径(D:\\Irvine；) 链接器输入附加依赖项中加入Irvine32.lib（用32位,别忘了分号隔开） 在Microsoft Macro Assemble中的include Paths 加上你的路径(D:\\Irvine；) 库测试1：整数IO操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960; 库测试,整数IO操作include Irvine32.inc.data count = 4 BlueTextOnGray = blue + (lightGray * 16) DefaultColor = lightGray + (black * 16) arrayD SDWORD 12345678h,1A4B2000h, 3434h, 7AB9h prompt BYTE &quot;Enter a 32-bit signed integer&quot;, 0.code main PROC ; 选择浅灰背景蓝色文本 mov eax, BlueTextOnGray call SetTextColor call Clrscr ; 清屏 ; 用DumpMen显示数组 mov esi, OFFSET arrayD ; 开始位置 mov ebx, TYPE arrayD ; 双字 mov ecx, LENGTHOF arrayD ; 单元数 call DumpMem ; 显示内存 ; 请求用户输入一组有符号整数 call Crlf ; 显示一个新空白行 mov ecx, COUNTL1: mov edx, OFFSET prompt call WriteString call ReadInt ; 输入数据存入EAX call Crlf ; 用十进制, 十六进制, 二进制显示 call WriteInt ; 显示为有符号十进制 call Crlf call WriteHex ; 显示为十六进制 call Crlf call WriteBin ; 显示为二进制数 call Crlf call Crlf loop L1 ; 返回控制台窗口的默认颜色 call WaitMsg ; &quot;Press any key...&quot; mov eax, DefaultColor call SetTextColor call Clrscr exitmain ENDPEND main DumpMem在控制台窗口中用16进制显示一段内存，其参数为：ESI存储内存区域首地址，ECX存放单元个数，EBX存放单个单元的大小 SetTextColor设置输出文本的前景色和背景色，颜色常量在Irvine32.inc中定义，要获得完整的颜色字节数值，将背景色乘16加上前景色，如下表示蓝色背景输出黄色字符： yellow + (blue * 16) WriteInt/Bin/Hex 用的都是EAX, 而WriteChar用的是AL WriteString向操作台窗口输出一个以空字节结束的字符串，过程中EDX传递偏移量 库测试2：生成随机数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647include Irvine32.incTab = 9 ; Tab的ASCII码main PROC call Randomize ; 初始化随机生成器 call Rand1 call Rand2 call WaitMsg exitmain ENDPRand1 PROC ; 生成10个伪随机数 mov ecx, 10 ; 循环10次 randLoop: call Random32 call WriteDec ; 无符号十进制形式输出 mov al, Tab ; 水平制表符 call WriteChar ; 输出制表符 loop randLoop call Crlf retRand1 ENDPRand2 PROC ; 生成-50 -- +49之间的10个伪随机数 mov ecx, 10 randLoop: mov eax, 100 ; 指定数值范围0-99 call RandomRange ; 生成随机数 sub eax, 50 ; 数值返回-50至49 call WriteInt ; 用有符号十进制的方式输出 mov al, Tab call WriteChar loop randLoop call Crlf retRand2 ENDPEND main 我们不需要完全记住每个的用法，需要的时候查查就行了 Randomize过程对Random32和RandomRange过程的第一个种子进行初始化，种子等于一天中的时间，精度为1/100秒，每当调用Random32和RandomRange的程序运行时，保证生成的序列都不相同 练习题 随机字符串 创建过程生成长度为L的随机字符串，字符全为大写。调用过程时用EAX传递长度为L的值，并传递一个指针指向用于保存该随机字符串的字节数组。编写测试程序调用10次，输出在控制台窗口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253include Irvine32.inc.data arrayB BYTE 50 DUP(?) pointer DWORD OFFSET arrayB prompt BYTE &quot;Please Enter the length of random string( &lt; 50 ): &quot;, 0.code;----------------------------------------------------------; 参数 EAX = 生成随机字符串长度 pointer 指向数组的指针; 用于随机生成指定长度的大写字符串; 无返回值generateString PROC mov ecx, eax ; 指定循环次数 call Randomize mov esi, pointer L1: mov eax, 27 ; 范围0--26 call RandomRange add eax, 41h mov [esi], al ; 存入内存 inc esi loop L1 retgenerateString ENDPrandString PROC mov edx, OFFSET prompt ; 参数为EDX,表示偏移量 call WriteString call ReadInt ; 读入EAX call Crlf push eax ; 保存有效长度 call generateString pop ecx ; 指定输出循环次数 mov esi, pointer L2: mov al, BYTE PTR [esi] call WriteChar inc esi loop L2 retrandString ENDPmain PROC call randString call Crlf call WaitMsg exitmain ENDPEND main RandomRange 产生的随机数结过会被保存在EAX中, 范围指定也需要EAX，所以每次loop时要重新给EAX赋值 WriteChar 使用al里的数写成字符, 我们使用PTR将高位数赋给低位寄存器(我寻思直接赋EAX也可以) 递归过程 编写程序调用一个递归过程，过程中对计数器自增来计数，向ECX输入一个值来控制递归次数，只使用loop，不使用后续的条件判断语句 想了好久，想不出来 我感觉不行 斐波那契生成器 编写一个过程生成含有N个数的斐波那契数列，并将其保存在一个双字数组中，输入参数为双字数组指针和生成个数的计数器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647include Irvine32.inc.datafiboArray DWORD 20 DUP(?)p DWORD OFFSET fiboArray.code;-----------------------------; 参数 ECX: 生成多少位斐波那契数, p: 存储数组指针; 生成首两位为1的斐波那契数列; 无返回Fibo PROC mov eax, 1 mov ebx, 1 mov esi, p ; 间接寻址 mov [esi], eax add esi, TYPE p mov [esi], ebx add esi, TYPE p sub ecx, 2generateFibo: mov edx, eax add edx, ebx mov eax, ebx mov ebx, edx mov [esi], edx add esi, TYPE p loop generateFibo retFibo ENDPmain PROC mov ecx, 20 call Fibo mov ecx, LENGTHOF fiboArray mov ebx, TYPE fiboArray mov esi, OFFSET fiboArray call DumpMem call Crlf call WaitMsg exitmain ENDPEND main","link":"/2019/07/23/AssemblyLanguageExp-3/"},{"title":"汇编实验","text":"对应基础4的练习 本章题比较多 布尔计算器 创建程序，其功能为简单的32位整数布尔运算。显示菜单提示用户选择下表中的一项，然后提示输入后并把运算结果以16进制形式显示在屏幕上,菜单如下: x AND y x OR y NOT x x XOR y Exit 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798INCLUDE Irvine32.incenter_key = 13.dataMenuList BYTE &quot;1.x AND y&quot;, 13, 10 BYTE &quot;2.x OR y&quot;, 13, 10 BYTE &quot;3.NOT x&quot;, 13, 10 BYTE &quot;4.x XOR y&quot;, 13, 10 BYTE &quot;5.Exit&quot;,13, 10, 0prompt BYTE &quot;Please choose a number:&quot;, 0prompt1 BYTE &quot;Enter Two Number&quot;, 0prompt2 BYTE &quot;Enter A Number&quot;, 0CaseTable DWORD 1 ;查询地址 DWORD Process_1 ;过程地址 DWORD 2 DWORD Process_2 DWORD 3 DWORD Process_3 DWORD 4 DWORD Process_4 DWORD 5 DWORD Process_5EntryNumber = 5EntrySize = ($ - CaseTable) / 5.codemain PROCL1: mov edx, OFFSET MenuList call WriteString mov edx, OFFSET prompt call readInt ;读入EAX mov esi, OFFSET CaseTable mov ecx, EntryNumber ;循环次数L2: cmp eax, [esi] ;搜索是否匹配 jne L3 ;不相等跳转 call NEAR PTR [esi+4] call Crlf jmp L1L3: add esi, EntrySize loop L2 call WaitMsg ;错误输入 jmp L1Process_1 PROC mov edx, OFFSET prompt1 call WriteString call readInt mov ebx, eax call readInt and eax, ebx call WriteHex retProcess_1 ENDPProcess_2 PROC mov edx, OFFSET prompt1 call WriteString call readInt mov ebx, eax call readInt or eax, ebx call WriteHex retProcess_2 ENDPProcess_3 PROC mov edx, OFFSET prompt2 call WriteString call readInt not eax call WriteHex retProcess_3 ENDPProcess_4 PROC mov edx, OFFSET prompt1 call WriteString call readInt mov ebx, eax call readInt xor eax, ebx call WriteHex retProcess_4 ENDPProcess_5 PROC call Crlf call WaitMsg exitProcess_5 ENDPmain ENDPEND main 消息加密 例题版 利于XOR的特性,一个数和另一个数异或后再和该数异或就能得到原本的数，对输入的字符的ASCII码与一个key异或加密，再异或一次解密,将结果输出到屏幕上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879;简单对称加密,利用XORINCLUDE Irvine32.incKEY = 239 ;1-255间任意一值BUFMAX = 128 ;缓冲区最大容量.datasPrompt BYTE &quot;Enter the plain text:&quot;, 0sEncrypt BYTE &quot;Cipher text:&quot;, 0sDecrypt BYTE &quot;Decrypted:&quot;, 0buffer BYTE BUFMAX+1 DUP(0)bufSize DWORD ?.codemain PROC call InputTheString ;输入明文 call TranslateBuffer ;加密缓冲区 mov edx, OFFSET sEncrypt call DisplayMessage call TranslateBuffer ;解密缓冲区 mov edx, OFFSET sDecrypt call DisplayMessage ;显示解密消息 call WaitMsg exitmain ENDPInputTheString PROC;----------------------;提示用户输入一个纯文本字符串,保存进buffer;无参数;无返回;----------------------- pushad ;保存32位寄存器 mov edx, OFFSET sPrompt call WriteString mov ecx, BUFMAX mov edx, OFFSET buffer ;指向缓冲区 call ReadString ;输入字符串 mov bufSize, eax ;保存长度 call Crlf popad retInputTheString ENDPDisplayMessage PROC;--------------------;显示加密或解密消息;参数:EDX指向消息;无返回值;-------------------- pushad call WriteString mov edx, OFFSET buffer call WriteString call Crlf call Crlf popad retDisplayMessage ENDPTranslateBuffer PROC;-----------------------;字符串的每个字节都与密钥异或实现转换;无参数;无返回值;------------------------ pushad mov ecx, bufSize mov esi, 0L1: xor buffer[esi], KEY inc esi loop L1 popad retTranslateBuffer ENDPEND main 修改 创建包含多个字符的密钥，使用该密钥与明文相应位进行按位异或，来对明文加密和解密，需重复使用密钥直到明文中的所有字符都转换完，假设密钥为ABXmv#7，（明文第8位与A异或） 1234567891011121314151617181920212223242526272829.codekey BYTE &quot;ABXmv#7&quot;, 0 ;指定key.dataTranslateBuffer PROC;-----------------------;字符串的每个字节都与密钥异或实现转换;无参数;无返回值;------------------------ pushad mov ecx, bufSize mov esi, 0 mov edi, 0L1: mov al, key[edi] xor buffer[esi], al inc esi inc edi cmp edi, LENGTHOF key je ResetEDIL2: loop L1 popad retResetEDI: xor edi, edi ;归零 jmp L2TranslateBuffer ENDP 奇偶性检查 数据传输系统和文件子系统常常依靠计算数据块的奇偶性（奇偶校验）来检查错误，我们需要创建一个过程，计算整个字节数组中的所有位，如果有偶数个1，则eax需要置1，反之eax需要置0 1234567891011121314151617181920212223242526272829303132333435363738394041424344.386.model flat,stdcall.stack 4096ExitProcess proto ,dwExitCode:DWORD.dataarray1 BYTE 1111b,111b,11b,1b,1b,0b,0b,0b,0b,0b ;奇校验array2 BYTE 11111b,1110b,1110b,1110b,1110b,10b,0b,0b,0b,0b ;偶校验.codemain proc mov esi, OFFSET array1 mov edi, LENGTHOF array1 call Check mov esi, OFFSET array2 mov edi, LENGTHOF array2 call Check invoke ExitProcess,0main ENDP Check PROC;------------------------;用于验证字节数组的所有位是奇校验还是偶校验;参数: ESI=数组指针, EDI=数组大小;返回值: EAX=0表示为奇校验,反之为偶校验;------------------------ mov ecx, edi dec ecx ;少执行一次 mov edx, 0 mov al, [esi]L1: inc edx mov bl, [esi+edx] xor al, bl loop L1 xor al, 0 jp END1 ;偶校验 mov eax, 0 retEND1: mov eax, 1 retCheck ENDPEND main 调试查看程序结果即可 循环内的if嵌套 把下面C++的代码转成汇编代码 1234567891011int array[] = {1,2,3,4,5,6,7,8,9,10}int sample = 3int ArraySize = sizeof(array)/ sizeof(int)int index = 0int sum = 0while( index &lt; ArraySize ){ if(array[index] &gt; sample){ sum += array[index] } index++} 尽量使用较少的指令数来用汇编实现,下面是我的实现： 1234567891011121314151617.datasum DWORD 0sample DWORD 3array DWORD 1,2,3,4,5,6,7,8,9,10ArraySize = ($-array) / TYPE array.code mov eax, OFFSET sum ;便于调试寻找内存 mov ecx, ArraySize mov esi, 0L1: mov eax, array[esi * TYPE array] cmp eax, sample jbe next ;小于,不求和 add sum, eaxnext: inc esi loop L1 我们可以看到如果仅是判断次数的while循环(可以用for替代)LOOP就会比条件判断容易很多,但如果是条件判断，写法就要复杂一些 12345678910111213141516171819;不使用loop.codemov eax, OFFSET sum ;便于调试寻找内存mov ecx, 0mov esi, 0L1: cmp ecx, ArraySize jae quit inc ecx mov eax, array[esi * TYPE array] cmp eax, sample jbe next ;小于,不求和 add sum, eaxnext: inc esi jmp L1quit: 我们只需要在第一个while判断时使用cmp，把使用结束循环的情况跳转到结束语句或者后面的语句即可 写在后面 要加快速度了，毕竟想学的东西太多了，但还是要一点一点来学，一遍尽量学扎实 空格咋抽风了，看着贼难受","link":"/2019/07/30/AssemblyLanguageExp-4/"},{"title":"汇编实验","text":"对应第五章内容及练习 最大公约数 求两个数的最大公约数 12345678910111213141516.dataval1 DWORD 120val2 DWORD 36.code mov eax, val1 mov ebx, val2L1: mov edx, 0 div ebx ;余数在EDX,商在EAX cmp edx, 0 je L2 mov eax, ebx ;除数做被除数 mov ebx, edx ;余数做除数 jmp L1L2: mov esi, ebx ;ESI返回最大公约数 需要注意一个问题就是EDX的值（被除数高位），每次计算时需要将其置零,否则容易导致结果溢出（存储商或者余数的寄存器无法放得下商或者余数） 压缩整数加法 课本例题：16位+16位 12345678910111213141516171819202122232425262728293031323334INCLUDE Irvine32.inc.datapacked_1 WORD 4536h ;4536packed_2 WORD 7207h ;7207sum DWORD ?.codemain PROC;初始化数组和索引 mov sum, 0 mov esi, 0;低字节相加 mov al, BYTE PTR packed_1[esi] add al, BYTE PTR packed_2[esi] daa mov BYTE PTR sum[esi], al;高字节相加 inc esi mov al, BYTE PTR packed_1[esi] add al, BYTE PTR packed_2[esi] daa mov BYTE PTR sum[esi], al;若还有进位,加上进位 inc esi mov al, 0 adc al, 0 mov BYTE PTR sum[esi], al;16进制显示和数 mov eax, sum call WriteHex call Crlf call WaitMsg exitmain ENDPEND main 结果就是压缩10进制的显示（16进制的11743） 课后拓展：同长度的任意位相加 扩展上面的程序，使其实现两个任意大小（但长度相同）的压缩十进制数加法，假设该过程使用如下寄存器传递参数： ESI————第一个数的指针 EDI————第二个数的指针 EDX————和数的指针 ECX————相加的字节数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758INCLUDE Irvine32.inc.datapacked1_1 WORD 4536hpacked1_2 WORD 7207hpacked2_1 DWORD 123456hpacked2_2 DWORD 234567hpacked3_1 BYTE 56hpacked3_2 BYTE 41hsum DWORD ?.codemain PROC mov edx, OFFSET sum mov esi, OFFSET packed1_1 mov edi, OFFSET packed1_2 mov ecx, TYPE packed1_1 call AddPacked mov sum, 0 mov esi, OFFSET packed2_1 mov edi, OFFSET packed2_2 mov ecx, TYPE packed2_1 call AddPacked mov sum, 0 mov esi, OFFSET packed3_1 mov edi, OFFSET packed3_2 mov ecx, TYPE packed3_1 call AddPacked call WaitMsg exitmain ENDPAddPacked PROC push ebx mov ebx, 0L1: mov al, BYTE PTR [esi+ebx] add al, BYTE PTR [edi+ebx] daa mov BYTE PTR [edx+ebx], al inc ebx loop L1 mov al, 0 adc al, 0 mov BYTE PTR [edx+ebx], al;16进制显示和数 mov eax, [edx] call WriteHex call Crlf pop ebx retAddPacked ENDPEND main 没啥困难的，注意几个点： 过程定义要定义在.code下，别定义到外面去了 mov [esi], 0 报错而直接mov内存和立即数是可以的，而间接寻址的内存却不可以，不知道为啥-_-|| 位元乘法 编写名为BitwiseMultiply的过程，仅使用移位和加法实现任意32位无符号数与EAX相乘，过程用EBX寄存器传递参数，用EAX寄存器传递返回值。假设乘积不会超过32位。 提示：一种可能的方法是用循环结构右移乘数，记录在进位标志被置1之前移动的位数，然后把这个位数用到SHL指令中，被乘数作为该指令的目的操作数。重复该过程直到乘数最后一个为1位 123456789101112131415161718192021222324252627282930INCLUDE Irvine32.inc.dataval1 DWORD 4536hval2 DWORD 2207h.codemain PROC mov eax, val1 mov ebx, val2 mov ecx, 32 mov edx, 0 ;结果保存在EDX中L1: ror ebx, 1 ;循环位移 jnc L2 ;非1时跳转 add edx, eax ;为1时相加L2: shl eax, 1 ;左移1位 loop L1 mov eax, edx call WriteHex call Crlf mov eax, val1 mov ebx, val2 mul ebx call WriteHex call Crlf call WaitMsg exitmain ENDPEND main 经用标准乘法验证正确，这里我优化了一下，每次循环都让eax移位一次，而只有当CF=1时才让edx和eax相加，写起来就简练很多 复杂的带符号乘除混合运算——2019.11.14补充 若x,y,z,v均为16位带符号数,计算(v-(x*y+z–540))/x 法一:我的实现 1234567891011121314151617181920212223242526.data X DW 1200HY DW 0034HZ DW 0F045HW DW 034AH.codemain PROC xor eax, eax xor edx, edx mov dx, 0 mov ax, X imul Y add ax, Z ;考虑进位, 对高位+cf和0 adc dx, 0 sub ax, 540 ;考虑退位,对高位-cf和0 sbb dx, 0 ;求补码,减法变成加法 neg dx neg ax add ax, W ;同上考虑进位情况 adc dx, 0 idiv X 法二:标答 123456789101112131415161718;省略.code和main声明.data MOV AX, X IMUL Y ; x*y -&gt;（DX,AX） MOV CX, AX ; 临时保存ax MOV BX, DX ; 临时保存dx MOV AX, Z CWD ; Z -&gt;（DX，AX） ADD CX, AX ADC BX, DX ; x*y+z -&gt;（BX，CX） SUB CX, 540 SBB BX, 0 ; x*y+z-540 MOV AX, W CWD ; W -&gt;（DX，AX） SUB AX, CX SBB DX, BX ; w-(x*y+z-540) IDIV X ; (w-(x*y+z-540))/x-&gt;（AX）余数-&gt;（DX）","link":"/2019/08/04/AssemblyLanguageExp-5/"},{"title":"汇编实验","text":"对应基础第6篇的部分 新建多模块程序 大型源文件难于管理且汇编速度慢，可以把单个文件拆分为多个子文件，但是对其中任意子文件的修改都需要对整个文件进行整体汇编。更好的方法是把一个程序按照 模块 （module）分割。每个模块可以单独汇编，因此，对一个模块源代码的修改就只需要重新汇编这个模块。链接器将所有汇编好的模块（obj文件）组合为一个可执行文件的速度相当快，链接大量目标模块比汇编同样数量的源代码花费的时间要少的多 调用外部过程 调用当前模块外的过程时使用EXTERN伪指令，它确定过程名和堆栈帧大小。 12345EXTERN sub1@0: PROC.codemain PROC call sub1@0... 过程名的后缀@n确定了已声明参数占用的堆栈空间总量，若使用PROC伪指令，没有声明参数，则EXTERN中的每个过程名后缀都为@0。 或者，可以用PROTO伪指令来代替EXTERN，不过就需要写出参数了 123AddTwo PROTO, val1: DWORD, val2: DWORD 使用Extern新建模块 PromptForIntegers 提示用户输入三个整数，调用ReadInt来获取值 12345678910111213141516171819202122232425262728293031323334353637INCLUDE Irvine32.inc.codePromptForIntegers PROC;--------------------;提示用户输入整数填充数组;参数: ; ptrPrompt: PTR BYTE ;提示信息字符串; ptrArray: PTR DWORD ;数组指针; arraySize: DWORD ;数组大小;返回:无;---------------------ptrPrompt EQU [ebp+8]ptrArray EQU [ebp+12]arraySize EQU [ebp+16] enter 0, 0 pushad ;保存全部寄存器 mov ecx, arraySize cmp ecx, 0 jle L2 ;小于或等于跳转 mov esi, ptrArray mov edx, ptrPromptL1: call WriteString ;显示字符串 call ReadInt ;整数读入EAX call Crlf mov [esi], eax add esi, 4 loop L1L2: popad leave ret 12 ;恢复堆栈(删除3个参数)PromptForIntegers ENDPEND ArraySum 计算数组元素和并用EAX返回计算结果 12345678910111213141516171819202122232425262728293031323334INCLUDE Irvine32.inc.codeArraySum PROC;-------------------------;计算32位整数数组之和;参数:; ptrArray ;数组指针; arraySize ;数组长度;返回: EAX=和;--------------------------ptrArray EQU [ebp+8]arraySize EQU [ebp+12] enter 0, 0 push ecx push esi mov eax, 0 mov esi, ptrArray mov ecx, arraySize cmp ecx, 0 jle L2L1: add eax, [esi] add esi, 4 loop L1L2: pop esi pop ecx leave ret 8ArraySum ENDPEND DisplaySum 显示标号和和数的结果 123456789101112131415161718192021222324252627282930INCLUDE Irvine32.inc.codeDisplaySum PROC;--------------------------------;在控制台里显示和数;参数:; ptrPrompt ;提示字符串的偏移量; theSum ;数组和(DWORD);返回: 无;--------------------------------theSum EQU [ebp+12]ptrPrompt EQU [ebp+8] enter 0,0 push eax push edx mov edx, ptrPrompt call WriteString mov eax, theSum call WriteInt call Crlf pop edx pop eax leave ret 8DisplaySum ENDPEND StartUp模块用于启动过程（main） 1234567891011121314151617181920212223242526272829303132333435363738394041INCLUDE Irvine32.incEXTERN PromptForIntegers@0:PROCEXTERN ArraySum@0:PROCEXTERN DisplaySum@0:PROCArraySum EQU ArraySum@0PromptForIntegers EQU PromptForIntegers@0DisplaySum EQU DisplaySum@0Count = 3 ;数组大小.dataprompt1 BYTE &quot;Enter a signed integer:&quot;, 0prompt2 BYTE &quot;The sum of the integers is:&quot;, 0array DWORD Count DUP(?)sum DWORD ?.codemain PROC call Clrscr ;清空屏幕;PromptForIntegers(addr prompt1, addr array, Count) push Count push OFFSET array push OFFSET prompt1 call PromptForIntegers;sum = ArraySum(addr array, Count) push Count push OFFSET array call ArraySum mov sum, eax;DisplaySum(addr prompt2, sum) push sum push OFFSET prompt2 call DisplaySum call Crlf call WaitMsg exitmain ENDPEND main INVOKE + PROTO 创建新模块 与更加传统的CALL和EXTERN相比，优势在于：能够将INVOKE传递的参数列表与PROC的列表进行匹配 我们需要编写头文件 1234567891011121314INCLUDE Irvine32.incPromptForIntegers PROTO, ptrPrompt: PTR BYTE, ptrArray: PTR DWORD, arraySize: DWORDArraySum PROTO, ptrArray: PTR DWORD, arraySize: DWORDDisplaySum PROTO, ptrPrompt: PTR BYTE, theSum: PTR DWORD 这样后面的子程序里只用INCLUDE sum.inc来获取过程原型，然后显示声明一下参数如下： 1234PromptForIntegers PROTO, ptrPrompt: PTR BYTE, ptrArray: PTR DWORD, arraySize: DWORD 去掉enter和leave语句，因为MASM遇到PROC伪指令以及其声明的参数时会自动生成这两条语言，同时ret不需要带常数了，PROC会处理好万能的PROC 最后，将启动模块的call调用的过程去掉，换成INVOKE，同时由于include了sum,inc不需要再使用EXTERN，INVOKE指令写法如下: INVOKE PromptForInteger, ADDR prompt1, ADDR array, Count C语言调用外部变量函数的方法和该方法十分的相似(托腮(ˇˍˇ) ) 课后题 由于篇幅受限，就放少量个课后题上来 近似相等元素计数器 编写过程接受两个有符号双字数组指针，表示两个数组长度的参数和表示两个匹配元素间的最大误差（称为diff）的参数。对第一个数组中的每个元素和第二个数组的对应元素，若误差小于等于diff，则计数器加1，用EAX返回相似个数。要求：使用INVOKE语句调用过程并传递堆栈参数，为过程创建PROTO说明，保存并恢复所有会被该过程修改的寄存器（EAX除外） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253.386.model flat, stdcall.stack 4096ExitProcess PROTO, dwExitCode:DWORDdiff = +10CountMatches PROTO, ptr1: PTR DWORD, ptr2: PTR DWORD, arraySize:DWORD.dataarray1 DWORD 5, 7, 9, 11, 12, 13, 15, 14, 10, 19array2 DWORD 1, 2, 3, 4, 5, 6, 7, 8, 9, 10number DWORD LENGTHOF array1.codemain PROC INVOKE CountMatches, ADDR array1, ADDR array2, number INVOKE ExitProcess, 0main ENDPCountMatches PROC, ptr1: PTR DWORD, ptr2: PTR DWORD, arraySize:DWORD ;什么都不用做,PROC会给你弄好关于堆栈的一切 ;只需要正常写就行了 push ecx push esi push edi push ebx mov eax, 0 ;初始化计数器 mov esi, ptr1 mov edi, ptr2 mov ecx, arraySizeL1: mov edx, [esi] sub edx, [edi] cmp edx, diff jg L2 ;大于跳转 inc eaxL2: add esi, 4 add edi, 4 loop L1 pop ebx pop edi pop esi pop ecx retCountMatches ENDPEND main 在过程内无法使用变址操作来索引数据，必须使用间接索引，不知道为啥 同时如果声明指针参数要使用PTR，表示指向现有类型的指针 显示过程参数 编写过程ShowParams，显示被调用过程运行时堆栈中32位参数的地址和十六进制数值。参数按照从低地址到高地址。过程输入只有一个整数，用于表示显示参数的个数，如下： INVOKE MySample, 1234h, 5000h, 6543h 然后在MySample中调用ShowParams,并向其传递希望显示参数的个数： MySample PROC first：DWORD， second：DWORD，third：DWORD paramCount = 3 call ShowParams, paramCount ShowParams将按如下格式输出： Stack Parameters: Address 0012FF80 = 00001234 Address 0012FF84 = 00005000 Address 0012FF88 = 00006543 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566INCLUDE Irvine32.incparamCount = 4MySample PROTO, first:DWORD, second:DWORD, third:DWORD, fourth:DWORD.dataaddrString BYTE &quot;Address &quot;, 0equalSign BYTE &quot; = &quot;, 0.codemain PROC INVOKE MySample, 1234h, 5000h, 4321h, 5h call Crlf call WaitMsgmain ENDPMySample PROC, first:DWORD, second:DWORD, third:DWORD, fourth:DWORD push fourth push third push second push first push paramCount call ShowParam retMySample ENDPShowParam PROC push ebp mov ebp, esp push eax push esi push edx mov ecx, [ebp+8] ;参数个数 cmp ecx, 0 jle L2 mov esi, ebp add esi, 8 ;起始地址 L1: add esi, 4 ;向上走一个数 mov edx, OFFSET addrString call WriteString mov eax, esi ;写出地址 call WriteHex mov edx, OFFSET equalSign call WriteString mov eax, [esi] call WriteDec ;写出数值 call Crlf loop L1L2: pop edx pop esi pop eax mov esp, ebp pop ebp ;清除局部参数 ret 8 + 4 * paramCountShowParam ENDPEND main 写在后面 本节还有一个重要的内容：参数的高级用法，主要讨论32位模式下向堆栈传参的不常见情况，但在查看C/C++编译器创建的代码时可能会用得到，这个将在后面抽空补上 下一讲会先跳过字符串数组的处理，先开宏和结构","link":"/2019/08/06/AssemblyLanguageExp-6/"},{"title":"Django入门——URL调度器","text":"前言 开新坑：Django框架 大一的时候在社团中使用来开发后端，现在整理当时的学习内容并完善，便于后续的查阅。 预计这个模块会有对Django源码的分析，根据我自己的实际情况来（有空就更），目前预计假期会抽出大量时间来阅读分析Django的源代码 什么？你问《程序员的自我修养》那个坑？I’m writing（咕咕咕） URL调度器（URL dispatcher） 本篇博客仅仅介绍在Django中url的书写和配置 博客的撰写基于我自己的使用和官方文档，有些内容还是需要阅读源码才能明白，源码分析的博客暂时处于计划中。 Django如何处理请求 简单的翻译一下就是： 1.首先Django决定使用哪个urls.py文件来作为根设置，这个在settings.py中的ROOT_URLCONF中设置，往往为项目名文件夹下的urls.py，但是如果来的Http请求HTTPRequest对象中有urlconf这个属性（通常由中间件设置），他的值会被用来替代ROOT_URLCONF 2.Django加载对应文件的urlpatterns变量，从中寻找第一个url路径匹配的path或者re_path对象（Django2.2中用它们替代了url对象），装载对象里的函数，或者是基于类的函数，并且向它们传递参数： HttpRequest实例 如果有正则匹配到的组，若没有名字，匹配到的组作为一个位置参数返回；若有名字，则任何匹配到的参数都将传递给要装载的函数。 3.没有任何url被匹配，则调用错误处理的view。 Django中注册url 2.2中path封装了一些常用的正则组，不需要自己书写： 1234567# Django2.2path('articles/&lt;int:year&gt;/&lt;int:month&gt;/&lt;slug:slug&gt;', views.article_detail),# Django 1.xurl(r'^articles/(?P&lt;year&gt;\\[0-9]+)/(?P&lt;month&gt;\\[0-9]+)/(?P&lt;slug&gt;[\\w-]+)$', views.article_detail') 上述写法基本等效，我们的article_detail函数应该长这个样子: def article_detail(request, year, month) 当前端访问了url：/articles/2005/03/时，year参数被传入2005，month参数被传入3 在2.2中，doc给出的例子里/articles/2005/03/中月份的0会被去掉，神奇，应该是做了判断 参数 匹配类型 str 匹配字符，除了&quot;/&quot;符 int 匹配0-9 slug 匹配特殊字符串，他们由-来连接，如：building-your-1st-django-site path 匹配一个路径，即匹配内容包含&quot;/&quot;符 uuid 匹配一个UUID格式的字符串，返回一个UUID的实例 自定义正则模式 doc给出的例子就很好 1234567891011121314151617181920class FourDigitYearConverter: regex = '[0-9]{4}' def to_python(self, value): return int(value) def to_url(self, value): return '%04d' % valuefrom django.urls import path, register_converterfrom . import converters, viewsregister_converter(converters.FourDigitYearConverter, 'yyyy')urlpatterns = [ path('articles/2003/', views.special_case_2003), path('articles/&lt;yyyy:year&gt;/', views.year_archive), ...] 上面的%04d用到了格式化字符串： 可以用如下的方式，对格式进行进一步的控制： %[(name)][flags][width].[precision]typecode (name)为命名 flags可以有+,-,’ ‘或0。+表示右对齐。-表示左对齐。’ '为一个空格，表示在正数的左侧填充一个空格，从而与负数对齐。0表示使用0填充。 width表示显示宽度 precision表示小数点后精度 简单来说，我们自定义了一个yyyy的匹配类型（就想int，str那样），它匹配4位数的年。 注意：自定义的类必须包含如下内容: regex：一个属性，正则匹配的字符串 to_python(self, value)：一个方法，将匹配的内容转成你想要的类型，当无法转换时，你需要抛出一个ValueError的异常来让别的函数捕获（只允许抛出ValueError异常，别的需要自己捕获处理） to_url(self, value)：一个方法，把Python类型转为一个字符串用于正则匹配 re_path re_path和老版的url基本类似，使用Python正则的语法，如(?Pxxx)表示匹配组然后可以用key获取到这个组而不是用group(x)来获取 这里只需要看一点：doc中的一个推荐规范要求 123456from django.urls import re_pathurlpatterns = [ re_path(r'^blog/(page-(\\d+)/)?$', blog_articles), # bad re_path(r'^comments/(?:page-(?P&lt;page_number&gt;\\d+)/)?$', comments), # good] 在正则中，我们用圆括号将所有选择项括起来，相邻的选择项之间用|分隔。但用圆括号会有一个副作用，使相关的匹配会被缓存，此时可用?:放在第一个选项前来消除这种副作用。 该例子中第二个就消除了page-的缓存，这个url捕获的参数仅仅只有属于整数的page_number，而第一个就捕获（缓存）了“page-”和我们需要的整数 url查找 请求的URL被看做是一个普通的Python 字符串， URLconf在其上查找并匹配。进行匹配时将不包括GET或POST请求方式的参数以及域名。 name参数 你可以把它理解为对url的注释（comment） 有了这个注释，你的所有需要输入该url的地方都可以换成这个comment 这通常使用在 view里的重定向中： 123def login_page(request): # do something return redirect(&quot;hello&quot;) html里涉及到的url跳转 1234&lt;a href=&quot;{% url 'hello' %}&quot;&gt;hello&lt;/a&gt;&lt;form method='post' action='{% url 'hello' %}'&gt;......&lt;/form&gt; 有什么好处呢？当然有了，当你需要修改url的时候（比如网站上线等），如果所有的url都是以硬编码的方式写在你的文件里，那么修改起来十分麻烦，如果使用了name，这样就可以只修改对应path的前面的匹配即可 留意，这个name必须全局唯一，官方文档推荐的命名方式是： Putting a prefix on your URL names, perhaps derived from the application name (such as myapp-comment instead of comment), decreases the chance of collision. 即name的命名中最好包括你的app的名字 include参数 上面使用name的方法也确实可以，但看起来不太美观，并且当你的项目需要很多的url时，你的root urlconf会十分庞大，难以维护。 最好的方式当然是分开写。 URL namespaces 就如同C++的命名空间一样，Django的app也是单独的命名空间。demo app下的一个url命名为“home”，foo app下一个url命名为“home”，他们处于不同的命名空间下，这时如果我们还想像前面一样访问，就不能简单用“home”来区分他们，需要加入命名空间 demo app 的 home url:demo:home foo app 的 home url: foo:home namespace也可以嵌套（nested），不过用的不多，doc里给了个例子: The named URL ‘sports:polls:index’ would look for a pattern named ‘index’ in the namespace ‘polls’ that is itself defined within the top-level namespace ‘sports’. 这样我们每个app维护一个urls.py文件，项目的路由就被合理的分开了 include + namespace 但外部访问的url只匹配root urlconf对应的文件的urlpattern，这时候我们就需要include来把app的urls.py包括进来。 官方文档的例子: 123456789101112131415161718# urls.pyfrom django.urls import include, pathurlpatterns = [ path('polls/', include('polls.urls')),]# polls/urls.pyfrom django.urls import pathfrom . import viewsapp_name = 'polls'urlpatterns = [ path('home/', views.home, name='home'), ...] 这时，我们要想访问home，就需要访问&quot;/poll/home/&quot;这个url，即所有被include的url都需要在最前面多一段 include 的调用者url路径才可以访问的到 使用include同时指定namespace urls.py1234567from django.urls import include, pathfrom demo.views import home_pageurlpatterns = [ path('demo/', include((&quot;demo.urls&quot;, &quot;demo&quot;), namespace=&quot;demo&quot;)),] namespace的名字并非必须与app的名字保持一致，但我比较喜欢这么做，一目了然（老版本好像必须一致）。 需要注意2.2和老版本不同的是，include的第一个参数为元组，不仅需要指定include的url而且要指出app的名字，不然会报错。 include 当然include也不一定要跨文件来引用别的url，同一个urlpattern下也可以使用include来将包含同一段url的合在一起 123456789101112from django.urls import include, pathfrom demo.views import home_pageurlpatterns = [ path('demo/', include((&quot;demo.urls&quot;, &quot;demo&quot;), namespace=&quot;demo&quot;)), path('test/', include([ path('test1', home_page), path('test2', home_page), ])) ] doc中给了另一种用法,也很有参考意义，比上面的更加清晰规范 123456789101112from django.urls import include, pathfrom . import viewspolls_patterns = ([ path('', views.IndexView.as_view(), name='index'), path('&lt;int:pk&gt;/', views.DetailView.as_view(), name='detail'),], 'polls')urlpatterns = [ path('polls/', include(polls_patterns)),] views.IndexView.as_view()是基于类的视图的写法 kwargs–hock 你可以在path里面加入字典形式的参数，这些被称为“钩子”（hock）（老版doc里这么叫，新版好像不这么说了） 目前我还没发现有啥用… -_-|| path无include的情况 urls.py123456from django.urls import pathfrom . import viewsurlpatterns = [ path('blog/&lt;int:year&gt;/', views.year_archive, {'foo': 'bar'}),] 这样相当于我们给了year_archive()函数一个我们指定的参数:foo，它的值为’bar’，当url为“/blog/2005/”，Django会调用views.year_archive(request, year=2005, foo='bar') path里有include的情况 基本能猜到，就是被包含的所有url里都有这个额外参数 12345678910111213141516171819202122232425262728293031from django.urls import include, pathurlpatterns = [ path('blog/', include('inner'), {'blog_id': 3}),]# inner.pyfrom django.urls import pathfrom mysite import viewsurlpatterns = [ path('archive/', views.archive), path('about/', views.about),]# 下面的写法和上面等效from django.urls import include, pathfrom mysite import viewsurlpatterns = [ path('blog/', include('inner')),]# inner.pyfrom django.urls import pathurlpatterns = [ path('archive/', views.archive, {'blog_id': 3}), path('about/', views.about, {'blog_id': 3}),] 后记 看doc基本看得一知半解，更清晰的理解需要认真阅读代码，我挺期待自己空下时间来阅读阅读大神的代码，但我太忙了 我太难了，我也不知道自己在忙啥，就是贼忙 现在的中心大部分还在学校课时上，我尽力保障每周1-2更 《程序员的自我修养》看得比较慢，有点难…","link":"/2019/10/15/Django-fresher-1/"},{"title":"Django入门——视图函数","text":"迟到的更新 视图函数 概述 A view function, or view for short, is simply a Python function that takes a Web request and returns a Web response. This response can be the HTML contents of a Web page, or a redirect, or a 404 error, or an XML document, or an image . . . or anything, really. The view itself contains whatever arbitrary（任意的）logic is necessary to return that response. the convention is to put views in a file called views.py, placed in your project or application directory. 文档里说的很清楚，view（视图函数）的功能就是一个Python的函数，它接受请求（request），作为函数的第一个参数，然后返回一个响应（response） 而我们的逻辑（logic）就写在函数体里 写法 HTTPResponse 以文档的例子： 1234567from django.http import HttpResponseimport datetimedef current_datetime(request): now = datetime.datetime.now() html = &quot;&lt;html&gt;&lt;body&gt;It is now %s.&lt;/body&gt;&lt;/html&gt;&quot; % now return HttpResponse(html) request是一个HttpRequest对象，具体这个对象的定义，需要阅读代码 return HTTPResponse就是我们所说的返回一个response响应，Django对它进行了封装，就是我们看到的HTTPResponse 有了这个逻辑函数，你在urls.py里的urlconf用path对应一下，将所有请求某个url的逻辑全部交给它来处理，这就是view层负责的工作 HTTPResponse继承自HttpResponseBase 属性有： content：表示返回的内容 charset：response采用的编码字符集 status：响应的HTTP状态码(在django1.x为status_code) content_type：指定响应头里的Content-Type，即返回数据的类型 Content-Type Http Header里的Content-Type一般有这三种： application/x-www-form-urlencoded：数据被编码为名称/值对。这是标准的编码格式。 multipart/form-data： 传输文件。 text/plain： 数据以纯文本形式进行编码 application/json ：json格式 form表单的enctrype属性即为编码方式， 常用有两种：application/x-www-form-urlencoded和multipart/form-data，默认为application/x-www-form-urlencoded。 jquery的ajax方法默认使用application/x-www-form-urlencoded 当请求的Content-Type为application/x-www-form-urlencoded浏览器用x-www-form-urlencoded的编码方式把form数据转换成一个字串（name1=value1&amp;name2=value2…）,同理为application/json时会转换为json数据格式 123# 自然返回的是hello几个字def test(request): return HttpResponse(content=&quot;hello&quot;, status=200, content_type=&quot;text/plain&quot;) 常用方法有： set_cookie(key, value=‘’, max_age=None, expires=None, path=‘/’, domain=None, secure=False, httponly=False, samesite=None) delete_cookie(key, path=‘/’, domain=None) 挑几个重要的参数说： max_age：持续最大时间 expires：过期时间 domain：请求的域名 write(content)：以文件的方式写 render&amp;redirect render是HTTPResponse的一个简写函数，它渲染指定的html然后返回（当然返回的也是HTTPResponse对象） redirect是HTTPResponseRedirect的简写函数，由后端发起一个重定向，将访问指定的url redirect(to, args, kwargs) 推荐使用reverse解析 reverse(viewname, urlconf, args, kwargs, current_app) 使用reverse就是解析你的url里的name然后获取url来填入重定向的url，当然，kwargs是和path的捕获组相对应，通过这样来指定捕获组的内容，这个参数会被接着传给重定向的url的处理函数里 123456789101112131415# views.pydef test(request): content_type=&quot;text/plain&quot;) return redirect(reverse(&quot;demo:ha&quot;, kwargs={&quot;name&quot;: &quot;cyx&quot;}))# 主路由urls.pyurlpatterns = [ path('admin/', admin.site.urls), path('demo/', include(('demo.urls', 'demo'), namespace='demo')),]# demo.urls.pyurlpatterns = [ path('test/&lt;str:name&gt;/', test2, name=&quot;ha&quot;)] Http404 exception 当我们想返回一个404页时使用 return HttpResponseNotFound('&lt;h1&gt;Page not found&lt;/h1&gt;') 或者 raise Http404(&quot;Poll does not exist&quot;) 这个错误只会在debug时显示出来 关于404页官方文档的描述 in order to show customized HTML when Django returns a 404, you can create an HTML template named 404.html and place it in the top level of your template tree. This template will then be served when DEBUG is set to False. 当我们关闭debug模式时，我们只需要在template里创建一个404.html，所有的404页都会调用它 request 这个就有很多能说的，这里只列举常用的： request.session 操作session,可以通过键值对的方式向里面添加元素 123456request.session['key'] = value # 设置键值对request.session.get('key', default=) # 获取键值对request.session.clear() # 清空此次会话的所有保存值request.session.set_expiry(value) # 设置session过期时间# value为整形，表示秒# 不填默认为2周后过期 request.method 获取请求的方法，GET或者POST，可以通过它和if来使不同请求在一个views函数里处理好 request.POST.get获取用户POST的内容 request.GET.get获取GET的参数 （自动urldecode过了） request.FILE request.FILE获取的是传入的所有的文件,他们以上传的文件名和二进制数据保存在里面 可以用下面的方法获取数据： 1234567def handle_uploaded_file(f): with open('some/file/name.txt', 'wb+') as destination: for chunk in f.chunks(): destination.write(chunk)# view里有这个handle_uploaded_file(request.FILES['file_name']) 待补充 想到了再加 views函数修饰器 你完全可以自己写，比如一个限制所有网站访问权限的修饰器 Django给你提供了一些视图函数修饰器： require_http_methods(request_method_list) Decorator to require that a view only accepts particular request methods. doc的代码示例： 1234567from django.views.decorators.http import require_http_methods@require_http_methods([&quot;GET&quot;, &quot;POST&quot;])def my_view(request): # I can assume now that only GET or POST requests make it this far # ... pass require_GET() Decorator to require that a view only accepts the GET method require_POST() Decorator to require that a view only accepts the POST method gzip_page() GZip 压缩 cache_control() 装饰器通过添加所有关键字参数来修补响应的 Cache-Control 头 never_cache(view_func) 告诉浏览器不缓冲页面 后记 doc这一个部分写的是真的少，都靠我当时学校1.11时的笔记和实践来补充的一些内容，深夜更新","link":"/2019/10/26/Django-fresher-2/"},{"title":"程序员的自我修养——Linux共享库","text":"Linux 共享库 共享库（Shared Library）其实在文件结构上和共享对象没有什么区别，Linux 下的共享库就是普通的 ELF 共享文件。由于共享对象可以被各个程序使用，所以它就成了库的很好的存在形式。 共享库的命名 有必要了解一下你的 Linux 里面那群 xxx.so.1… 表示啥含义的 共享库的命名模板为: libname.so.x.y.z 其中最前面使用前缀 “lib”，中间的库名和 “.so” 后缀。最后面跟着的三个数字表示版本号。 “x” 表示主版本号（Major Version Number），表示库的重大升级，不同主版本号之间不兼容。 “y” 表示次版本号（Minor Version Number），表示库的增量升级，即增加一些新的接口符号，且保持原来的符号不变。 “z” 表示发布版本号（Release Version Number），表示库的一些错误的修正，性能改进，并不增加新的接口，也不对接口进行更改。 大体上按照这样的标准，但实际上有不少库的名字并不符合这个模板。 SO-NAME 在 Linux 系统中，系统会为每个共享库在它的所在目录创建一个和 “SO-NAME” 相同的并且指向它的软链接（Symbol Link）。比如说系统中有一个共享库 /lib/libfoo.so.2.6.1，那么 Linux中的共享库管理程序就会为它产生一个软链接 /lib/libfoo.so.2 指向它。 建立以 SO-NAME 为名字的软链接的目的是，使得所有依赖某个共享库的模块，在编译，链接和运行时，都使用共享库的 SO-NAME，而不使用详细的版本号。 共享库系统路径 目前大多数包括 Linux 在内的开源操作系统都遵循一个叫做**FHS（File Hierarchy Standard）**的标准。根据其规定，一个系统中主要有3个存放共享库的位置： /lib: 这个位置主要放系统最关键和基础的共享库，比如说动态链接器，C 语言运行库，数学库 /usr/lib: 这个目录下主要保存的是一些非系统运行时所需要的关键性的共享库，主要是一些开发时用到的共享库，这些共享库一般不会被用户的程序或 Shell 脚本直接用到。这个目录下面还包含了一些开发时可能用到的静态库，目标文件。 /usr/local/lib: 这个目录用来放置一些跟操作系统本身并不相关的库，主要是一些第三方应用程序的库。比如说 python 语言的解释器。GNU 的标准推荐第三方的应用程序的库全部安装到 usr/local/lib 下。 共享库查找过程 在开源的系统中，包括所有的 Linux 系统在内的很多都是基于 Glibc 的。我们知道在这些系统里面，动态链接的 ELF 可执行文件在启动的同时会启动动态链接器。在 Linux 系统中，动态链接器是 /lib/ld-linux.so.X(version)。程序所依赖的共享对象全部由动态链接器负责装载和初始化。任何一个动态链接器的模块所依赖的模块路径保存在 “.dynamic” 里面，由 DT_NEED 类型的项来表示。如果保存的是绝对路径，则就会去按照这个路径寻找。如果是相对路径，那么动态链接器会在 /lib, /usr/lib 和 /etc/ld.so.conf 配置文件指定的目录中查找共享库。 1234567/etc$ cat ld.so.confinclude /etc/ld.so.conf.d/*.conf/etc$ cd ld.so.conf.d/etc/ld.so.conf.d$ lsfakeroot-x86_64-linux-gnu.conf libc.conf zz_i386-biarch-compat.confi386-linux-gnu.conf x86_64-linux-gnu.conf zz_x32-biarch-compat.conf 如果动态链接器每次都要去查找这些文件目录，将会非常耗时间。所以 Linux 系统中有一个叫做 ldcofig 的程序，这个程序的作用是为共享库目录下的各个共享库文件创建，删除，更新相应的 SO-NAME（符号链接），这个程序还会收集这些 SO-NAME，集中放到 /etc/ld.so.cache 里面查找。如果没有找到，还是需要遍历 /lib, /usr/lib 这两个目录去寻找，如果还是找不到就链接失败。 理论上我们增加，删除，更新任意一个共享库或者我们修改了 /etc/ld.so.conf 的配置，都需要运行 idcofig 这个程序。很多软件包的安装程序往往在里面安装共享库以后都会调用 idcofig 环境变量 LD_LIBRARY_PATH Linux 提供很多方法来改变动态链接装载共享库路径的方法，使用这些方法我们可以满足一些特殊的要求，比如共享库的调试和测试，应用程序级别的虚拟等。改变共享库查找路径最简单的方法是使用 LD_LIBRARY_PATH 环境变量，这个方法可以临时改变某个应用程序的共享库查找路径，而不会影响系统中的其他程序。 总的来说，动态链接器会按照下列顺序依次装载或查找共享对象（目标文件）： 由环境变量 LD_LIBRARY_PATH 指定的路径 由路径缓存文件 /etc/ld.so.cache 指定的路径 默认共享库目录，先 /usr/lib 再 /lib LD_PRELOAD 系统中另外还有一个环境变量叫做 LD_PRELOAD，这个文件中我们可以指定预先装载的一些共享库甚或是目标文件。在LD_PRELOAD 里面指定的文件会在动态链接器按照固定的规则搜素共享库之前装载，它比 LD_LIBRARY_PATH 里面所指定的目录中的共享库还要优先。无论程序是否依赖于它们，LD_PRELOAD 里面指定的共享库或目标文件都会被装载。 由于全局符号介入这个机制的存在，LD_PRELOAD 里面指定的共享库或目标文件中的全局符号就会覆盖后面加载的同名全局符号，正常情况下应该避免使用 LD_PRELOAD LD_DEBUG 这个变量可以打开动态链接器的调试功能，当我们设置这个变量是，动态链接器会在运行时打印各种有用的信息。 值 含义 bindings 显示动态链接的符号绑定过程 libs 显示共享库的查找过程 versions 显示符号的版本依赖关系 reloc 显示重定位过程 symbols 显示符号表查找过程 statistics 显示动态链接过程中的各种统计信息 all 显示以上全部信息 help 显示上面的各种可选值和帮助信息 我们运行一个简单的动态链接程序 hello.c12345#include&lt;stdio.h&gt;int main(int argc, char* argv[]){ printf(&quot;Hello World&quot;);} 用 gcc 编译然后设置 LD_DEBUG 值执行： 123456789101112131415161718$ LD_DEBUG=libs ./hello 57: find library=libc.so.6 [0]; searching 57: search cache=/etc/ld.so.cache 57: trying file=/lib/x86_64-linux-gnu/libc.so.6 57: 57: 57: calling init: /lib/x86_64-linux-gnu/libc.so.6 57: 57: 57: initialize program: ./hello 57: 57: 57: transferring control: ./hello 57: 57: 57: calling fini: ./hello [0] 57:Hello World 共享库的创建 创建共享库的过程和创建一般的共享对象的过程基本一致，最关键的是使用 GCC 的两个参数，即 “-shared” 和 “-fPIC”。“-shared” 表示输出结果是共享库类型的， “-fPIC” 表示使用地址无关代码的技术来生成输出文件。另外还有参数是 “-WI”，这个参数可以将指定的参数传递给链接器，比如当我们使用 “-Wl, -soname, my_soname” 时，GCC 会将 “-soname my_soname” 传递给链接器来指定输出共享库的 SO-NAME。 我们可以使用下面的命令来生成一个共享库 $gcc -shared -Wl, -soname, my_soname -o library_name source_files... !如果我们不使用 -soname来指定，那么该共享库默认没有 SO-NAME，使用 idconfig 更新软链接时对该共享库是无效的 例如我们有源码 “libfoo1.c” 和 “libfoo2.c”，我们希望产生一个 “libfoo.so.1.0.0” 的共享库，这个共享库依赖于 “bar1.so” 和 “bar2.so”，这样你就可以使用下面命令: $gcc -shared -fPIC -Wl, -soname, libfoo.so.1 -o libfoo.so.1.0.0 libfoo1.c libfoo2.c -lbar1 -lbar2 多步进行: 1234$gcc -c -g -Wall -o libfoo1.o libfoo1.c$gcc -c -g -Wall -o libfoo2.o libfoo2.c$ld -shared -soname libfoo.so.1 -o libfoo.so.1.0.0 \\libfoo1.o libfoo2.o -lbar1 -lbar2 清除符号信息 正常情况下编译出来的共享库或可执行文件里面带有符号信息和调试信息，这些信息在调试时很有用，但对于最终的发布版本意义不大。我们可以使用一个叫 “strip” 的工具清除掉共享库或可执行文件的所有符号和调试信息，这样可以减少文件的大小 strip libfoo.so 也可以使用 ld 的 “-s” 和 “-S” 参数，使得在生成输出文件时就不产生符号信息，前者消除所有的符号信息，后者消除调试符号信息。","link":"/2020/09/14/Linkers-Loaders-10/"},{"title":"Linkers-Loaders-11","text":"内存 程序的环境由：内存，运行库，系统调用组成。 我们在前面已经提到过了，大多数操作系统会将一部分内存挪用给内核使用，应用程序一般无法使用，一个 Linux 进程里的经典内存布局如下： 栈 关于栈，我们其实已经相当熟悉了（陌生的可以去看汇编模块的过程调用篇，有对过程调用中栈的变化有说明）。 而在 C++ 里返回一个对象的时候，对象要经过2次拷贝构造函数的调用才可以完成返回对象的传递，1次拷贝到栈上的临时对象里，另一次把临时对象拷贝到存储返回值的对象里。 这样带来一个恶果，就是返回较大的对象时会有非常多的额外开销，因此 C++ 程序中避免返回对象，同时为了减小返回对象的开销，C++ 提出了返回值优化（Return Value Optimization, RVO）的技术，可以在某些场合减少对象的拷贝1次。如下: 1234cpp_obj re_test(){ return cpp_obj();} 这时，构造一个 cpp_obj 对象会调用一次他的构造函数，在返回时会调用拷贝构造函数。c++的返回优化可以将这两部合并，直接构造在传出时使用的临时变量，减少一次复制的过程。 堆 堆（Heap）是一块巨大的内存空间，常常占用整个虚拟空间的绝大部分，在这里，程序可以申请一块连续的内存空间，这块内存再程序主动放弃之前都会一直的有效。 我们常常使用 malloc() 分配空间，直到 free() 去释放它们之前，程序都可以自由的使用。 malloc() 是如何实现的？有一种做法是把进程的内存管理交给操作系统的内核去做，既然内核管理者进程的地址空间，那么它提供一个系统调用，让程序使用这个系统调用去申请内存就可以了。这是一个理论上可行的方法，但实践起来性能相当的差，程序每次需要申请或者释放内存的时候就需要系统调用，而系统调用的性能开销很大，这时就会极大的影响程序的性能。比较好的做法是程序向操作系统申请一块适当大小的堆空间，然后由程序自己管理这块空间。 进程堆管理 Linux 下进程堆的管理稍微有些复杂，它提供了两种堆空间的分配方式，即两个系统调用：一个是 brk() 系统调用，另外一个是 mmap()。 brk() 的实际作用就是设置进程数据段的结束地址，即它可以扩大或缩小数据段（Linux 下数据段和 BSS 一起统称数据段）。如果我们将数据段的结束地址向高地址移动，那么扩大的部分就可以被使用，把这块空间拿来作为堆空间是最常见做法之一。 mmap() 的作用就是向操作系统申请一段虚拟地址空间，这块虚拟地址空间可以映射到某一个文件（这也是这个系统调用的最初的作用），当你不将这块地址空间映射到某个文件时，我们又称这块空间为匿名（Anonymous）空间，匿名空间就拿来作堆空间。函数声明和官方文档解释如下： void *mmap(void *addr, size_t length, int prot, int flags,int fd, off_t offset); mmap() creates a new mapping in the virtual address space of the calling process. The starting address for the new mapping is specified in addr. The length argument specifies the length of the mapping (which must be greater than 0). If addr is NULL, then the kernel chooses the address at which to create the mapping; this is the most portable method of creating a new mapping. If addr is not NULL, then the kernel takes it as a hint about where to place the mapping; on Linux, the mapping will be created at a nearby page boundary. The address of the new mapping is returned as the result of the call. brk()的文档看不懂就不贴了 prot/flags 用于设置申请的空间的权限（可读可写可执行），映射类型（文件，匿名） 新的地址空间将会从一个页的边界开始（意思大概是会舍弃不够大小的一个页的剩余部分） Glibc 的 malloc 函数是这样处理用户的空间请求的：如果小于 128KB，它会在现有的堆空间里按照堆分配算法分配一块空间出来并返回，对于大于 128KB 的请求来说，它会使用 mmap() 函数为它分配一块匿名空间，然后在这个匿名空间中为用户分配空间。 ps：我们注意一个点：分配内存都是对进程分配的，也就是说给我们正在运行的一个程序分配，当这个进程中止时，进程的相关资源（如进程的地址空间，物理内存，打开的文件，网络连接等）将会被操作系统关闭或回收，所以 malloc 申请的内存在程序结束后不会再存在。（这让我想起当时问c++老师和c老师的这个问题，老师很模糊的回答让我一度认为这样的空间会被一直占用直到内存断电） 堆内存分配算法 1. 空闲链表 空闲链表（Free List）就是将堆中各个空闲的块按照链表的方式连接起来，当用户申请空间时，遍历整个链表找到合适大小的块并将它拆分，释放空间时将它合并进入空闲链表。 一个链表的节点由空闲空间的开头，上一个空闲块的地址，下一个空闲块的地址组成，分配空间时找到大小合适的空闲块，将其分为两部分，一部分给用户，一部分作为新的空闲空间，将空闲链表中该位置节点的信息修改掉，如果刚好够，就删去这个点。 但是释放时就遇到一个问题，不知道块的大小，这时就需要一个额外字段（如用户要k分k+4，用多出来的4字节记录分配出去这一块的大小）来记录大小。当然，问题不只有这一个，一旦链表被破坏或者记录字段被修改，整个堆就无法正常的工作了。 2. 位图 针对空闲链表的弊端，人们提出了位图（Bitmap）方法，其核心思想就是将整个堆划分为大量的块（Block），每个块大小相同，当用户请求内存时总是分配整数个块的空间给用户，第一个块我们称为已分出去的头（Head），其余的称为分配区域的主体（Body），我们采取一个整数数组来记录块的使用情况，由于每个块只有头/空闲/主体3个状态，所以仅仅需要2位。 位图为: （High）11 00 00 10 10 11 00 00 00 00 00 00 00 10 11（Low） 缺点同样很明显，如碎片内存会有很多，当位图很大时有可能失去Cache命中率高的优势 3. 对象池 对象池的思路很简单，如果每次分配的空间大小都是一样的，那么按照这个每次请求分配的大小作为一个单位，将堆空间划分为大量的小块，每次分一个出去。由于假定了每次请求都是一个固定的大小，所以可以快速满足请求。实现方法用空闲链表或者位图都可以。 实际上在现实的应用中，堆分配算法往往是采取多种算法复合而成的，比如对于 glibc 来说，它对于小于64字节的空间申请是采用类似对象池的方法，而对于大于512字节的空间采用的是最佳适配算法，在2者中间的采用上述方法的折中策略，对于大于 128KB 的申请，直接走 mmap() 向操作系统申请空间。 Glibc的分配方法 待更新，学习中…","link":"/2020/09/23/Linkers-Loaders-11/"},{"title":"程序员的自我修养——编译和链接","text":"编译和链接 在一般的IDE中，编译和链接被合并在了一起，称为构建（build），往往一些本质的东西是无法了解到 被隐藏的过程 在Linux下如果使用gcc编译一个c语言程序，只需最简单的命令： gcc hello.c ./a.out 事实上，上述的过程可以分为4个步骤： 预处理（Prepressing） 编译（Compilation） 汇编（Assembly） 链接（Linking） 预编译 首先是源代码文件hello.c和相关的头文件，如stdio.h等被预编器cpp预编译成一个.i文件。对于C++程序来说，它的源代码文件的扩展名可能是.cpp或.cxx，头文件的扩展名可能是.hpp，而预编译后的扩展文件名是.ii，第一步预编译的过程相当于如下命名： gcc -E hello.c -o hello.i 其中-E表示只进行预编译 或者： cpp hello.c &gt; hello.i 预编译过程主要处理那些源代码中的以 “#” 开头的预编译指令，主要处理规则如下： 将所有的&quot;#define&quot;删去，并且展开所有的宏定义 处理所有的条件预编译指令，如 “#if”、“#ifdef” 等 处理&quot;#include&quot;预编译指令，将被包含的文件插入到该预编译指令的位置 删除所有的注释 添加行号和文件名标识，比如#2&quot;hello.c&quot; 2，以便编译时产生调试用的行号信息，提示错误等等 保留所有的&quot;#pragma&quot;编译指令，因为编译器需要使用它们 编译 编译过程就是把预处理完成的文件进行一系列词法分析，语法分析，语义分析以及优化后生成相应的汇编代码文件。 gcc -S hello.i -o hello.s 得到编译输出的汇编文件hello.s 汇编 汇编器将汇编代码转变为机器可以执行的指令，每个汇编语句几乎对应一条机器指令。上面的汇编我们可以调用汇编器as来完成 as hello.s -o hello.o 也可以用gcc直接从c源码输出目标文件 gcc -c hello.c -o hello.o 链接 我们需要把一大堆文件链接起来才能得到&quot;a.out&quot;，即最终的可执行文件， 链接过程会链接一些程序如：crt1.o、crti.o、crtbeginT.o、crtend.o、crtn.o 编译器做了什么 最直观的说，编译器将高级语言转化为机器语言。 细一点说，就是上面提到的词法分析和语法分析那些。 词法分析 首先，源代码程序被输入到扫描器（Scanner）中，扫描器的任务很简单，它只是简单的进行词法分析，运用一种类似于有限状态机（Finite State Machine）的算法可以轻松地将源代码的字符串分割为一系列的记号（Token），有一个叫做lex的程序可以实现词法扫描。 有限状态机 有限状态自动机（FSM “finite state machine” 或者FSA “finite state automaton” ）是为研究有限内存的计算过程和某些语言类而抽象出的一种计算模型。有限状态自动机拥有有限数量的状态，每个状态可以迁移到零个或多个状态，输入字串决定执行哪个状态的迁移。有限状态自动机可以表示为一个有向图。有限状态自动机是自动机理论的研究对象(来源百度) Lex Lex 是一种生成扫描器的工具。扫描器是一种识别文本中的词汇模式的程序。 这些词汇模式（或者常规表达式）在一种特殊的句子结构中定义。 一种匹配的常规表达式可能会包含相关的动作。这一动作可能还包括返回一个标记。 当 Lex 接收到文件或文本形式的输入时，它试图将文本与常规表达式进行匹配。 它一次读入一个输入字符，直到找到一个匹配的模式。 如果能够找到一个匹配的模式，Lex 就执行相关的动作（可能包括返回一个标记）。 另一方面，如果没有可以匹配的常规表达式，将会停止进一步的处理，Lex 将显示一个错误消息。 Lex 和 C 是强耦合的。一个 .lex 文件（Lex 文件具有 .lex 的扩展名）通过 lex 公用程序来传递，并生成 C 的输出文件。这些文件被编译为词法分析器的可执行版本。 词法分析产生的记号可以分为如下几类：关键字，标识符，字面量（含数字，字符串）和特殊符号（加号，等号） 如： array[index] = (index + 4) * 2 记号 类型 array 标识符 [ 左方括号 index 标识符 ] 右花括号 = 赋值 ( 左圆括号 index 标识符 + 加号 4 数字 ) 右圆括号 * 乘号 2 数字 语法分析 接下来语法分析器（Grammar Parser）将对扫描器产生的记号进行语法分析，从而产生语法树（Syntax Tree）。整个分析采取**上下文无关语法（Context-free Grammar）**的分析手段 上下文无关语法分析手段 由语法分析器生成的语法树就是以**表达式（Expression）**为节点的树。我们知道，C语言的一个语句是一个表达式，而复杂的语句是多个表达式的组合。 以书上的语法树的样子作为一个例子： 这个例子中，整个语句被当做一个赋值表达式，在语法分析的同时，很多的运算符号的优先级和含义也被确定下来了。 语法分析也有一个现成的工具yacc（Yet Another Compiler Compiler）。对于不同的编程语言，编译器的开发者只需要改变语法规则，而无需为每个编译器写一个语法分析器，所以它又被称为**“编译器编译器（Compiler Compiler）”** yacc 我们看到 Lex 从输入序列中识别标记。 如果你在查看标记序列，你可能想在这一序列出现时执行某一动作。这种情况下有效序列的规范称为语法。Yacc 语法文件包括这一语法规范。它还包含了序列匹配时你想要做的事。 为了更加说清这一概念，让我们以英语为例。 这一套标记可能是：名词, 动词, 形容词等等。为了使用这些标记造一个语法正确的句子，你的结构必须符合一定的规则。 一个简单的句子可能是名词+动词或者名词+动词+名词。(如 I care. See spot run.) 用 Yacc 来创建一个编译器包括四个步骤： 通过在语法文件上运行 Yacc 生成一个解析器。 说明语法： 编写一个 .y 的语法文件（同时说明 C 在这里要进行的动作）。 编写一个词法分析器来处理输入并将标记传递给解析器。 这可以使用 Lex 来完成。 编写一个函数，通过调用 yyparse() 来开始解析。 编写错误处理例程（如 yyerror()）。 编译 Yacc 生成的代码以及其他相关的源文件。 将目标文件链接到适当的可执行解析器库。 语义分析 语义分析由语义分析器（Semantic Analyzer）来完成，语法分析仅仅只是表面的上的分析，但他并不明白这个语句真正有没有含义。编译器能分析的语义是静态语义（Static Semantic），在编译期间可以确定的语义，而对应的**动态语义（Dynamic Semantic）**就只有在运行中才可以确定。 静态语义通常包括声明和类型匹配，类型转换。如：浮点数赋值给了一个整型，隐含一个转换，就需要静态语义的分析。 动态语义就是分析运行时的语义问题，如：0不能做除数，需要抛出错误异常等，需要动态语义分析 中间语言生成 现代的编译器有很多层的优化，往往在源代码级别会有一个优化过程，称为源码级优化器（Source Code Optimizer） 源码优化器往往会将整个语法树转换为中间代码（Intermediate Code），中间代码很接近目标代码了，只是其与运行的机器的环境无关，如：不包含数据的尺寸，变量地址，寄存器名称。中间代码有很多的类型，比较常见的是三地址码（Three-address Code）和P-代码（P-Code） 最基本的三地址码是这样的： x = y op z 一般为了使所有的操作都符号三地址码，往往需要添加中间变量 12345678array[index] = (index + 4) * 2// 三地址码t1 = index + 4t1 = t1 * 2array[index] = t1 目标代码的生成 **代码生成器（Code Generator）**将中间代码转换为目标机器代码。 生成目标代码后会进一步的优化，如选择合适的寻址方式，使用移位来代替乘法，删除多余的指令等。 经过扫描，语法语义分析，源代码优化，代码生成和目标代码的优化，源代码被编译为目标代码，但如果想要使用汇编编译成真正能够在机器上执行的指令，还需要考虑一些别的问题： 上述代码中index和array的地址怎么获得 如果只是在一个文件里，直接分配空间就可以确定地址，但如果在别的程序模块里呢？ 链接器 当程序设计模块化时，各个模块直接通信依赖的就是链接（Linking），链接又分2种，静态链接和动态链接 链接的主要作用就是把各个模块之间的符号引用部分处理好。它所做的工作就是调地址，修正一些引用。链接的过程主要包括：地址空间分配（Address and Storage Allocation），符号决议（Symbol Resolution），重定位（Relocation） 以c语言为例，当我们在main里引用了再func.c里声明的函数foo()，那么在编译main.c时。编译器并不知道foo函数的地址，所以它就先搁置，等链接时去修正，链接器会把待修正的地址根据在引用的目标文件里查找来修正，这个修正的过程叫重定位，每个修正的地方叫重定位入口（Entry） 静态链接 最基本的静态链接就是把库和目标文件链在一起，最常见的就是运行时库（Runtime Library），库就是一组目标文件的包，把一些常用的代码编译成目标文件然后打包存放起来。 动态链接 为了节省内存，在运行时只装载一部分的文件进入内存，同时保障程序正常运行。常见的.dll文件就是动态链接库 后记——实验环境 我的Linux机又又又炸了，忍无可忍，在windows下用wsl windows装wsl 在应用商店里搜索Ubuntu，安装应用即可 安装完后按下面的步骤启动Windows对Linux子系统的支持： 我的电脑 &gt; 属性 &gt; 控制面板 &gt; 程序 &gt; 启用或关闭Windows的功能，找到适用于Linux的Windows子系统，勾选然后重启。 不行的话 Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 然后按提示重启 然后换源，升级apt，后续的就按你自己的喜好来吧","link":"/2019/10/20/Linkers-Loaders-2/"},{"title":"程序员的自我修养—目标文件里有什么","text":"第三章的后半部分 链接的接口 链接的本质是要把多个不同的目标文件之间相互&quot;粘&quot;在一起。为了使不同的目标文件可以相互粘合，这些目标文件之间必须有固定的格式。 在链接中，目标文件之间相互拼合实际上是目标文件之间对地址的引用，即对函数和变量的地址的引用。 我们可以将符号看作是链接中的粘合剂，整个链接过程中正是基于符号才能正确完成。链接过程中很关键的一部分就是符号的管理，每一个目标文件都会有一个相应的符号表（Symbol Table），这里面记录了目标文件中所用到的所有符号。每个定义的符号有一个对应的值，叫做符号值（Symbol Value），对于变量和函数来说，符号值就是他们的地址。首先对符号进行一定的分类： 定义在本目标文件的全局符号，可以被其他目标文件引用。 在本目标文件中引用的全局符号，却没有定义在本目标文件，这一般被叫做外部符号（External Symbol）。 段名，这种符号往往由编译器产生，它的值就是该段的起始地址。 局部符号，这类符号只在编译单元内部可见。调试器可以使用这些符号来分析程序或崩溃时的核心转储文件。这些局部符号对于链接过程没有作用，链接器往往也忽略它们。 对于我们来说，最值得关注的是全局符号。使用 nm xxx.o 来查看符号表。 ELF 符号表结构 ELF中的符号表往往是文件中的一个段，段名为 “.symtab”。符号表的结构很简单，它是一个 Elf32_Sym 结构（32位ELF文件）的数组，每个 Elf32_Sym 结构对应一个符号。这个数组的第一个元素是无效的未定义符号，结构定义如下： 123456789typedef struct{ Elf32_Word st_name; /* Symbol name (string tbl index) */ Elf32_Addr st_value; /* Symbol value */ Elf32_Word st_size; /* Symbol size */ unsigned char st_info; /* Symbol type and binding */ unsigned char st_other; /* Symbol visibility */ Elf32_Section st_shndx; /* Section index */} Elf32_Sym; st_name 符号名，这个成员包含了该符号在字符串表中的下标 st_value 符号相对应的值，这个值和符号有关 st_size 符号的大小，对于包含数据的符号，这个值是该数据类型的大小。如 double 8字节，但若为0，则表示符号大小为0或未知 st_info 符号类型和绑定信息 st_other 0，目前无意义 st_index 符号所在的段 符号类型和绑定信息 低4位表示符号的类型（Symbol Type），高28位表示绑定信息（Symbol Binding） 符号绑定信息 宏定义名 值 说明 STB_LOCAL 0 局部符号 STB_GLOBAL 1 全局符号 STB_WEAK 2 弱引用 符号类型 宏定义名 值 说明 STT_NOTYPE 0 未知类型符号 STT_OBJECT 1 该符号是数据对象，如变量，数组 STT_FUNC 2 该符号是一个函数或其他可执行代码 STT_SECTION 3 该符号表示一个段 STT_FILE 4 该符号表示文件名，一般都是该目标文件对应的源文件名 符号所在段 如果符号定义在本目标文件中，那么这个成员表示符号所在的段在段表中的下标；但是如果符号不是定义在本目标文件中，或者对于有些特殊的符号，sh_shndx 的值会有些特殊 符号表所在段特殊常量 宏定义名 值 说明 SHN_ABS 0xfff1 表示该符号包含一个绝对的值 SHN_COMMON 0xfff2 表示该符号是一个 COMMON 块，一般来说，未初始化的全局符号定义就是这种类型 SHN_UNDEF 0 该符号未定义。这个符号表示该符号在本目标文件中被引用到但定义在其他目标文件中 符号值 在目标文件中，如果是符号的定义并且该符号不是 “COMMON” 块类型，则 st_value 表示该符号在段中的偏移。即符号所对应的函数或变量位于由 st_shndx 指定的段，偏移 st_value 的位置。这也是目标文件中定义全局变量的符号最常见的情况，如 main, global_init_var 在目标文件中，如果符号是 “COMMON” 块，则 st_value 表示该符号的对齐属性，比如 simple_section.o 中的 global_uninit_var 可执行文件中，st_value 表示符号的虚拟地址。这个虚拟地址对于动态链接器很有用 可以使用 readelf -s xxx.o 123456789101112131415161718192021222324readelf -s simple_section.oSymbol table '.symtab' contains 20 entries: Num: Value Size Type Bind Vis Ndx Name 0: 00000000 0 NOTYPE LOCAL DEFAULT UND 1: 00000000 0 FILE LOCAL DEFAULT ABS simple_section.c 2: 00000000 0 SECTION LOCAL DEFAULT 2 3: 00000000 0 SECTION LOCAL DEFAULT 4 4: 00000000 0 SECTION LOCAL DEFAULT 5 5: 00000000 0 SECTION LOCAL DEFAULT 6 6: 00000004 4 OBJECT LOCAL DEFAULT 4 static_var.1419 7: 00000000 4 OBJECT LOCAL DEFAULT 5 static_var2.1420 8: 00000000 0 SECTION LOCAL DEFAULT 7 9: 00000000 0 SECTION LOCAL DEFAULT 9 10: 00000000 0 SECTION LOCAL DEFAULT 10 11: 00000000 0 SECTION LOCAL DEFAULT 8 12: 00000000 0 SECTION LOCAL DEFAULT 1 13: 00000000 4 OBJECT GLOBAL DEFAULT 4 global_init_var 14: 00000004 4 OBJECT GLOBAL DEFAULT COM global_uninit_var 15: 00000000 46 FUNC GLOBAL DEFAULT 2 func1 16: 00000000 0 FUNC GLOBAL HIDDEN 7 __x86.get_pc_thunk.ax 17: 00000000 0 NOTYPE GLOBAL DEFAULT UND _GLOBAL_OFFSET_TABLE_ 18: 00000000 0 NOTYPE GLOBAL DEFAULT UND printf 19: 0000002e 81 FUNC GLOBAL DEFAULT 2 main 对于未显示的 STT_SECTION 类型的符号，它们表示下标为 Ndx 的段的段名，他的符号名就是段名，如 Ndx 为1应为 .text 段 static_var 变成了 static_var.1419，这和符号修饰有关 simple_section.c 表示编译单元的源文件名 特殊符号 当我们使用 ld 作为链接器来链接生成可执行文件时，它会为我们定义很多特殊的符号，这些符号并没有在你的程序中定义，但你可以直接声明并且引用它，我们称之为特殊符号。链接器会在将程序最终链接成可执行文件的时候将其解析为正确的值。只有用 ld 链接生产最终可执行文件的时候这些符号才会存在。 __exectuable_start: 程序的起始地址，并非入口地址，是程序最开始的地址 __etext &amp; _etext &amp; etext: 代码段结束地址，即代码段最末尾的地址 _edata &amp; edata: 该符号表示数据段结束地址，即代码最末尾的地址 _end &amp; end: 程序结束的地址 符号修饰和函数签名 最早的时候，编译器编译源代码产生目标文件时，符号名与相应的变量名或者函数名是一致的。但后来 UNIX 平台和 C 语言出现，一个 C 程序想要使用原来用汇编写的库或者目标文件时，就不能用和这些库中定义的函数和变量名字重复的，否则会造成冲突。 为了防止符号名冲突，UNIX 下的 C 语言规定， C 语言源代码文件中的所有全局变量和函数经过编译以后，相应符号名前加上下划线。别的语言也加上别的东西。这是最原始的解决方法。后来便有了命名空间（NameSpace） 的方法来解决多模块的符号冲突问题。 C++ 符号修饰 函数名修饰12345678910111213141516int func(int);float func(float);class C { int func(int); class C2{ int func(int); };};namespace N { int func(int); class C { int func(int); };} 区别他们，用到了一个叫做**函数签名（Function Signature）**的东西，函数签名包括了一个函数的信息，如：参数类型，类，函数名，返回值等。这样每个函数名虽然相同，但其函数签名不同，我们用某种名称修饰的方法使得每个函数签名对用一个修饰后的名字。 上述函数在 gcc 编译器下相对应的修饰后的名称： 函数签名 修饰后的符号名 int func(int) _Z4funci float func(float) _Z4funcf int C::func(int) _ZN1C4funcEi int C::C2::func(int) _ZN1C2C24funcEi int N::func(int) _ZN1N4funcEi int N::C::func(int) _ZN1N1C4funcEi 我们不需要了解怎么修饰， binutils 提供了一个 “c++filt” 的工具可以解析 12$ c++filt _ZN1N1C4funcEiN::C::func(int) 当然 Visual C++ 修饰的方法和结果与 gcc 完全不同。 由于不同的编译器采取不同的的名字来修饰，必然导致不同的编译器直接的文件无法正常相互链接，这是导致不同编译器之间不能互操作的重要的原因之一 extern “C” C++ 为了与 c 兼容，在符号管理方面，使用 extern “C” 来把作用的代码当做 C 的代码来处理。 很多时候，我们会碰到有些头文件声明了一些 C 语言的函数和全局变量，但是这个头文件可能会被 C 语言的代码或 C++ 代码包含。如 string.h 库中的 memset 函数。如果不做任何处理，在 C++ 中就会认为其是 C++ 的函数，这样修饰后就无法和 C 语言库的 memset 符号进行链接。对于 C++，必须使用 extern “C” ，但 C 语言没有这个。 解决方法：使用 C++ 的宏 “__cplusplus” 12345678910// 使用条件宏来判断当前编译单元是不是 C++ 的代码#ifdef __cplusplusextern &quot;C&quot; {#endifvoid *memset(void *, int, size_t);#ifdef __cplusplus}#endif 如果是 C++ 会加上 extern “C” 来声明。如果是 C 代码就直接声明。上面这段代码的技巧几乎在所有的系统头文件里都被用到。 强符号和弱符号 全局初始化的变量会被称为强符号（Strong Symbol）。而未初始化则被认为是弱符号（Weak Symbol） 我们可以用 GCC 的 “__attribute__((weak))” 来定义任何一个强符号为弱符号。需要注意：强符号和弱符号都是相当于定义来说的，而不是针对符号的引用。针对强弱符号的概念，链接器按如下规则处理 不允许强符号被多次定义 如果一个符号在某个目标文件中是强符号，在其他文件中是弱符号，则选择强符号作为定义 如果一个符号在多个目标文件中都是弱符号，则选择占用空间最大的 弱引用和强引用 对外部目标文件的符号引用在目标文件被最终链接时要被正确的决议。如果找不到定义，则报未定义错误，这种被称为强引用（Strong Reference）。与之对应还有弱引用（Weak Reference），在处理弱引用时，如果有定义，则用定义。如果没有则对于该引用不报错。一般对于未定义的弱引用，链接器默认其为0。 12345678__attribute__((weak)) void foo();int main(){ if(foo){ foo(); } return 0;} 执行一下没有任何结果，果然 foo 被赋值为0 关于 weakref weakref weakref (“target”) The weakref attribute marks a declaration as a weak reference. Without arguments, it should be accompanied by an alias（别名） attribute naming the target symbol. Optionally, the target may be given as an argument to weakref itself. In either case, weakref implicitly（隐式） marks the declaration as weak. Without a target, given as an argument to weakref or to alias, weakref is equivalent to weak. static int x() __attribute__ ((weakref (“y”))); /* is equivalent to… / static int x() __attribute__ ((weak, weakref, alias (“y”))); / and to… */ static int x() __attribute__ ((weakref)); static int x() __attribute__ ((alias (“y”))); A weak reference is an alias that does not by itself require a definition to be given for the target symbol. If the target symbol is only referenced through weak references, then it becomes a weak undefined symbol. If it is directly referenced, however, then such strong references prevail, and a definition is required for the symbol, not necessarily in the same translation unit. At present, a declaration to which weakref is attached can only be static. 调试信息 如果在 gcc 编译时加上 -g 参数，就会加上调试信息。 调试信息有相应的标准格式而且往往很大（比程序的代码和数据本身大好多倍）","link":"/2020/02/02/Linkers-Loaders-4/"},{"title":"程序员的自我修养-静态链接","text":"当我们有两个目标文件时，如何将它们链接起来形成一个可执行文件？这个过程中发生了什么？ 静态链接 使用下面两个源码文件 a.c, b.c 来展开我们关于静态链接的学习 123456789101112131415161718192021222324/* a.c */extern int shared;int main(){ int a = 100; swap(&amp;a, &amp;shared);}/* b.c */int shared = 1;void swap(int *a, int *b){ // 高级的交换方法 /* *a = *a ^ *b *b = *a ^ *b *a = *a ^ *b */ *a ^= *b ^= *a ^= *b;} 空间与地址分配 可执行文件中的代码段和数据段都是由输入的目标文件中合并而来的。那么链接器如何将多个段和并起来的？ 按序叠加 最简单的方式就是将输入的目标文件按照次序叠加起来，但这样很明显对空间的浪费太严重，因为每个段都有一定的地址和空间对齐要求，这样造成了大量的空间浪费。 相似段合并 一个更实际的方法是将相同性质的段合并在一起。如把所有目标文件的 .data 合并到输出文件的 .data 段里。 关于 .bss 段，它在目标文件和可执行文件中并不占用文件的空间，但是它在装载时占用地址空间，所以链接器在合并各个段的同时也将 .bss 段合并，并且分配虚拟空间。 现在的链接器空间分配一般都采取相似段的合并的方法，使用这种方法的链接器一般都采用一种叫做**两步链接（Two-pass Linking）**的方法，也就是说整个链接过程分为两步： 两步链接法 空间与地址分配 扫描所有的输入目标文件，获取它们各个段的长度，属性和位置，并且将输入目标文件中的符号表中的所有的符号定义和引用收集起来，统一放到一个全局的符号表中。这一步中，链接器将能够获取所有输出目标文件的段长度，并且将它们合并，计算出输出目标文件中各个段合并后的长度和位置并且建立映射关系。 符号解析与重定位 使用上面一步收集到的所有信息，读取输入文件中段的数据，重定位信息，并且进行符号解析与重定位，调整代码中的地址。最重要的是重定位的过程。 自己尝试时无法用 ld 链接，使用 gcc 链接发现 gcc 加了很多的东西（动态链接），只好放截图 VMA(Virtual Memory Address) 即虚拟地址， LMA(Load Memory Address) 即加载地址，正常情况下两个的值应该一样，但有些嵌入式系统中，特别是在那些程序放在 ROM 的系统中时，LMA 和 VMA 是不相同的。 在链接之前目标文件中的 VMA 都是0，因为虚拟空间还没有被分配。等到链接后，可执行文件 ab 的各个段都被分配到了相应的虚拟地址。 链接器将可执行文件 “ab” 的 .text 段分配到 0x08048094，.data 分配到 0x08049108，因为在 Linux 下 ELF 可执行文件默认从地址 0x08048000 开始分配。 符号地址的确定 当段的虚拟地址确定后，链接器需要计算各个符号的地址，由于在段内的相对位置固定，所以只需要给每个符号加一段偏移量就可以调整到正确的虚拟地址。 符号解析与重定位 重定位 在完成空间和地址的分配步骤后，链接器就进入了符号解析与重定位的步骤，这是静态链接的核心内容。 使用 objdump -d a.o 来查看代码反汇编的结果，我们把注意力放在这几条命令中: e8 fc ff ff ff call 27 &lt;main+0x27&gt; 以及 c7 44 24 04 00 00 00 movl $0x0, 0x4(%esp) main 的起始代码为0，这是因为并没有分配空间。 在编译阶段，编译器并不知道 shared 和 swap 的地址，因此编译器暂时把0看做 shared 的地址，所有和 shared 相关的地址全部为0x0 而 swap， E6 是 call 的机器码，而后面的数 FC FF FF FF 是小端存储的数字， 为-4。 call 是一条近地址相对位移调用指令（Call near, relative, displacement relative to next instruction），即相对于调用指令的下一条指令的偏移量，这里我们的地址是一个临时的假地址。 这时我们再重新计算 call 的目标地址，发现是正确的，因为链接器以及重新计算好了符号的地址。 重定位表 链接器如何知道哪些指令需要被调整？这些指令的哪些部分要被调整？怎么调整？ 事实上，在 ELF 文件中有一个重定位表（Reloaction Table）的结构专门用来保存这些与重定位相关的信息。它在 ELF 中往往是一个或多个段。如.rel.text, .rel.data，我们可以使用 objdump -r xx.o 来查看重定位表。每一个需要重定位的地方叫做一个重定位入口（Relocation Entry），入口的偏移量（Offset） 表示该入口在要被重定位的段中的位置。 对32位 Intel x86 系列的处理器来说，重定位表的结果也很简单： 12345typedef struct{ Elf32_Addr r_offset; /* Address */ Elf32_Word r_info; /* Relocation type and symbol index */} Elf32_Rel; r_offset 重定位入口的偏移。对于可重定位文件来说，这个值是该重定位入口所要修正的位置的第一个字节相对于段起始的偏移 r_info 重定位入口的类型和符号。低8位表示类型，高24位表示重定位入口的符号在符号表中的下标 符号解析 重定位过程中，每个重定位的入口都是对一个符号的引用，那么链接器需要对某个符号的引用进行重定位的时候，它就要确定这个符号的目标地址，这时链接器就会去查找所有输入目标文件的符号表组成的全局符号表，找到后进行重定位。 GLOBAL 类型的符号除了 main 定义在代码段外，其余都是 UND，即 undefined。当链接器扫描完所有的输入目标文件之后，所有这些定义的符号都应该可以在全局符号表中找到，否则链接器就报符号未定义的错误。 指令修正方式 宏定义 值 重定位修正方法 R_386_32 1 绝对寻址修正 R_386_PC32 2 相对寻址修正 绝对寻址修正：S + A ，相对寻址修正：S + A - P A = 保存在被修正位置的值 P = 被修正的位置（相对于段开始的偏移量或者虚拟地址） S = 符号的实际地址，r_info 的高 24 位指定的实际地址 我们假设 main 函数的虚拟地址为 0x1000， swap 函数为 0x2000， shared 变量为 0x3000 shared: S = 0x3000, A = 0x0000, result = 0x3000 swap: S = 0x2000, A = 0xFFFFFFFC P = 0x1000 + 0x27(被修正位置的虚拟地址) result = 0xFD5 COMMON 块 如果弱符号定义在多个目标文件中，而它们的类型又不同，怎么办？变量类型对于链接器来说是透明的，它只知道一个符号的名字，并不知道类型是否是一致的。当我们定义的多个符号定义类型不一致是，主要分为三种情况： 两个或两个以上的强符号类型不一致 -&gt; 非法 有一个强符号，其他都是弱符号，出现类型不一致 两个或两个以上弱符号不一致 为了处理后面两种问题，链接器都支持一种叫 COMMON 块的机制。即以最大的为准。 COMMON 类型的规则主要是针对符号都是弱符号来说的，当有强符号时，最终和强符号一致。 C++ 相关问题 重复代码消除 C++ 编译器在很多时候会产生重复的代码，比如模板（Template），外部内联函数（Extern Inline Function）和虚函数表（Virtual Function Table）都可能在不同的编译单元里生成相同的代码。最简单的情况就拿模板来说，模板从本质上来讲很像宏，当模板在一个编译单元里被实例化时，它并不知道自己是否在别的编译单元也被实例化了。所以当一个模板在多个单元同时实例化相同的类型时，必然会产生重复的代码。 为了解决这个问题，一个比较有效的方法就是将每个模板的实例的代码都单独地存放在一个段里，每个段只包含一个模板实例。如一个模板函数 add&lt;T&gt;()，某个编译单元以 int 类型和 float 类型实例了该模板函数。那么该编译单元的目标文件中就包含了两个该模板实例的段。为了简单起见，我们假设这两个段的名字分别叫 .temp.add 和 .temp.add, 这样当别的编译单元以同样的类型实例化了之后，也会生成相同的名字，这样链接器可以区分开这些相同模板的实例，然后将它们合并如最后的代码段。 这种做法被主流的编译器采用。GCC 把这种类似的需要在最终合并的段叫做 “Link Once”，它的做法是将这些段命名为 “.gnu.linkonce.name”, name 是该模板函数实例的修饰后名称。 函数级别链接 VISUAL C++ 提供了一个编译选项叫函数级别链接（Function-Level Linking），这种做法可以很大程度上减小输出文件的长度，减少空间浪费。但这个优化选项将所有的函数像模板函数一样单独保存到一个段里，用的时候就合并到输出文件，不用就废弃。这样会使编译更加慢，目标文件也会变大。 GCC 也有类似的编译选项。 全局构造和析构 Linux 下一般程序的入口是 “_start”， 这个函数是 Linux 系统库（Glibc）的一部分。这个函数就是程序的初始化部分的入口，程序初始化部分完成一系列初始化过程后，会调用 main 函数来执行程序的主体。在 main 执行完成以后，返回初始化部分，它进行一些清理工作，然后结束进程。 对于有些场合，程序的一些特定操作必须在 main 函数之前被执行，还有一些操作必须在 main 之后执行，如 C++ 全局对象的构造和析构。因此，ELF 定义了两种特殊的段： .init： 保存可执行指令，构成了进程的初始代码，有 Glibc 的初始化部分安排执行这个段中的代码 .fini：保存进程终止代码指令，当 main 函数正常退出时，Glibc 会安排执行这个段中的代码。 C++ 和 ABI 如果要是两个编译器编译出来的目标文件能够相互链接，那么这两个目标文件必须满足下面这些条件：采用相同的目标文件的格式，拥有相同的符号修饰标准，变量的内存分布方式相同，函数的调用方式相同等等。我们把符号修饰标准，变量内存分布，函数调用方式这些和可执行代码二进制兼容性相关的内容称为 ABI(Application Binary Interface) 静态库链接 一个程序如何输入输出？最简单的方法是使用操作系统提供的应用程序编程接口（API），那程序是如何使用操作系统提供的 API？ 一种语言的开发环境往往会附带有语言库（Language Library），这些库就是对操作系统的 API 的包装。如 printf 函数，在各个操作系统中，向终端输出字符串的 API 都不一样，Linux 下是一个 write 的系统调用，而 Win 下则是 WriteConsole 系统 API。 其实静态库可以看做是一组目标文件的集合，即很多目标文件经过压缩而形成的一个文件，我们可以使用 ar 工具来查看静态库包含了那些目标文件。 ar -t xxx.a 123456789$ ar -t libc.ainit-first.olibc-start.osysdep.oversion.ocheck_fds.olibc-tls.oelf-init.o... 可以使用ar -x xx.a 来将这些目标文件解压到当前目录 链接过程控制 整个链接过程有很多内容需要确定：使用哪些目标文件？使用哪些库文件？是否在最终可执行文件中保留调试信息？输出文件格式？还有考虑是否要导出某些符号以供调试器，程序本身或其他程序使用等。 链接控制脚本 链接器一般都提供多种方式控制整个链接过程，可以使用命令行参数，可以链接指令放到目标文件里，也可以使用链接控制脚本。当我们使用 ld 不指定脚本时会使用默认的链接脚本，一般在 “/usr/lib/dscripts/” 下，我们可以使用 -T 参数来指定自己的链接脚本。 书中的最小的程序咋也没法运行… BFD 库 由于现代的硬件和软件平台种类繁多，它们之间千差万别。这些五花八门的软硬件导致每个平台都有其独特的目标文件格式。即使同一个格式如 ELF 也有很多的变种。种种差异导致编译器和链接器很难处理不同平台之间的目标文件。最好有一种统一的接口来处理这些不同格式之间的差异。 BFD（Binary File Descripor library）就是这样一个 GNU 项目，它就是希望通过一种统一接口的方式来处理不同的目标文件的格式。 BFD 这个项目本身是 binutils 项目中的一个子项目。 BFD 把目标文件抽象成一个统一的模型。比如在这个抽象的目标文件模型中，最开始有一个描述整个文件信息的&quot;文件头&quot;，文件头后面是一系列的段，每个段都有属性，名字和内容。同时还定义抽象符号表，重定位表，字符串表等类似的概念。使得 BFD 库的程序只要通过抽象的目标文件模型就可以实现操作所有 BFD 支持的目标文件。 现在 GCC，链接器 ld，调试器 GDB 及 binutils 的其他工具都是通过 BFD 库来处理目标文件，而不是直接操作目标文件。这样做的最大的好处就是将编译器和链接器本身同具体的目标文件隔离开来，一旦我们需要支持一种新的目标文件格式，只需要在 BFD 中添加一种格式即可，而不需要修改编译器和链接器。","link":"/2020/02/18/Linkers-Loaders-5/"},{"title":"程序员的自我修养——动态链接","text":"动态链接 动态链接确实有很多的优势，比静态链接要灵活的多，但它也是牺牲一部分性能为代价的， ELF 程序在静态链接下要比动态库稍微快一些，大约为 1%~5%。动态链接比静态链接慢的主要原因是动态链接下对于全局和静态的数据访问要通过 GOT 表定位，然后间接寻址，对于模块间的调用也需要 GOT 表，然后进行间接跳转，如此一来，程序的运行速度必定会减慢。另一个原因是动态链接的链接工作在运行时完成，即程序开始执行时，动态链接器需要进行一次链接工作，寻找并装载所需要的共享对象，然后符号查找地址重定位等工作，势必会减慢程序的启动速度。我们将在后面看到如何进行优化。 延迟绑定(PLT) 延迟绑定的实现 在动态链接下，程序模块之间包含了大量的函数引用（全局变量往往比较少，因为大量的全局变量将会导致模块间的耦合度变大），所以在程序开始执行前，动态链接会耗费不少时间来用于解决模块之间的函数引用的符号查找以及重定位，这也是我们上面提到的减慢动态链接性能的第二个原因。 为了优化，ELF 采用了一种叫做延迟绑定（Lazy Binding）的做法，基本思想就是当函数第一次被用到时才进行绑定（符号查找，重定位等），如果没有用到就不进行绑定。所以当程序开始执行的时候，模块间的函数调用都没有进行绑定，而是需要用到时才由动态链接器负责绑定。 ELF 使用 PLT（Produce Linkage Table）的方法来实现。当我们调用某个外部模块的函数时，如果按照通常的做法应该是通过 GOT 中相应的项进行间接跳转。PLT 为了实现延迟绑定，在这个过程中加入了一层间接跳转。调用函数并不直接通过 GOT 跳转，而是通过一个叫做 PLT 项的结构来进行跳转。每个外部函数在 PLT 中都有一个相应的项，比如 bar() 函数在 PLT 中的项的地址我们称之为 bar@plt 12345bar@pltjmp *(bar@GOT) // 1push n // 2push moduleID // 3jump _dl_runtime_resolve // 4 第一条指令是一条通过 GOT 间接跳转的指令，bar@GOT 表示 GOT 中保存 bar() 这个函数相应的项。如果链接器在初始化阶段已经初始化该项，并且将地址填充上去了，那么我们就可以直接跳转过去了。但实际上为了延迟绑定，链接器并没有在初始化的时候就将 bar() 的地址填入到该项中，而是将上面代码中第二条指令push n的地址填入到 bar@GOT 中，这个步骤不需要查找任何符号，所以代价很低。很明显，第一条指令的效果就是跳转到第二条指令，将一个数字 n 压入堆栈中，这个数字是 bar 这个符号引用在重定位表.rel.plt 中的下标，接着将模块 ID 压入栈中，然后跳转到函数地址绑定函数。 先将所需要的决议符号的下标压入堆栈，再将模块 ID 压入堆栈，然后调用动态链接器的 _dl_runtime_resolve() 函数来完成符号解析和重定位工作。 一旦解析完成后，当我们再次调用 bar@plt 时，第一条 jump 指令就能够跳转到真正的 bar() 函数中。 这个只是基本的原理，PLT 真正的实现要比它的结构复杂一些。ELF 将 GOT 表拆分成2个来保存，一个是 .got 另一个是 .got.plt。其中 got 表用来保存全局变量引用的地址， gotplt 表用于保存函数引用的地址，此外它的前三项也是有特殊的含义： 第一项保存的是 .dynamic 段的地址，这个段描述了本模块动态链接相关的信息 第二项保存的是本模块的 ID 第三项保存的是 _dl_runtime_resolve 的地址 其中第二项和第三项有动态链接器在装载共享模块的时候负责将它们初始化，其余的项对应于外部函数的调用。 12345678910;实际的 PLT 基本结构PLT0:push *(GOT+4) // idjump *(GOT+8) // _dl_runtime_resolve...bar@plt:jump *(bar@GOT)push njump PLT0 动态链接相关结构 ELF 的动态链接的方式比 PE 稍微简单一点。 在动态链接的情况下，可执行文件的装载与静态链接情况基本一样，首先操作系统会读取可执行文件的头部，检查文件的合法性，然后从头部中的 Program Header 中读取每个 Segment 的虚拟地址，文件地址和属性，并把他们映射到进程虚拟空间的相应位置，这些步骤和静态链接的情况基本一致，此时如果是静态链接，操作系统就会把控制权交给可执行文件的入口地址，然后程序执行，但在动态链接的情况下，操作系统还不能在装载完的时候就移交可执行权限，因为我们知道，可执行文件依赖很多共享对象，这时候文件里的对外部符号的引用还处于无效地址的状态，这时操作系统需要启动动态链接器（Dynamic Linker） 在 Linux 下，动态链接器 ld.so 实际上是一个共享对象，操作系统通过映射的方式将它加载到进程地址空间中。操作系统在加载完动态链接之后，就将控制权交给动态链接器的入口地址。然后动态链接器开始自身初始化，根据当前环境参数对可执行文件进行动态链接工作。当所有的动态链接工作完成后，动态链接器会将控制权转交到可执行文件的入口地址，程序开始正式执行。 .interp 段 系统中哪个才是动态链接器呢？它的地址不由系统配置指定，也不是由环境参数决定，而是由 ELF 可执行文件决定。在动态链接的 ELF 可执行文件中有 .interp 负责存储，它的里面保存一个字符串格式的可执行文件动态链接器的路径，但往往操作系统中这个路径是一个软链接，它指向的文件才是真正的动态链接器，可以使用 readelf -l xxx | grep interpreter 来查看 $ readelf -l a.out | grep interpreter [Requesting program interpreter: /lib/ld-linux.so.2] .dynamic 段 动态链接 ELF 中最重要的结构应该就是 .dynamic 段，这个段里保存了动态链接所需要的基本信息，比如依赖哪些共享对象，动态链接符号表的位置，动态链接重定位表的位置，共享对象初始化代码的地址等。 12345678910// .dynamic 的结构typedef struct{ Elf32_Sword d_tag; /* Dynamic entry type */ union { Elf32_Word d_val; /* Integer value */ Elf32_Addr d_ptr; /* Address value */ } d_un;} Elf32_Dyn; Elf32_Dyn 的结构由一个类型值加上一个附加的数值或指针，对于不同的类型，后面附加的数值或者指针有着不同的含义。这里列举几个比较常见的类型值（这些值都是定义在 elf.h 里面的宏） d_tag类型 d_un的含义 DT_SYMTAB 动态链接符号表的地址，d_ptr表示.dynsym的地址 DT_STRAB 动态链接字符串表地址，d_ptr表示.dynstr的地址 DT_STRSZ 动态链接字符串表地址，d_val表示大小 DT_HASH 动态链接器哈希表地址，d_ptr表示.hash的地址 DT_SONAME 本共享对象SO-NAME DT_RPATH 动态链接共享对象搜索路径 DT_INIT 初始化代码地址 DT_FINT 结束代码地址 DT_NEED 依赖的共享对象，d_ptr表示所依赖的共享对象文件名 DT_REL,DT_RELA 动态链接重定位表地址 DT_RELENT,DT_RELAENT 动态重读位表入口数量 使用 readelf -d Lib.so 来查看 动态符号表 为了完成动态链接需要解决模块之间的符号导入和导出关系，ELF 有专门一个叫做动态符号表（Dynamic Symbol Table）的段用来保存这些信息，这个段通常叫做 .dynsym，与 .symtab 不同的是，前者只保存了动态链接相关的符号，而对于那些模块内部的符号，比如模块私有变量则不保存。很多时候动态链接的模块同时拥有 .dynsym 和 .symtab 两个表，.symtab 往往保存了所有的符号。 符号表为了保存字符串，会有动态符号字符串表（Dynamic String Table），即 .dynstr。由于动态链接下，我们需要在程序运行的时候查找符号，为了加快符号的查找过程，往往还有辅助的符号哈希表（.hash），我们可以使用 readelf -sD xxx.so 来查看 ELF 文件的动态符号表和它的哈希表。 动态链接重定位表 动态链接中，导入符号的地址需要在运行时才能确认，所以需要在运行时进行导入符号的修正（重定位），动态链接的可执行文件使用的方法是PIC（地址无关代码）方法，但这并不能改变它需要重定位的本质。对于一个动态链接来说，如果一个共享对象不是以PIC模式编译的，那么它需要在装载的时候被重定位。但如果一个共享对象是PIC模式编译的，那么它依然需要在装载时进行重定位。 对于实行PIC技术的可执行文件或者共享对象来说，虽然它们的代码段不需要重定位（因为地址无关），但数据段依旧包含了绝对地址的引用，因为代码段中绝对地址相关的部分被分离了出来，变成了GOT，GOT表是数据段的一部分，除它之外，数据段还可能包含绝对地址引用。 动态链接重定位相关结构 在静态链接的文件中，.rel.text 是代码段的重定位表而 .rel.data 是数据段的重定位表，在动态链接的文件中有.rel.dyn 和 .rel.plt，相当于上面的两个。.rel.dyn 实际上是对数据引用的修正，它所修正的位置位于 .got 以及数据段，而 .rel.plt 实际上是对于函数引用的修正，它修正的位置位于.got.plt 使用 readelf -r 和 readelf -S 来查看一个动态链接的文件的重定位表： 123456789101112131415$ readelf -r Lib.soRelocation section '.rela.dyn' at offset 0x428 contains 7 entries: Offset Info Type Sym. Value Sym. Name + Addend000000200e10 000000000008 R_X86_64_RELATIVE 600000000200e18 000000000008 R_X86_64_RELATIVE 5c0000000201020 000000000008 R_X86_64_RELATIVE 201020000000200fe0 000100000006 R_X86_64_GLOB_DAT 0000000000000000 _ITM_deregisterTMClone + 0000000200fe8 000300000006 R_X86_64_GLOB_DAT 0000000000000000 __gmon_start__ + 0000000200ff0 000400000006 R_X86_64_GLOB_DAT 0000000000000000 _ITM_registerTMCloneTa + 0000000200ff8 000500000006 R_X86_64_GLOB_DAT 0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0Relocation section '.rela.plt' at offset 0x4d0 contains 1 entry: Offset Info Type Sym. Value Sym. Name + Addend000000201018 000200000007 R_X86_64_JUMP_SLO 0000000000000000 printf@GLIBC_2.2.5 + 0 我们关注R_X86_64_JUMP_SLO R_X86_64_GLOB_DAT R_X86_64_RELATIVE，虽然和书上的不同，但这也仅仅是处理器不同。JUMP_SLO 和 GLOB_DAT 的修正方式都是将正确的地址填入对应的位置中。而比较麻烦的是RELATIVE类型的重定位入口。 这种类型实际上是基址重置（Rebasing），共享数据无法做到地址无关（它可能会包含对绝对地址的引用），而对于绝对地址的引用，我们必须在装载时就进行重定位。如： 12static int a;static int* p = &amp;a; 在编译的时候，共享对象的地址从0开始，我们假设该静态变量 a 相对于起始地址0的偏移量为 B，p的值为 B。一旦共享对象被装载到地址 A，那么实际 a 的地址为 A+B，那么 p 的值需要加上一个装载的地址 A，才是正确的。 RELATIVE 类型的重定位入口就是专门用来重定位指针变量 p 这种类型的。 动态链接时进程堆栈初始化信息 站在动态链接的角度看，当操作系统把控制权交给它的时候，它将开始做链接工作。那么至少它需要知道关于可执行文件和本进程的一些信息，比如可执行文件有几个段（Segment），每个段的属性，程序的入口地址（因为动态链接器到时候需要把控制权交给可执行文件）等。这些信息往往由操作系统传递给动态链接器，保存在进程的堆栈里面。进程初始化的时候，堆栈里面保存了关于进程执行环境和命令行参数等信息。除此之外，堆栈还保存了动态链接器所需要的一些辅助信息数组（Auxiliary Vector），其格式也是结构数组，被定义在 elf.h 中 123456typedef struct{ uint32_t a_type; union{ uint32_t a_val; // 这个联合体没啥用 } a_un;} Elf32_auxv_t; 这个数组位于进程堆栈中环境变量指针的后面，假如操作系统传给了动态链接器的辅助信息有4个，分别是: AT_PHDR，值为0x08048034，表示程序表头位于0x08048034。 AT_PHENT，值为20，表示程序表头中每个项的大小为20字节。 AT_PHNUM，值为7，程序表头共有7项。 AT_ENTRY，值为0x08048320，程序的入口地址为0x08048320 联合前面的进程堆栈的初始化，我们可以得到比较全面的堆栈的初始化信息了： 0xBF801FD8 ~ 0xBF802000 记录了环境变量等信息： HOME=/home/usr PATH=/usr/bin 执行的命令是 prog 123 参考 《程序员的自我修养》","link":"/2020/06/26/Linkers-Loaders-8/"},{"title":"程序员的自我修养——动态链接","text":"动态链接的步骤和实现 动态链接基本上分为3步：先是启动动态链接器本身，然后装载所需要的共享对象，最后是重定位和初始化。 自举 动态链接器本身也是一个共享对象，但实际上对于普通共享对象文件来说，它的重定位工作有动态链接器来完成；它也可以依赖别的共享对象，其中被依赖的共享对象又由动态链接器来负责装载和链接。那对于动态链接器本身的重定位工作由谁来完成？它是否可以依赖于别的共享对象。 很明显，动态链接器由于特殊性，它本身不可以依赖任何其他共享对象，其次是动态链接器本身所需要的全局和静态变量的重定位工作由它自己来完成，这就使得动态链接器在启动的时候必须要有一段非常精巧的代码来完成这项工作，同时不使用全局变量和静态变量，这种具有一定的限制条件的启动代码往往被称为自举（Bootstrap） 动态链接器入口地址即是自举代码的入口，当操作系统将进程交给动态链接器的时候，动态链接器的自举代码开始执行。自举代码首先找到自己的GOT，而GOT的第一个入口保存的即是.dynamic段的偏移地址，因此找到动态链接器本身的.dynamic段，通过其中的信息自举代码便可以获得动态链接器本身的重定位表和符号表，从而得到动态链接器本身的重定位入口，先将它们全部重定位，从这一步开始，动态链接器中的代码才可以开始使用自己的全局变量和静态变量。 自举代码也不能使用自己的函数，因为使用PIC（地址无关代码）模式编译的时候，对于模块内部的函数调用也是采用模块外部函数调用一样的处理方式（GOT/PLT），所以在GOT/PLT没有被重定位之前，自举代码不能使用任何全局变量，也不能调用任何函数。 装载共享对象 完成自举后，动态链接器将可执行文件和链接器本身的符号全部合并到一个符号表中，我们可以称它为全局符号表（Global Symbol Table），然后链接器开始寻找可执行文件所依赖的共享对象（通过DT_NEEDED），链接器将这些共享对象的名字放到一个装载集合当中，一个一个打开文件从中读取相应的 ELF 文件头和 .dynamic 段，然后将它相应的代码段和数据段映射到进程空间中。如果这个ELF文件也依赖于其他的共享对象，那么往往采用广度优先的装载顺序。当所有的共享对象都被装载进来的时候，全局符号表里面就包含了进程的所有的动态链接所需要的符号。 符号优先级 123456789101112131415161718192021222324/* a1.c */#include&lt;stdio.h&gt;void a(){ printf(&quot;a1.c\\n&quot;);}/* a2.c */#include&lt;stdio.h&gt;void a(){ printf(&quot;a2.c\\n&quot;);}/* b1.c */void a();void b1(){ a();}/* b2.c */void a();void b2(){ a();} 然后我们在编译时指定依赖关系： 1234567891011121314$ gcc -fPIC -shared a1.c -o a1.so$ gcc -fPIC -shared a2.c -o a2.so$ gcc -fPIC -shared b1.c a1.so -o b1.so -Xlinker -rpath ./$ gcc -fPIC -shared b2.c a2.so -o b2.so -Xlinker -rpath ./$ ldd b1.so linux-vdso.so.1 (0x00007ffffc2e8000) a1.so =&gt; ./a1.so (0x00007fd9767f0000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fd9763f0000) /lib64/ld-linux-x86-64.so.2 (0x00007fd976e00000)$ ldd b2.so linux-vdso.so.1 (0x00007fffcbe7c000) a2.so =&gt; ./a2.so (0x00007f3f94550000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3f94150000) /lib64/ld-linux-x86-64.so.2 (0x00007f3f94a00000) 当有程序同时使用 b1.c 和 b2.c 中的函数时会怎么样？ 注：这里也需要-Xlinker -rpath ./ 否则 a1.so 那里显示的是未找到（not found），这会导致后面的链接无法执行。 1234567891011/* main.c */#include&lt;stdio.h&gt;void b1();void b2();int main(){ b1(); b2(); return 0;} 指定共享对象进行编译链接: gcc main.c b1.so b2.so -o main -Xlinker -rpath ./ 运行发现竟然打印了两个 a1.c，这四个共享对象应该都被装载进来了，但为什么 a2.so 中的 a 函数被忽略了。这种一个共享对象里面的全局符号被另一个共享对象的同名全局符号覆盖的现象又被称为共享对象全局符号介入（Global Symbol Interpose）。 在 Linux 下动态链接器针对全局符号介入的处理方式是：如果符号名相同并且已经存在，后入的符号被忽略。安照广度优先的顺序进行装载，首先是 main，然后是 b1.so b2.so a1.so 最后是a2.so，所以后面的被忽略了。当程序使用大量的共享对象的时候应当非常小心符号的重名问题。 重定位和初始化 当上面的步骤都完成的时候，链接器开始重新遍历可执行文件和每个共享对象的重定位表，将它们的 GOT/PLT 中每个需要重定位的位置进行修正。因为此时动态链接器已经有了进程的全局符号表，所以修正过程相对容易。重定位完成后，如果某个共享对象有 .init 段，那么动态链接器会执行 .init 段的代码，用以实现共享对象特有的初始化过程。比如最常见的，共享对象中的 C++ 的全局/静态对象的构造就需要通过 .init 来初始化。相应的，共享对象中还可能有 .finit 段，当程序退出时会执行 .finit 段中的代码，可以用来实现 C++ 全局对象析构之类的操作。 Linux 动态链接器的实现 内核在装载完 ELF 可执行文件之后就返回用户空间，将控制权交给程序的入口。对于不同链接形式的 ELF 可执行文件来说，程序的入口存在区别。对于静态可执行文件来说，程序的入口就是 ELF 文件头中 e_entry 指定的入口，对于动态链接，这个入口是不行的，因为可执行文件所依赖的共享库还没有被装载，也没有进行动态链接。对于动态链接的可执行文件，内核会分析它的动态链接器地址（在 .interp 段），将动态链接器映射至进程地址空间，然后把控制权交给动态链接器。 Linux 的动态链接器本身是一个共享对象，它的路径 /lib/ld-linux.so.2 指向 /lib/ld-x.y.z.so 这个才是真正的动态连接器文件。共享对象也是一个 ELF 文件，它也有跟可执行文件一样的 ELF 文件头。动态链接器不仅是一个共享对象，也可以执行。 $ /lib/ld-linux.so.2 Usage: ld.so [OPTION]… EXECUTABLE-FILE [ARGS-FOR-PROGRAM…] You have invoked ld.so', the helper program for shared library executables. This program usually lives in the file /lib/ld.so’, and special directives in executable files using ELF shared libraries tell the system’s program loader to load the helper program from this file. … Linux 的内核在执行 execve() 时不关心目标 ELF 文件是否可执行（文件头 e_type 是 ET_EXEC 还是 ET_DNY），它只是简单按照程序头表里面的描述对文件进行装载然后把控制权转交给 ELF 入口地址，这点也能看出共享库和可执行文件实际上没有什么区别，除了文件头的标志位和扩展名有所不同。 几点问题： 动态链接器本身是动态链接还是静态链接？ 动态链接本身是静态链接，它不能依赖于其他共享对象，动态链接器本身是用于帮助其他 ELF 文件解决共享对象的依赖问题。 $ ldd /lib/ld-linux.so.2 statically linked 动态链接器本身必须是 PIC 的吗？ 是不是 PIC 对于动态链接器本身来说并不关键，动态链接器可以是也可以不是 PIC，但往往使用 PIC 会更加简单一些。如果不是 PIC 的话，会使得代码段无法共享，浪费内存，另一方面也使得 ld.so 本身初始化更加复杂。因为自举时要对代码进行重定位。实际上 ld-linux.so.2 是 PIC 的。 动态链接器本身可以被当做可执行文件运行，那么它的装载地址应该是多少？ ld.so 的装载地址跟一般的共享对象没区别，即为 0x00000000。这个装载地址是一个无效的装载地址，作为一个共享库，内核在装载它时会为其选择一个合适的装载地址。 显示运行时链接 支持动态链接的系统往往都支持一种更加灵活的模块加载方式，叫做显示运行时链接（Explicit Run-time Linking），有时也叫做运行时加载。也就是让程序自己在运行时控制加载指定的模块，并且在不需要该模块的时候将其卸载。这种共享对象往往被叫做动态装载库（Dynamic Loading Library）。 最常见的例子是 WEB 服务器程序。对于 WEB 服务器程序来说，它需要根据配置来选择不同的脚本解释器，数据库链接驱动等，对于不同的脚本解释器分别做成一个独立的模块，当 WEB 服务器需要某种脚本解释器的时候就将其加载进来，这对于数据库连接的驱动程序也是一样的原理。 动态装载库通过一系列动态链接器提供的 API 来实现装载，这些 API 的实现在 libdl.so.2 里面。 dlopen() void *dlopen(const char *filename, int flag) 第一个参数是被加载的动态库路径，如果这个路径是绝对路径，该函数会尝试直接打开该库，否则会尝试以一定的顺序查找该动态库文件。 flag 表示函数符号的解析方式，有RTLD_LAZY(延迟绑定), RTLD_NOW(模块被加载时立即完成绑定) dlopen() 返回被加载模块的句柄，如果被加载过了会返回同一个句柄，加载失败返回 NULL，若存在依赖关系则需要手动加载被依赖模块。 dlsym() void *dlsym(void *handle, char *symbol) 第一个参数 handle 就是 dlopen() 返回的动态库的句柄，第二个参数即要查找的符号的名称，一个以 '\\0' 结尾的 C 字符串。如果没找到，返回 NULL，查找函数，返回函数的地址，查找变量，返回变量的地址，查找常量，返回常量的值。需要注意的是如果 dlerror() 返回NULL，说明找到符号了，否则返回响应的信息。 dlerror() 每次调用后都可以调用它来看看上一次调用是否成功，返回NULL表示成功，返回字符串表示上次调用的错误信息 dlclose() 卸载一个已经装载的模块。系统会维护一个加载引用计数器，每次加载一个新模块的时候相应的计数器 +1，卸载时 -1。只有当计数器的值减到0时模块才会真正的被卸载。卸载过程与加载相反，先执行 .finit 代码，然后将符号从符号表中去除，取消进程空间跟模块的映射关系，然后关闭该模块。 小例子 1234567891011121314151617181920212223#include&lt;stdio.h&gt;#include&lt;dlfcn.h&gt;int main(int argc, char* argv[]){ void *handle; double (*func)(double); char *error; handle = dlopen(argv[1], RTLD_NOW); if (handle == NULL){ printf(&quot;Open library %s error: %s\\n&quot;, argv[1], dlerror()); return -1; } func = dlsym(handle, &quot;sin&quot;); if ((error = dlerror()) != NULL){ printf(&quot;Symbol sin not found: %s\\n&quot;, error); } else{ printf(&quot;%f\\n&quot;, func(3.1415926/2)); } dlclose(handle);} #include&lt;stdio.h&gt; #include&lt;dlfcn.h&gt; int main(int argc, char* argv[]){ void *handle; double (*func)(double); char *error; handle = dlopen(argv[1], RTLD_NOW); if (handle == NULL){ printf(&quot;Open library %s error: %s\\n&quot;, argv[1], dlerror()); return -1; } func = dlsym(handle, &quot;sin&quot;); if ((error = dlerror()) != NULL){ printf(&quot;Symbol sin not found: %s\\n&quot;, error); } else{ printf(&quot;%f\\n&quot;, func(3.1415926/2)); } dlclose(handle); } 使用数学库模块用运行时加载的方式加载到进程中，然后获取 sin() 函数符号地址，调用 sin() 返回结果 gcc -o simple_run simpe_run.c -ldl ./simple_run /lib/x86_64-linux-gnu/libm-2.27.so ps： -ldl 表示使用 DL（Dynamic Loading） 库 原书中适用于32位系统，当对于64位系统的时候，要正确的找到自己 libm 库的位置，若出现错误 wrong ELF class: ELFCLASS32 说明你使用的动态库是32位的。","link":"/2020/08/23/Linkers-Loaders-9/"},{"title":"NumPy 入门","text":"NumPy 初识 NumPy NumPy 的主要对象是同质多维数组，也就是在一个元素（通常是数字）表中，元素的类型都是相同的。其中可以通过正整数的元组来对元素进行索引。 在 NumPy 中，数组的维度被称为轴（axes），轴的数量被称为秩（rank）。例如在三维空间的一个点坐标[1,2,1]，就是秩为1的数组，因为它只有一个轴。 NumPy 的数组称为 ndarray， 别名为 array。numpy。array 与 Python 标准库里的 array.array 不一样，标准库只能处理一维数组并且功能相对较少。 ndarray 对象属性 属性 含义 T 转置 size 数组的元素的个数 itemsize 每个元素的大小 dtype 数组元素的数据类型对象 ndim 数组的轴数量 shape 数组的维度 Flat 返回数组的一维迭代器 imag 返回数组的虚部 real 返回数组的实部 nbytes 数组中所有元素的字节长度 NumPy 数组类型 int8, int16, int32, int64, uint8, uint16, uint32, uint64 float16, float32, float64 complex64, complex128 可以使用 dtype 来指定数据类型，也可以通过 astype() &gt;&gt;&gt;print(np.array(5, dtype=int32)) 5 &gt;&gt;&gt;print(np.array(5, astype(float))) 5.0 NumPy 创建数组 可以用 numpy.array 来将列表或元组转换为 ndarray 数组，可以通过 order= 来指定顺序 使用 arange()，和 range() 基本一样，可以指定 dtype 来设置返回的 ndarray 的类型 linspace() 生成等差数列 numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None) endpoint 表示最后一个样本在不在序列内， retstep 为 True 时会返回间距 使用 logspace 生成等比数列 numpy.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None) base 表示基底，取对数时 log 的下标 ones, zeros 分别创建一个指定形状的全1数组和全0数组 索引和切片索引 和c中对多维数组的索引获取一个道理，不同的是其支持切片如a[0:2, 0:2], 含义是第1,2行的1,2列组成的2x2的矩阵 123456789import numpy as npmatrix = np.arange(16)matrix = matrix.reshape(4, 4)print(matrix[1][2])print(matrix[1:2, 2:3])# 结果# 6# [[6]] 切片一定得到的是一个列表 布尔型索引 布尔型索引又叫花式索引（Fancy indexing），指的是利用整数数组进行索引。布尔型的索引是基于布尔数据的索引，它也是利用特定的迭代器对象实现的 123456789import numpy as npa = np.arange(16).reshape(4, 4)x = np.array([0, 1, 2, 1])print(x == 1)print(a[x == 1])# [False True False True]# [[ 4 5 6 7]# [12 13 14 15]] 同样的，布尔索引也支持别的运算符如大于号小于号等等 矩阵的合并与分割 矩阵的合并 hstack() 左右合并, vstack() 上下合并 也可以用 vstack((A, B)), hstack((A, B)) 来实现不同轴上的合并 1234567import numpy as np# 矩阵合并a = np.floor(10*np.random.random((2, 2)))b = np.floor(10*np.random.random((2, 2)))c = np.vstack((a, b))d = np.hstack((a, b))print(&quot;a =\\n{}\\nb=\\n{}\\nc =\\n{}\\nd =\\n{}&quot;.format(a, b, c, d)) 矩阵的分割 在数组的合并操作中，函数 column_stack() 支持列方向上的合并，但是在处理一维数组时，按列方向组合，结果为二维数。 当处理二维数组时和 hstack 方法一样。同样， row_stack() 支持行方向上的合并，在处理一维数组时按行方向组合，二维数组 vstack 方向一样。 123456789101112131415161718192021222324252627282930# 矩阵分割import numpy as npfrom numpy import newaxisa = np.array([1, 2])b = np.array([3, 4])c = np.column_stack((a, b))d = np.hstack((a, b))print(&quot;a =\\n{}\\nb =\\n{}\\nc =\\n{}\\nd = \\n{}&quot;.format(a, b, c, d))e = np.column_stack((a[:, newaxis], b[:, newaxis])) # 插入新的维度，由一维变成二维f = np.hstack((a[:, newaxis], b[:, newaxis]))print(&quot;e =\\n{}\\nf =\\n{}\\n&quot;.format(e, f))# 结果&quot;&quot;&quot;a =[1 2]b =[3 4]c =[[1 3] [2 4]]d = [1 2 3 4]e =[[1 3] [2 4]]f =[[1 3] [2 4]]&quot;&quot;&quot; 矩阵运算与线性代数 求范数 np.linalg.norm(x, ord=None, axis=None, keepdims=False) x 表示要度量的向量 ord 处理范数的种类 ord= 描述 公式 ord=2 二范数 $\\sqrt{ \\sum_{i=1}{n}x_{i}{2}}$ ord=1 一范数 $\\sum_{i=1}^{n} \\left| x_{i}\\right| $ ord=np.inf 无穷范数 $max(\\left| {x_{i}} \\right|)$ 求矩阵的逆 12345import numpy as npa = np.mat(&quot;0 1 2;1 0 3;4 -3 8&quot;)a_inv = np.linalg.inv(a)print(a)print(a*a_inv) 注意: 该矩阵必须可逆，否则抛出 LinAlgError 异常 不可逆的情况: |A| = 0 求方程组的解 1234567import numpy as npa = np.array([[3, 1], [1, 2]])b = np.array([8, 9])x = np.linalg.solve(a, b)print(x)# 使用 dot 函数检查求得的解是否正确print(np.dot(a, x)) 计算矩阵行列式 123import numpy as npa = np.array([[1, 2], [3, 4]])print(np.linalg.det(a)) 最小二乘求线性函数 numpy.linalg.lstsq(array_A, array_B)[0] 12345678910111213import numpy as npimport matplotlib.pyplot as pltx = np.array([0, 1, 2, 3])y = np.array([-1, 0.2, 0.9, 2.1])A = np.vstack([x, np.ones(len(x))]).T # 转置print(A)m, c = np.linalg.lstsq(A, y, rcond=-1)[0]# 绘图plt.plot(x, y, 'o', label='Original data', markersize=10)plt.plot(x, m*x + c, 'r', label='Fitter line')plt.legend()plt.show() 求特征值和特征向量 在 numpy.linalg 模块中，eigvals 函数可以计算矩阵的特征值(eigenvalue)，而 eig 函数可以返回一个包含特征值和对应的特征向量(eigenvector)的元组 1234567891011121314import numpy as npC = np.mat(&quot;3 -2; 1 0&quot;)c0 = np.linalg.eigvals(C)print(c0)# 使用 eig 函数求解会返回一个元组，第一列为特征值第二列为特征向量c1, c2 = np.linalg.eig(C)print(c1)print(c2)# 使用 dot 函数验证是否正确for i in range(len(c1)): print(&quot;left:&quot;, np.dot(C, c2[:, i])) print(&quot;right:&quot;, c1[i] * c2[:, i]) 奇异值分解 奇异值分解(Singular Value Decomposition, SVD)是一种因子分解运算，将一个矩阵分解为3个矩阵的乘积。 U, Sigma, V = np.linalg.svd(D) 结果是两个正交矩阵UV, 以及中间的奇异值矩阵 NumPy 的广播机制 广播(Broadcasting) 是一种维度处理原则，广播操作会使程序更加简洁高效。 广播原则：如果两个数组的后缘维度（即从末尾开始算起的维度）的轴长相符或其中一方的长度为1，则认为它们是广播兼容的， 广播会在缺失或长度为1的轴上进行。当我们使用函数计算时，函数会先对两个数组的对应元素进行计算，因此要求两个数组具有相同的大小， 如果不同，为了避免多重循环，会进行如下广播处理： 让所有的输入数组都向维度最长的数组看齐，维度不足的部分通过在前面加1补齐 输出数组的维度是输入数组维度的各个轴上的最大值 如果输入数组的某个轴和输出数组的对应轴的长度相同或者都为1时，这个数组能够用来计算，否则出错 如果输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值 如果任何一个维度是1，那么另一个不为1的维度将被用作最终结果的维度。也就是说为1的维度将延展到与另一个维度匹配。 123456import numpy as npa = np.array([0.0, 10.0, 20.0, 30.0])a = a[:, np.newaxis] # 加入新的坐标轴b = np.array([1.0, 2.0, 3.0])c = a + bprint(c) 广播补全可以参考下图 numpy 统计函数 用的时候可以再查 最大最小 123456789import numpy as npa = np.arange(4).reshape((2, 2))print(a)print(np.amin(a))print(np.amin(a, axis=0)) # 第一轴(纵轴)的最小值b = np.arange(5, dtype=np.float)b[2] = np.nanprint(np.amin(b)) # result: nanprint(np.nanmin(b)) # 不含 nan 的最小值，result: 0.0 极差 numpy.ptp(ndarray[, axis=]) 可以用 axis 指定行或列轴, axis=0 为列轴 均值方差 1234567891011121314import numpy as npa = np.array([[1., 2.], [3., 4.]])print(a)print(np.median(a, axis=0)) # 求中位数print(np.average(a))print(np.mean(a)) # 均值print(np.average(range(1, 11), weights=range(10, 0, -1)))print(np.average(a, axis=1, weights=[1./4, 3./4])) # 加权平均print(np.std(a, axis=1)) # 标准差print(np.var(a, axis=1)) # 方差a[0][1] = np.nanprint(a)print(np.nanvar(a, axis=1)) NumPy 排序，搜索 numpy.sort 可以指定 axis = None, 0, 1 来指定排序方法， None 会将结果折叠为一维数组，0会按列处理， 默认为1，按行处理 使用关键字排序1234567import numpy as npdtype = [(&quot;name&quot;, &quot;S10&quot;), (&quot;height&quot;, float), (&quot;age&quot;, int)]values = [(&quot;Arthur&quot;, 1.8, 41), (&quot;Lancelot&quot;, 1.9, 38), (&quot;Galahad&quot;, 1.7, 38)]a = np.array(values, dtype=dtype) # 创建一个结构体数组print(np.sort(a, order='height'))# 当 age 相等时使用 height 作为比较print(np.sort(a, order=['age', 'height'])) numpy.argsort 对 a 排序，a 不变，返回一个排序后的索引，其余和 sort 相同 numpy.lexsort 支持对数组按指定行或列的顺序来排序，是间接排序 使用lexsort排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import numpy as npdtype = [(&quot;name&quot;, &quot;S10&quot;), (&quot;height&quot;, float), (&quot;age&quot;, int)]values = [(&quot;Arthur&quot;, 1.8, 41), (&quot;Lancelot&quot;, 1.9, 38), (&quot;Galahad&quot;, 1.7, 38)]a = np.array(values, dtype=dtype) # 创建一个结构体数组print(np.sort(a, order='height'))# 当 age 相等时使用 height 作为比较print(np.sort(a, order=['age', 'height']))# lexsorta = [1, 5, 2, 4, 3, 4, 4]b = [9, 4, 0, 4, 0, 4, 1]ind = np.lexsort((b, a)) # 先按a排序，再按b排序print(ind)a = np.array([[3, 4, 7, 1], [35, 44, 9, 1], [22, 12, 3, 3]])# 按最后一列顺序排序print(a[np.lexsort(a.T)])# 按最后一列逆序排序print(a[np.lexsort(-a.T)])# 按第一列顺序排序print(a[np.lexsort(a[:, ::-1].T)])# 按最后一行顺序排序print(a.T[np.lexsort(a)].T)# 按第一行顺序排序print(a.T[np.lexsort(a[::-1, :])].T)# 结果&quot;&quot;&quot;[(b'Galahad', 1.7, 38) (b'Arthur', 1.8, 41) (b'Lancelot', 1.9, 38)][(b'Galahad', 1.7, 38) (b'Lancelot', 1.9, 38) (b'Arthur', 1.8, 41)][0 2 4 6 3 5 1][[ 3 4 7 1] [35 44 9 1] [22 12 3 3]][[22 12 3 3] [35 44 9 1] [ 3 4 7 1]][[ 3 4 7 1] [22 12 3 3] [35 44 9 1]][[ 1 7 4 3] [ 1 9 44 35] [ 3 3 12 22]][[ 1 3 4 7] [ 1 35 44 9] [ 3 22 12 3]]&quot;&quot;&quot; argmax, nargmax 如果不指定 axis 则返回平坦化的下标，指定会按指定列或行轴来返回最值下标","link":"/2020/01/21/NumPy_base/"},{"title":"Python-base-general","text":"Python 基础的一些补充 生成器 概念 如果使用yield语句， 可以让函数生成一个结果序列，而不仅仅是一个值 如： 12345678910111213&gt;&gt;&gt;def countdown(n): print(&quot;Counting down!&quot;) while n &gt; 0: yield n n -= 1&gt;&gt;&gt;countdown(5)&lt;generator object countdown at 0x00000289CCDB0888&gt;&gt;&gt;&gt;c = countdown(5)&gt;&gt;&gt;c.__next__()Counting down!5&gt;&gt;&gt;c.__next__()4 __next__（）调用使生成器函数一直运行，到下一条语句为之。此时__next__()将返回传递给yield的值，而且函数将暂时中止执行，再次调用next时，将执行yield之后的语句的，持续到函数返回为止。 通常不会手动调用__next__()，而是使用for in 循环 应用举例 生成器是编写基于处理管道，流或数据流程序的一种极强大的方式 下面代码模拟了常用于监控日志文件的UNIX tail -f命令的行为： tail 命令可用于查看文件的内容，有一个常用的参数 -f 常用于查阅正在改变的日志文件。 tail -f filename 会把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，只要 filename 更新就可以看到最新的文件内容。 123456789import timedef tail(f): f.seek(0, 2) # 移动到EOF while True: line = f.readline() # 尝试读取新的一行文本 if not line: # 如果没有内容，暂时休眠并尝试 time.sleep(0.1) continue yield line 下面代码用于在很多行中查找特定的子字符串，结果返回 1234def grep(lines, searchText): for line in lines: if searchText in line: yield line 这和你写个函数内的列表每次append一下，最后返回列表从结果看没啥区别 每次__next__调用时，到下一条yield，也就是到下一个匹配的字符，即可以迭代获得所有有特定子字符串的行。 生成器的微妙之处在于编写for in 语句时，in后面可以跟列表，文件生成器函数的结果，或者支持迭代的其他任意对象。扩大了程序可拓展性。 文档字符串 如果模块，类或者函数的第一条语句是一个字符串的话，该字符串会成为doc 通过函数名/类名/模块名.__doc__调用 类型与对象 type（）&amp;isinstance（） type() 函数如果只有第一个参数则返回对象的类型，三个参数返回新的类型对象。 isinstance() 与 type() 区别： type() 不会认为子类是一种父类类型，不考虑继承关系。 isinstance() 会认为子类是一种父类类型，考虑继承关系。 如果要判断两个类型是否相同推荐使用 isinstance()。 语法 以下是 type() 方法的语法: type(object) type(name, bases, dict) 参数 • name – 类的名称。 • bases – 基类的元组。 • dict – 字典，类内定义的命名空间变量。 返回值 一个参数返回对象类型, 三个参数，返回新的类型对象。 实例 123456789101112131415161718192021222324252627282930&gt;&gt;&gt;type(1) &lt;type 'int'&gt;&gt;&gt;&gt;type('runoob') &lt;type 'str'&gt;&gt;&gt;&gt;type([2]) &lt;type 'list'&gt;&gt;&gt;&gt;type({0:'zero'}) &lt;type 'dict'&gt;&gt;&gt;&gt;x = 1；type( x ) == int True &gt;&gt;&gt;class X(object): a = 1&gt;&gt;&gt;X = type('X', (object,), dict(a=1)) # 产生一个新的类型 X&gt;&gt;&gt;X&gt;&gt;&gt;&lt;class '__main__.X'&gt;#type() 与 isinstance()区别：class A: pass class B(A): passisinstance(A(), A) # returns Truetype(A()) == A # returns Trueisinstance(B(), A) # returns Truetype(B()) == A # returns False 垃圾回收机制 在python中 变量无需事先声明 变量无需指定类型 程序员不用关心内存管理 变量名会被回收 del语句可以直接释放资源 变量定义 变量在使用前必须先声明，python中变量在第一次被赋值时自动声明 动态类型：python中变量无需声明类型，对象的类型和内存都是运行时确定的 引用计数 增加引用计数 当对象被创建并（将其引用）赋值给变量时，该对象的引用计数就被设置为1 当同一个对象（的引用）又被赋值给其他变量时，或作为参数传递给函数，方法或类的实例时，该对象的引用计数自动+1 如 x=3.14 y=x （此时并没有为y新建一个对象，而是将该对象x的引用次数+1） 减少引用计数 当对象的引用被销毁时，引用计数会减少，最明显的例子是当引用离开其作用范围时，这种情况最经常出现在函数运行结束，局部变量自动销毁。 当变量被赋值为另外一个对象时，原对象的引用计数也会自动-1 del删除 引申：任何追踪或调试程序都会给一个对象增加一个额外的引用，可以推迟对象被回收的时间 垃圾收集 不再使用的内存会被一种称为垃圾收集的机制释放。 当一个对象的引用计数变为0时，解释器会暂停，释放掉这个对象和仅有的这个对象可访问（可到达的)其他对象。 ps： 可以使用sys.getrefcount(t)来获取t的当前引用计数 深浅拷贝 对每个对象的浅拷贝其实就是创建了一个类型跟原对象一样，其内容是原来对象的引用的对象。序列类型（list，tuple）对象的拷贝默认是浅拷贝，并可以以下几种方式实施：完全切片操作，工厂函数，copy模块的copy 浅拷贝意味着如果修改原对象，拷贝的对象也会跟着改变 使用copy.deepcopy（）实现深拷贝（在copy标准库里） 上下文管理协议 with语句支持在另一个成为上下文管理器的对象的控制下执行一系列语句。 with context [as var] statement 其中context对象需要实现下表的中的方法： 方法 描述 __enter__(self) 进入上下文时调用，其返回值将被放入有with语句的as说明符指定的变量中 __exit__(self, type, value, tb) 离开上下文时调用。如果有异常，则type，value，tb分别为异常的类型，异常的值，跟踪信息。保证安全释放资源 上下文管理接口的首要用途是简化涉及系统状态（打开文件，网络连接和锁定对象）的对象的控制。 如果没有要处理的错误，所有三个值将被置成None Attention！ 一般情况下，引发的异常可能导致控制流跳过负责释放关键资源（如锁）的语句，而使用with语句就会更加安全。 1234567891011#sample-1with open(&quot;debug_log&quot;, &quot;a&quot;) as f: f.write(&quot;Debugging\\n&quot;) #statement#sample-2import threadinglock = threading.Lock() #获取锁with lock: #statement 第一个例子中，当控制流离开with语句时，会自动关闭已经打开的文件 第二个例子中，当控制流进入with后的语句时，会自动请求锁 lock.acquire()，在控制流离开时会释放这个锁 lock.release() 我们还可以自定义实现上下文管理器，看下面的例子： 1234567891011121314151617181920212223242526272829# -*- coding:utf-8 -*-#Transaction: 交易,办理,事务class ListTransaction(): def __init__(self, list): self.list = list def __enter__(self): self.copyList = list(self.list) return self.copyList def __exit__(self, exc_type, exc_val, exc_tb): if exc_type is None: self.list[:] = self.copyList return False items = [1, 2, 3]with ListTransaction(items) as working: working.append(4) working.append(5)print(items)items = [1, 2, 3]try: with ListTransaction(items) as working: working.append(4) working.append(5) raise RuntimeError(&quot;Toooooo Much!!&quot;)except RuntimeError: passprint(items) 当exc_type 为None 时, 说明没有捕获到异常，将copyList赋值到list里 若不为None，说明出现异常，返回false（这会将异常传递出上下文，该函数的返回值表示产生的异常是否处理了） 由于返回false， 我们外面的except 才捕捉到了上下文传出的异常，而当有异常时，我们的self.list并不发生变化（没有赋值） 结果： [1, 2, 3, 4, 5] [1, 2, 3] contextlib模块通过包装生成器函数，更容易实现自定义上下文 下面是contextmanager源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class _GeneratorContextManager(ContextDecorator, AbstractContextManager): &quot;&quot;&quot;Helper for @contextmanager decorator.&quot;&quot;&quot; def __init__(self, func, args, kwds): self.gen = func(*args, **kwds) self.func, self.args, self.kwds = func, args, kwds # Issue 19330: ensure context manager instances have good docstrings doc = getattr(func, &quot;__doc__&quot;, None) if doc is None: doc = type(self).__doc__ self.__doc__ = doc def _recreate_cm(self): return self.__class__(self.func, self.args, self.kwds) def __enter__(self): try: return next(self.gen) except StopIteration: raise RuntimeError(&quot;generator didn't yield&quot;) from None def __exit__(self, type, value, traceback): if type is None: try: next(self.gen) except StopIteration: return False else: raise RuntimeError(&quot;generator didn't stop&quot;) else: if value is None: # tell if we get the same exception back value = type() try: self.gen.throw(type, value, traceback) except StopIteration as exc: # Suppress StopIteration *unless* it's the same exception that # was passed to throw(). This prevents a StopIteration # raised inside the &quot;with&quot; statement from being suppressed. return exc is not value except RuntimeError as exc: # Don't re-raise the passed in exception. (issue27122) if exc is value: return False # Likewise, avoid suppressing if a StopIteration exception # was passed to throw() and later wrapped into a RuntimeError # (see PEP 479). if type is StopIteration and exc.__cause__ is value: return False raise except: # only re-raise if it's *not* the exception that was # passed to throw(), because __exit__() must not raise # an exception unless __exit__() itself failed. But throw() # has to raise the exception to signal propagation, so this # fixes the impedance mismatch between the throw() protocol # and the __exit__() protocol. # if sys.exc_info()[1] is value: return False raise raise RuntimeError(&quot;generator didn't stop after throw()&quot;)def contextmanager(func): &quot;&quot;&quot;@contextmanager decorator. Typical usage: @contextmanager def some_generator(&lt;arguments&gt;): &lt;setup&gt; try: yield &lt;value&gt; finally: &lt;cleanup&gt; This makes this: with some_generator(&lt;arguments&gt;) as &lt;variable&gt;: &lt;body&gt; equivalent to this: &lt;setup&gt; try: &lt;variable&gt; = &lt;value&gt; &lt;body&gt; finally: &lt;cleanup&gt; &quot;&quot;&quot; @wraps(func) def helper(*args, **kwds): return _GeneratorContextManager(func, args, kwds) return helper 我们的关注点在__enter__和__exit__，虽然不能完全看懂，但可以看明白个大概： __enter__中捕获可迭代对象的StopIteration（当迭代到最后一项时抛出），即进入时检测是否可以迭代 __exit__调用迭代函数的返回结果一次，看看到最后没，结束时检测是否迭代到最后，否则抛出RuntimeError，如果出现异常，则调用函数throw出异常（这里好多看不懂的…） ps：当能看懂的时候我会回来完善的 另外一个关注点就是contextmanager修饰器的doc，有这个铺垫就可以看懂书上的这段代码： 12345678from contextlib import contextmanager@contextmanagerdef list_transaction(items): copy_list = list(items) yield copy_list #仅在没有出现错误时才会修改原始列表 items[:] = copy_list 当然最安全的写法是try list（items），防止无法转成列表，然后就可以调用yield了。 这个例子将传递给yield的值作用了__enter__方法的返回值，调用__exit__时，执行将在yield语句后恢复。","link":"/2019/07/09/Python-base-addition/"},{"title":"Python爬虫--协程","text":"2020/4/20 更新，根据给社团新生的讲课内容适当进行了补充 协程 协程（coroutine），又称微线程，纤程， 是一种用户级的轻量级的线程。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存在其他地方，在切换回来时，恢复先前保存的寄存器上下文和栈。因此协程可以保存上一次调用的状态，每次过程重入时，就相当于进入上一次调用的状态。在并发编程中，协程与线程类似，每个协程表示一个执行单元，有自己的本地数据，与其他协程共享全局数据和其他资源。 协程需要用户自己来编写调度逻辑，对于CPU来说，协程实际是单线程，所以CPU不考虑怎么去调度，切换上下文，这就省去了CPU切换的开销，所以协程在一定程度上又好于多线程。 Python使用yield提供了对协程的基本支持 第三方库gevent库是最好的选择，gevent提供了比较完善的协程支持。gevent是一个基于协程的Python的网络函数库，gevent对协程的支持本质是greenlet在实现切换工作。greenlet工作流程如下：假如进行访问网络的I/O操作时，出现阻塞，greenlet就显示切换到另一段没有被阻塞的代码段执行，直到原先的阻塞情况消失以后，再自动切换回原来的代码段继续执行。因此，greenlet是一种合理安排的串行方式。 I/O操作耗时，而使程序处于等待状态，有gevent帮我们切换，保证了总有greenlet在运行，而不是等待I/O。 例子1 123456789101112131415161718from gevent import monkey; monkey.patch_all()import geventimport requestsdef run_task(url): print('Visit ---&gt; %s' %(url)) try: response = requests.get(url) data = response.content print('%d byte received from %s' %(len(data), url)) except Exception as e: print(e)if __name__ == '__main__': urls = ['https://github.com/', 'https://www.python.org/', 'http://www.cnblog.com/'] greenlets = [gevent.spawn(run_task, url) for url in urls] gevent.joinall(greenlets) 结果 123456 Visit ---&gt; https://github.com/Visit ---&gt; https://www.python.org/Visit ---&gt; http://www.cnblog.com/2043 byte received from http://www.cnblog.com/92576 byte received from https://github.com/48995 byte received from https://www.python.org/ 以上主要使用了gevent中的spawn方法和joinall方法，spawn方法可以看做是用来形成协程，而joinall方法就是添加这些任务，而且启动运行，从结果来看，三个操作似乎是并发的，而且结束顺序不同，但实际只有一个线程。 补充关于 yield 的例子 123456789101112131415# -*- coding:utf-8 -*-# n = 1# From Webdef gen(n): n = 0 while True: yield n n += 1g = gen(n)print(g) # &lt;generator object gen at 0x00000246E165A7C8&gt;print(next(g)) # 输出结果为0print(next(g)) # 输出结果为1 当我们需要下一个 g 的时候，gen 才会继续执行，直到执行到 yield 语句后暂停。这里就可以很明显的猜到其实现就是基于协程的实现，每次执行到 yield 语句的时候保存现场然后切换出去（执行运行的代码的下一条语句），需要计算下一个值的时候恢复上次的计算状态然后接着计算。 优势 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。","link":"/2020/04/20/Python-coroutine/"},{"title":"Python--线程&amp;进程","text":"2020/4/20 更新，根据给社团新生的讲课内容适当进行了补充 2020/10/25 更新，整合内容 多线程和多进程概念 当计算机运行程序时，就会创建包含代码和状态的进程。这些进程会通过计算机的一个或多个CPU执行。不过，同一时刻一个CPU只会执行一个进程，然后在不同进程之间快速切换，这样就给人以多个程序同时进行的感觉（所有进程都使用一个CPU，占用一定时间后切换给另一个进程）。同理，在一个进程中，程序的执行也是在不同的线程间进行切换的，每个线程执行程序的不同部分。 例子 多线程使得程序内部可以分出多个线程来做多件事情，而不会造成程序界面卡死。比如迅雷等多线程下载工具就是典型的多线程。一个下载任务进来，迅雷把文件平分成10份，然后开10个线程分别下载。这时主界面是一个单独的线程，并不会因为下载文件而卡死。而且主线程可以控制下属线程，比如某个线程下载缓慢甚至停止，主线程可以把它强行关掉并重启另外一个线程。 另外就是一些程序的打印功能，比如记事本、Adobe Reader，打印的时候就只能打印，无法在主界面进行操作，而Word就有“后台打印”的功能，点了打印命令之后，还可以回到主界面进行修改、保存等操作。 进程是程序在计算机上的一次执行活动。当你运行一个程序，你就启动了一个进程。显然，程序是死的(静态的)，进程是活的(动态的)。进程可以分为系统进程和用户进程。凡是用于完成操作系统的各种功能的进程就是系统进程，它们就是处于运行状态下的操作系统本身；用户进程就不必我多讲了吧，所有由你启动的进程都是用户进程。进程是操作系统进行资源分配的单位。 当电脑如果是一个多核的 CPU 的时候，情况可能会有些不同： 多核CPU即多个CPU组成，这些CPU集成在一个芯片里，可以通过内部总线来交互数据，共享数据，这些CPU中分配出一个独立的核执行操作系统，这些CPU通过总线来交互数据，并且工作是并行的，资源分配是由操作系统来完成的，操作系统来决定程序CPU的控制权分配，所以一个多核CPU的工作效率大多体现在操作系统的分配上，因为一个CPU基本上可以执行很多个程序，然后来回跳转，所以当你的CPU核过多时，操作系统在分配时可能会导致部分CPU闲置。 Python 进程池 -当要启动大量子进程时，使用进程池批量创建子进程的方法更常见。这时用Process动态生成多进程时过于麻烦，进程池Pool发挥作用的机会到了 -multiprocessing模块提供了一个Pool类来代表进程池对象 -Pool可以提供指定数量的进程供用户调用，默认大小是CPU的核数。当有新的请求提交到Pool中，如果池还没满，就会创建新的进程，否则就会等待直到池中有进程结束。 注意：Pool对象调用join（）方法会等待所有子进程执行完毕，调用join（）前必须先调用close（），调用close（）后就不能添加新的Process了 实例方法 类的方法 apply(func[, args[, kwds]])：同步进程池 apply_async(func[, args[, kwds[, callback[, error_callback]]]]) ：异步进程池 close() ： 关闭进程池，阻止更多的任务提交到pool，待任务完成后，工作进程会退出。 terminate() ： 结束工作进程，不在处理未完成的任务 join() : wait工作线程的退出，在调用join()前，必须调用close() or terminate()。这样是因为被终止的进程需要被父进程调用wait（join等价与wait），否则进程会成为僵尸进程。pool.join()必须使用在 创建进程池 12345678910111213141516171819202122232425262728293031def run_task(name): print(&quot;Task %s (pid = %s) is running ...&quot; % (name, os.getpid())) time.sleep(random.random() * 3) print(&quot;Task %s end&quot; % (name,))if __name__ == '__main__': print(&quot;Current process %s.&quot; % (os.getpid())) p = Pool(processes=3) for i in range(5): p.apply_async(run_task, args=(i,)) print(&quot;Waiting for all subprocess&quot;) p.close() p.join() print(&quot;All subprocess done&quot;)#运行结果#Current process 11268.#Waiting for all subprocess#Task 0 (pid = 15428) is running ...#Task 1 (pid = 17956) is running ...#Task 2 (pid = 1324) is running ...#Task 2 end#Task 3 (pid = 1324) is running ...#Task 1 end#Task 4 (pid = 17956) is running ...#Task 3 end#Task 0 end#Task 4 end#All subprocess done 同步进程池&amp;异步进程池 仍以上例： apply_async为异步执行，即不堵塞，当碰到子进程后，主进程说：让我先运行个够，等到操作系统进行进程切换的时候，再交给子进程运行。若没有p.join(),则会出现由于我们的程序太短，还没等到操作系统进行进程切换，主进程就运行完毕了，子进程自然没法运行。 想要子进程执行，就告诉主进程：你等着所有子进程执行完毕后，在运行剩余部分，就是p.join()。 而若改apply_async为apply，则阻塞主进程。主进程开始运行，碰到子进程，操作系统切换到子进程，等待子进程运行结束后，再切换到另外一个子进程，直到所有子进程运行完毕再切换到主进程，运行剩余的部分。 这样的效率明显不高，而且这样和单进程就几乎没啥两样了，所以建议使用apply_async，而不是apply。 Python 多线程 多线程类似于同时执行多个不同的程序，多线程有如下有优点： 可以把运行时间长的程序放到后台去处理 用户界面可以更加吸引人，比如用进度条去显示处理的进度。 可以加速程序的运行 在一些需要等待的任务实现上，如用户输入，文件读写，网络收发数据，线程就会很有用，这种情况下我们可以释放一些珍贵的资源，如内存占用 使用threading模块创建多线程 threading模块一般通过两种方式创建多线程：第一种方式是把一个函数传入并创建一个Thread实例，然后调用start方法开始执行；第二种方式是直接从threading.Thread 继承并创建线程类，然后重写__init__方法和run方法。 例子：创建多线程流程 1234567891011121314151617181920212223242526272829303132333435class MyThread(threading.Thread): def __init__(self, name, urls): threading.Thread.__init__(self, name=name) self.urls = urls def run(self): print(&quot;Current %s is running...&quot; % threading.current_thread().name) for url in self.urls: print(&quot;%s ----&gt;&gt;&gt; %s&quot; % (threading.current_thread().name, url)) time.sleep(random.randint(1, 3)) print(&quot;%s ended.&quot; % threading.current_thread().name)print(&quot;%s is running...&quot; % threading.current_thread().name)t1 = MyThread(name=&quot;Thread_1&quot;, urls=[&quot;url_1&quot;, &quot;url_2&quot;, &quot;url_3&quot;])t2 = MyThread(name=&quot;Thread_2&quot;, urls=[&quot;url_4&quot;, &quot;url_5&quot;, &quot;url_6&quot;])t1.start()t2.start()t1.join()t2.join()print(&quot;%s ended.&quot; % threading.current_thread().name)#结果#MainThread is running...#Current Thread_1 is running...#Thread_1 ----&gt;&gt;&gt; url_1#Current Thread_2 is running...#Thread_2 ----&gt;&gt;&gt; url_4#Thread_2 ----&gt;&gt;&gt; url_5#Thread_1 ----&gt;&gt;&gt; url_2#Thread_2 ----&gt;&gt;&gt; url_6#Thread_1 ----&gt;&gt;&gt; url_3#Thread_1 ended.#Thread_2 ended.#MainThread ended. 线程同步 如果多个线程共同对某个数据修改，则由于修改的先后可能会导致某次修改被“吞”，出现不可预料的结果，为了保证数据的正确性，需要对多线程进行同步。使用Thread对象的Lock和Rlock可以实现简单的线程同步（线程锁，访问数据时锁死数据防止别的线程修改），这两个对象都有acquire方法（获取锁）和release方法（释放锁），对于每次只允许一个线程操作的数据，可以将其操作放在acquire和release之间 对于Lock对象而言，如果一个线程连续两次进行acquire操作，那么由于第一次acquire之后没有release，第二次acquire将挂起该线程（此时该线程还在等待获取锁），这会导致Lock对象永远不会release，使得线程死锁。 Rlock对象允许一个线程多次对其进行acquire操作，因为在其内部有一个counter变量记录acquire的次数，而且每一次acquire操作后必须有个release操作与之对应，在所有的release操作完成后，别的线程才可以申请Rlock对象。 获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try…finally来确保锁一定会被释放。 例子 12345678910111213141516171819202122232425262728293031import threadingmylock = threading.RLock()num = 0 class MyThread(threading.Thread): def __init__(self, name): threading.Thread.__init__(self, name=name) # 一个线程多次访问锁 def run(self): global num while True: # 获取锁 mylock.acquire() print(&quot;%s locked, number: %d&quot; % (threading.current_thread().name, num)) if num &gt;= 4: mylock.release() print(&quot;%s released, number: %d&quot; % (threading.current_thread().name, num)) break num += 1 print(&quot;%s released, number: %d&quot; % (threading.current_thread().name, num)) mylock.release()if __name__ == '__main__': thread1 = MyThread(&quot;thread_1&quot;) thread2 = MyThread(&quot;thread_2&quot;) thread2.start() thread1.start() Python全局解释锁 在python的原始解释器CPython中存在GIL（Global Interpreter Lock），因此在解释执行Python的代码时，会产生互斥锁（在一个线程修改变量时加锁，则其他线程等待加锁的变量解锁后再执行）来限制线程对共享资源的访问，直到解释器遇到I/O操作或者操作次数达到一定数目时才会释放GIL。由于全局解释锁的存在，在进行多线程操作时不能调用多个CPU内核，只能用一个内核，所以在进行CPU密集操作时不推荐使用多线程，更倾向于使用多进程。 那么多线程适合干啥？ 对于I/O密集操作，多线程可以明显提高效率，例如Python爬虫开发，绝大多数时间爬虫是在等待socket返回数据，网络I/O的操作延迟比CPU大很多 GIL 例子1 12345678910111213141516171819202122232425262728# -*- coding:utf-8 -*-from threading import Thread, RLocklock = RLock()value = 0class MyThread(Thread): def __init__(self): super().__init__() def run(self): global value for i in range(50000): value += 1if __name__ == '__main__': thread_1 = MyThread() thread_2 = MyThread() thread_1.start() thread_2.start() thread_1.join() thread_2.join() # 结果会是你想象的 value ！= 100000 吗 print(value) 我们得到的结果是 100000，你可能会很好奇，难道不会因为多线程竞争导致有些加操作无效了吗，这里就是全局解释锁在起作用，确保当前语句在被解释的时候变量被上锁。 很神奇的是，当你修改累加次数更大如5000000时，这个结果每次运行就会不同，我个人觉得这是因为当某个操作达到一定次数的时候，全局解释锁被释放导致竞争中一些加操作被吞了。 另外的一个例子 1234567891011121314151617181920212223242526# -*- coding:utf-8 -*-import threadingimport timezero = 0lock = threading.Lock()def change_zero(): # lock.acquire() global zero for i in range(100000): zero += 1 zero -= 1 # lock.release()if __name__ == '__main__': th1 = threading.Thread(target=change_zero) th2 = threading.Thread(target=change_zero) th1.start() th2.start() th1.join() th2.join() # zero == 0 ??? 是这样吗? print(zero) 结果当然不为 0 而且每次都不一样，这是因为在解释完 zero += 1 后有可能全局解释锁给了别的线程，但是在累加次数比较小的时候结果是0。 python 的这一点和编译性语言完全不同。 GIL 例子2 我们来验证在 gil 的情况下多线程对于 CPU 密集操作和 I/O 密集操作造成了什么影响。 CPU 密集操作即需要大量的计算的操作 I/O 密集操作即需要频繁的进行输入输出的操作 I/O 密集操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- coding:utf-8 -*-from threading import Threadimport timetime_1 = 0time_2 = 0def my_counter(): for temp in range(5000): with open(&quot;test.txt&quot;, 'w+') as fp: fp.write(&quot;Hello, Hello, This is cyx\\n&quot;) print(&quot;Hello, Hello, This is cyx&quot;) fp.close()def test1(): thread_array = {} start_time = time.time() for tid in range(2): t = Thread(target=my_counter) t.start() t.join() # 模拟单线程 end_time = time.time() return end_time - start_timedef test2(): thread_array = {} start_time = time.time() for tid in range(2): t = Thread(target=my_counter) t.start() thread_array[tid] = t for i in range(2): thread_array[i].join() end_time = time.time() return end_time - start_timeif __name__ == '__main__': time_1 = test1() time_2 = test2() print(&quot;test1: Total time= {}&quot;.format(time_1)) print(&quot;test2: Total time= {}&quot;.format(time_2)) 执行以下可以发现，2线程的执行时间基本达到了单线程的一半时间，可以看出相当的有效 而对于 CPU 密集操作就不是那么有效了，稍微修改一下例子 CPU 密集操作 123456789101112131415161718192021222324252627282930313233343536373839# -*- coding:utf-8 -*-from threading import Threadimport timedef my_counter(): i = 0 for temp in range(1000000): i = i + 1def test1(): thread_array = {} start_time = time.time() for tid in range(2): t = Thread(target=my_counter) t.start() t.join() # 模拟单线程 end_time = time.time() print(&quot;Total time: {}&quot;.format(end_time - start_time))def test2(): thread_array = {} start_time = time.time() for tid in range(2): t = Thread(target=my_counter) t.start() thread_array[tid] = t for i in range(2): thread_array[i].join() end_time = time.time() print(&quot;Total time: {}&quot;.format(end_time - start_time))if __name__ == '__main__': test1() test2() 运行可以看到，2线程相对于单线程的时间没有减少反而增多了，因为 GIL 上锁的机制导致并没有提高很大的速度（很有可能还减慢了速度） 所以，最好使用多线程的方式还是读写文件等一些 I/O 操作者，这样才可以充分发挥多线程的优势。","link":"/2020/10/25/Python-process-and-thread/"},{"title":"AI-Introduction","text":"每羊大学 2020 级软工不做网站/应用了，改成了做一个人工智能相关的项目（亚达），这门课改名为软件工程——人工智能导论！ 人工智能绪论 人工智能 &gt; 机器学习 &gt; 深度学习 监督学习 数据标记（输出空间）已知，目的在于学习输入和输出的映射 标注所有的数据过于庞大 无监督学习 数据标记未知，目的在于发现数据中的模式或者有意义的信息 半监督学习 数据标记部分已知，是监督学习和无监督学习的混合 强化学习 数据标记未知，知道与输出目标相关的反馈，适用于决策类问题 虽然使用未标记的数据，但可以知道离目标越来越近还是越来越远（奖励反馈） 数据分布 参数模型 对数据分布进行假设，待求解的数据模式/映射可以用一组有限且固定数目的参数来刻画 比如假设条件概率 P(Y|X) 属于高斯分布，我们就应该用一个线性回归模型来解决（对问题数据的假设后用固定数量参数的模型来解决） 非参数模型 无法得到数据的分布，所有的模型特性都从数据本身来学。非参 != 无参 建模对象 生成模型：对输入X和输出Y的联合分布P(X, Y)建模 判别模型：对已知输入X条件下输出Y的条件分布P(Y|X)建模 机器学习历史 特征 传统机器学习：人工设计特征 预处理：经过数据的预处理，如去除噪声等。比如在文本分析中去除停用词 特征提取：从原始数据中提取一些有效的特征。比如在图像分类中提取边缘，尺度不变特征变换特征等 特征转换：对特征进行一定的加工，比如降维和升维。降维包括： 特征抽取（Feature Extraction）：PCA，LDA 特征选择（Feature Selection）：互信息，TF-IDF 深度学习的不能 算法输出不稳定，容易被攻击（如：one pixel attack） 模型复杂程度高，难以纠错和调试 模型层级复合程度高，参数不透明 专注直观感知类问题，对开放性推理问题无能为力 人类知识无法有效引入进行监督，机器偏见难以避免 可解释性差 神经网络基础 浅层神经网络 启发：生物神经元 每个神经元都是一个多输入单输出的信息处理单元 神经元具有空间整合和时间整合特性 神经元输入分为兴奋性输入和抑制性输入 神经元具有阈值特性 生物神经元 -&gt; M-P 神经元 f？激活函数，超出阈值才会被激活。为什么要引入激活函数？ 没有激活函数就相当于矩阵相乘，只能拟合线性函数 加入激活函数使得对非线性函数有拟合能力 sigmoid 函数，逻辑函数: $\\sigma \\left ( z \\right ) = \\frac{1}{1+e^{-z} }$，其导数 ${\\sigma \\left ( z \\right ) }’ = \\sigma \\left ( z \\right )\\left ( 1- \\sigma \\left ( z \\right ) \\right )$ 由于输出不对称，修改为双极S性函数 $$ tanh(x) = 2 \\times sigmoid(2x)-1 = \\frac{e{z}-e{-z}}{e{z}+e{-z}} \\ g(z)’ = 1 - g(z)^2 $$ 其余的还有ReLU修正线性单元 $relu(z) = max(0,z)$，leaky ReLU $leakyrelu(z)=max(0.01z, z)$ （增加了可以跳出0的初值） 单层感知器 非线性激活函数 $h(x)=g(10-20x_1)$，当x=0时，z=10，h计算选择 sigmoid 函数，此时h近似为1，当x=1时，z=-10，h近似为0，相当于实现了逻辑非，我们只看x和h，相当于在01空间里做了一个分界面，这个面就是我们上面的函数。 但是异或就无法被划分了，单层-&gt;多层 来解决这个问题。 拿基础的逻辑or或者and组合来完成这个操作，对于原始的输入，经过第一步处理形成了一个中间层，中间层通过组合来确立最终的输出。 深度学习训练过程可视化 playground.tensorflow.org 如果一个隐层包含足够多的神经元，三层前馈神经网络（输入-隐层-输出）能以任意精度逼近任意预定的连续函数。当隐层足够宽时，双隐层感知器可以逼近任何非连续函数 为什么隐层越多越精确？ 每一层的数学公式 $\\vec{y}=a(W\\cdot\\vec{x}+b)$ 完成输入到输出空间的变化（升维降维，放大缩小，旋转平移，弯曲） 神经网络学习如何利用矩阵的线性变换加激活函数的非线性变换，将原始输入空间投影到线性可分的空间去分类/回归。增加节点数：增加线性转换能力，增加层数:增加激活函数的次数，即增加非线性转换次数。 Fat and Short or Thin and Tall? 有论文说明：深度和宽度对函数复杂度的贡献是不同的，深度的贡献是指数增长的，而宽度贡献是线性的。 但实际我们如果用上面的网站，尝试在使用 sigmoid 激活函数做二分时，当深度在4,5时就无法分类了。 这就是多层神经网络的一个梯度消失问题 多层神经网络可以看做一个复合的非线性多元函数，但不断的传输会导致损失不断的增大。 无约束优化：梯度下降 参数沿负梯度方向更新可以使函数值下降 $$ \\theta_j = \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta) $$ 误差反向传播 复合函数的链式求导 $$ \\frac{\\partial L}{\\partial w_i} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_i} $$ 代入 $$ \\sum_{c}{k=1}(a_k-y_k)2 \\ \\sigma(z)=\\frac{1}{1+e^-z} $$ 经过计算 $$ \\frac{\\partial L}{\\partial w_i} = 2(a-y)\\cdot a(1-a) \\cdot x_i $$ 残差：定义为损失函数在某个结点的偏导： $da^{[1]}=\\frac{\\partial L}{\\partial a^{[1]}} = \\frac{\\partial L}{\\partial z^{[2]}} \\cdot W^{[2]}$ 梯度消失 误差在反向传播时在乘激活函数的倒数时由于斜率过低导致误差直接消失掉了。也就是说前面的几层根本无法接收到这个传回来的误差。这样虽然更新了后面的几层，但是当新一个 x 传入时，后面的值又变了回来，相当于这次基于误差的修改并没有起到作用。 逐层预训练（layer-wise pre-training）解决局部最小值的问题和梯度消失问题，即寻找一个还不错的局部最小值。 受限波尔兹曼机和自编码器 自编码器：最初被提出来用来降维 堆叠自编码器（stacked autoencoder，SAE） 将多个自编码器得到的隐层串联 将所有层预训练完成后，进行基于监督学习的全网络微调 受限玻尔兹曼机（RBM）： 目的是让隐藏层得到可见层v’ 与原来的可见层v分布一致，从而使隐藏层作为可见层输入的特征。两个方向权重w共享，偏置不同。 最终形式，条件概率建模，以 sigmoid 作为激活函数: $$ P(h_i=1|v) = sigm(c_i+W_i v) \\ P(v_j=1|h) = sigm(b_j+{W_j}'h) $$ 联合概率 -&gt; 条件概率，即需要从联合概率里推出两个方向的条件概率 $$ p(h|v)=\\frac{p(h,v)}{p(v)}, p(v|h)=\\frac{p(h,v)}{p(h)} $$ 怎么推出来的？什么是波尔兹曼？ 判别模型：直接建模计算条件概率 生成模型：先计算联合概率，然后通过贝叶斯公式来计算条件概率 那受限波尔兹曼的联合条件概率是什么样子的？ 统计物理学：能量越低越稳定，概率越大（熵小），即我们通过熵来联系概率和能量。 把能量的玻尔兹曼分布定义联合概率 把玻尔兹曼公式代入条件概率计算： RBM 到 DBN（深度信念网络） 一个 DBN 模型有若干个 RBM 堆叠而成，最后加一个监督层（如 BP 网络） 一般波尔兹曼机（BM）： 如今，逐层预训练成为了历史… 新的激活函数 + 优化方法 + 更大的标注训练数据使得预训练很少再被使用了，逐层训练无法从本质上解决梯度消失问题。 主流的深度学习平台甚至不支持 RBM 和预训练。 自编码器的变种 正则自编码器（Regularized AE），使提取的特征表达式符合某种性质 稀疏自编码器（Sparse AE），提取稀疏特征表达（我们认为高维而稀疏的表达式是好的） 去噪自编码器（Denoising AE），对被破坏或者污染的数据中重构原始数据，提取特征 变分自编码器（Variational AE），与对抗式生成网络 GAN 关系密切，是深度学习—概率图模型的桥梁","link":"/2020/10/15/ai-intro/"},{"title":"记一次写刷分程序","text":"假期回到家里接到老妈的需求，帮忙网课刷分 好孩子不要学 好嘞，写段js贼容易 发现这个网站登录需要app扫码 emmm，app扫码登录是怎么实现的呢？ 经过我的一波搜索，大致明白了过程 1.服务器生成二维码，我们使用解码工具可以看到，里面是一个网址加上一段字符作为参数，这个参数也是由服务器生成的，用来标识用户的唯一id 2.手机登录状态下，扫描二维码会访问这个url，服务器将该（登录）用户与这个id绑定 3.网页客户端轮询问服务器是否确定了id和用户，服务器一但绑定完成后接到请求，变给网页端返回该用户的信息 看起来不困难回来弄个 我使用Python自动化测试的selenium来模拟浏览器操作 需求是：扫描二维码登录，然后随机点6篇文章，模拟阅读，然后退出 首先也尝试过使用request来获取二维码，但是发现不行，经过排查发现这个二维码是js动态生成的，原本的html中是没有的，难受了 只好使用webdriver顺带获取了 先贴代码，这个是第一版的，以后可能会有优化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# -*- coding:utf-8 -*-from selenium import webdriverimport randomimport timeimport base64from PIL import Image, ImageTkimport tkinter as tkfrom io import BytesIOoptions = webdriver.FirefoxOptions()import osfrom multiprocessing import Process, Queue# options.add_argument('-headless')# options.add_argument('--disable-gpu')url = &quot;https://pc.xuexi.cn/points/login.html?ref=https%3A%2F%2Fwww.xuexi.cn%2Fd184e7597cc0da16f5d9f182907f1200%2F9a3668c13f6e303932b5e0e100fc248b.html&quot;def save_in_mem_qrcode(Qrcode): f = BytesIO() Qrcode = base64.b64decode(bytes(Qrcode, &quot;utf-8&quot;)) f.write(Qrcode) return fdef save_in_file_qrcode(Qrcode): Qrcode = base64.b64decode(bytes(Qrcode, &quot;utf-8&quot;)) fp = open(&quot;qr-code.png&quot;, 'wb+') fp.write(Qrcode) fp.close()class AutoLearn(): def __init__(self): self.ids = random.sample([x for x in range(1,20)], 6) self.passages_url = &quot;https://www.xuexi.cn/d184e7597cc0da16f5d9f182907f1200/9a3668c13f6e303932b5e0e100fc248b.html&quot; print(self.ids) self.driver = webdriver.Firefox(firefox_options=options) self.driver.maximize_window() def auto_read(self): self.scan_qrcode() self.driver.switch_to_default_content() try: self.driver.get(self.passages_url) except Exception as e: print(e) else: self.driver.implicitly_wait(30) for i in self.ids: try: self.driver.find_elements_by_xpath('//div[@class=&quot;text-link-item-title&quot;]/div[1]')[i].click() self.driver.implicitly_wait(30) main_handle = self.driver.current_window_handle handles = self.driver.window_handles self.driver.switch_to.window(handles[1]) print(self.driver.current_url) height = 0 i = 0 while i &lt; 8: self.driver.execute_script(&quot;window.scrollTo(100, {});&quot;.format(height)) time.sleep(random.randint(10, 20)) height += random.randint(200, 250) i += 1 time.sleep(10) self.driver.execute_script(&quot;window.scrollTo(100, document.body.scrollHeight);&quot;) time.sleep(10) self.driver.close() except Exception as e: print(e) self.driver.close() else: self.driver.switch_to.window(main_handle) def scan_qrcode(self): try: self.driver.get(url) except Exception as e: print(e) else: self.driver.implicitly_wait(60) self.driver.switch_to.frame('ddlogin-iframe') src = self.driver.find_element_by_xpath(&quot;//*[@id='qrcode']/img&quot;).get_attribute('src') qrcode = src.split(',')[1] p = Process(target=QR_GUI, args=(qrcode, )) p.start() p.join() # save_in_file_qrcode(qrcode) # path = &quot;qr-code.png&quot; def __del__(self): self.driver.close()def QR_GUI(code): root = tk.Tk() root.wm_resizable(False, False) # 不允许调整宽高 root.title(&quot;扫描二维表登录&quot;) fp = save_in_mem_qrcode(code) img_open = Image.open(fp) img_png = ImageTk.PhotoImage(img_open) label_img = tk.Label(root, image=img_png) label_img.pack() root.mainloop()if __name__ == '__main__': # q = Queue() t = AutoLearn() t.auto_read() 不知道为啥使用无头的时候不行，必须使用有界面的 当然遇见了不少问题，下面罗列供以后参考： 如何跳转到新建页面？ 其实每个页面都有一个叫handle的参数，来唯一标识这个页面，我们使用handles = driver.window_handles来获取目前浏览器的所有页面,然后driver.switch_to.window(handles[x])来获取第x个页面 如何实现拖动滚动条？ driver.execute_script(&quot;window.scrollTo(100, {});&quot;.format(height)) ps：这里我前端学到不扎实，忘了一些大小的计算关系，源码这个滚动条是随便指定位置的 当然，我们直接执行driver.execute_script(&quot;window.scrollTo(100, document.body.scrollHeight);&quot;)就可以跳转到页面底部 怎么往Tkinter中加入图片啊？ from PIL import Image,ImageTk 你需要pillow库支持，如下面的代码 12345#创建一个图片管理类img_open = Image.open(fp)img_png = ImageTk.PhotoImage(img_open)label_img = tk.Label(root, image=img_png) 这里fp是图片的文件路径，也可以直接在PhotoImage中指定file=xxx而省略第一步。不同的是我是把图片写在内存里了，这里，Image.open的模式不要指定，如果指定必须为’r’（不要因为是二进制就自己写个‘rb’） 我遇见了bug！ 我试图driver.get(&quot;xxx&quot;)时报错： InvalidArgumentException: Message: Malformed URL: can’t access dead object 问题所在： I think you switched into a frame just before .get(). And you cannot open an url in the frame.（来自Stack Overflow） 解决：driver.switch_to_default_content() 我看见了一个神奇的img标签！ 如下： &lt;img alt=“Scan me!” style=“display: block;” src=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANIAAADSCAYAAAA/… 这里是把图片的base64编码写在了html中，你可尝试复制下来图片，打开使用base64编码，会发现是一样的。这个被称为Data URI scheme 这个目的是将一些小的数据，直接嵌入到网页中，从而不用再从外部文件载入，减少服务器开销，毕竟我们把图像文件的内容直接写在了HTML文件中，节省了一个HTTP请求。坏处呢，就是浏览器不会缓存这种图像。 base64简单地说，它把一些 8-bit 数据翻译成标准 ASCII 字符 路径对啊，怎么访问不到? 可能是frame的问题： 在web 应用中经常会遇到frame 嵌套页面的应用，页WebDriver 每次只能在一个页面上识别元素，对于frame 嵌套内的页面上的元素，直接定位是定位是定位不到的。这个时候就需要通过switch_to.frame()方法将当前定位的主体切换了frame 里。 写在后面 这个程序还有很多地方待完善，功能也不是很全 马上就更汇编咕咕咕","link":"/2019/07/31/auto-learnVer1/"},{"title":"bochs","text":"Bochs 安装 2020/10/10 更新: Ubuntu20.04下安装Bochs 在学操作系统，想学着自己写一个玩，就找了书来读，第一步就是在 Linux 环境下安装 Bochs（一款开源的可调式虚拟机软件） 配环境什么的，我折腾过很多了，完全不怕！（然后就折腾了一下午） 准备好 Linux 系统 我本机是 Win10，又不想折腾双系统，就用 VMware 配了一个虚拟机，使用 CentOS7 的镜像 VMware 配虚拟机不需要多说，这个都用过，强烈建议装带图形界面的系统，不然后面安装和使用的时候会比较难受。 如果配的网络不行，或者想使用固定 IP 的形式，可以参考这篇博客： CentOS7安装详解 下载并解压 Bochs 下载官网 下不下最新版都可以，关键是要尽可能减少安装时的痛苦(?)，所以我选择的是和安装教程同一个版本的 记得下载 .tar.gz 正常解压，如果你使用的是图形界面，直接双击可以解压，也可以命令行解压: tar zxvf bochs-xx.xx.xx.tar.gz 编译安装 最痛苦的过程，我把我成功的流程发出来，说不定换个电脑就不行了 先安装各种依赖: 123sudo yum install gtk2 gtk2-develsudo yum install libXt libXt-develsudo yum install libXpm libXpm-devel 进入解压后的目录，然后执行: 1./configure --with-x11 --with-wx --enable-debugger --enable-disasm --enable-all-optimizations --enable-readline --enable-long-phy-address --enable-ltdl-install --enable-idle-hack --enable-plugins --enable-a20-pin --enable-x86-64 --enable-smp --enable-cpu-level=6 --enable-large-ramfile --enable-repeat-speedups --enable-fast-function-calls --enable-handlers-chaining --enable-trace-linking --enable-configurable-msrs --enable-show-ips --enable-cpp --enable-debugger-gui --enable-iodebug --enable-logging --enable-assert-checks --enable-fpu --enable-vmx=2 --enable-svm --enable-3dnow --enable-alignment-check --enable-monitor-mwait --enable-avx --enable-evex --enable-x86-debugger --enable-pci --enable-usb --enable-voodoo 有不少 no 是很正常的现象，我遇见的问题大致如下: Permission denied su 切换成 root，全部安装完成后再切回来(su - your_name) sudo ./configure.... xxx is not in the sudoer file su root (su -l) 输入root用户密码 chmod u+w /etc/sudoers vim /etc/sudoers, 在 ROOT ALL=（ALL）ALL 下加一行：xxx ALL=(ALL) ALL 然后保存并退出。其中xxx是你要加 sudo 权限的用户名 chmod u-w /etc/sudoers su - xxx no acceptable C compiler found in $PATH 没装 gcc sudo yum install gcc configure: error: C++ preprocessor “/lib/cpp” fails sanity check 出现该情况是由于 C++ 编译器的相关包没有安装 sudo yum install glibc-headers, sudo yum install gcc-c++ 如果你没有用图形界面，好像还会报别的错误，这时候需要安装一些别的包（所以为啥要自己为难自己呢） 上面步骤没啥问题后执行编译 make sudo make install 当然不会一帆风顺: 没有规则可以创建 “misc/bximage.o” … 原因是没有 .cc 文件，按照书上的方法我们将 .cpp 拷贝一份成 .cc 文件即可 123456cp misc/bximage.cpp misc/bximage.cccp iodev/hdimage/hdimage.cpp iodev/hdimage/hdimage.cccp iodev/hdimage/vmware3.cpp iodev/hdimage/vmware3.cccp iodev/hdimage/vmware4.cpp iodev/hdimage/vmware4.cccp iodev/hdimage/vpc-img.cpp iodev/hdimage/vpc-img.cccp iodev/hdimage/vbox.cpp iodev/hdimage/vbox.cc ISO C++ 不允许成员 PHY_MEM_PAGES 的初始化 我是真的不知道这个问题咋解决，出现的时候我用的是 Centos6 的镜像，重新解压编译也不行，就换成了Centos7，就没这问题了… symbols: DSO missing from command line collect2: error: ld returned 1 exit status 网上很多博客都说的一个问题，我是没遇见 在 Makefile 的 LIBS 中添加如下内容： -lz -lrt -lm -lpthread 全部完成之后试着打开一下，如果像下面一样就没啥问题了: .brochsrc 的配置 ls 是看不见有这个文件的，需要 ls -a 才能看见，我们有一个默认的，记得修改之前备份一下 按照任何一个教程里的，或者书上的文件配置复制粘贴进去就行了 .brochsrc12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# configuration file generated by Bochsplugin_ctrl: unmapped=1, biosdev=1, speaker=1, extfpuirq=1, parallel=1, serial=1, iodebug=1config_interface: textconfigdisplay_library: x#memory: host=2048, guest=2048romimage: file=&quot;/usr/local/share/bochs/BIOS-bochs-latest&quot;vgaromimage: file=&quot;/usr/local/share/bochs/VGABIOS-lgpl-latest&quot;boot: floppyfloppy_bootsig_check: disabled=0floppya: type=1_44, 1_44=&quot;boot.img&quot;, status=inserted, write_protected=0# no floppybata0: enabled=1, ioaddr1=0x1f0, ioaddr2=0x3f0, irq=14ata0-master: type=noneata0-slave: type=noneata1: enabled=1, ioaddr1=0x170, ioaddr2=0x370, irq=15ata1-master: type=noneata1-slave: type=noneata2: enabled=0ata3: enabled=0pci: enabled=1, chipset=i440fxvga: extension=vbe, update_freq=5 cpu: count=1:1:1, ips=4000000, quantum=16, model=corei7_haswell_4770, reset_on_triple_fault=1, cpuid_limit_winnt=0, ignore_bad_msrs=1, mwait_is_nop=0, msrs=&quot;msrs.def&quot; cpuid: x86_64=1,level=6, mmx=1, sep=1, simd=avx512, aes=1, movbe=1, xsave=1,apic=x2apic,sha=1,movbe=1,adx=1,xsaveopt=1,avx_f16c=1,avx_fma=1,bmi=bmi2,1g_pages=1,pcid=1,fsgsbase=1,smep=1,smap=1,mwait=1,vmx=1cpuid: family=6, model=0x1a, stepping=5, vendor_string=&quot;GenuineIntel&quot;, brand_string=&quot;Intel(R) Core(TM) i7-4770 CPU (Haswell)&quot; print_timestamps: enabled=0debugger_log: -magic_break: enabled=0port_e9_hack: enabled=0private_colormap: enabled=0clock: sync=none, time0=local, rtc_sync=0# no cmosimage# no loaderlog: -logprefix: %t%e%ddebug: action=ignoreinfo: action=reporterror: action=reportpanic: action=askkeyboard: type=mf, serial_delay=250, paste_delay=100000, user_shortcut=nonemouse: type=ps2, enabled=0, toggle=ctrl+mbuttonspeaker: enabled=1, mode=systemparport1: enabled=1, file=noneparport2: enabled=0com1: enabled=1, mode=nullcom2: enabled=0com3: enabled=0com4: enabled=0 megs: 2048 制作软盘 一定要在你编译完成的文件夹下执行命令 ./bximage 然后选择 1(Create new floppy or hard disk image) 然后输入 fd(创建一个软盘) 然后回车(大小默认) 然后起一个名字 如 boot.img 做好的软盘 boot.img 默认在当前文件夹中，要放在 bochs 的文件夹根目录中，不要移动了 更新 由于 Centos7 使用体验极差（虚拟机出了各种问题）索性换到 Ubuntu20.04 大致可能出现的问题和前面类似，不再赘述，说一些新的问题 缺少 usb_uhci 巴拉巴拉一些 不会处理，看了网上的别人说的，这是低版本 Bochs 源码的问题，建议使用高版本 好吧，使用最新的 2.6.11 源码编译的时候出错 问题就像下面一样，这次好，有解决方案 x86_64-pc-linux-gnu-g++ -c -I… -I./… -I…/instrument/stubs -I./…/instrument/stubs -I. -I./. -march=native -O2 -pipe -D_FILE_OFFSET_BITS=64 -D_LARGE_FILES -pthread -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT dbg_main.cc -o dbg_main.o In file included from dbg_main.cc:28: dbg_main.cc: In function ‘void bx_dbg_tlb_lookup(bx_lin_address)’: …/cpu/cpu.h:383:28: error: invalid use of ‘this’ in non-member function 383 | # define BX_CPU_THIS_PTR this-&gt; | ^~~~ …/cpu/tlb.h:62:32: note: in expansion of macro ‘BX_CPU_THIS_PTR’ 62 | #define BX_ITLB_INDEX_OF(lpf) (BX_CPU_THIS_PTR ITLB.get_index_of(lpf)) | ^~~~ … 解决方案: 找到 bx_debug/dbg_main.cc 或者是 dbg_main.cpp, 修改里面的部分代码（记得原版备份） 123456789101112char cpu_param_name[16]; - Bit32u index = BX_ITLB_INDEX_OF(laddr); //这一行改成下面一行+ Bit32u index = BX_CPU(dbg_cpu)-&gt;ITLB.get_index_of(laddr); sprintf(cpu_param_name, &quot;ITLB.entry%d&quot;, index); bx_dbg_show_param_command(cpu_param_name, 0); - index = BX_DTLB_INDEX_OF(laddr, 0); //同理+ index = BX_CPU(dbg_cpu)-&gt;DTLB.get_index_of(laddr); sprintf(cpu_param_name, &quot;DTLB.entry%d&quot;, index); bx_dbg_show_param_command(cpu_param_name, 0); 重新编译即可正常的运行 真难…","link":"/2020/09/24/bochs/"},{"title":"breaks","text":"2019/7/9 结束了大一的课程考试，看了看成绩，简直gg 果然我还是半吊子 假期要好好学习了，大跃进大跃进 假期： 首先是重新更广的学习Python 会穿插一些做网站的前端后端的部分（可能） 汇编语言（看的真的艰辛） 这不是结束，而是新的开始 送给自己一段话：但行耕耘，莫问收获 ps：前一段时间不更是因为忙着复习了","link":"/2019/07/09/breaks/"},{"title":"complain","text":"@#￥@#%@% 记于2020年11月27日某个很坑的课实验做不出来 （28日再看自己写的好羞耻啊） 心情很差，随便写点东西吧 先讲讲自己，我不知道什么时候开始对自己失望，我还记得大一的时候，我满怀的热情，考入了转专业直通车慧与班，能学自己感兴趣的计算机专业。大一加入了爱特工作室，学习的虽然是怎么写网站，后端，sql这些在某些人眼里&quot;廉价&quot;的东西，但对于什么都不懂得我来说，说实话，很cool，很有趣，让我在枯燥的c语言（大一上专业课）之外有了愿意付出时间学习研究的东西，那个时候的真的很好，每周都有各种各样的bug，但历经千辛万苦解决后看着成功运行的功能，很高兴。就这样在爱特度过了大一的一年。绩点并不高（在全年级里） 时间来到了大二，我发现身边的人都在学算法（很后悔当时没有加入他们），我就觉得，为了打比赛去学这些，太功利了，我在看着没人愿意看的汇编，链接，库。让我印象很深的是:计基的实验，用的是csapp的炸弹实验和覆盖栈指针返回位置攻击实验（忘了叫啥名字了），我做了很久终于解决后很高兴，想要和我的同学们交流思路的时候，我得到的只是冷冰冰的回复:这种实验网上照着做不就行了吗。我沉默了，确实，像我这种&quot;吃力不讨好&quot;的事没人（有可能是在我身边我不认识吧）愿意做。当我看书学习到自闭，看不懂的时候，身边没人和我交流，大一的时候，还和社团的别人讨论，现在都没有了，大家都在各忙各的。大二下，在家度过，学数学建模，很多时候就觉得自己很累，但还是咬着牙坚持吧。 大二，绩点没啥大变化。然后我排名就掉了很多。 老师学长口中&quot;保研&quot;的压力开始出现，我估摸着算了一下，现在踩着边。我有点慌了，我有些科目考的确实不好，甚至好好学了还没划划水的考的好，我承认自己菜，复习不到位。大三好好努力吧。 大二暑期小学期，国赛没打好，下次再努力吧。我选了web框架这门课（上了几次课我发现这门课根本不讲框架），少了好多熟人，我就很有疑问。问了问，他们告诉我:这门课给分低，不选。实话实说，我觉得不同老师给分差别很大，我也体验到了，但我一直以来都觉得无所谓，从此时，我开始觉得:绩点重要!最明显的是这次选课吧，按照大一的我，肯定就:这个课有意思，选。选不到好老师，没啥，目的是排另一门课。现在选门课问三问四，非xxx老师不选，无非:给分高吗，事多吗。选课的时候我还觉得没啥，身边的不少人也都在这样做。但晚上躺在床上胡思乱想的时候，就很难受，短短2年自己已经变了这么多。功利心直线上升，学习就是为了保研，保不了就炸了这种病态的想法开始蚕食我自己。我们抛开那些所谓的&quot;课上学不到东西，水水就行了，全靠课下自学所以选个水的老师&quot;这种言论，我个人在好多课上都能学到很多东西。当我要选一门&quot;很坑的课t&quot;的时候，竟然有人说&quot;他怎么敢&quot;这种话。（事实上这门课确实坑，实验环境都仿佛是上个世纪的东西，据说给分超低） 但实话实说，学到了很多东西。 我庆幸我还有自己最后的倔强:大三我在学写操作系统（这门专业课讲的太哲学了），我还想在大三下好好系统学编译原理（据说课上几乎啥也没交）。 我觉得，如果你按照学校安排的课程学几乎啥也学不会。所以就多学别的啊，但看着别人分考的越来越高（我菜，两面兼顾的我身边也有，比我小一级），我悠闲的心态也变了。大学真的和我想的不一样了，用你们的话说&quot;内卷&quot;，我也身处其中，不得不卷了，拼高分，拼光鲜的奖。但每每有些时候，我都觉得，自己已经不是自己了，可能长大了吧，小孩子那种幼稚的想法:学到东西就是好，分尽力考已经不现实了，你要用尽全力考高分（包括争取一些非能力的因素如老师），进好的研究生学校。 逻辑写的有点乱，没理没据，就是自己菜，还考不好的无奈的说辞。 希望你们不要像我一样，自闭，多去交流吧，计算机那么多东西，网上总有人和你有同样的爱好，兴趣，愿你能找到更多的知音。","link":"/2020/11/28/complain/"},{"title":"deep-learning-intro","text":"深度学习中的数学基础 软工作业 Week 2 概率是基础 支持向量机涉及很多数学基础 梯度下降是神经网络的共同基础 矩阵线性变换 对于给定的矩阵 A，假设其特征值为 $\\lambda$，特征向量为x，则他们之间的关系如下: $$ Ax = \\lambda x $$ 矩阵 A 对于 A 的特征向量做线性变换的时候，方向不再发生变化。 从线性变换的角度，矩阵相乘对原始向量同时施加方向变化和尺度变化。 对于有些特殊的向量，矩阵的作用只有尺度变化而没有方向变化，这类向量就是特征向量，变化系数就是特征值 矩阵的秩 线性方程组的角度： 度量矩阵行列之间的相关性 如果矩阵的各行或列是线性无关的，矩阵就是满秩的，也就是说秩等于行数 数据点分布的角度： 表示数据需要的最小的基数量 数据分布模式越容易被捕捉，即需要的基越少，秩就越小 数据冗余度越大，需要的基就越小，秩越小 若矩阵表达的是结构化信息，如图像，用户-物品表等，个行之间存在一定相关性，一般是低秩的 低秩近似 较大奇异值包含了矩阵的主要信息，只保留前r个较大奇异值及其对应的特征向量，一般 r 取 d 的十分之一就可以保留足够信息，可以实现数据从 n x d 维降维到 n x r + r x r + r x d 矩阵低秩近似: $$ A_{m \\times n} = U_{m \\times n} \\textstyle \\sum_{n \\times n}^{} V_{k \\times n}^T \\quad rank(A)=r \\ \\hat{A}{m \\times n} = U{m \\times n} \\textstyle \\sum_{n \\times n}^{} V_{k \\times n}^T \\quad rank(\\hat A)=r $$ 图像去噪：数据矩阵X一般同事包含结构信息和噪声 矩阵分解为两个矩阵的相加，一个是低秩的（结构信息造成行或列间线性相关）另一个是稀疏的（噪声是稀疏的），很多问题中都会有这样类似的优化方法，写成函数如下: $$ \\min_{A,E} ,rank(A) + \\lambda \\left | E \\right |_0 \\ s.t., X = A+E $$ 概率函数形式统一 同一个模型可以用概率形式和函数形式来表示 指数族：对常见分布标准化的形式；广义线性模型：线性回归，逻辑回归都是广义线性回归 指数族决定是高斯分布，那么广义线性模型就是线性回归模型。 例子：对于逻辑回归模型，假定的概率分布是伯努利分布，根据伯努利分布的定义，其概率质量函数 PMF 为： $$ P(Y=n)= \\begin{cases} 1-p \\quad n=0\\p \\quad n=1 \\end{cases} $$ 似然函数可以写成：$L(\\theta)=\\prod_{i=1}{m}P(y=1|x_i){y_i}P(y=0|x_i)^{1-y_i}$ 常规操作——取对数，然后求最大化的对数似然 $$ max ;lnL(\\theta)\\longrightarrow min ;-lnL(\\theta)=\\sum_{i=1}^{m}-y_i ln P(y=1|x_i)-(1-y_i)ln(1-P(y=1|x_i)) $$ 这个公式的每个加数子项表示单个样本的对数损失：若yi=1，P(y=1|x)越大损失越小；yi=0，P(y=1|x) 越小损失越小。 这些样本的损失，实际上和逻辑回归的经验风险损失$J(\\theta)$很相近，逻辑回归也可以直接采用对数损失函数通过经验风险最小化求参，而经验风险最小化策略与极大似然策略优化得到的模型参数是一致的。 策略设计 衡量训练误差与泛化误差的差异：计算学习理论，它得出来一个结论——训练误差与泛化误差的差异和训练样本样本量与模型的复杂程度有关，样本量越大误差越小，模型越复杂差异越大 PAC 理论给出了实际训练学习器的目标 从合理数量的训练数据中通过合理计算量学习到可靠的知识（置信度高） 奥卡姆剃刀原理 如无必要，勿增实体：简单有效原理（说白了，如果你有两个方案，选择最简单的，多出来的东西并非有益，反而会带来麻烦） 如果多种模型能够同等程度地符合一个问题的观测结果，那么应该选择其中使用假设最少的最简单的模型 过拟合&amp;欠拟合 欠拟合：训练集的一般性质没有被学习器学好（训练误差大） 提高模型复杂度 决策树：拓展分支 神经网络：增加训练轮数 过拟合：学习器把训练集特点当做样本一般的特点（训练误差小，测试误差大） 降低模型复杂度 优化目标加正则项 决策树：剪枝 神经网络：early stop, dropout 数据增广（扩大数据训练集）：如计算机视觉可以将图像旋转，缩放，剪切；自然语言处理中可以将同义词替换；语音识别中可以加入随机噪声。 损失函数 BP 神经网络和损失函数： 如果设定$S(x)=\\frac{1}{1+e^-x}$，损失函数 $$ L=\\frac{1}{2}\\sum_{k=1}^{N}D(f(x_k), h(x_k)) = \\frac{1}{2}\\sum_{k=1}{N}\\sum_{i=1}{c}(f_i(x_k)-x_{k_i}{(\\mathfrak{h})})2=\\sum_{k=1}^{N}E_k $$ 令 $E_k=\\sum_{i=1}{c}(f_i(x_k)-x_{k_i}{(\\mathfrak{h})})^2$ 为每个样本的平方损失代价 待优化参数：权重 $\\omega_{ij}^{(t)}$ 待优化算法：梯度下降，需要计算代价函数L和梯度 $\\frac{\\partial L}{\\partial \\omega_{ij}^{(t)}}$ 更新公式：$\\omega_{ij}^{(t)}\\leftarrow \\omega_{ij}^{(t)}- \\eta\\frac{\\partial E_k}{\\partial \\omega_{ij}^{(t)}}$ 平方损失 $\\frac{\\partial L}{\\partial w_i}=2(a-y)\\cdot a(1-a)\\cdot x_i$ 计算困难，采用交叉熵（对数损失函数） $L(a,y)=-yloga-(1-y)log(1-a)$ 巴拉巴拉…听不懂了这里，改天再改改 概率学派&amp;贝叶斯学派 频率学派：关注可独立重复的随机试验中单个事件发生的频率，假设概率是客观存在的并且是固定的。这样得出的模型参数唯一，需要从有限的观测数据中估计参数值。 贝叶斯学派：关注随机事件的&quot;可信程度&quot;，在数据之上加入假设，数据作用是对初始的假设做出修正，使观察者对概率的主观认识（先验）更接近客观实际（观测）；模型参数本身是随机变量，需要顾及参数的整个概率分布。 深度学习概述 Yule-Simpson 悖论 相关性并不可靠，会因为一些混杂因素而改变。 因果性=相关性+忽略的因素 卷积神经网络（Convolutional Neural Network） 全连接网络处理图像的问题： 参数太多：权重矩阵的参数太多 -&gt; 过拟合 卷积神经网络的解决方式： 局部关联，参数共享 卷积神经网络的应用 分类 检索 检测 分割 人脸识别，人脸验证 表情识别，图像生成，图像风格转化，自动驾驶 … 卷积 一维卷积经常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器在时刻 t 发出一个信号xi，其信息衰减率为 fk，即在 k-1 个时间步长后，信息衰减为原来的 fk 倍。 我们设 f1=1,f2=0.5,f3=0.25，在 t 时刻收到的信号 yt 为当前时刻产生的信息和以前时刻延迟信息的叠加： $$ yt=1\\times x_i+\\frac{1}{2} \\times x_{i-1} + \\frac{1}{4} \\times x_{i-2} =\\sum_{3}^{k=1}f_k \\cdot x_{i-k+1} $$ 此处的 $f=[f_1,f_2,f_3]$ 被称为滤波器（filter）或者叫卷积核（convolutional kernel），假设滤波器 f 的长度为 m，它和一个信号序列 $x=[x_1,x_2,x_3,…]$ 的卷积记为 $y_t = \\sum_{m}^{k=1}f_k \\cdot x_{i-k+1}$ 那么卷积是什么? convolution is an operation on two functions of a real-valued argument. 卷积是对两个实变函数的一种数据操作 卷积核的输出等于卷积核的与输入对应位置的内积（逐个对应相乘再相加），粉色位置的值应为4（=1x1+1x0+1x1+0x0+1x1+1x0+0x1+0x0+1x1），步长为1，每次向右移动1格，这样特征图每一行就有3个数值了。 但有的时候，我们的输入无法被指定的步长分割好，这时候往往加入 padding，即在最外圈补一定数量的0 输出的特征图的大小： (N(input_scale)-F(filter_scale))/stride(step)+1 (N+padding*2-F)/stride+1 加入深度：会直接影响输出的层数，有几层特征图的输出同样也有几层，(相当于使用不同的卷积核处理的次数?)。 池化（Pooling） 保留了主要特征的同时减少参数和计算量，防止过拟合来提高模型的泛化能力 一般处于卷积层和卷积层之间，全连接层与全连接层之间 常用的有最大值池化和平均值池化： 分类识别任务的时候，最大值池化比平均值池化效果更好。 全连接（Fully Connecting） 全连接层（FC layer） 两层之间的所有神经元都有权重链接 通常全连接层在卷积神经网络尾部 全连接层参数量通常很大 各种深度学习的模型概述 AlexNet ReLU 激活函数的优点: 解决了梯度消失的问题 计算的速度很快，只需要判断输入是否大于0 收敛速度远快于 sigmod 使用 dropout 来防止过拟合: 训练的时候随机关闭一些神经元，测试时整合所有的神经元。 ZFNet 网络结构和 AlexNet 相同，将卷积层1中的感受野大小由11x11改为7x7，步长改为2，同时修改了3，4，5层滤波器的个数。 VGG 加深了 AlexNet 的层数，由8层变为了16，19层 GoogleNet 网络包含22个带参数的层，参数量大概是Alexnet的1/12。 使用不同的卷积核来增加特征的多样性 使用辅助分类器来解决模型深度过高导致过拟合 ResNet 残差学习网络（deep residual learning network） 运用了残差的思想：去掉相同的主体部分，从而突出微小的变化，可以被用来训练非常深的网络。","link":"/2020/10/24/deep-learning-intro/"},{"title":"cuda 安装受难记","text":"2020/11/22 更新了解决下载过慢的问题 如何无痛安装 cuda + Anaconda + pytroch 环境 !! 重要声明，这仅仅只是我的痛苦安装过程的一个踩坑记录，如果可以帮助你无痛安装，那自然是极好的了。 Anaconda Anaconda 是一个python 的发行版，包括了python 和很多常见的软件库，和一个包管理器 conda 但它巨大，囊括了1000+的 Python 库，如果你不需要，强烈建议你安装 mini 版本 我没有遇到很多的问题，但建议你看这个，我们的重点不在这里： https://zhuanlan.zhihu.com/p/75717350 cuda Anaconda 安装完毕后，不要急着安装 pytorch，先去安装 CUDA Toolkit！！！ 在这些之前，你需要看看你的 GPU 驱动的版本，查看的方法很简单： 找到你的电脑的 NVIDIA 控制面板，打开，左下角点击系统信息，它看起来就像是这样： 然后去官网找到你的 driver 匹配的版本 Release note， 找好之后去下载 cuda downloads 然后安装，可以自定义安装，我们只选择 Development，Runtime，Sample，Document 这四个组件即可。可以修改路径，如果不想安在C盘的话就改改。 安装完成后还需要配置系统环境变量，在系统环境变量那里和 PATH 同级的地方添加下面的环境变量： 12345678CUDA_PATH = D:\\NVIDIA GPU Computing Toolkit\\CUDA\\v10CUDA_PATH_V10_0 = D:\\NVIDIA GPU Computing Toolkit\\CUDA\\v10CUDA_SDK_PATH = D:\\NVIDIA GPU Computing Toolkit\\sampleCUDA_LIB_PATH = %CUDA_PATH%\\lib\\x64CUDA_BIN_PATH = %CUDA_PATH%\\binCUDA_SDK_BIN_PATH = %CUDA_SDK_PATH%\\bin\\win64CUDA_SDK_LIB_PATH = %CUDA_SDK_PATH%\\common\\lib\\x64 在用户环境变量的 PATH 里添加下面的部分，如果你是文本编辑记得加上分号。 1234%CUDA_LIB_PATH%%CUDA_BIN_PATH%%CUDA_SDK_BIN_PATH%%CUDA_SDK_LIB_PATH% 重启电脑进入你的 cuda 安装路径，\\extras\\demo_suite 路径，执行 deviceQuery.exe 和 bandwidthTest.exe 程序，会有一堆输出，如果显示了 Result = PASS，证明你安装成功了。这时你的任务管理器会多一栏 GPU。 Nvidia 显示设置不可用 自己平常明明可以正常打开控制面板，但今天我就突然打不开了…，看了看网上说的，大多数是让你更新一下驱动，好吧，那么我们更新一下吧。 右键右下角窗口里面的 NVIDIA 图标，点 NVIDIA GeForce experience，竟然需要登录，好吧，就注册一个账号然后登录…，然后就无法注册。我人傻了，只好去官网上重新下一个 https://www.nvidia.cn/geforce/drivers/ 下载自动更新驱动程序。 之后就正常的安装，然后注册登录，它会自动提示你更新驱动。（我从2017年的驱动更新到了最新的…），还有一个注意的是不知道为啥它死活不能用QQ登录，会卡在认证的页面上。 pytorch 在官网选择你的系统配置： install 用下面的命令一下安装好，新建一个 py 文件测试一下 12device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)print(&quot;Using gpu: %s&quot; % torch.cuda.is_available()) 显示 “Using gpu: xxx” 针不戳。 是不是很简单？才怪！ 下载速度太慢 如果下载速度太慢，建议添加清华的源 123456789conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes# 添加第三方 conda 源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 这时执行安装就不要再加 -c 了 conda install pytorch==1.2.0 torchvision==0.4.0 cudatoolkit=10.0 CUDA 版本太低 这里面并没有 CUDA10.0 这个版本，但是我自作聪明的修改 cudatoolkit=10.0 也正常安装了，不错，然后运行一下，提示 CUDA 版本太低…，我严重怀疑是版本不匹配的问题，cuda 是不想再装一遍了，只好重装一个低版本的 pytorch。 学老实点，去早期版本找匹配吧 previous versions 找到一条适合你的版本的命令，比如说我的 conda install pytorch==1.2.0 torchvision==0.4.0 cudatoolkit=10.0 -c pytorch 然后安装就好了，记得先卸掉你装过的 cudatoolkit。打开 Anaconda Prompt，输入 conda uninstall cudatoolkit 即可。 Solving environment: failed with initial frozen solve… 安装了很久还没成功，事情似乎没有那么简单，看了报错，Solving environment: failed with initial frozen solve. Retrying with flexible solve. 具体什么原因我还没搞明白，可能是依赖的问题。遇事不决先升级，不行就重装： 12conda update -n base condaconda update --all 还是不行，只好去百度，试了不少法子，放一个我最终成功解决问题的方法：issue#93676 具体来说就是起一个虚拟环境然后再重新安装，有人说这是 Anaconda3 的一个最新版的问题，我也不懂也别乱说了，就照着别人的方法试就完事了: 123conda create -n your_virtual_environment_name(I use the pytorch)conda activate pytorchconda install pytorch==1.2.0 torchvision==0.4.0 cudatoolkit=10.0 -c pytorch 具体点来看是用了一个旧一些的版本的 conda 的库（可能），这么说前面更新还是不应该更的了吗…，不过这发生在你装一个老版本的库时，我觉得把cuda更新到最新，装个最新的 pytorch 不香吗 写在后面 每次安环境都是最痛苦的，希望人没事。后续一些问题我会跟进增加内容","link":"/2020/11/20/cuda-disaster/"},{"title":"WSGI","text":"前言 开个新坑，Django 源码学习以及深入理解 Django Web 框架 首先从 WSGI 开始，本篇和 Django 看似无联系，确实很重要的一个部分 Django 的自带服务器是基于 Python 的 wsgiref 模块实现的，所以我们在测试期间往往不需要部署 nginx 之类的，那么想要理解这里，就要从 PEP 对于WSGI规范的定义开始 WSGI 全名 Python Web Server Gateway Interface doc 理由和目标 Python currently boasts a wide variety of web application frameworks, such as Zope, Quixote, Webware, SkunkWeb, PSO, and Twisted Web – to name just a few. This wide variety of choices can be a problem for new Python users, because generally speaking, their choice of web framework will limit their choice of usable web servers, and vice versa. By contrast, although Java has just as many web application frameworks available, Java’s “servlet” API makes it possible for applications written with any Java web application framework to run in any web server that supports the servlet API. The availability and widespread use of such an API in web servers for Python – whether those servers are written in Python (e.g. Medusa), embed(嵌入) Python (e.g. mod_python), or invoke Python via a gateway protocol (e.g. CGI, FastCGI, etc.) – would separate choice of framework from choice of web server, freeing users to choose a pairing that suits them, while freeing framework and server developers to focus on their preferred area of specialization. This PEP, therefore, proposes(提出) a simple and universal interface between web servers and web applications or frameworks: the Python Web Server Gateway Interface (WSGI) 看原文更有味道 Thus, WSGI must be easy to implement, so that an author’s initial investment in the interface can be reasonably low. Again, the goal of WSGI is to facilitate easy interconnection of existing servers and applications or frameworks, not to create a new web framework. it allows for the possibility of an entirely new kind of Python web application framework: one consisting of loosely-coupled WSGI middleware components. 简单来说就是: enable the use of any framework with any server OverView The Application/Framework Side The application object is simply a callable object that accepts two arguments. The term “object” should not be misconstrued as requiring an actual object instance: a function, method, class, or instance with a __call__ method are all acceptable for use as an application object. Application objects must be able to be invoked more than once, as virtually all servers/gateways (other than CGI) will make such repeated requests. 不一定需要实例，只需要 __call__() 接口来提供调用方法 官方文档给出的样例 sample1234567891011121314151617181920212223242526272829303132def simple_app(environ, start_response): &quot;&quot;&quot;Simplest possible application object&quot;&quot;&quot; status = '200 OK' response_headers = [('Content-type', 'text/plain')] start_response(status, response_headers) return ['Hello world!\\n']class AppClass: &quot;&quot;&quot;Produce the same output, but using a class (Note: 'AppClass' is the &quot;application&quot; here, so calling it returns an instance of 'AppClass', which is then the iterable return value of the &quot;application callable&quot; as required by the spec. If we wanted to use *instances* of 'AppClass' as application objects instead, we would have to implement a '__call__' method, which would be invoked to execute the application, and we would need to create an instance for use by the server or gateway. &quot;&quot;&quot; def __init__(self, environ, start_response): self.environ = environ self.start = start_response def __iter__(self): status = '200 OK' response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield &quot;Hello world!\\n&quot; # 每被迭代一次就返回hello world? The Server/Gateway Side The server or gateway invokes the application callable once for each request it receives from an HTTP client, that is directed at the application. To illustrate, here is a simple CGI gateway, implemented as a function taking an application object. Note that this simple example has limited error handling, because by default an uncaught exception will be dumped to sys.stderr and logged by the web server. sample1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import os, sysdef run_with_cgi(application): environ = dict(os.environ.items()) environ['wsgi.input'] = sys.stdin environ['wsgi.errors'] = sys.stderr environ['wsgi.version'] = (1, 0) environ['wsgi.multithread'] = False environ['wsgi.multiprocess'] = True environ['wsgi.run_once'] = True if environ.get('HTTPS', 'off') in ('on', '1'): environ['wsgi.url_scheme'] = 'https' else: environ['wsgi.url_scheme'] = 'http' headers_set = [] headers_sent = [] def write(data): if not headers_set: raise AssertionError(&quot;write() before start_response()&quot;) elif not headers_sent: # Before the first output, send the stored headers # 自动解包依次赋值给变量 status, response_headers = headers_sent[:] = headers_set # 为啥是 \\r\\n? sys.stdout.write('Status: %s\\r\\n' % status) for header in response_headers: sys.stdout.write('%s: %s\\r\\n' % header) sys.stdout.write('\\r\\n') sys.stdout.write(data) sys.stdout.flush() def start_response(status, response_headers, exc_info=None): if exc_info: try: if headers_sent: # Re-raise original exception if headers sent raise exc_info[0], exc_info[1], exc_info[2] finally: exc_info = None # avoid dangling circular ref elif headers_set: raise AssertionError(&quot;Headers already set!&quot;) # 保持 headers_set id 不变，只将值赋给其 headers_set[:] = [status, response_headers] return write result = application(environ, start_response) try: # 把所有返回的结果都写好之后再返回 for data in result: if data: # don't send headers until body appears write(data) if not headers_sent: write('') # send headers now if body was empty finally: if hasattr(result, 'close'): result.close() Middleware 中间键文档中也有给出的例子，不过这个不在我们这次的讨论范围里，中间键是对我们第一步处理的一个二次处理或者一定的补充。 Routing a request to different application objects based on the target URL, after rewriting the environ accordingly. Allowing multiple applications or frameworks to run side-by-side in the same process Load balancing and remote processing, by forwarding requests and responses over a network Perform content postprocessing, such as applying XSL stylesheets Specification Details 我们的目的起码目前不是自己写一个，无需看详细的细节，前面的都弄明白就行了 总结 简单来说，WSGI 定义了服务器程序和 Web 框架直接通信的手段：服务器程序将请求和包装好的环境变量传给 Web 框架的程序，这种传递方法官方文档给出了传递函数指针的方式或者被调用者实现 callable 的接口，也就是 __call__ 方法。例子中使用的是 start_response， 这个函数在服务器类中被定义，在 Web 框架的函数中被调用。结果作为类的一个属性被，当类被加载时，为了获取这个属性，就会去调用 application（框架程序）来处理。以 call 的方式实现的如 Django 的 WSGIHandler，我们会在后面说到。 Python wsgiref wsgiref 是 Python 内置的一个实现 wsgi 的参考，纯 Python 编写，它提供了一个开发和测试的工具，其实现的功能有： 操作 wsgi 的环境变量 应答头部的处理 实现简单的 HTTP server 简单的对程序端和服务器端校验函数 代码结构 wsgiref |-- handlers.py # 负责 wsgi 程序的处理 |-- headers.py # 处理头 |-- __init__.py # |-- simple_server.py # 简单的 wsgi HTTP 服务器实现 |-- util.py # 帮助函数 |-- validate.py # wsgi 格式检查和校验 流程 服务器应用程序创建 socket，并监听在特定的端口（往往是80），等待客户端的连接 客户端发送 http 请求 socket server 读取请求的数据，交给 WSGIServer WSGIServer 首先用继承自 http server 的方法基于 http 的规范解析请求 WSGIServer 把客户端的信息存放在 environ 变量里，然后交给绑定的 handler 处理请求 WSGIRequestHandler 调用继承 HTTPHandler 的方法解析请求，把 method、path 等放在 environ，通过自己的额外函数把服务器端的信息也放到 environ 里 WSGIRequestHandler 调用绑定的 wsgi ServerHandler，把上面包含了服务器信息，客户端信息，将本次请求信息的 environ 传入 wsgi ServerHandler 调用注册的 wsgi app，把 environ 和 start_response 作为参数传递过去 wsgi app 处理后将 reponse header、status、body 回传给 wsgi handler，然后 handler 逐层传递，最后把这些信息通过 socket 发送到客户端，客户端的程序接到应答，解析应答，并把结果打印出来。 源码简单解读 我们可以对 simple_server.py 展开详细的阅读 simple_server.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149class ServerHandler(SimpleHandler): server_software = software_version def close(self): try: self.request_handler.log_request( self.status.split(' ',1)[0], self.bytes_sent ) finally: SimpleHandler.close(self)class WSGIServer(HTTPServer): &quot;&quot;&quot;BaseHTTPServer that implements the Python WSGI protocol&quot;&quot;&quot; application = None def server_bind(self): &quot;&quot;&quot;Override server_bind to store the server name.&quot;&quot;&quot; HTTPServer.server_bind(self) self.setup_environ() def setup_environ(self): # Set up base environment env = self.base_environ = {} env['SERVER_NAME'] = self.server_name env['GATEWAY_INTERFACE'] = 'CGI/1.1' env['SERVER_PORT'] = str(self.server_port) env['REMOTE_HOST']='' env['CONTENT_LENGTH']='' env['SCRIPT_NAME'] = '' def get_app(self): return self.application # 绑定 app def set_app(self,application): self.application = applicationclass WSGIRequestHandler(BaseHTTPRequestHandler): server_version = &quot;WSGIServer/&quot; + __version__ def get_environ(self): # 拷贝一份基本的环境变量 env = self.server.base_environ.copy() # 设置服务器的版本，协议 env['SERVER_PROTOCOL'] = self.request_version env['SERVER_SOFTWARE'] = self.server_version # 请求方法 env['REQUEST_METHOD'] = self.command # 获取请求的 url 中的参数 if '?' in self.path: path,query = self.path.split('?',1) else: path,query = self.path,'' env['PATH_INFO'] = urllib.parse.unquote(path, 'iso-8859-1') env['QUERY_STRING'] = query # 这里不是很明白，大概是对于请求的 ip 的获取 host = self.address_string() if host != self.client_address[0]: env['REMOTE_HOST'] = host env['REMOTE_ADDR'] = self.client_address[0] # 请求内容 if self.headers.get('content-type') is None: env['CONTENT_TYPE'] = self.headers.get_content_type() else: env['CONTENT_TYPE'] = self.headers['content-type'] # 获取请求内容字段长 length = self.headers.get('content-length') if length: env['CONTENT_LENGTH'] = length # 除标注定义外的一些额外字段的添加? for k, v in self.headers.items(): k=k.replace('-','_').upper(); v=v.strip() if k in env: continue # skip content length, type,etc. if 'HTTP_'+k in env: env['HTTP_'+k] += ','+v # comma-separate multiple headers else: env['HTTP_'+k] = v return env def get_stderr(self): return sys.stderr # 处理单次请求 def handle(self): &quot;&quot;&quot;Handle a single HTTP request&quot;&quot;&quot; self.raw_requestline = self.rfile.readline(65537) if len(self.raw_requestline) &gt; 65536: self.requestline = '' self.request_version = '' self.command = '' self.send_error(414) return if not self.parse_request(): # An error code has been sent, just exit return # 请求交给 handler 处理 handler = ServerHandler( self.rfile, self.wfile, self.get_stderr(), self.get_environ() ) handler.request_handler = self # backpointer for logging # 把封装的环境变量交给 ServerHandler，然后由 ServerHandler 调用 wsgi app handler.run(self.server.get_app())def demo_app(environ,start_response): from io import StringIO stdout = StringIO() print(&quot;Hello world!&quot;, file=stdout) print(file=stdout) h = sorted(environ.items()) for k,v in h: print(k,'=',repr(v), file=stdout) start_response(&quot;200 OK&quot;, [('Content-Type','text/plain; charset=utf-8')]) return [stdout.getvalue().encode(&quot;utf-8&quot;)]def make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): &quot;&quot;&quot;Create a new WSGI server listening on `host` and `port` for `app`&quot;&quot;&quot; server = server_class((host, port), handler_class) server.set_app(app) return serverif __name__ == '__main__': with make_server('', 8000, demo_app) as httpd: sa = httpd.socket.getsockname() print(&quot;Serving HTTP on&quot;, sa[0], &quot;port&quot;, sa[1], &quot;...&quot;) import webbrowser webbrowser.open('http://localhost:8000/xyz?abc') httpd.handle_request() # serve one request, then exit 简易 demo 我们可以自己尝试弄一个简易的服务器来玩 1234567891011121314151617# app.pydef hello_world_app(environ, start_response): # environ 是一个包含所有 HTTP 请求信息的 dict 对象 status = &quot;200 OK&quot; # HTTP响应的输出都可以通过 start_response() 加上函数返回值作为 Body headers = [(&quot;Content-type&quot;, &quot;text/html&quot;)] start_response(status, headers) body = &quot;&lt;h1&gt;hello {}&lt;/h1&gt;&quot;.format(environ['PATH_INFO'][1:] or &quot;Web&quot;) # 去掉第一个斜杠 return [body.encode(&quot;utf-8&quot;)]# server.pyfrom wsgiref.simple_server import make_serverfrom app import hello_world_apphttpd = make_server('', 8000, hello_world_app)print(&quot;Starting server at 8000&quot;)httpd.serve_forever() 下集预告? Django 中自带的 wsgi的实现 参考 深入理解wsgiref WSGI接口 PEP333","link":"/2020/01/31/django-understanding-1/"},{"title":"Django WSGI Server","text":"复习 WSGI 协议主要包括 server 和 application 两部分： WSGI server 负责从客户端接收请求，将 request 转发给 application，将 application 返回的 response 返回给客户端 WSGI application 接收由 server 转发的 request，处理请求，并将处理结果返回给 server。application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现 server 与 application，因此可以在 WSGI 服务器与 WSGI 应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器。 WSGI 协议其实是定义了一种 server 与 application 解耦的规范，即可以有多个实现 WSGI server 的服务器，也可以有多个实现 WSGI application 的框架，那么就可以选择任意的 server 和 application 组合实现自己的web应用。例如uWSGI和Gunicorn都是实现了 WSGI server 协议的服务器，Django，Flask是实现了WSGI application 协议的web框架，可以根据项目实际情况搭配使用。 Django 中自带的 WSGI 实现 WSGI Server 找到代码，位于 django/core/servers/basehttp.py This is a simple server for use in testing or debugging Django apps. It hasn’t been reviewed for security issues. DON’T USE IT FOR PRODUCTION USE! Django 其内部已经自带了一个方便本地测试的小服务器, 所以在刚开始学习 Django 的时候并不需搭建 apache 或者 nginx 服务器. Django 自带的服务器基于 python wsgiref 模块实现的, 其百分之七八十的代码都是 wsgiref 中的代码, 只重写了一部分, 所以 Django 自带的服务器测试写个 helloworld 就好了，生产时千万不要用。 新增的要点的简析 水平有限，选了一些重要的重写部分来详细学习 异常的处理和日志记录 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 省略部分代码logger = logging.getLogger('django.server') # 很眼熟的一个日志模块中的内置loggerdef is_broken_pipe_error(): exc_type, exc_value = sys.exc_info()[:2] return issubclass(exc_type, socket.error) and exc_value.args[0] == 32class WSGIServer(simple_server.WSGIServer): def handle_error(self, request, client_address): if is_broken_pipe_error(): logger.info(&quot;- Broken pipe from %s\\n&quot;, client_address) else: super().handle_error(request, client_address)class WSGIRequestHandler(simple_server.WSGIRequestHandler): def log_message(self, format, *args): extra = { 'request': self.request, 'server_time': self.log_date_time_string(), } if args[1][0] == '4': # 0x16 = Handshake, 0x03 = SSL 3.0 or TLS 1.x if args[0].startswith('\\x16\\x03'): extra['status_code'] = 500 logger.error( &quot;You're accessing the development server over HTTPS, but &quot; &quot;it only supports HTTP.\\n&quot;, extra=extra, ) return if args[1].isdigit() and len(args[1]) == 3: status_code = int(args[1]) extra['status_code'] = status_code if status_code &gt;= 500: level = logger.error elif status_code &gt;= 400: level = logger.warning else: level = logger.info else: level = logger.info level(format, *args, extra=extra) 比原先多处理了一个Broken PIPE Error, 这是啥? 可以参考这个博客:https://www.cnblogs.com/yaowen/p/9726357.html 日志根据服务器的状态码来记录，不难理解 log_message 函数，回避 HTTPS 请求，500+ 的是服务器错误，400+ 为警告，其余为正常，状态码非数字用 info 等级（这是啥情况） TODO: 搞明白 args 传进来了啥 HTTP1.1 123456789101112131415161718# 省略部分代码class ServerHandler(simple_server.ServerHandler): http_version = '1.1' def cleanup_headers(self): super().cleanup_headers() # HTTP/1.1 requires support for persistent connections. Send 'close' if # the content length is unknown to prevent clients from reusing the # connection. if 'Content-Length' not in self.headers: self.headers['Connection'] = 'close' # Mark the connection for closing if it's set as such above or if the # application sent the header. if self.headers.get('Connection') == 'close': self.request_handler.close_connection = True 注释写的很详细了，关于 Content-Length 为什么会没有? 客户端在 http 头加 Connection:keep-alive时，服务器的 response 是 Transfer-Encoding:chunked 的形式，通知页面数据是否接收完毕，例如长连接或者程序运行中可以动态的输出内容。 在Http 1.0及之前版本中，Content-Length 字段可有可无。 在http1.1及之后版本。如果是 keep alive，则 Content-Length 和 chunked 只能在头里出现一个 重写了单次请求处理函数 12345678910111213141516171819202122232425262728293031class WSGIRequestHandler(simple_server.WSGIRequestHandler): def handle(self): self.close_connection = True self.handle_one_request() while not self.close_connection: self.handle_one_request() try: self.connection.shutdown(socket.SHUT_WR) except (socket.error, AttributeError): pass def handle_one_request(self): &quot;&quot;&quot;Copy of WSGIRequestHandler.handle() but with different ServerHandler&quot;&quot;&quot; self.raw_requestline = self.rfile.readline(65537) if len(self.raw_requestline) &gt; 65536: self.requestline = '' self.request_version = '' self.command = '' self.send_error(414) return if not self.parse_request(): # An error code has been sent, just exit return handler = ServerHandler( self.rfile, self.wfile, self.get_stderr(), self.get_environ() ) handler.request_handler = self # backpointer for logging &amp; connection closing handler.run(self.server.get_app()) //TODO: 理解 close_connection 会因什么而发生变化 RUN 函数 12345678910111213141516171819def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer): server_address = (addr, port) if threading: httpd_cls = type('WSGIServer', (socketserver.ThreadingMixIn, server_cls), {}) else: httpd_cls = server_cls httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6) if threading: # ThreadingMixIn.daemon_threads indicates(指出) how threads will behave on an # abrupt shutdown; like quitting the server by the user or restarting # by the auto-reloader. True means the server will not wait for thread # termination before it quits. This will make auto-reloader faster # and will prevent the need to kill the server manually if a thread # isn't terminating correctly. httpd.daemon_threads = True # daemon_thread 守护进程 httpd.set_app(wsgi_handler) httpd.serve_forever() type() 函数 只有第一个参数则返回对象的类型，三个参数返回新的类型对象。 不会认为子类是一种父类类型，不考虑继承关系。 type(name:类名, bases:基类的元组, dict:类内定义的命名空间变量) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# type不会认为子类是父类的类型，不会考虑继承关系class A: def foo(self): print(&quot;You Called A.foo&quot;)class B(A): def foo(self): print(&quot;You Called B.foo&quot;)class C: def bar(self): print(&quot;You Called C.bar&quot;)if __name__ == &quot;__main__&quot;: clazz_A = type(&quot;A&quot;, (A, C), {}) t = clazz_A() t.bar() t.foo() print(type(t)) clazz_B = type(&quot;B&quot;, (A, C), {}) t = clazz_B() t.bar() t.foo() print(type(t)) clazz_A = type(&quot;A&quot;, (B, C), {}) t = clazz_A() t.bar() t.foo() print(type(t))&quot;&quot;&quot;You Called C.barYou Called A.foo&lt;class '__main__.A'&gt;You Called C.barYou Called A.foo&lt;class '__main__.B'&gt;You Called C.barYou Called B.foo&lt;class '__main__.A'&gt;&quot;&quot;&quot; 这个就是启动函数，会创建一个 WSGI Server 的实例，和我们在上一篇中的流程图唯一有一个不同就是使用的是 WSGI Handler类，而不是模块里写的一个 demo_app。 参数解析 add: 地址，可传入 ip 地址，一般是 127.0.0.1 port: 端口，自定义端口 wsgi_handler: 上节提到的 application， 在 django.core.handlers 中定义 ipv6: 如果为 true, 会将协议地址族换成是 AF_INET6 threading: 如果为 true, 服务器类会多继承一个类，这样能多线程处理请求 run() 什么时候会被调用呢?当然是在 runserver 时。 get_wsgi_application 123456789101112131415161718192021from django.core.wsgi import get_wsgi_applicationdef get_internal_wsgi_application(): from django.conf import settings app_path = getattr(settings, 'WSGI_APPLICATION') if app_path is None: return get_wsgi_application() try: return import_string(app_path) except ImportError as err: raise ImproperlyConfigured( &quot;WSGI application '%s' could not be loaded; &quot; &quot;Error importing module.&quot; % app_path ) from err# wsgi.pyfrom django.core.handlers.wsgi import WSGIHandlerdef get_wsgi_application(): django.setup(set_prefix=False) return WSGIHandler() 当你在你的项目中配置了 WSGI_APPLICATION，那么使用你选的。否则用 Django 自己的，就是 WSGIHandler import_string 不难猜测，用字符串来引入一个模块，可以学习一下 Django 对于 Python 模块导入的包装 123456789101112131415161718192021222324import copyimport osfrom importlib import import_modulefrom importlib.util import find_spec as importlib_finddef import_string(dotted_path): &quot;&quot;&quot; Import a dotted module path and return the attribute/class designated by the last name in the path. Raise ImportError if the import failed. &quot;&quot;&quot; try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError as err: raise ImportError(&quot;%s doesn't look like a module path&quot; % dotted_path) from err module = import_module(module_path) try: return getattr(module, class_name) except AttributeError as err: raise ImportError('Module &quot;%s&quot; does not define a &quot;%s&quot; attribute/class' % ( module_path, class_name) ) from err 总结 WSGI Application 篇幅太长了，放到下一篇里吧 参考 https://blog.csdn.net/jeremyjone/article/details/80616577 https://www.cnblogs.com/daoluanxiaozi/p/3306471.html","link":"/2020/02/11/django-understanding-2/"},{"title":"denominator","text":"更新于 2020/10/15 从菜鸡开始的计科学习 从美赛到国赛，体验了数学建模，个人从4月开始也一直在断断续续的准备建模比赛，虽然感觉自己已经掌握了不少的数模方法，看完了数模经典——数学模型（姜启源），但真正比赛才感受到，自己学的还是不够充分，仍有很多的分析方法需要现学，同时还要去看题目中自己不了解的学科的一些基础知识，感觉压力拉满了。忙了3天算是交了一份满意（？）的答卷。 一晃眼自己已经到了大三的门口了，想想自己会什么，算法不会，计算机系统，底层东西也学得一知半解，开发方面也只能做一做小的项目，也没有什么拿得出手的奖，成绩绩点也不是很出色，就顿时感觉自己白过了2年，后续的学习还需要更加的认真和努力。 数模仅仅是个开端，虽然以后已经没有参赛保研（？）的机会了，也不好找队友了，但后续的数学分析方法的学习和模型代码实现也不能停止学习，重要的是我希望可以学习一些人工智能，机器学习的一些知识（我看往年数模论文好多用了这些方法），这些都需要前面的一些基础模型的铺垫。 希望明天能更好吧~~~ 博客的一些变化 增加了基于 gitalk 的评论（评论内容会直接记录在 issue 里） 自定义了一些样式，将博客的文章内容页面的右边框删除，便于阅读 更多的个人定制方法： https://www.alphalxy.com/2019/03/customize-icarus/ 处理 fontawesome 加载拖慢页面问题（好像是云服务被土啬了），在配置文件里将 iconcdn 后面的改成这个: https://cdn.bootcss.com/font-awesome/5.13.0/css/all.css 懒得开新页面了就写在这里 不知不觉已经写了 60+ 篇博客了，其实大部分是 note 吧，以后会更多的写自己研究的东西，将一些学习的东西整合的更加精细一些，坚持就是胜利 瞅了眼隔壁 AiDai 大佬的博客，我是不是也得多更新一些日常生活篇呢，小本本上记上。 欢迎来评论，嘻嘻嘻","link":"/2020/10/15/denominator/"},{"title":"Django WSGI Application","text":"WSGI Handler Django 自带的 WSGIHandler 实际上在 wsgi 规范中是作为一个 WSGI application ，它是一个定义了 __call__ 的类。 涉及的几个关键性文件 django/core/handler/base.py django/core/handler/execption.py django/core/handler/wsgi.py 我们首先关注 wsgi.py 里定义的类 wsgi.py LimitedStream 类 12345678910111213141516171819202122232425262728293031# 截取部分代码class LimitedStream: &quot;&quot;&quot;Wrap another stream to disallow reading it past a number of bytes.&quot;&quot;&quot; def __init__(self, stream, limit, buf_size=64 * 1024 * 1024): self.stream = stream self.remaining = limit self.buffer = b'' self.buf_size = buf_size def _read_limited(self, size=None): if size is None or size &gt; self.remaining: size = self.remaining if size == 0: return b'' result = self.stream.read(size) self.remaining -= len(result) return result def read(self, size=None): if size is None: result = self.buffer + self._read_limited() self.buffer = b'' elif size &lt; len(self.buffer): result = self.buffer[:size] self.buffer = self.buffer[size:] else: # size &gt;= len(self.buffer) result = self.buffer + self._read_limited(size - len(self.buffer)) self.buffer = b'' return result 一个包装了一个流的类，它的函数 read 当 size 的大小未指定的时候只读取限定大小的流，当给出 size 大小时先从流中读取，如果流中的数据不够再使用 read_limited 读取指定大小的流，同时 buffer 永远保存着没有读取的流。 WSGIHandler 类 12345678910111213141516171819202122232425class WSGIHandler(base.BaseHandler): request_class = WSGIRequest def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.load_middleware() def __call__(self, environ, start_response): set_script_prefix(get_script_name(environ)) # 请求处理之前发送信号 signals.request_started.send(sender=self.__class__, environ=environ) request = self.request_class(environ) response = self.get_response(request) response._handler_class = self.__class__ status = '%d %s' % (response.status_code, response.reason_phrase) response_headers = [ *response.items(), *(('Set-Cookie', c.output(header='')) for c in response.cookies.values()), ] # server 提供的回调方法，将响应的 header 和 status 返回给 server start_response(status, response_headers) if getattr(response, 'file_to_stream', None) is not None and environ.get('wsgi.file_wrapper'): response = environ['wsgi.file_wrapper'](response.file_to_stream) return response list = [*dict.items()] 这种写法，list 最后会是一个包含元组的列表，每个元组为字典中的 key, value 的组合 我们通过前面的学习知道了请求被交给这个类作为 WSGI 中的 Application 来处理请求最终也通过它来返回请求（start_response），返回响应的正文 我们发现__init__() 函数除了调用父类的初始化，又调用了 load_middleware() 这个函数在 BaseHandler 中定义，猜测一下是加载 Django 的中间件在处理请求的时候使用 Set-Cookis 这个头属性在这个类中被加入返回头里 处理请求调用 get_response() 方法，该方法的的主要逻辑是通过 urlconf 找到对应的 view，按顺序执行 middleware 和 view 函数，具体在 View 模块详细的研究 WSGIRequset 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class WSGIRequest(HttpRequest): def __init__(self, environ): script_name = get_script_name(environ) path_info = get_path_info(environ) or '/' self.environ = environ self.path_info = path_info self.path = '%s/%s' % (script_name.rstrip('/'), path_info.replace('/', '', 1)) self.META = environ self.META['PATH_INFO'] = path_info self.META['SCRIPT_NAME'] = script_name self.method = environ['REQUEST_METHOD'].upper() self.content_type, self.content_params = cgi.parse_header(environ.get('CONTENT_TYPE', '')) if 'charset' in self.content_params: try: codecs.lookup(self.content_params['charset']) except LookupError: pass else: self.encoding = self.content_params['charset'] try: content_length = int(environ.get('CONTENT_LENGTH')) except (ValueError, TypeError): content_length = 0 self._stream = LimitedStream(self.environ['wsgi.input'], content_length) self._read_started = False self.resolver_match = None def _get_scheme(self): return self.environ.get('wsgi.url_scheme') @cached_property def GET(self): # The WSGI spec says 'QUERY_STRING' may be absent. raw_query_string = get_bytes_from_wsgi(self.environ, 'QUERY_STRING', '') return QueryDict(raw_query_string, encoding=self._encoding) def _get_post(self): if not hasattr(self, '_post'): self._load_post_and_files() return self._post def _set_post(self, post): self._post = post @cached_property def COOKIES(self): raw_cookie = get_str_from_wsgi(self.environ, 'HTTP_COOKIE', '') return parse_cookie(raw_cookie) @property def FILES(self): if not hasattr(self, '_files'): self._load_post_and_files() return self._files POST = property(_get_post, _set_post)# views/generic/base.pyfrom django.core.handlers.wsgi import WSGIRequestclass View(object): def __init__(self, *args, **kwargs): self.request = WSGIRequest() if False else None self.args = list() self.kwargs = dict() wsgi.url_scheme：http 或者 https （URL 方案嘛）， wsgi.input：一个类文件的输入流，application 可以通过这个获取 HTTP 请求的 body 看见GET, POST, FILES, Cookies 我们可以大胆的猜测，我们的 view 函数中传入的 request 就是这个类的实例，具体是不是这样我们需要详细的阅读 view 部分。 @cached_property 是一个缓存装饰器， @property 我们应该很熟悉，当一个函数被这个装饰器装饰的时候，我们可以把这个函数返回值当做属性来获取，而 @cached_property 就和名字一样，加了缓存，当被调用第一次会进行计算，计算完之后把实例的 __dict__[‘xxx’] 设置为计算后的值。下次读值的时候会直接从其中读取，避免了多次计算。 具体的部分我看不懂 =_= 但我们知道了 self.method = environ[‘REQUEST_METHOD’] 中保存的是请求的方法，这样我们就可以使用中间件来扩充 http 请求的类型，比如 DELETE 类型 get，post 应均返回一个 QueryDict 类型，它被定义在 django.http.QueryDict 1234567891011121314151617# 自定义中间件from django.http import QueryDictfrom django.utils.deprecation import MiddlewareMixinclass HttpOtherMethodMiddleware(MiddlewareMixin): def process_request(self, request): try: request_method = request.META['REQUEST_METHOD'] if requset_method.upper() not in ('GET', 'POST'): setattr(request, requset_method.upper(), QueryDict(request.body)) except Exception: pass finally: return base.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140# 省略部分代码class BaseHandler: _view_middleware = None _template_response_middleware = None _exception_middleware = None _middleware_chain = None def load_middleware(self): &quot;&quot;&quot; Populate middleware lists from settings.MIDDLEWARE. Must be called after the environment is fixed (see __call__ in subclasses). &quot;&quot;&quot; self._view_middleware = [] self._template_response_middleware = [] self._exception_middleware = [] # 将函数发生的异常转变为 response 返回，避免无法正常返回 handler = convert_exception_to_response(self._get_response) for middleware_path in reversed(settings.MIDDLEWARE): # 又看见了 import_string 这个函数，用来导入模块 middleware = import_string(middleware_path) try: mw_instance = middleware(handler) except MiddlewareNotUsed as exc: if settings.DEBUG: if str(exc): logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc) else: logger.debug('MiddlewareNotUsed: %r', middleware_path) continue # 抛出异常 if mw_instance is None: raise ImproperlyConfigured( 'Middleware factory %s returned None.' % middleware_path ) # 栈式结构 if hasattr(mw_instance, 'process_view'): self._view_middleware.insert(0, mw_instance.process_view) if hasattr(mw_instance, 'process_template_response'): self._template_response_middleware.append(mw_instance.process_template_response) if hasattr(mw_instance, 'process_exception'): self._exception_middleware.append(mw_instance.process_exception) handler = convert_exception_to_response(mw_instance) # We only assign to this when initialization is complete as it is used # as a flag for initialization being complete. self._middleware_chain = handler def make_view_atomic(self, view): non_atomic_requests = getattr(view, '_non_atomic_requests', set()) for db in connections.all(): if db.settings_dict['ATOMIC_REQUESTS'] and db.alias not in non_atomic_requests: view = transaction.atomic(using=db.alias)(view) return view def get_response(self, request): &quot;&quot;&quot;Return an HttpResponse object for the given HttpRequest.&quot;&quot;&quot; # Setup default url resolver for this thread set_urlconf(settings.ROOT_URLCONF) response = self._middleware_chain(request) response._closable_objects.append(request) if response.status_code &gt;= 400: log_response( '%s: %s', response.reason_phrase, request.path, response=response, request=request, ) return response def _get_response(self, request): &quot;&quot;&quot; Resolve and call the view, then apply view, exception, and template_response middleware. This method is everything that happens inside the request/response middleware. &quot;&quot;&quot; response = None if hasattr(request, 'urlconf'): urlconf = request.urlconf set_urlconf(urlconf) resolver = get_resolver(urlconf) else: resolver = get_resolver() resolver_match = resolver.resolve(request.path_info) callback, callback_args, callback_kwargs = resolver_match request.resolver_match = resolver_match # Apply view middleware for middleware_method in self._view_middleware: response = middleware_method(request, callback, callback_args, callback_kwargs) # 在中间件中返回有内容，则后面的中间件不需要再执行了 if response: break if response is None: wrapped_callback = self.make_view_atomic(callback) try: response = wrapped_callback(request, *callback_args, **callback_kwargs) except Exception as e: response = self.process_exception_by_middleware(e, request) # Complain if the view returned None (a common error). if response is None: if isinstance(callback, types.FunctionType): # FBV view_name = callback.__name__ else: # CBV view_name = callback.__class__.__name__ + '.__call__' raise ValueError( &quot;The view %s.%s didn't return an HttpResponse object. It &quot; &quot;returned None instead.&quot; % (callback.__module__, view_name) ) # If the response supports deferred rendering, apply template # response middleware and then render the response elif hasattr(response, 'render') and callable(response.render): for middleware_method in self._template_response_middleware: response = middleware_method(request, response) # Complain if the template response middleware returned None (a common error). if response is None: raise ValueError( &quot;%s.process_template_response didn't return an &quot; &quot;HttpResponse object. It returned None instead.&quot; % (middleware_method.__self__.__class__.__name__) ) try: response = response.render() except Exception as e: response = self.process_exception_by_middleware(e, request) return response def process_exception_by_middleware(self, exception, request): &quot;&quot;&quot; Pass the exception to the exception middleware. If no middleware return a response for this exception, raise it. &quot;&quot;&quot; for middleware_method in self._exception_middleware: response = middleware_method(request, exception) if response: return response raise 我的理解是 middleware 分为3类，view_middleware（视图中间件），template_response_middleware（模板中间件） ，exception_middleware（异常中间件），在我们的 view 函数处理前，先通过视图中间件，然后当响应返回渲染的 html，这时会通过模板中间件进行进一步处理，当发生异常时，会通过异常中间件一步一步处理响应（process_exception_by_middleware 函数） // TODO: 这里的中间件和我们 Django setting 中的中间件有什么区别?","link":"/2020/02/12/django-understanding-3/"},{"title":"Docker入门（不用入土）","text":"了解Docker 概述 Docker官网 啥是Docker: Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版），我们用社区版就可以了。 Docker的优点有啥: Docker容器虚拟化，意味着： 1.环境隔离： 通过cgroups和namespace进行实现资源的隔离，实现一个机器运行多个容器互不影响。 2.更快速的交付部署： 利用Docker，开发人员可以使用镜像快速构建一套标准的开发环境；开发完成后，测试运维人员可以直接使用相同的环境部署代码。Docker可以快速创建和删除容器，节省大量部署时间。 3.资源利用高效： Docker容器的运行不需要额外的虚拟化管理程序的支持，它是内核级的虚拟化，可以实现更高的性能。 4.移迁移扩展： docker的容器几乎可以在任意的平台下运行。 虽然现在看的云里雾里，但随着我们的后续学习，会对这些优势有一点程度上的理解 安装Docker 略，详见网上的各种教程 笔者的docker安装在centos7服务端 虚拟化与Docker Docker 使用客户端-服务器 (C/S) 架构模式，使用远程API来管理和创建Docker容器。 Docker 容器通过 Docker 镜像来创建。 容器与镜像的关系类似于面向对象编程中的对象与类。 概念 描述 Docker 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板。 Docker 容器(Container) 容器是独立运行的一个或一组应用。 Docker 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker API与Docker 的守护进程通信 Docker 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 Docker 仓库(Registry) Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。DockerHub 提供了庞大的镜像集合供使用 使用Docker 镜像操作 1.获取镜像 docker pull&lt;域名&gt; / &lt;namespace&gt; / &lt;repo&gt;;&lt;tag&gt; 镜像是Docker运行容器的前提 用户可以从网络上下载镜像，若不指定tag，则会默认选择lastest的标签，即下载最新版（和git pull；git tag有点相似） 默认从docker官方下载，不需指定命名空间 [root@VM_0_4_centos docker]# docker pull ubuntu Using default tag: latest latest: Pulling from library/ubuntu 6abc03819f3e: Pull complete 05731e63f211: Pull complete 0bd67c50d6be: Pull complete Digest:sha256:f08638ec7ddc90065187e7eabdfac3c9 6e5ff0f6b2f1762cf31a4f49b53000a5 Status: Downloaded newer image for ubuntu:latest 2.查看镜像列表 docker images 列出本地主机上的已有镜像 表格信息含义为：来自于哪个仓库，镜像标签信息，镜像id（唯一），创建时间，大小 [root@VM_0_4_centos docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 7698f282e524 2 weeks ago 69.9MB hello-world latest fce289e99eb9 5 months ago 1.84kB 3.查看镜像信息 docker inspect&lt;image_id&gt; 返回json格式的信息，如果我们只看一项，使用-f指定 [root@VM_0_4_centos docker]# docker inspect fce289e99eb9 [ { “Id”: “sha256:fce289e99eb9bca977dae136fbe2a82b6b7d 4c372474c9235adc1741675f587e”, “RepoTags”: [ “hello-world:latest” ], “RepoDigests”: [ “hello-world@sha256:0e11c388b664df8a27a901dce21eb89f1 1d8292f7fca1b3e3c4321bf7897bffe” ], “Parent”: “”, … [root@VM_0_4_centos docker]# docker inspect -f{{.Id}} fce289e99eb9 sha256:fce289e99eb9bca977dae136fbe2a82b6b7d4 c372474c9235adc1741675f587e 注意我们指定时用的是**{{.xx}}**， 点不要漏了 4.查找镜像 docker search &lt;image_name&gt; 可以搜索远端仓库中的共享镜像，默认搜索Docker hub官方仓库的镜像 5.删除镜像 docker rmi &lt;image&gt;; &lt;tag&gt; img可以指定为标签或id 当一个镜像有多个标签时，只是删除其中的一个指定标签，不影响镜像文件 当只有一个tag时，删tag就是删镜像本身 当有该镜像的容器存在时，镜像文件无法被删除 [root@VM_0_4_centos docker]# docker tag fce289e99eb9 cyx:hello-world [root@VM_0_4_centos docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 7698f282e524 2 weeks ago 69.9MB cyx hello-world fce289e99eb9 5 months ago 1.84kB hello-world latest fce289e99eb9 5 months ago 1.84kB [root@VM_0_4_centos docker]# docker rmi cyx:hello-world Untagged: cyx:hello-world [root@VM_0_4_centos docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 7698f282e524 2 weeks ago 69.9MB hello-world latest fce289e99eb9 5 months ago 1.84kB 试图删除hello-world [root@VM_0_4_centos docker]# docker rmi hello-world Error response from daemon: conflict: unable to remove repository reference “hello-world” (must force) - container 16aafe3a6ff9 is using its referenced image fce289e99eb9 错误，仍有容器在运行这个镜像，不建议-f，会让你的容器找不到镜像，导致混乱 6.创建镜像 docker commit &lt;options&gt; &lt;container_id&gt; &lt;repository:tag&gt; -a, --auther:作者信息 -m, --message:提交信息 -p, --pause=true: 提交时暂停容器运行 （炒鸡像git） [root@VM_0_4_centos docker]# docker run -ti ubuntu bash root@8da371140128:/# touch test.txt root@8da371140128:/# vi test.txt bash: vi: command not found root@8da371140128:/# echo root@8da371140128:/# echo “test” &gt; test.txt root@8da371140128:/# cat test.txt test root@8da371140128:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys test.txt tmp usr var root@8da371140128:/# exit exit 运行Ubuntu，-ti把容器内标准绑定到终端并运行bash，发现这个操作系统里很多命令都没有，只保留了很少系统运行的参数 [root@VM_0_4_centos docker]# docker commit -a&quot;cyx&quot; -m “add test.txt” 8da371140128 cyx/test sha256:036f85781fd0c78066f957d3fe809d8c48 19f9cad5979d832a8f130e6cbb8c74 [root@VM_0_4_centos docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE cyx/test latest 036f85781fd0 4 seconds ago 69.9MB ubuntu latest 7698f282e524 2 weeks ago 69.9MB hello-world latest fce289e99eb9 5 months ago 1.84kB 7.迁出镜像 docker save -o &lt;image&gt;.tar&lt;image&gt;:&lt;tag&gt; -o为设置存储压缩后的文件名称 image可以为标签或id 8.载入镜像 docker load --input&lt;image&gt;.tar 或 docker load &lt; &lt;image&gt;.tar 会导入镜像的相关数据信息，包括标签 9.上传镜像 docker push &lt;域名&gt;/&lt;namespace&gt;/&lt;repo&gt;:&lt;tag&gt; 可能会需要登陆 使用docker login [root@VM_0_4_centos docker]# docker save -o test.tar 036f85781fd0 [root@VM_0_4_centos docker]# docker rmi 036f85781fd0 Untagged: cyx/test:latest Deleted: sha256:036f85781fd0c78066f957d3fe8 09d8c4819f9cad5979d832a8f130e6cbb8c74 Deleted: sha256:8978e7051b78201de4a5fff1b3 e1a45ef22947123424c471ac3c701b8653f005 [root@VM_0_4_centos docker]# docker load &lt; test.tar bb370513b24b: Loading layer [==================================================&gt;] 3.584kB/3.584kB Loaded image ID: sha256:036f85781fd0c78066f957d3fe809d8c4819f9 cad5979d832a8f130e6cbb8c74 [root@VM_0_4_centos docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE &lt;none&gt; &lt;none&gt; 036f85781fd0 10 minutes ago 69.9MB ubuntu latest 7698f282e524 2 weeks ago 69.9MB hello-world latest fce289e99eb9 5 months ago 1.84kB [root@VM_0_4_centos docker]# docker tag 036f85781fd0 “cyx/test” [root@VM_0_4_centos docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE cyx/test latest 036f85781fd0 11 minutes ago 69.9MB ubuntu latest 7698f282e524 2 weeks ago 69.9MB hello-world latest fce289e99eb9 5 months ago 1.84kB 导入是没有设定库和tag，这时我们重新命名一下就好 [root@VM_0_4_centos docker]# docker tag 036f85781fd0 “cyxfree/test” [root@VM_0_4_centos docker]# docker push cyxfree/test The push refers to repository [docker.io/cyxfree/test] bb370513b24b: Pushed 8d267010480f: Pushed 270f934787ed: Pushed 02571d034293: Pushed latest: digest: sha256:92bcfc7a5946eccc845c88491ca 250b6957e099872af320e1ae4de3941ab004b size: 1150 注意，push后面跟的cyxfree/test是你的仓库名，如果没有这个远程仓库，则会创建一个 正常情况下为push (username)/(repository):tagname, 默认是最新的 PS: makedown &lt; 需要转义为&amp;lt 再加个； hexo 有个bug “}}”不在代码块要添加你的内容， 不然会出错（是解释成模板了吗，不懂）","link":"/2019/06/05/docker-1/"},{"title":"feint","text":"多灾多难 本来开心的用着 hexo，写公式的时候发现有点问题，网上解决了一下，顺手更新了一下 npm 包，然后整个人就裂开了，折腾了一晚上 + 一上午，曲线解决了问题。m*，还我时间… 数学公式 Hexo 的 MathJax 在渲染 LaTex 数学公式时会把一些字符转义导致公式无法正常显示。 可以通过修改渲染的规则来解决这个问题。 npm uninstall hexo-renderer-marked --save npm install hexo-renderer-kramed --save 执行上面的命令即可，先卸载原来的渲染引擎，再安装新的，换一个渲染的引擎。 然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为 hexo-renderer-kramed 引擎也有语义冲突的问题。 接下来到博客根目录下，找到 node_modules\\kramed\\lib\\rules\\inline.js，把第11行的 escape 变量的值做相应的修改： 12- escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_&gt;])/,+ escape: /^\\\\([`*\\[\\]()#$+\\-.!_&gt;])/ 这一步是在原基础上取消了对 ,{,} 的转义 同时把第20行的 em 变量也要做相应的修改 12- em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,+ em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/ 重新启动 hexo，如果不行试着 clean 一下缓存再重新生成。 Node 版本 在解决这个问题的时候，我手贱更新了 npm，然后自动修复更新了一些包，强制更新了一些包（现在想想为啥要更新）。然后 hexo 的依赖就各种崩，我还找不到原来的 package.json，只好逐一试试网上的一些方法。其中一个就是回退 NodeJs 的版本。 推荐使用 nvm 工具来管理电脑上的 node，官方下载链接 https://github.com/coreybutler/nvm-windows/releases 然后就可以使用简单的命令来管理电脑上的不同版本的 node 1234nvm ls # 查看安装的版本nvm use xxx # 使用某个版本,xxx 为版本号nvm install vxx # 安装对应vxx版本的nodenvm uninstall vxx # 卸载对应版本的node 然鹅这并没有用处 报的错误是 TypeError [ERR_INVALID_URL]，看了下错误找到对应的位置，是一个 new URL() 初始化抛出的异常被捕获了，去掉捕获代码（这个错误提示信息真的太少了），然后发现错误的原因是 / 根目录错误，应该写为 '/' … 但是重要的是，当我改完我博客里面的所有 root 符号的时候，还有错误，这次是在一些我找不到的或者看不懂的文件里面了… 翻了好久网上，没有能解决的，推测为 hexo 的版本的问题，但我也不知道该回滚到那一个版本，大晚上心态炸裂然后就睡了。 弃疗 早早起床，备份博客和配置文件，删除重装… icarus 更新到 4.0 了，变成了一个 npm 包，我之前用的还是 2.x 版本。然后我就不会魔改了，扒拉对比了半天找到几个修改的地方，向着我原来的样子改： 修改文章详情页 原本情况下主页和文章详情页都是只能同样的栏数，这很不好看，在原来的版本中可以参考网上的一些修改方法，新版我就没找到 后来发现 issue 里提出了解决方法：复制 _config.yml 到 _config.post.yml 和 _config.page.yml，然后在相应的配置文件中修改 widget 布局 这个好像是 4.0 的新的特性，之前我咋不知道呢。官方文档里也有提到这些配置文件的优先级和使用顺序。 然后就是页面大小问题，即使设置了 post 页两栏，文章内容这一栏也很小，需要修改代码里的这样一些地方（源码在 node_modules 的 hexo-theme-icarus 里）: layout/common/widget.jsx 修改 getColumnSizeClass 函数 layout/common/widget.jsx1234567891011function getColumnSizeClass(columnCount) { switch (columnCount) { case 2: return 'is-4-tablet is-4-desktop is-3-widescreen'; case 3: return 'is-4-tablet is-4-desktop is-3-widescreen'; } return '';} layout/layout.jsx 修改 columnCount 对应生成的属性（第29行和第30行） layout/layout.jsx 修改生成 body 的属性（第19行）（感觉手机适配会有一些问题，暂时没考虑） 123456- &lt;body class={`is-${columnCount}-column`}&gt;+ &lt;body class={`is-3-column`}&gt;...'is-8-tablet is-8-desktop is-9-widescreen': columnCount === 2,'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3... include/style/responsive.styl 增加新的 class 样式 1234567891011121314151617181920+widescreen() .is-1-column .container, .is-2-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap .is-3-column .container max-width: $widescreen - $gap width: $widescreen - $gap+fullhd() .is-2-column .container max-width: $widescreen - 2 * $gap width: $widescreen - 2 * $gap .is-1-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap .is-3-column .container max-width: $fullhd - $gap width: $fullhd - $gap 还有一点，在原本的里面可以给 toc 生成的目录标签加一个 sticky 属性，这样无论你前面加了几个插件，当滑到 toc 这里的时候就会黏上。只在配置文件里面修改的话是从一开始第一个插件的位置就黏上了。目前还没有找到如何修改 加自定义的 icon 可以在配置文件里修改默认的服务器，我怕改了之后有问题，就引了别的 iconfont 网站的图标 layout/common/head.jsx 里加入你的引用路径 如：&lt;link rel=&quot;stylesheet&quot; href=&quot;xxxxxx&quot; /&gt; 即可 写在后面 网上还有一些别的魔改，感觉喜欢的话可以自己试试，我觉得这些就够了。我上一次 essay 也写了一些魔改的方法和大佬的魔改版，可以去瞅瞅。 官方文档是个好东西，不认真看肯定要吃亏。 不要作死更新你的项目的版本，除非你真的需要并且做好了备份或者版本控制 参考博客: https://blog.csdn.net/zhan_lijian/article/details/85165930 https://www.jianshu.com/p/7ab21c7f0674 https://github.com/ppoffice/hexo-theme-icarus/issues/658","link":"/2020/10/25/feint/"},{"title":"HTTP头","text":"HTTP头 HTTP报文分为请求报文和响应报文。请求报文和响应报文的的第一行叫做状态行。状态行后面就跟着多个HTTP首部字段。 首先，咱们得清楚HTTP头部有什么作用，HTTP首部用来向请求报文或者响应报文中添加一些附加信息。通过HTTP首部信息，客户端或者服务器端就能了解到这次报文到底具有哪些属性，报文发送端有哪些喜好等等。 HTTP首部的分类： 1.通用首部：请求报文和响应报文都支持，换句话说，就是既可以出现在请求报文中，也可以出现在响应报文中。 2.请求首部：出现在请求报文第一行（请求行）的后面，为请求报文添加一些附加信息 3.响应首部：出现在响应报文第一行的后面，提供了一些关于响应报文的一些信息 4.实体首部：我们都知道，请求报文和响应报文都包含实体报文，实体首部就是用来描述实体报文的一些属性。 5.扩展头部：HTTP规范中没有定义的首部。 Header部分解释12345678910111213Accept 指定客户端能够接收的内容类型 Accept-Charset 浏览器可以接受的字符编码集Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型。 Accept-Language 浏览器可接受的语言 Authorization HTTP授权的授权证书 Cache-Control 指定请求和响应遵循的缓存机制 Connection 表示是否需要持久连接。（HTTP 1.1默认进行持久连接） Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。Content-Length 请求的内容长度 Content-Type 请求的与实体内容类型 Date 请求发送的日期和时间 Referer 请求的来源urlUser-Agent User-Agent的内容包含发出请求的用户信息 Header常见字段的举例 Accept：/ 最常见，指接受所有类型 还有text/plain，text/html，分别指接受纯文本和html格式 Accept-Encoding: gzip gzip是一种压缩方式，使用最为广泛，使用gzip可以省下很多网页流量,在网速一定的情况下，可以提高访问效率, 而deflate同样也为一种压缩方法（使用LZ77 算法和哈夫曼编码），使数据无损 Accept-Language: zh-CN；en-US 语言，zh-CN是简体中文，而zh是中文，en-US是英文 而q是权重系数，范围 0 =&lt; q &lt;= 1，q 值越大，请求越倾向于获得其“;”之前的类型表示的内容，若没有指定 q 值，则默认为1，若被赋值为0，则用于提醒服务器哪些是浏览器不接受的内容类型。 Accept-Charset: GB2312,utf-8;q=0.7,*;q=0.7 浏览器支持的字符编码分别是 GB2312、utf-8 和任意字符，优先顺序是 GB2312、utf-8、。 其中表示任意字符编码，虽然 q 都是等于 0.7，但明确指定的 GB2312,utf-8 比 * 具有更高的优先级。 Connection: keep-alive HTTP请求是基于TCP连接的，TCP的请求会包含（三次握手，中间请求，四次挥手） 在HTTP/1.0时代，一个HTTP请求就要三次握手和四次挥手，当一个网页中包含大量的图片或者其它外部资源时，加载一个Document要很多个HTTP请求，也就意味着要多次三次握手和四次挥手，这样就造成了网络资源的浪费 到了HTTP/1.1的时候，通过请求头的connection字段用来申明，作用就是减少TCP握手次数，开始的三次握手后就可以进行多次HTTP正文请求，可以长时间的保持，也就是加载一个Document的时候，即使有大量的图片等，也只用进行一次握手，这样就大大的减少了传输量了。keep-alive就表示之前已经进行过握手，可以直接进行HTTP正文传输，close表示结束，我接下来没有东西了，可以进行四次挥手结束这个TCP连接了 Content-Type Http Header里的Content-Type一般有: 1.application/x-www-form-urlencoded: 数据被编码为名称/值对。这是标准的编码格式。 2.multipart/form-data: 传输文件。 3.text/plain: 数据以纯文本形式进行编码 4.application/json: json格式 对于一个form表单，其enctrype属性即为编码方式 常用有两种：application/x-www-form-urlencoded和multipart/form-data，默认为application/x-www-form-urlencoded。 x-www-form-urlencoded jquery的ajax方法默认使用application/x-www-form-urlencoded 当请求的Content-Type为application/x-www-form-urlencoded浏览器用x-www-form-urlencoded的编码方式把form数据转换成一个字串（name1=value1&amp;name2=value2…） 同理为application/json时会转换为json数据格式 form-data http请求中的multipart/form-data,它会将表单的数据处理为一条消息，以标签为单元，用分隔符分开。 既可以上传键值对，也可以上传文件。 当上传的字段是文件时，会有Content-Type来表名文件类型而content-disposition，用来说明字段的一些信息； 由于有boundary隔离，所以multipart/form-data既可以上传文件，也可以上传键值对，它采用了键值对的方式，所以可以上传多个文件。 boundary通常由浏览器随机生成 示例 使用HTTP Client 对本地服务器模拟post操作 后端为Django 使用application/x-www-form-urlencoded 123456POST http://127.0.0.1:8000/test.api/Accept: */*Cache-Control: no-cacheContent-Type: application/x-www-form-urlencodedname=test&amp;list=aaaa&amp;list=456 后端捕获代码12form_name = request.POST.get(&quot;name&quot;, None)form_list = request.POST.getlist(&quot;list&quot;, None) list被解析为列表而name被解析为k-v对，我们看到，虽然x-www-form-urlencoded是以k-v对的形式来传递参数的，这并不意味着它不能传递数组（列表），我们只需指定传递的key相同值不同的多组数据即可 使用multipart/form-data 1234567891011121314151617181920212223242526272829POST http://127.0.0.1:8000/test.api/Accept: */*Cache-Control: no-cacheContent-Type: multipart/form-data;boundary=yurnnlukjwfbrdiqvnqnegfitaaddkom--yurnnlukjwfbrdiqvnqnegfitaaddkomContent-Disposition: form-data;name=&quot;pic&quot;; filename=&quot;photo.jpg&quot;Content-Type: image/jpg&lt; E:\\img\\path\\name.jpg--yurnnlukjwfbrdiqvnqnegfitaaddkomContent-Disposition: form-data;name=&quot;list&quot;;Content-Type: text/plain11--yurnnlukjwfbrdiqvnqnegfitaaddkomContent-Disposition: form-data;name=&quot;list&quot;;Content-Type: text/plainbackground--yurnnlukjwfbrdiqvnqnegfitaaddkomContent-Disposition: form-data;name=&quot;name&quot;;Content-Type: text/plaincyx--yurnnlukjwfbrdiqvnqnegfitaaddkom-- 后端捕获代码123456789101112131415161718192021222324form_file = request.FILES.get(&quot;pic&quot;, None)form_name = request.POST.get(&quot;name&quot;, None)form_list = request.POST.getlist(&quot;list&quot;, None)if form_file is not None: random_name = str(uuid.uuid1()) &quot;&quot;.join(random_name.split(&quot;-&quot;)) path = path + &quot;\\\\&quot; + random_name + &quot;.jpg&quot; with open(path, &quot;wb&quot;) as destination: for chunk in form_file: destination.write(chunk) destination.close() print(&quot;write a pic&quot;)if form_name is not None: print(form_name)if form_list is not None: for i in form_list: print(i)return render(request, 'test.html')# 结果# write a pic# cyx# 11# background 我们指定boundary的值为 yurnnlukjwfbrdiqvnqnegfitaaddkom，这个完全根据自定义，但一般浏览器会以若干—开头以防止和数据名称或内容等冲突导致出错 我们的图片是以2进制的形式上传的，所以写入操作也要对应为2进制文件操作 Response常见字段举例 Cache-Control（默认为private） 常用属性值。 1.no-cache:这个属性呢，不要被他的样貌给迷惑了，它并不是不缓存响应报文，只不过在服务器返回响应时，缓存都要向服务器评估缓存的新鲜度。也就是说，如果服务器返回的响应相比缓存有所变动，则使用服务器的响应。 2.no-store:该指令规定不缓存任何内容（注意和no-cache的区别） 3.max-age:用法max-age=60(秒)，用来表示缓存资源的保鲜时间。当缓存的内容缓存时间大于该值时，请求将重新转发至服务器。 4.s-maxage:用法和max-age相同，并且行为和max-age也相同，不同的是s-maxage适用于公共缓存。 通过指定“Expires”（过期时间）值也会影响到缓存。与max-age不同的是，expires的值是绝对时间，而max-age是相对时间（我的理解） CORS CORS(cross-origin sharing standard) 什么情况下需要CORS? XMLHttpRequest或Fetch Web字体 等等 使用XMLHttpRequest (XHR)对象可以与服务器交互。您可以从URL获取数据，而无需让整个的页面刷新。这使得Web页面可以只更新页面的局部，而不影响用户的操作。XMLHttpRequest在 Ajax 编程中被大量使用。 什么时候触发 CORS可以让你实现跨站点请求并同时阻止恶意js的请求，它会在你发送下面几种HTTP请求时触发： 不同的域名 （比如在网站 example.com 请求 api.com) 不同的子域名 （比如在网站 example.com 请求 api.example.com) 不同的端口 （比如在网站 example.com 请求 example.com:3001) 不同协议 （比如在网站 https://example.com 请求 http://example.com) 跨域请求 只有服务器实现了cors接口才可以进行跨域请求 cors对于浏览器发过来的ajax请求有简单请求和非简单请求 简单请求： HEAD， GET， POST请求 浏览器会在header中加上字段 key：origin value：协议+域名+端口（如http：//localhost:8080） 服务器根据origin值来决定是否同意这个请求 如果请求通过会在header中多增加几个字段： Access-Control-Allow-Origin： http：//localhost:8080 （仍以上为例） 用来明确指定那些客户端的域名允许访问这个资源。它的值可以是： 允许任意域名（*）或者和一个完整的域名名字（比如：https://example.com） Access-Control-Allow-Credentail：True（是否包含cookie） 非简单请求 非简单请求需要发一个option方法的预检请求，成功后浏览器开始发出cors请求，其余与前面相同 其余的我暂时没有过多了解 Referer Referer是HTTP请求header 的一部分，当浏览器（或者模拟浏览器行为）向web服务器发送请求的时候，头信息里有包含Referer 比如我在www.google.com里有一个www.baidu.com链接那么点击这个www.baidu.com，它的header信息里就有Referer=http://www.google.com Referer的正确英语拼法是referrer。由于早期HTTP规范的拼写错误，为了保持向后兼容就将错就错了。其它网络技术的规范企图修正此问题，使用正确拼法，所以目前拼法不统一。还有它第一个字母是大写。 X-Forward-For X-Forward-For跟Referer和User-Agent一样，都是 HTTP 中的头域。 当存在X-Forward-For字段时，说明原始请求使用了代理， X-Forward-For的正向用途是便于服务端识别原始IP。 假设有一个ip为192.0.2.40的客户端，它经过多个代理访问服务器： 代理服务器1：ip=192.0.2.22 代理服务器2：ip=192.0.2.33 服务器：ip=192.0.2.44 那么各个服务器之间的X-Forward-For字段分别为： 代理服务器1和客户端： 请求中没有 Forwarded 头域 代理服务器2和代理服务器1：Forwarded:for=192.0.2.40 代理服务器2和服务器： Forwarded:for=192.0.2.40, for:192.0.2.22;by:192.0.2.44;proto=http;host=example.com 由于客户端到代理1的请求没有使用代理，所以值为空或短横线。到代理2时，中间经过了代理1，所以值为原始IP。到服务端时，中间经过了代理1和代理2，所以值为原始IP和代理 1IP 当然，这个字段可以伪造，这样服务器就无法知道你的真实IP 写在后面 对于之前的一次内容的整理和翻新，后续会继续添加，可能会有格式的小问题，后续会进行修改","link":"/2019/12/03/http-header/"},{"title":"from-optimization-to-ml","text":"From Optimization To Machine Learning ps：数学公式好多渲染出奇怪的问题，我佛了，看看换个渲染引擎 Regession Problems General 先补充回顾一下范数 我们前面包括后面见到的 $||x ||_2$ 就是 l2 范数，表示向量或者矩阵的元素的平方和： $$ || x ||_2 = \\sqrt { \\sum_i {x_i}^2 } $$ 回归方法是建立模型常用的一种策略，当我们有数据但没有建立起具体的模型或者是想要一个便于计算的模型时，回归模型是一种不错的选择。它可以从多个预测变量中得到一个连续的预测值。 我们假设有 M 个输入的点 $z_m$，对应输出 $y_m$，构成二元对${(z_m, y_m)}_{m=1}^M$，我们的目标是训练一个函数 $y=f(z)$。 虽然插值(interpolant)可以很好和精巧的找到这样的 f，但实际现实中的数据往往包含噪声，对于这样的点，插值模型会很大程度上受到数据的影响，模型的普适性很差。更好的方法是用 N 个基础函数去表示 f： $$ f(x)=\\sum_{n=1}^{N}c_n \\psi_n(x) $$ 系数 $c_n$ 可以告诉我们对应的函数（可以理解为函数提取出来的特征）在预测数值时的重要性。$\\psi_n(x)$ 是我们认为设置的，我们要训练的就是系数 $c_n$，老方法，把它转换为一个优化问题： $$ \\min_{c_1, \\cdots, c_N} \\ \\sum_{m=1}^{N}(y_m-\\sum_{n=1} \\psi_n (z_m) * c_n)^2 $$ 写成矩阵的形式： $$ X = \\begin{bmatrix} \\psi_1(x_1) &amp; \\cdots &amp; \\psi_N(x_1) \\\\ \\vdots &amp; &amp; \\vdots \\\\ \\psi_1(x_m) &amp; \\cdots &amp; \\psi_N(x_m) \\end{bmatrix} Y= \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_M \\end{bmatrix} , c=\\left [ c_1, \\cdots, c_N \\right ]^T $$ 这样，我们就可以将原来的优化问题化为标准形式： $$ \\min_{c} ||Y-Xc ||_2^2 $$ 线性回归的优化问题可以用解方程来解决，避免了迭代方法： $$ c=(X^T X)^{-1} (X^T Y) $$ 实际上，对于监督学习的神经网络就是非线性的回归模型。 Regularization 线性回归（Linear regression）指回归模型的系数是线性的，模型的输入并没有必要是线性的。对于线性最小二乘问题，我们可以直接求出最小值点，对于一些有高维度系数的问题，有特殊的数值方法去寻找解。 当数据点的个数比要学习的参数多时，方程的个数大于未知数的个数（M &gt; N），最小二乘问题是**系统超定（overdetermined）**的，反之是未确定的（underdetermined）。 对于超定的最小二乘问题通常有特殊解，而未确定系统有无穷多个系数可以使损失函数最小，虽然他们得到的目标函数的值是一样的，但在预测未知点的时候有很大的不同，这个问题被称为不适定问题（ill-posed problem） 要解决不适定问题，一种方法是平衡要估计的参数和数据点个数，另一种方法是正则化（regularization），正则化在原目标函数上增加了惩罚项： $$ \\min_{c} || Y-Xc || _2^2 + \\lambda R ( c ) $$ $\\lambda$ 是正则化系数，$ R ( c ) $ 是正则化项。$ R ( c ) $ 有很多种选择，比如： L2 正则化：Tikhonov regularization (Ridge regression) $ R( c )={||c||}_{2}^{2} = { \\sum_n^{N} c_n^2} $ L1 正则化：LASSO (sparse regression) $ R ( c )= ||c|| _1= \\sum_n^N \\left | c_n \\right | $ 为什么增加惩罚函数会有效？ 当你的参数比数据点还多的时候，你会希望一些参数的值为 0，而我们以 L1 形式为例，它就有这样的魔法，让一些不是很重要的参数变成 0。结合下面的图，我们给出从图像角度的理解： 我们绘制出 L1 惩罚函数的图像，横坐标和纵坐标是 c1 和 c2 满足 $\\left | c_1 \\right | + \\left | c_2 \\right | = k$，他们的曲线构成了一圈一圈的正方形。接着我们画出 $Xc=Y$ 达成最小值的解 c1 和 c2 的图像，有很多的点，他们构成一条直线，直线必然与 $\\left | c_1 \\right | + \\left | c_2 \\right | = k$ 有个交点，这取决于 k 值，但要确保我们的目标函数为极小值，我们也要让 k 尽量的小，也就是尽量靠内侧的正方形，在图中表现就是交点，同样也是与 c1 轴的交点，此时 c1 = k, c2 = 0 $R©$ 就选择了最重要的系数 c1。 Python 中的线性回归 官方文档给出的例子 12345678# Create linear regression objectregr = linear_model.LinearRegression()# Train the model using the training setsregr.fit(diabetes_X_train, diabetes_y_train)# Make predictions using the testing setdiabetes_y_pred = regr.predict(diabetes_X_test) Classification Problems 分类问题是针对于离散的点或者不连续的输出的方法，用线性回归模型去建立分类器可能并不好，回归模型不会被限制为具有离散的输出，并且可以在范围外进行预测。 Logistic Regression 逻辑回归将线性模型转变为逻辑函数的形式$logistic(s) = \\frac{e^{s} } {1+e^s } $： $$ f(x; c) = \\frac { e ^ {c^T x} } { 1 + e ^ {c^T x}} $$ 其中 $c^T$ 表示模型中的参数 $\\left [ c_1, \\cdots, c_n \\right ]$。逻辑函数的特征是：输出范围为$[0, 1]$，对于小的输入，输出接近 0；对于大的输入，输出接近 1。 这样我们要解决的优化问题如下： $$ \\max_{c} \\prod_{m:y_m=1} f(x_m;c) \\ \\prod_{m:y_m=0}1 - f(x_m;c) $$ $\\prod_{m:y_m=1} f(x_m;c)$ 代表所有输入是$x_m$，输出$y_m=1$的点。目标函数力图让$y_m=1$时我们函数的预测值尽可能的接近 1，当$y_m=0$时尽可能预测值为 0，这样 $1-f(x)$ 最大。在统计学中，常常使用极大似然估计法来求解，即找到一组参数，使得在这组参数下，我们的数据的似然度（概率）最大。为了方便求解，我们通常求对数： $$ \\sum (\\ln(f(x_m;c)) + \\ln(1-f(x_m;c))) $$ 逻辑回归不仅可以做二分类问题，不仅可以预测出来类别，还能得到预测的概率，在逻辑回归模型中，我们最大化似然函数和最小化损失函数实际上是等价的。 Multi-valued logistic regression 例子：待完成 Stochastic Gradient Descent 回归，分类问题，参数估计都需要解优化问题，它们有一个一般的形式： $$ \\min_{c} \\sum_{i=1}^{M}\\ell (y_i, f(x_i; c)) $$ l 是损失函数，表示预测值和实际值的误差，而在每个数据点误差的和常常被称为经验风险（empirical risk）。对于回归问题，$\\ell$ 是平方误差 $\\ell (y_i, f(x_i; c))=(f(x;c)-y)^2$，对于逻辑回归，$\\ell (y_i, f(x_i; c))=log(1+e^{-yf(x;c)})$。 当我们的数据集很大的时候，迭代方法每次都要对所有的点计算 M 大小的梯度值就会导致很耗时，随机（stochastic）梯度下降（SGD）通过随机选择一个数据集的子集去计算梯度，并用这个值来近似整体的梯度，一个简单的方法就是每次迭代选择一个点： 随机从 ${1, \\cdots, M}$ 选择 j 点 用这个点计算每一步梯度的值：$(x_j, y_j): c_{n+1}=c_n- \\alpha \\nabla_c \\ell(y_j, f(x_j;c_n))$ 通过每个样本都重复迭代，如果数据有1万条，就迭代1万次，每次用一个点计算来获取最优解，而梯度下降迭代一次要用到全部的样本。优点当然是训练的速度快，缺点是噪声较多，每次迭代不一定朝着整体最优化的方向前进。 Mini-Batch Gradient Descent 在权衡随机梯度下降和批量梯度下降方法后，便有了小批量梯度下降法（MBGD），每次迭代的时候用样本的子集，样本的一部分来代替全部的样本计算梯度。比如说有 1000 个样本，我们选择 10 个一组，这样就有了100 个 mini-batch，重复 100 次计算，每次有 $ c_{n+1}=c_n- \\frac{1}{10} \\alpha \\nabla_c \\ell(y_j, f(x_j;c_n)); j=1…100; x_j = [x_j^1, …, x_j^{10}]$ Assessing Model Fit 当我们训练的模型对于训练集的一些不重要的特征关注的太多了后，在新的数据到来时表现的结果很差，这就是过拟合（Over-fitting），我们需要一种验证误差的方法，它可以帮助我们决定什么时候停止训练来避免过拟合。 对于回归模型，很经典的方法是计算确定系数$R^2$ $$ R^2 = 1 - \\frac{ || Xc-Y ||_2^2 }{ || \\bar{y}-Y ||_2^2 } $$ $\\bar{y}$表示输出的 y 值的平均值，$R^2$ 越接近 1 说明模型很好的表现了数据的变化，如果数据集有很多的噪声，可能会导致 $\\bar{y}$ 很小，但有可能模型依旧有很好的适应性和预测能力","link":"/2021/03/11/from-optimization-to-ml/"},{"title":"迷惑行为","text":"最近社团被要求写科技推送，第一稿还被打回了，理由是讲的太难了。绝了，给了别的社团的范文，我细品： 我打开 word 文件一看，这别的社团正文里没有知识，歪歪斜斜的每页上都写着&quot;学习xx，参考xx&quot;几句话。我横竖品不出来，仔细看了半小时，才从字缝里看出字来，满篇都写着的是&quot;可以保研&quot;！ 我写好了新的一版，文笔不好，放出来让大火乐乐： 下面是正文： 在家也要打牢 Python 基础！ 疫情期间，虽然我们无法返回学校，但是这不影响我们在家坚持学习。 如果你觉得 c，c++ 深奥难懂，java 各种类记得异常痛苦，go，js 只停留在会拼写上。不妨来试试学习 Python，这是一门简洁优美，方便高效的语言，学习的门槛低，上手容易，工具支持多，在科研领域人工智能也有出色的第三方库支持。 学习 Python 的渠道有太多了，但下面两个网址一定要常用常看： github stackoverflow 具体怎么样才算 “学懂” Python 了呢，不同人对这句话的理解是不一样的。只把语言当做工具用的小伙伴们会说会用就行，基础语法会写就是&quot;学懂了&quot;，但当真正的问题出现时，仅仅只会简单的语法并不能帮助你解决问题。 我的建议是多去深入理解语言背后的一些内部机制，而不是会了点语法就沾沾自喜。当然语言的内部很复杂，我们学习的时候找准一个点切入，一点一点的学习即可。 还有很重要的一点是：从现在开始去留心自己程序中出现的 bug，有些你想当然的结果往往和最终程序的运行结果不同，这时就需要你发现背后的原因，而不是仅仅修复这个问题。 正文 宅家期间闲来无事，不如花 5-10 min 和我一起看看这些有趣的 Python 例子。 提示：请确保你接触过一些 Python，我们不会提及 Python 最最最基础的东西，那样就太无趣了。 What Happened in my PYTHON? 今天是一个阳光明媚的一天，当我正打算开心的开始写 Python 代码的时候，一条 QQ 消息突然蹦了出来，原来是我的朋友找我: 你这个朋友是不是你自己 朋友: xxx，你是计算机专业的吧 我：是啊，怎么了 朋友：你学过 python 是吗 我：是的 朋友：太好了，我最近也在学，刚好有些问题搞不明白，希望你能帮帮我 我心想，Python 入门起来应该很容易的啊，只要熟悉掌握字典，列表，元组的操作就可以很舒适的使用了啊？会有什么问题呢？ 我催促着他贴出来了问题，让我们来看看: Q1:Same? 12345678&gt;&gt;&gt; a = dict()&gt;&gt;&gt; a[5.0] = &quot;Python&quot;&gt;&gt;&gt; a[&quot;5.0&quot;] = &quot;Java&quot;&gt;&gt;&gt; a{5.0: 'Python', '5.0': 'Java'}&gt;&gt;&gt; a[5] = &quot;Ruby&quot;&gt;&gt;&gt; a{5.0: 'Ruby', '5.0': 'Java'} 我的好朋友表示很不理解，5.0 怎么能和 5 一样呢？ 结果难道不是应该为: {5.0: 'Python', '5.0': 'Java', 5: 'Ruby'} Why? 这个问题有对于字典一类的映射数据结构的本质有一定的了解就不会产生迷惑: 我们首先要知道，在 Python 中，为了快速比较字典的键来查找对象，Python 字典通过检查键值是否相等和比较哈希值来确定两个键是否相同。 首先，“哈希值” 是什么，简单来说就是通过一个记录的存储位置和它的关键字之间建立一个确定的对应关系 f将关键字映射后得到的一个值，一般情况下具有独一无二性。展开叙述并不在我们的讨论范围内，有需要的自行百度解决。 具有相同值的不可变对象在 Python 中始终具有相同的哈希值，但这并不意味着哈希值可以唯一确定字典的键，具有不同值的对象也可能具有相同的哈希值（哈希冲突） 那我们回到这个问题，我们可以大胆的猜测，1 和 1.0 的 哈希值是一样的！不然就无法得到这样的结果，你的 Python 解释器不会出错！ 验证一下，确实是这样的: 1234&gt;&gt;&gt; 5 == 5.0True&gt;&gt;&gt; hash(5) == hash(5.0)True Q2:I thought “for … in range” is same as for statement in C! 朋友没有放过我，问出了下一个问题： 朋友：C 语言的 for(i=0;i&lt;n;i++) 循环和 Python for i in range(n) 循环次数是一样的吧 我：对的，怎么了 他给出了他写的代码: 12345678for i in range(4): print(i) i = 10# output# 0# 1# 2# 3 朋友表示：这个循环难道不会只运行一次? Why? 看起来似乎很有道理。但在 Python 的 for 语句中，可迭代对象的每一项都会执行一个赋值操作。在每次迭代开始之前，迭代器（这里指 range(4)）生成的下一个元素就被赋值给目标变量（i）了，所以赋值语句 i = 10 并不会影响迭代。 对于 for 循环的官网解释 什么，你问我什么是迭代器？建议重新学一遍 python 的 for 语句 -_-|| 简单的来说，迭代就是重复同样的操作通过当前元素得到下一个元素的操作，就想我们迭代函数一样。 $$ f_n(x) = f(f_{n-1}(x)) $$ 迭代器就是迭代取值的工具，它允许迭代操作。 Q3: I only revise ONE VALUE in the matrix! 我朋友说他想创建一个 3x3 的数组，但又嫌弃嵌套一堆列表太不好看，于是他查到了这样一个神奇的代码: 1234row = [&quot;&quot;] * 3matrix = [row] * 3print(matrix)# [['', '', ''], ['', '', ''], ['', '', '']] 看起来不错，优美简洁，Pythonic，但是问题也来了 123456789&gt;&gt;&gt; row = [&quot;&quot;] * 3&gt;&gt;&gt; matrix = [row] * 3&gt;&gt;&gt; print(matrix)[['', '', ''], ['', '', ''], ['', '', '']]&gt;&gt;&gt; matrix[0][0]''&gt;&gt;&gt; matrix[0][0] = 1&gt;&gt;&gt; print(matrix)[[1, '', ''], [1, '', ''], [1, '', '']] wt? 我就修改了一个元素啊？？？ Why? 可以，这很 c 语言。这个问题涉及到很多高级语言的一个知识：深浅复制 对于 Python，当你使用复制语句的时候 a=b，实际上并非开辟了新的内存空间来将 b 的值完全复制过去，Python 的解释器仅仅只是给 b 添加了一个新的引用（或者说指针）。回到上面的问题，这里*实现的就是一个浅复制，在内存空间中上面问题是这样的: 很明显，你的数组仅仅只有三个基本元素，其余的都是对这些元素的引用，所以当你修改这三个中的任意一个时，会连带三行的元素都进行修改。 那应该怎么写？ 1234&gt;&gt;&gt; matrix = [['']*3 for i in range(3)]&gt;&gt;&gt; matrix[0][0] = 1&gt;&gt;&gt; matrix[[1 , '', ''], ['', '', ''], ['', '', ''] 或者老老实实的写[[&quot;&quot;,&quot;&quot;,&quot;&quot;],[&quot;&quot;,&quot;&quot;,&quot;&quot;],[&quot;&quot;,&quot;&quot;,&quot;&quot;]] Fin 我的朋友心满意足。 智商 + N，满足 + N 关于我们 我是谁？信息科学学院爱特工作室社团的一员 (: 爱特是干什么的？爱特工作室成立于 2002 年，是一个以计算机技术人才培养，网站开发为特色，的技术性团体。工作室设有前端开发，程序开发，UI设计，APP开发，游戏开发五个部门，并通过技术培训、以老带新等方式，不断提升团队成员的技术水平。这里小伙伴和你一起肝项目，放飞你的想象力，也有大佬带你原地起飞。目前程序部开发的语言是 Python，如果你喜欢 Python 也喜欢 web 开发，我们欢迎你的加入。 (*^o^)人(^o^*) 官网（报名系统已经关闭）www.itstudio.club ): 我们的新生培训讲课同样也对外开放，欢迎任何感兴趣的同学，具体事项可以联系蔡同学（QQ:3519161997） (。-ω-)zzz 附我的博客地址https://cyx0706.github.io/ (=´ω｀=)","link":"/2020/03/16/lmts/"},{"title":"matplotlib 入门","text":"初识 Matplotlib Matplotlib 是 Python 中常用的可视化工具之一，使用它可以方便的创建二维图和一些基本的三维图表 基础画图 123456789101112131415161718192021222324252627282930313233import numpy as npimport matplotlib.pyplot as pltx = [1, 2, 3, 4]y = [3, 5, 10, 25]plt.subplot(241)plt.plot(x, y)plt.title(&quot;plot&quot;)plt.subplot(242)plt.scatter(x, y)plt.title(&quot;scatter&quot;)plt.subplot(243)plt.pie(y)plt.title(&quot;pie&quot;)plt.subplot(244)plt.bar(x, y)plt.title(&quot;bar&quot;)plt.subplot(245)plt.boxplot(y, sym='o')plt.title(&quot;box&quot;)plt.subplot(246)t = np.arange(0, 5, 0.2)plt.plot(t, t, 'r--', t, t**2, &quot;bs&quot;, t, t**3, 'g^') # 'r--' 字符串指定的绘制线条颜色和类型plt.title(&quot;Pyplot Three&quot;)delta = 0.025cx = cy = np.arange(-3.0, 3.0, delta)X, Y = np.meshgrid(cx, cy)Z = Y**2 + X**2plt.subplot(247)plt.contour(X, Y, Z)plt.colorbar()plt.title(&quot;contour&quot;)plt.show() 上面的简单例子展示了绘制各种类型的基础图形 1234fig = plt.figure() # an empty figure with no axesfig.suptitle('No axes on this figure') # Add a title so we know which it isfig, ax_lst = plt.subplots(2, 2) # a figure with a 2x2 grid of Axes 官方文档里给出的一种写法是先创建一个 figure 然后在用 subplot 指定 figure 的大小 但是，实际上 pyplot 模块会在需要的时候自动帮我们创建一个 figure For functions in the pyplot module, there is always a “current” figure and axes (which is created automatically on request). 我们使用 plt.plot 来绘制一个线性函数，并且可以使用 label= 来指定函数的名字 需要注意的是你的 x 和 y 必须是两个列表 1234567891011121314x = np.linspace(0, 2, 100)plt.plot(x, x, label='linear')plt.plot(x, x**2, label='quadratic')plt.plot(x, x**3, label='cubic')plt.xlabel('x label') # x 坐标的名字plt.ylabel('y label')plt.title(&quot;Simple Plot&quot;)plt.legend() # 将标签绘制到图中plt.show() legend() 也可以指定参数来标记每个函数的 label line, = ax.plot([1, 2, 3]) legend((line1, line2, line3), (‘label1’, ‘label2’, ‘label3’)) plt.plot 通过指定 marker=‘字符’ 来改变绘制出来的点的样式 plt.plot 会返回每个画的线条，以元组的形式，我们只需用, 来解包即可 plt.plot 线条的相关属性标记设置 线条风格linestyle 描述 ‘-’ 实线 ‘:’ 虚线 ‘None’ 什么都不画 ‘-.’ 点划线 线条标记marker 描述 ‘o’ 圆圈 ‘.’ 点 ‘D’ 菱形 ‘s’ 正方形 ‘h’ 六边形1 ‘*’ 星号 ‘H’ 六边形2 ‘d’ 小菱形 ‘_’ 水平线 ‘v’ 一角朝下的三角形 ‘8’ 八边形 ‘&lt;’ 一角朝左的三角形 ‘p’ 五边形 ‘&gt;’ 一角朝右的三角形 ‘,’ 像素 ‘^’ 一角朝上的三角形 ‘+’ 加号 ‘’ 竖线 ‘None’ 无 ‘x’ X 颜色color 描述 b 蓝色 g 绿色 r 红色 y 黄色 c 青色 k 黑色 m 洋红色 w 白色 当然也可以使用 HTML 十六进制字符串 color=&quot;#123456&quot; plt.subplot() 支持一个窗口绘制多个图形，只需要传入一个百位数如plt.subplot(242) 表示分成2行4列在第二个位置开始绘图 直方图 例子：绘制正态分布(Normal distribution)图 1234567891011121314151617import numpy as npfrom matplotlib import pyplot as pltsamples1 = np.random.normal(0, size=1000) # random.normal 构建一个组基于正态分布的随机数据samples2 = np.random.normal(1, size=1000)# 绘制样本直方图bins = np.linspace(-4, 4, 30)# bins 定义每个区间的右边缘histogram1, bins = np.histogram(samples1, bins=bins, normed=True)histogram2, bins = np.histogram(samples2, bins=bins, normed=True)# 绘制图像plt.figure(figsize=(6, 4)) # 指定大小为长 6 英寸宽 4 英寸plt.hist(samples1, bins=bins, normed=True, label=&quot;Samples 1&quot;)plt.hist(samples2, bins=bins, normed=True, label=&quot;Samples 2&quot;)plt.legend(loc=&quot;best&quot;)plt.show() legend() 指定 loc 参数来指定放置图例的位置，可以使用字符串来代替特定数字表示位置 官方文档给出了解释，下面摘取常用的 best: ‘best’ for axes, ‘upper right’ for figures The strings ‘upper left’, ‘upper right’, ‘lower left’, ‘lower right’ place the legend at the corresponding corner of the axes/figure. 饼图(Pie Chart) 1234567891011import matplotlib.pyplot as pltplt.rcParams[&quot;font.sans-serif&quot;] = ['SimHei'] # 显示中文标签plt.rcParams[&quot;axes.unicode_minus&quot;] = False # 正常显示负号labels = ['A', 'B', 'C', 'D']sizes = [15, 30, 45, 10]explodes = (0, 0.1, 0, 0)fig1, ax1 = plt.subplots()ax1.pie(sizes, explode=explodes, labels=labels, autopct=&quot;%1.1f%%&quot;, shadow=True, startangle=90)ax1.axis(&quot;equal&quot;) # 使饼图长宽相等plt.title(&quot;饼图&quot;)plt.show() 一些参数的解释: explode: 饼块偏离中心点的大小 autopct: 控制饼图内百分比设置， shadow: 是否在饼图下面画一个阴影 startangle: 起始绘制角度,默认图是从 x 轴正方向逆时针画起,如设定为 90 则从 y 轴正方向画起 radius: 饼的半径，默认为1 官网上还有好多别的例子，可以学习如何把饼图画的更好 分组条图(Grouped bar chart) 学习官方文档里给出的例子 竖直 1234567891011121314151617181920212223242526272829303132333435363738394041import matplotlibimport matplotlib.pyplot as pltimport numpy as nplabels = ['G1', 'G2', 'G3', 'G4', 'G5']men_means = [20, 34, 30, 35, 27]women_means = [25, 32, 34, 20, 25]x = np.arange(len(labels)) # the label locationswidth = 0.35 # the width of the barsfig, ax = plt.subplots()rects1 = ax.bar(x - width/2, men_means, width, label='Men')rects2 = ax.bar(x + width/2, women_means, width, label='Women')# Add some text for labels, title and custom x-axis tick labels, etc.ax.set_ylabel('Scores')ax.set_title('Scores by group and gender')ax.set_xticks(x)ax.set_xticklabels(labels)ax.legend()def autolabel(rects): &quot;&quot;&quot;Attach a text label above each bar in *rects*, displaying its height.&quot;&quot;&quot; for rect in rects: height = rect.get_height() ax.annotate('{}'.format(height), xy=(rect.get_x() + rect.get_width() / 2, height), xytext=(0, 3), # 3 points vertical offset textcoords=&quot;offset points&quot;, ha='center', va='bottom')autolabel(rects1)autolabel(rects2)fig.tight_layout()plt.show() matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align=‘center’, data=None, **kwargs) x: 绘制的左 x 坐标 height: 绘制的高度 width: 绘制的宽度 bottom: 相对于 y 轴的偏移量，默认为0 align: 每个图的对齐方式，可选有 ‘center’: 中心对齐 x 坐标 ‘edge’: 左对齐 x 坐标 需要右对齐的时候往往需要将 align=edge，width 传入一个负值 matplotlib.pyplot.annotate(s, xy, *args, **kwargs) 用于将文本放置在指定的 xy 位置 text: 要放的文本(s 已经过时了!) xy: xy 坐标 xytext: 官方文档里解释是 The position (x,y) to place the text at. If None, defaults to xy. 按例子来看就是一个相对于原 xy 的 xy 偏移值，这实际上和下一个参数有关 textcoords: 设置 xytext 的偏移方式，‘offset points’ 表示以点的形式解释应用 xytext 的值，表示 xytext 给出的是偏移度量为点 figure.tight_layout() 可以解决一些排布问题，如 label 和图形重叠之类的 水平 123456789101112131415161718192021222324import matplotlib.pyplot as pltimport numpy as np# Fixing random state for reproducibilitynp.random.seed(20200130)plt.rcdefaults()fig, ax = plt.subplots()# Example datapeople = ('Cyx', 'Ly', 'Chy', 'Rhy', 'Zyw')y_pos = np.arange(len(people))performance = 3 + 10 * np.random.rand(len(people))error = np.random.rand(len(people))ax.barh(y_pos, performance, xerr=error, align='center')ax.set_yticks(y_pos)ax.set_yticklabels(people)ax.invert_yaxis() # labels read top-to-bottomax.set_xlabel('Performance')ax.set_title('How fast do you want to go today?')plt.show() 基本和竖着的表格一样，这里解释一下 xerr= 这个参数，表示 x 方向上的 error_bar(误差线) 长度 invert_yaxis() 函数会翻转坐标轴，即将会按照从上到下排列数据 堆积条图(Stack Bar) 1234567891011121314151617181920212223import numpy as npimport matplotlib.pyplot as pltN = 5menMeans = (20, 35, 30, 35, 27)womenMeans = (25, 32, 34, 20, 25)menStd = (2, 3, 4, 1, 2)womenStd = (3, 5, 2, 3, 3)ind = np.arange(N) # the x locations for the groupswidth = 0.35 # the width of the bars: can also be len(x) sequencep1 = plt.bar(ind, menMeans, width, yerr=menStd)p2 = plt.bar(ind, womenMeans, width, bottom=menMeans, yerr=womenStd)plt.ylabel('Scores')plt.title('Scores by group and gender')plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))plt.yticks(np.arange(0, 81, 10))plt.legend((p1[0], p2[0]), ('Men', 'Women'))plt.show() 有了上面一些函数的理解，不难看懂官方文档里给出的画法","link":"/2020/01/30/matplotlib-base/"},{"title":"mini-os","text":"2020/11/6 刚跟着书测试完了代码，太累了明天后天再整理 2020/11/8 打了学校举办的 acm 比赛，感受到了自己有多菜，老老实实回来写博客了，完成了 Boot 部分 2020/11/9 完成 Loader 部分 2020/11/10 整理出思维导图 2020/11/13 补充内容 自己动手写一个操作系统 参考学习《一个64位操作系统的设计与实现》（田宇著） 前言: bochs 环境配置，可参考同 tag 下的 bochs 那篇。 书上的代码给的很破碎，看书根本实现不出来…，完整代码可以参考这个 github 仓库 The-design-and-implentation-of-a-64-bit-os 自己磨蹭了快一个月才看完一章（第三章），不得不说自己计组是白学了…，第三章的汇编感觉是真的难，涉及到的东西也是最多的 本系列用于记录学习笔记，构建思维导图，以及补充各种书上没有说的知识，希望这个系列结束后自己对操作系统的理解能更上一层楼吧（我自己是肯定写不出来的） Boot &amp; Loader Boot 计算机上电之后，首先会经过自检，这个过程 BIOS 会检测硬件设备是否存在问题，如果没有，这时将根据 BIOS 的启动项配置选择引导设备，目前支持软盘启动，U盘启动，硬盘启动以及网络启动 啥是软盘 书上创建的软盘都是 1.44M 的，这里就以 1.44M 为例简述一下软盘的结构： 2个盘面（0和1），一个盘面有80条磁道（或称磁柱），一个磁道有18个扇区，一个扇区大小为512 Byte，于是软盘总容量：2*80*18*512 Byte = 1474560 Byte=1.44M 软盘不以扇区为单位存放数据，而是以多个扇区（2n个）构成的簇（Cluster），一个簇所含的扇区数与盘容量以及 FAT 表格式有关，特别的，2M 以下的磁盘一个簇只有一个扇区，一个文件至少占一个簇。 需要留意，软盘的第0磁头第0磁道第1扇区实际是软盘的第一个扇区。 Boot 引导原理 对于一张 3.5 英寸的 1.44MB 的软盘来讲，一个扇区的容量只有 512B，而 BIOS 仅仅只负责加载这一个扇区到物理内存中，这样小的空间肯定容不下操作系统，Boot 程序仅仅只能作为一个一级助推器，将更加强大的 Loader 装载到内存中，这也可以看做是硬件设备向软件移交控制权。 那么怎么让 BIOS 读取到我们的 Boot 呢，实际上这和 BIOS 的自检有关。BIOS 自检结束后会根据启动选项设置去选择启动设备，即检测软盘的第0磁头第0磁道第1扇区，是否以数值 0x55 和 0xaa 两字节作为结尾，如果是，那么 BIOS 认为这个扇区是一个 BootSector（引导扇区），进而把此扇区的数据复制到物理内存地址 0x7c00 处然后跳到 0x7c00 去执行这段程序。 Boot 做的事情很简单：加载 Loader 到内存，具体一点来说就是，从根目录中读入一个扇区的数据，接着遍历这个扇区的目录项，寻找与 (LOADER BIN,0) 相匹配的目录项，接着把文件内的数据和代码读入内存，然后跳转过去。 FAT12 文件系统简述 Boot 里面最关键的代码都与你的文件系统有关系，由于我们使用的是上个世纪的软盘，文件系统是过时的 FAT12，但也需要了解一下这种文件系统，同时它也是 FAT32 的前身（应该）。 下面的内容主要参考这篇博客 https://zhuanlan.zhihu.com/p/121807427，这里提取重要的部分： FAT12 文件系统将2880个扇区分成5个部分：MBR 引导记录，FAT1表，FAT2表，根目录，数据区 部分 长度 MBR 1个扇区 FAT1 9个扇区 FAT2 9个扇区 根目录 14个扇区 数据区 2847个扇区 MBR引导 记录 FAT12 文件系统整个组织结构的信息，这些信息描述了 FAT12 文件系统对磁盘扇区的管理情况。 FAT1，FAT2 这两个表完全相同，FAT2 目的是为了修复 FAT1 表。因此在实际操作的过程中可以将 FAT1 表在关机的时候赋值给 FAT2 即可。 FAT 表每12个bit（1.5个字节）为一个FAT项，代表数据区的一个簇。第0个和第1个FAT项始终不使用，对应 0xFF0（坏簇标记） 和 0xFFF（簇结束标记），第2个FAT项开始表示数据区的每一个簇，也就是说，第2个FAT项表示数据区第一个簇，即2号簇代表32号扇区。依次类推。由于文件系统将无法确保文件中的数据存储在连续的磁盘扇区内，则借助 FAT 表项，将这些不连续的文件片段按照簇号连接起来。簇和扇区的构成看起来就像C语言中的链表： 12345struct list{ struct block *next; // 簇就是这里的指针 char block[512]; // 扇区就是这里的block，储存数据}; 每个簇具储存了什么呢？首先12个二进制数字表示这个簇指向的下一个簇。FAT 表从零开始编号。如果2号簇储存的数字为3，那么说明2号簇指向3号簇。3号簇的12位数字储存的是5的话，那么说明3号簇指向5号簇。这就形成了一个链表，链表的空指针 NULL（结尾标志），使用 0xFFF 表示。 为什么簇和扇区要分离？ 我们当然可以把 next 指针放在一个扇区内，这样看上去更像编程中的链表结构。然而在实际操作系统中，很多时候只需要访问簇号就可以了，不需要访问扇区中的数据（计算目录的大小），这个时候只读取一个扇区内的容基本上就可以完成操作，极大的减少了 I/O 时间。 根目录区 根目录顾名思义就是系统最初的文件夹。根目录中储存了文件和子目录，两者的真正数据都是储存在数据区中，在根目录中之储存基本信息，用来找到它们真正的数据。这些基本信息叫文件目录项。 一个文件目录项有32个字节，结构如下： 偏移量 长度 描述 0 8 文件名 8 3 文件扩展名 11 1 文件属性 12 10 保留位 22 2 创建时间 24 2 创建日期 26 2 首簇号 28 4 文件大小 如果文件名没有满8位，则需要将后面的字符置为空格，而不是0 文件有3个属性：隐藏文件0x27，目录0x10，普通文件0x20 首簇号是文件第一个段信息存放的地址，FAT12 中，一个簇映射到一个数据区的扇区。 数据区 数据区的某一个扇区如果是一个目录，那么这个目录被称为子目录。子目录分为一级、二级…，他们的组织方法和根目录基本一样。子目录中一定要包含 . 和 .. 项。即 dot 和 dotdot 项。 Loader Loader 必须要在内核程序执行前为其准备好一切数据，比如说硬件的检测信息，处理器模式切换，向内核传递参数等。 Loader 引导加载程序需要检测的硬件信息很多，主要是通过 BIOS 中断服务程序来获取和检测硬件信息。由于 BIOS 在上电自检出的大部分信息只能在实模式下获取，而内核运行在非实模式下，那么就必须在进入内核程序前将这些信息检测出来。 处理器模式切换在后面介绍。 Loader 向内核传递数据分为两类：控制信息和硬件数据信息，这些数据一方面控制内核程序的执行流程，另一方面为内核初始化提供数据信息支持。 控制信息一般用于控制内核执行流程或者限制内核的某些功能，如启动模式（图形 or 命令行）等。 硬件数据信息通常供内核程序在初始化的时候分析，配置和使用，如内存地址等。 A20 功能 参考文档：http://wenku.baidu.com/view/b673e3360b4c2e3f57276369.html 在 8086/8088中，只有 20 根地址总线，所以可以访问的地址是 $2^20=1M$，但由于 8086/8088 是 16 位地址模式，能够表示的地址范围是 0-64K，所以为了在 8086/8088 下能够访问 1M 内存，采用了segment:offset的寻址方法，实际地址等于 segment &lt;&lt; 4 + offset，这样 8086/8088 能寻址的范围就成了从 0000:0000 ~ 0000:FFFF 开始到 F000:0000 ~ F000:FFFF 但这种方式引起了新的问题，通过上述分段模式，能够表示的最大内存为：FFFFh:FFFFh=FFFF0h+FFFFh=10FFEFh=1M+64K-16Bytes（1M多余出来的部分被称做高端内存区HMA）。但 8086/8088 只有 20 位地址线，如果访问 100000h~10FFEFh 之间的内存，系统并不认为其访问越界而产生异常，而是自动从重新0开始计算，也就是说系统计算实际地址的时候是按照对1M求模的方式进行的，这种技术被称为 wrap-around。 到了80286，系统的地址总线发展为24根，这样能够访问的内存可以达到$2^24=16M$。就可以正常的访问到 100000H-10FFEFH 之间的内存，而不是象过去一样重新从0开始。这样就造成了访问高端内存时 80286 在 real mode 下和 8086/8088 行为不同，兼容性就存在问题了。 为了解决上述问题，IBM 想出了一个古怪的方法：当 80286 运行在 real mode 时，将 A20 地址线（第 21 条 address bus）置为 0。方法是使用键盘控制器上剩余的一些输出线来管理第 21 根地址线（从0开始数是第20根），被称为 A20Gate：如果A20 Gate 被打开，则当程序员给出 100000H-10FFEFH 之间的地址的时候，系统将真正访问这块内存区域；如果 A20Gate 被禁止，则当程序员给出 100000H-10FFEFH 之间的地址的时候，系统仍然使用 8086/8088 的方式（认为造成了 wraparound 现象）。 上面所述的内存访问模式都是实模式，在 80286 以及更高系列的 PC 中，即使 A20Gate 被打开，在实模式下所能够访问的内存最大也只能为 10FFEFH，尽管它们的地址总线所能够访问的能力都大大超过这个限制。为了能够访问 10FFEFH 以上的内存，则必须进入保护模式。（其实所谓的实模式，就是 8086/8088 的模式，这种模式存在的唯一理由就是为了让旧的程序能够继续正常的运行在新的 PC 体系上） 在这里，我们开启实模式也是为了让 FS 段寄存器在实模式下寻址能力超过 1MB，这样就可以打开 Big Real Mode 模式。 处理器模式 这个不得不说一下历史：Intel 系列的微处理器主要发展过程是：8080，8086/8088，80186，80286，80386，80486，Pentium… 从 80386 开始，cpu 就有了3种工作模式： 实模式 保护模式 虚拟 8086 模式 在刚刚启动的时候是实模式，等到操作系统运行起来的时候就是保护模式。实模式其实就是一个 8086 模式，只能寻址 1M 以下的常规内存，而在保护模式下，32条地址线全部有效，可以寻址高达 4G 的物理地址空间。而虚拟 8086 就是在保护模式下运行的实模式，主要用于在 32 位保护模式下兼容执行纯 16 位程序，其实还是属于保护模式。 保护模式比实模式多了对内存的保护，程序内部使用的都是操作系统提供的虚拟地址，而由操作系统将虚拟地址转化为物理地址。这样就避免了实模式下用户程序的指针修改其他程序的物理地址的值造成的错误结果。 上面都是历史了，现在还有一种扩展模式：IA-32e： 由于保护模式加入了权限和分页等管理功能，使得程序的执行效率降低。当页管理单元出现后，段机制显得更加多余，随着硬件不断提升和对大容量内存的渴望，就出现了 IA-32e 模式，它简化了段级保护措施，升级内存的寻址能力，扩展了页管理单元的组织结构和页面大小。 IA-32e 有兼容模式和 64 位模式，子模式的切换完全基于代码段寄存器。64位模式可以执行 64 位程序，但要运行 16 或者 32 位程序，就需要切换到兼容模式了。 最后记一下 bochs 调试命令大全 https://blog.csdn.net/hua19880705/article/details/8124514","link":"/2020/11/06/mini-os-1/"},{"title":"aix","text":"正式开课了，这里仅是我的学习记录。 Module 1 introduction Now, engineering and science applications may, as you know, have very different demands. Accuracy and reliability may be paramount(=very important). Large data sets might or might not be available. And we might need to use prior physical knowledge with new data-driven insights. We need to really combine physical modeling with what data can tell us. The computational paradigm change over centuries: The experiment based model such as Newton’s Laws of Motion, we just observe carefully and distill the pricinple from thousands of experiments. The theory based model. It describe the physical world with a great deal of predictive power, accuary, and generalizability. The computational modeling and simulation. Based on the ideas that we use the computer to help us broaden the theory based model. The data-driven model. Using the machine learning method which gives us powerful ways of rebuilding models together with making predictions. Module 2：常微分方程 they are equations that describe how things vary in time. they are equation that describe how certain things vary in space. they can be understood as a very deep limit of a recurrent neural network. … 常微分方程的一般形式是 $$ \\frac{du}{dt} = f(u,t) $$ 其中 u 代表状态向量(state vector) 而 t 代表时间。 计算机求解常微分方程 补充一下泰勒展开: 当函数 $f(x)$ 在点 $x_0$ 处可导时，在点 $x_0$ 的邻域内恒有: $$ f(x)=f(x_0)+f’(x_0)\\frac{(x-x_0)1}{1!}+f’'(x_0)\\frac{(x-x_0)2}{2!}+…+f{(n)}(x_0)\\frac{(x-x_0)n}{n!} $$ 一个很好的讲解(3bBlue1Brown) 如果我们从本质来看，可以更好的理解泰勒展开 如上图，我们绘制了一个函数 $f(x)$ 的导数的图像，在这个 $\\frac{df}{dx}$ 图像中, $f(x)$ 的值可以用 $x$ 和这个曲线围成的面积来计算。我们要求的 $f(x)$ 由三个部分组成： $f(a)$ 矩形 近似面积三角形 矩形的面积很简单，为长乘宽 $(x-a)\\frac{df}{dx}(a)$, 我们取的三角形为图中 $a$ 点导数与 $x$ 构成的区域, 那么三角形的面积就是 $$ S = 0.5h(x-a) = 0.5f’'(a)(x-a)(x-a) = \\frac{1}{2}f’'(a)(x-a)^2 $$ 这就是一个二阶的泰勒展开式，如果我们借助3阶甚至更高阶导数来进一步求面积，就会使结果更加的精确，就有了上面的泰勒展开式的形式。 显式欧拉法(Forward-Euler) 显示欧拉法的核心是用 $\\frac{f(x_{n+1})-f(x_n)}{x_{n+1}-x_n}$ 来代替 $f’(x_n)$, 这样在一阶泰勒展开式就可以用我们已知的量来计算未知的 $f(x_n)$ 的值。为了保证计算更加的精确，同时我们将从 $x_n$ 到 $x_{n+1}$ 分成若干个 $\\Delta t$ , 我们通过步步迭代来求得最终的估计值。迭代的函数如下: $$ u_{k+1} = u_k + \\Delta t f(u_k, t_k) \\ u(t_0)=u_0=f(x_0) \\ u(t_n)=f(x_n) $$ 其中 $u_k$ 为我们的估计值，而 $t_k$ 就是当前累计迭代的 $t$ 值，由于我们忽略掉了泰勒展开二阶以后的所有量，所以我们的这个方法只有一阶的精度。 隐式欧拉法(Backward-Euler) 和显示欧拉大部分相同，但有些微不同。不同就在于隐式欧拉法选择用 $\\frac{f(x_{n+1})-f(x_n)}{x_{n+1}-x_n}$ 代替 $f’(x_{n+1})$, 这样如果对 $f(x_{n+1})$ 在 $x_n$ 处展开，就能得到一个包含未知数的方程的递推公式。 $$ u_{k+1}=u_k+\\Delta t f(u_{k+1}, t_{k+1}) \\ u(t_0)=u_0=f(x_0) \\ u(t_n)=f(x_n) $$ 隐式欧拉也等价于找上述方程的解，如果这个解有解，那么自然近似值也有解，即隐式欧拉可以更加好的确保稳定性，这对于考察一些系统的长期行为有帮助（我们会在后面的代码中说明这一点） 龙格库塔法(Runge-Kutta) 龙格库塔方法是一种高阶的方法，注意这里的高阶并不意味着任何时候它更加精确，只是它在我们减小步长的时候更误差会降低的更小。实际上，以四阶龙格库塔法为例，当步长选的比较大的时候，它的误差甚至比显式欧拉法还大。（我们会在后面的代码中观察到这一现象） 下面介绍 RK4（4阶龙格库塔）方法，迭代公式如下: $$ t_{k+\\frac{1}{2}}=t_k+\\frac{\\Delta t}{2}; t_{k+1}=t_k+\\Delta t \\ S_1=f(u_k, t_k) \\ S_2=f(u_k+\\frac{\\Delta t}{2}S_1, t_{k+\\frac{1}{2}}) \\ S_3=f(u_k+\\frac{\\Delta t}{2}S_2, t_{k+\\frac{1}{2}}) \\ S_4=f(u_k+\\Delta t S_3, t_{k+1}) \\ u_{k+1}=u_k+\\frac{\\Delta t}{6}(S_1+2S_2+3S_3+S_4) $$ 以4阶龙格库塔方法为例，当我们减半$dt$，误差的值将会变为原来的 1/16，同样的低阶方法（如显示欧拉）只能将误差变为原来的 1/2。 代码 多数无益，我们用几个例子来比较一下这些方法 FE vs BE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 显式欧拉和隐式欧拉的对比import mathimport matplotlib.pyplot as pltimport numpy as npllam = 1u0 = 3t_final = 3 * math.pidt = 1e-1def dudt(t, u): return -llam * (u - math.cos(t)) - math.sin(t)def tf(t): return (u0 - 1) * math.exp(-llam * t) + math.cos(t)def forward_euler(f, u0, dt, t_final): us = [u0] u = u0 t = 0 for i in range(0, int(t_final/dt)): u = u + dt * f(t, u) us.append(u) t += dt return usdef backward_euler(f, u0, dt, t_final, lam): # newton nonlinear solver function def newton(t, u, f, dt, lam): uu = u g = lambda x: ((x - u) / dt - f(t, x)) j = lambda x: 1 / dt + lam for _ in range(1, 100): u_next = uu - g(uu) / j(uu) uu = u_next if abs(g(u_next)) &lt;= 1e-14: break return uu us = [u0] u = u0 t = 0 for i in range(0, int(t_final/dt)): u = newton(t+dt, u, f, dt, lam) us.append(u) t += dt return ust_true = np.linspace(0, t_final, 1000)u_true = [tf(t) for t in t_true]plt.plot(t_true, u_true, 'b', label=&quot;True Function&quot;)t = [i*dt for i in range(0, int(t_final/dt)+1)]uFE = forward_euler(dudt, u0, dt, t_final)uBE = backward_euler(dudt, u0, dt, t_final, llam)err_FE = np.mean([abs(uFE[i] - u_true[i]) for i in range(len(uFE))])err_BE = np.mean([abs(uBE[i] - u_true[i]) for i in range(len(uFE))])print(&quot;Error of Forward Euler: &quot;, err_FE)print(&quot;Error of Backward Euler: &quot;, err_BE)plt.plot(t, uFE, &quot;r-&quot;, label=&quot;Forward Euler&quot;)plt.plot(t, uBE, &quot;g-&quot;, label=&quot;Backward Euler&quot;)plt.legend()plt.savefig(&quot;./fe_be.png&quot;)plt.show() 我们前面提到了一般来说，隐式欧拉更加的精确并且稳定（但有例外，尤其是原函数是线性函数的时候，显式欧拉更加精确）。什么是稳定性呢，就是当函数变化的时候，我们的估值计算误差不会发生很大的浮动。 上面的代码对 cos 函数做了一个小小的修改，以便于稳定性的比较，当 llam 很小的时候（如代码中），我们看到如下图： 当我们将 llam 调到 100 的时候，就会发现图像变成了下面的样子： 观察误差 Error of Forward Euler: 1.183439944385943e+88; Error of Backward Euler: 0.9107412532059388 明显，显式欧拉法的不稳定性弊端就凸显出来了。 计算隐式欧拉法的根的时候采用的牛顿法估计根，方法的描述如下图（懒得打了网上找了张图） FE vs RK4 RK4 也并非一直都比 FE 更加的精确，看下面的这个例子： 我们设计下面一个 ODE： $$ \\frac{du(t)}{dt} = -\\lambda u(t); u(0)=1 $$ 令$ u(t)=e^{-\\lambda t} $, ODE 公式如下，当我们放大参数$\\lambda$就可以比较 FE 和 RK4 方法的误差之处，有了真实函数方便我们计算误差，码来 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import mathimport matplotlib.pyplot as pltcoff = 100 # 1 10 100 尝试变化u0 = 1t_final = 1fe_error = []rk4_error = []def f(t, u): return -coff * udef true_f(u): return u0 * math.exp(-coff*u)def forward_euler(f, u0, dt, t_final): t = 0 u = u0 while t &lt; t_final: u = u + dt * f(t, u) t = t + dt return udef rk4(f, u0, dt, t_final): t = 0 u = u0 while t &lt; t_final: t_half = t + 0.5 * dt t_next = t + dt k1 = dt * f(t, u) u1 = u + 0.5 * k1 k2 = dt * f(t_half, u1) u2 = u + 0.5 * k2 k3 = dt * f(t_half, u2) u3 = u + k3 k4 = dt * f(t_next, u3) u = u + (1/6) * (k1 + 2 * (k2 + k3) + k4) # 更新 t t = t_next return udt_vec = [1e-4, 2e-4, 1e-3, 2e-3, 1e-2, 2e-2, 1e-1]for i in range(0, len(dt_vec)): dt = dt_vec[i] fe_result = forward_euler(f, u0, dt, t_final) rk_result = rk4(f, u0, dt, t_final) fe_error.append(abs(true_f(t_final) - fe_result)) rk4_error.append(abs(true_f(t_final) - rk_result))# 绘图plt.loglog(dt_vec, fe_error, &quot;r-&quot;, label=&quot;Forward Euler Error&quot;)plt.loglog(dt_vec, rk4_error, &quot;b&quot;, label=&quot;RK4 Error&quot;)plt.xlabel(&quot;dt&quot;)# y 轴设置反向# ax = plt.gca()# ax.invert_yaxis()plt.ylabel(&quot;error&quot;)plt.legend()plt.savefig(&quot;fe_rk.png&quot;)plt.show() 当我们取 $\\lambda=10$ 时 当我们取 $\\lambda=100$ 时 我们可以明显的感受到，并非高阶方法就能带来更小的误差，高阶只代表随着计算迭代次数增加，误差收敛的快。但这同时也要求有一个很好的 $dt$ 的选择。通常在对精度要求不高的计算中，我们都可以选择 FE 来解决。 (ps: 实际运算的时候 matlab 和 python 结果有些不同，matlab 更加精确一些，图像看起来也更好看。但图像变换的趋势和结论是一样的)","link":"/2021/01/28/ode/"},{"title":"mini-os-2","text":"这是第四章的补充知识 尚未完成啊啊啊 GNU C 内嵌汇编语言 __asm__ 关键字：用于声明这行代码是一个内嵌汇编的表达式 __volatile__ 关键字：其作用是告诉编译器此行代码不能被编译器优化，编译时保持代码原状。否则经过编译器优化后，汇编语句很可能被修改以至于不能达到预期的效果。 内嵌汇编表达式 GNU C 语言的内嵌汇编表达式由四个部分组成，它们之间使用 “:” 号分隔，其完整的格式为：指令部分:输出部分:输入部分:损坏部分 指令部分 汇编代码本身，其书写格式与 AT&amp;T 汇编语言程序的格式基本相同，但有些微变化： 当指令表达式中存在多条汇编代码的时候，可以全部书写在一对双引号中；亦可将汇编代码放在多对双引号中。如果将所有指令编写放在同一双引号中，那么相邻两条指令之间必须使用分号（;）或者换行符（\\n）分隔，如果使用了换行符那么通常还会跟一个制表符（\\t）。当汇编代码引用寄存器时，必须在寄存器名前再加上一个 % 符，以表示对寄存器的引用，例如代码 &quot;movl $0x10, %%eax&quot; 输出部分 记录指令的部分的输出信息，其格式为：“输出操作约束”(输出表达式),输出操作约束&quot;(输出表达式), …。格式中的输出操作约束和输出表达式成对出现，每部分之间用逗号（,）分割。 输出表达式部分主要负责保存指令部分的执行结果，通常情况下输出表达式是一个变量。 双引号内的部分，被称为输出操作约束，输出约束必须用等号和加号修饰，等号表示这是一个纯粹的输出的标识，加号表示既用于输出也用于输入。不论加号还是等号，都只能用在输出部分，不能用在输入部分。 输入部分 记录指令部分的输入信息，其格式 “输出操作约束”(输出表达式),输出操作约束&quot;(输出表达式), …。同样成对出现，但输入操作约束中不允许使用等号和加号，因此输入部分都是只读。 损坏部分 描述了在指令部分执行的过程中，将被修改的寄存器，内存空间或标志寄存器，并且这些修改部分并未在输出部分和输入部分出现过，格式为 “损坏描述”, “损坏描述”,…，如果要声明多个寄存器，则需要逗号隔开。","link":"/2020/11/29/mini-os-2/"},{"title":"new-year-2020","text":"2019 年终总结? 仍是菜鸡一个 2019 的好多 flag 都倒了_(:з」∠)_ 大二一学期越来越发现自己菜的真实 学习了计算机系统的一些基础知识，对编译，链接等的学习仍是很浅，目前也就做了 CSAPP 的 bomblab (炸弹实验)， buflab (缓冲区溢出攻击实验)， datalab 学习了java，一知半解，期中项目和期末项目遗留了一堆 bug (项目时间太紧了) 初次体验打算法比赛，感觉挺有意思 作为爱特站长为社团做出了贡献和作为程序部的负责人带出了 5 个新生(还挺好? 教学互长) 体验了一次校内项目(算是外包?)，被甲方各种迷惑行为搞到心态爆炸(结项改UI，最终还不然阶段性部署???) 仍要好好努力 感觉自己的数学还是超级菜，以后要好好学习数学，离散，概率，线代这都是基础科目，要学扎实 即将尝试第一次打美赛，要好好准备，最终目标是国赛 入手的《程序员的自我修养》才看了3章就因为期中复习断了，之后各种项目也没再看，明明立的 flag 是秋季学期看起码一半 python web 一点都没看，算了… 2020 再看 要开始学习算法了，配合我们的专业课和建模一起，争取大二下 CSP 拿 300+ (先定个小目标) 寒假不要浪了 博客严重拖更，我发现一旦懒下来就会越更越慢，所以寒假惯例至少 2-3 天一更 要给新生们准备下学期的讲课内容，希望自己定一些更好的，同时借此机会自己再深入去学习这些东西 努力去看英文的论文，课本，英语也不要放过 期末冲冲冲 个人感觉好像没有大一收获的多，也不知道自己这一年都忙了什么，唉","link":"/2020/01/01/new-year-2020/"},{"title":"aix","text":"2021/3/9 补充了数学层面的牛顿公式理解和在求解最小二乘问题中的应用 Optimization 一个优化问题包含三个部分： 优化的参数 损失函数 约束（可选） 优化问题实际上就是寻找参数来使得在约束的范围内损失函数最小。 LEAST SQUARES PROBLEMS 最小二乘问题是很经典的优化问题。 考虑这样一个线性方程组： $$ Mx=b $$ 我们将解一个线性方程组变化为一个无约束的最小值问题： $$ x^* = arg \\ min \\left | Mx-b \\right | _2^2 $$ 这就是一个线性的最小二乘问题。虽然线性方程组仅在某些条件下具有解决方案，如条件不能约束过度，但最小值问题在过度约束下依旧是有解的，并且可以直接计算等式来获得： $$ x^* = (M ^ \\top M)^{-1} M^ \\top b $$ 我们通常记 $(M^ \\top M)^{-1} M^\\top$ Moore-Penrose 逆矩阵，也通常将其简记为 $M^\\dagger$ （M dagger 还真就是匕首） Gradient Descent 迭代方法包括 3 个主要部分： 解的初始猜想 每一步的迭代方法 收敛的标准 梯度下降是一种求最优解的迭代方法，它设置了初始猜想值为$x_0$，每一步都向下降最快的方向前进一步（负梯度），当当前的 x 的梯度为 0 或者接近 0 时，算法停止。 初始值$k=0$，假设初始最优解为$x_0$ 更新 x: $$ x_{k+1}=x_k- \\alpha \\nabla J(x_k) $$ if $\\left |\\nabla J(x_{k+1}) \\right | &lt; \\tau $ 停止，$x_{k+1}$为最优解，否则令$k=k+1$，重复第二步。 其中，$J(x)$ 是损失函数，$\\nabla J(x_k)$是它的梯度，一般来说，梯度可以定义为一个函数的全部偏导数构成的向量（这一点与偏导数与方向导数不同，两者都为标量）。$\\alpha$ 是步长，$\\tau$ 是一个定义的允许的误差值。 梯度下降得到的是局部最优解，一个局部最小值（local minimum），而不一定是全局的最小值（global minimum） 梯度下降的性能和表现取决于它的步长，如果步长太大，会导致无法收敛；而小的步长会增加迭代的次数，增加开销。 梯度下降需要我们能够写出来损失函数和计算损失函数的梯度，有的时候我们无法找到一个合适的损失函数去评估或者无法计算其梯度。 Newton’s Method 概念 牛顿法同样也是一种迭代方法。它和梯度下降很相似。即我们在寻找$\\nabla J(x)=0$的时候采用 Newton-Raphson 寻根法。 初始值$k=0$，假设初始最优解为$x_0$ 更新 x: $$ x_{k+1}=x_k- \\alpha_k [H(x_k)]^{-1} \\nabla J(x_k) $$ if $\\left |\\nabla J(x_{k+1}) \\right | &lt; \\tau $ 停止，$x_{k+1}$为最优解，否则令$k=k+1$，重复第二步。 其中，$J(x)$ 是损失函数，$\\nabla J(x_k)$是它的梯度，$\\alpha$ 是步长，$\\tau$ 是一个定义的允许的误差值。$H(x_k)$ 是 海森矩阵（Hessian Matrix），是一个多元函数的二阶偏导数构成的方阵，描述了函数的局部曲率。 用公式来描写的话就像下面这样： $$ \\nabla^2 J(x)=H(x)=\\begin{bmatrix} \\frac{\\partial^2 J}{\\partial x_1^2} &amp; \\cdots &amp; \\frac{\\partial^2 J}{\\partial x_1 \\partial x_n} \\ \\frac{\\partial^2 J}{\\partial x_1 \\partial x_2} &amp; \\cdots &amp; \\frac{\\partial^2 J}{\\partial x_2 \\partial x_n} \\ \\vdots &amp; \\vdots &amp; \\vdots \\ \\frac{\\partial^2 J}{\\partial x_1 \\partial x_n} &amp; \\cdots &amp; \\frac{\\partial^2 J}{\\partial x_n^2} \\ \\end{bmatrix} $$ 牛顿方法是一个二阶方法，它的每次计算都要计算二阶偏导。 同样由于是迭代法，依旧只能找到局部最优解，也同样很依赖 $\\alpha_j$ 的选择。但总体来看，牛顿方法可以用更少次数的迭代就使得结果收敛，但每一步的计算量很大。 沿用牛顿的方法的思路，有另外一种优化算法被称作拟牛顿法（Quasi-Newton Method），但这些方法采用梯度信息来近似海森矩阵，所以比传统的牛顿法更加有效。 数学层面理解 牛顿公式： $$ x_{k+1} = x_k - \\frac{f(x_k)}{f’(x_k)} $$ 若要求原函数的极小值，即在$f’(x)$上寻找根，这样就可以应用牛顿方法： $$ x_{k+1} = x_k - \\frac{f{(1)}(x_k)}{f{(2)}(x_k)} $$ 在高维空间，将一阶导换成梯度，二阶导换成海森矩阵就得到了前面的式子。 例子：两者的比较 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 博客优化问题部分对应的例子: 梯度下降法和牛顿方法的比较# 部分代码参考: https://zhuanlan.zhihu.com/p/92359902# f(x) = x^T * Q * x# Q = [[q1, 0], [0, q2]]import numpy as npimport matplotlib.pyplot as pltq1 = 1q2 = 10Q = [ [q1, 0], [0, q2]]Q = np.array(Q)def f(x): return (x.T.dot(Q)).dot(x)def g(x): return (2 * x.T.dot(Q)).Tdef H(x): return 2 * Qalpha = 0.1 # 步长x0 = np.array([10, 1])steps = 30gd_results = []newton_results = []def gradient_descent(f_gd, x, lr, max_steps, precision=0.0001, decay=0.005): # 学习率的变化公式用: lr = lr/(1+decay*i) current_x = x gd_results.append(current_x) for i in range(max_steps): lr = lr / (1 + decay * i) # 调整步长 gd = f_gd(current_x) if np.linalg.norm(gd) &lt; precision: break else: current_x = current_x - lr * gd gd_results.append(current_x) return current_xdef newtons_method(f_gd, f_H, lr, x, max_steps, precision=0.0001, decay=0.005): newton_results.append(x) hessian = f_H(x) hessian_reverse = np.linalg.inv(hessian) H_G = np.matmul(hessian_reverse, f_gd(x)) current_x = x - lr * H_G newton_results.append(current_x) for i in range(1, max_steps): lr = lr / (1 + decay * i) gd = f_gd(current_x) if np.linalg.norm(gd) &lt; precision: break else: hessian_reverse = np.linalg.inv(hessian) H_G = np.matmul(hessian_reverse, gd) current_x = current_x - lr * H_G newton_results.append(current_x) return current_xprint(gradient_descent(g, x0, alpha, steps))print(newtons_method(g, H, alpha, x0, steps))gd_results = np.array(gd_results)newton_results = np.array(newton_results)# 生成网格图X1, X2 = np.meshgrid(np.linspace(-10, 10, 100), np.linspace(-10, 10, 100))obj_results = np.zeros((100, 100))for i in range(100): for j in range(100): obj_results[i][j] = f(np.array(([X1[i][j], X2[i][j]])))# cmap可以调用cm颜色库中的填充颜色pic_color = plt.contourf(X1, X2, obj_results, 20, cmap=&quot;Reds&quot;)# 绘制等高线pic = plt.contour(X1, X2, obj_results, 20, linewidths=1.5)# plt.clabel(pic)plt.colorbar(pic_color) # ticks 参数可以省略plt.plot(list(gd_results[:, 0]), list(gd_results[:, 1]), &quot;-or&quot;, linewidth=2, label=&quot;Gradient Descent&quot;)plt.plot(list(newton_results[:, 0]), list(newton_results[:, 1]), &quot;-ob&quot;, linewidth=2, label=&quot;Newton's Method&quot;)plt.xlabel(&quot;x1&quot;)plt.ylabel(&quot;x2&quot;)plt.legend()# plt.savefig(&quot;minimum_searching.png&quot;)plt.savefig(&quot;minimum_searching2.png&quot;)plt.show() 在没有步长衰减的情况下，得到的图像如下： 牛顿法显然更好，完全避免了左右横跳，因为牛顿法能看的更远，牛顿法有函数的二阶导数的信息，不仅知道哪一点可以下降的最快，而且还知道从这个点走一步后得到的下一个点的梯度的大小。这就解释了为什么牛顿法会避免&quot;之&quot;字形，因为之字形当前的梯度虽然比较大，但是下一步的梯度不大，而如果顺着&quot;山脊&quot;走，可能当前的梯度没有&quot;之字形&quot;的梯度大，但是下一步可能的梯度会更大一点。 如果加入步长衰减，适当增加最大步数，得到结果如下： 明显的梯度下降方法准确度上升很多，不再是在最小值点左右横跳无法收敛了。但相比之下对牛顿方法没有太大的影响。 Nonlinear Least Squares 概念 假设我们有模型 f，输入 z 和 x 参数。$y = f(z, x) x \\in \\mathbb{R}^n$，这样一个模型既可以是一个线性函数，也可以是一个非线性函数： 如：f 是多项式函数，x 是 f 的系数。 如：z 是初始时刻在一个导热棒上温度的分布情况，y 是最终最大温度值。f 涉及模拟热传导方程来计算 y 值，x 可以被定义为在这个物体上的热扩散率。 我们要对这个函数做参数的优化，为了找到最好的最适合当前数据集的 x，我们先收集在 m 个输入下的 m 个点 $(x_1, y_1), (x_2, y_2), \\cdots, (x_m, y_m)$， 用这些点去寻找最优的 x 对于这个优化问题，损失函数怎么定义？对于每个函数，我们考察预测值和实际值的误差：$r_i(x)=f(z_i, x)-y_i$，把所有的误差相加得到我们的误差函数（也就是优化的目标函数） $$ J(x) = \\sum_{i=1}^{m} r_i(x)^2 = \\sum_{i=1}^{m} (f(z_i, x)-y_i)^2 $$ 这个问题被称为非线性最小二乘问题，由于目标函数是一个非线性函数。解这个问题当然还是可以使用迭代方法，相当于求解如下优化问题： $$ \\min_{x \\in \\mathbb{R}^d} \\sum_{i=1}^{m}(f(z_i, x)-y_i)^2 $$ 这个函数也被称为经验风险最小化函数。对于梯度下降方法，我们假设初始值是 x_0，步长为 $\\alpha$，根据我们前面学的迭代公式： $$ x_{n+1}=x_n-\\alpha \\nabla J(x_n) $$ 上面目标函数的梯度公式为： $$ \\nabla J(x_n) = \\sum_{i=1}^{m}2(f(z_i, x_n)-y_i)\\nabla_x f(z_i, x_n) $$ 其中 $\\nabla_x f(z_i, x_n)$ 是 f 在 x 方向上的梯度： $$ \\nabla_x f(z_i, x_n)=\\left [ \\frac{\\partial f}{\\partial x_i}(z_i, x_n), \\cdots , \\frac{\\partial f}{\\partial x_d}(z_i, x_n) \\right ]^T $$ 为什么我们不直接对原函数采用梯度下降等方法来寻找最小值？ 因为$\\nabla f(x)$ 并不能确保我们找到了局部最小值，梯度为0既可能是最小值，也有可能是最大值，我们无法根据一阶倒数或者偏导来确定。 Applied in Least-Squares? Gradient Descent 如果采用梯度下降方法去优化最小二乘问题的目标函数：$f(x) = \\left | Mx-b \\right | _2^2$ 代入梯度下降公式，得到的递推式如下： $$ x_{k+1}=x_k- 2 \\alpha M^T (Mx_k-b) $$ Newton’s Method 如果采用牛顿方法，令$\\alpha = 1$ $$ x_{k+1}=x_k- (\\nabla^2 f(x_k))^{-1} \\nabla f(x_k) $$ 我们前面知道，最小二乘问题的最优解为 $x^* = (M ^ \\top M)^{-1} M^ \\top b$ 又计算得出 $\\nabla f(x_k)=2M^T (Mx_k-b)$，$\\nabla^2 f(x_k)=2M^TM$，代入上式可得： $$ x_{k+1}=x_k-\\frac{1}{2}(M^T M)^{-1} * 2M^T (Mx_k-b) = (M ^ \\top M)^{-1} M^ \\top b $$ 一步到位直接求得极值点。这是从数学推导角度来看的，如果从二阶导方面来理解，牛顿方法包含二阶倒数的近似值来进行迭代计算，而最小二乘问题的目标函数一个二阶的，所以精确的用一步可以找到解。","link":"/2021/03/04/optimization/"},{"title":"Pandas 科学计算入门","text":"Pandas 入门 基本操作 Pandas 基于 NumPy 开发，提供了大量快捷便利的数据处理方法，由 AQR Capital Management 于 2008 年开发，2009 年开源发布， 是支撑 Python 科学计算的强大工具 12345678910111213141516import pandas as pdimport numpy as npdates = pd.date_range(&quot;20200101&quot;, periods=6) # 生成6个数据df = pd.DataFrame(np.random.rand(6, 4), index=dates, columns=['A', 'B', 'C', 'D'])# 获取数据print(&quot;获取df数据:\\n{}&quot;.format(df))# 观察数据print(&quot;获取前两行数据:\\n{}&quot;.format(df.head(2)))print(&quot;获取后两行数据:\\n{}&quot;.format(df.tail(2)))# 查看属性和原始 ndarrayprint(&quot;获取数据结构中的索引:\\n{}&quot;.format(df.index))print(&quot;获取维度基本属性:\\n{}&quot;.format(df.shape))print(&quot;获取数据结构中的实际数据:\\n{}&quot;.format(df.values))print(&quot;获取数据结构中A列的实际数据:\\n{}&quot;.format(df[['A']].values))# 描述统计量print(&quot;描述统计量:\\n{}&quot;.format(df.describe())) # 包含count, mean, max, min 等基础的统计信息 Pandas 数据结构 数据结构 维度 轴标签 Series 一维 index（唯一的轴） DataFrame 二维 index（行）和columns（列） Panel 三维 items、major_axis 和 minor_axis Series 最基础的 Pandas 对象，它定义了 NumPy 的 ndarray 对象的接口 __arrat__(), 因此可以用 NumPy 的数组处理函数直接处理 Series 对象。 123456789101112import pandas as pdimport numpy as npdata = [0, 1, 2]index = ['a', 'b', 'c']s = pd.Series(data, index=index)s1 = pd.Series(data)print(&quot;指定索引\\n{}&quot;.format(s))print(&quot;不指定索引\\n{}&quot;.format(s1))data1 = {'a': 1, 'b': 2, 'c': 3}s2 = pd.Series(data=data1)print(&quot;指定字典作为data\\n{}&quot;.format(s2)) 无索引时默认为0,1,2… DataFrame DataFrame 是表格型的数据结构，它含一组有序的列，每列可以是不同的值类型（数值，字符串，布尔值） 1234567891011121314import numpy as npimport pandas as pddata = np.array([[1, 2, 3], [0, 1, 2]])index = ['a', 'b']columns = [&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;]df1 = pd.DataFrame(data, columns=columns, index=index)print(&quot;df1=\\n{}&quot;.format(df1))df2 = pd.DataFrame(data)print(&quot;无索引情况 DataFrame, df2=\\n{}&quot;.format(df2))data1 = {&quot;Bob&quot;: ['M', 51, &quot;worker&quot;, 7000], &quot;Jane&quot;: ['F', 28, &quot;manager&quot;, 10000], &quot;Alice&quot;: ['F', 19, &quot;student&quot;, 0]}index = [&quot;gender&quot;, &quot;age&quot;, &quot;profession&quot;, &quot;incomes&quot;]df3 = pd.DataFrame(data=data1, index=index)print(&quot;传入data为字典, df3=\\n{}&quot;.format(df3)) 没有指定索引时行列名为索引的数值，看着怪怪的 当然也可以读取本地数据文件来建立 Series 和 DataFrame 函数 说明 read_csv() 从 csv 格式的文本文件读取数据 read_execl() 从 Excel 文件读取数据 read_sql() 从 SQL 数据库的查询结果载入数据 read_pickle() 读入 pickle() 序列化后的数据 Pandas 数据的选取和清洗 用中括号[]选取行列 可以使用单个标签如 ‘a’ 或者标签的列表或数组如 [‘a’, ‘b’, ‘c’]来索引 具有标签’a’: ‘f’ 的切片对象，但与 Python 的 切片相反，包括开始和停止。 df['A'] 会返回 Series 对象，等效于 df.A ， df[['A']] 返回的是 DataFrame df.loc &amp; df.iloc &amp; df.ix 标签定位 用逗号分隔开的左边的是行索引，右边的是列索引 ‘:’ 表示全部 loc 可以使用行列的索引（字母）来获取值而 iloc 使用的是整型的索引 ix 既可以使用字母来索引也可以用整型的索引 df.at &amp; df.iat 精确定位，使用方法如 df.at['a', 'A'], df.iat[0, 0] 数据清洗的基础操作 我们获取的数据有些时候并不完整或者包含错误，这就需要我们批量的统一处理来便于我们的后续计算 data_clean.py1234567891011121314151617181920212223242526272829303132333435363738import pandas as pdimport numpy as npdf = pd.DataFrame(np.random.randint(1, 10, [5, 3]), index=['a', 'c', 'e', 'f', 'h'], columns=[&quot;one&quot;, &quot;two&quot;, &quot;three&quot;])df.loc['a', &quot;one&quot;] = np.nandf.loc['c', &quot;two&quot;] = -99df.loc['c', &quot;three&quot;] = -99df.loc['a', &quot;two&quot;] = -100df[&quot;four&quot;] = &quot;bar&quot;df[&quot;five&quot;] = df[&quot;one&quot;] &gt; 0df2 = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])print(df2)# 丢弃缺失的值print(&quot;删除缺失的值所在的行(axis=0)或列(axis=1)\\n{}&quot;.format(df2.dropna(axis=0))) # axis=0为默认可以不指定print(&quot;一行中全部为NaN才丢弃\\n{}&quot;.format(df2.dropna(how='all')))# 指定条件移除print(&quot;移除所有字段中有属性小于4的行\\n{}&quot;.format(df2.dropna(thresh=4)))print(&quot;移除指定列为空的所在行的数据\\n{}&quot;.format(df2.dropna(subset=[&quot;one&quot;, &quot;five&quot;])))# 缺失值填充print(&quot;缺失值用0填充\\n{}&quot;.format(df2.fillna(0)))print(&quot;指定列空值赋值\\n{}&quot;.format(df2.fillna({&quot;one&quot;: 0, &quot;two&quot;: 1})))print(&quot;向前填充值\\n{}&quot;.format(df2.fillna(method=&quot;ffill&quot;))) # 等效于 fill()print(&quot;向后填充值\\n{}&quot;.format(df2.fillna(method=&quot;backfill&quot;))) # 等效于 bfill()print(&quot;以列均值来替换\\n{}&quot;.format(df2.fillna(df2.mean()[&quot;one&quot;: &quot;three&quot;]))) #从 one 到 three 用均值替代 nan# 替换值print(&quot;替换所有的行列的某个相同的值\\n{}&quot;.format(df2.replace(-99, 99)))print(&quot;指定单列替换\\n{}&quot;.format(df2[[&quot;two&quot;]].replace(-99, 99))) # 里面多一层[]是让返回 DataFrame 这样才可以调用其函数df2[[&quot;two&quot;]] = df2[[&quot;two&quot;]].replace(-99, 99)print(&quot;替换后\\n{}&quot;.format(df2))# 对重复值的处理print(&quot;判断重复的值:只有每行所有列的值一样的时候返回True\\n{}&quot;.format(df2.duplicated()))print(&quot;针对'one'列除第一次出现外之后的进行判断\\n{}&quot;.format(df2.duplicated(&quot;one&quot;, keep=&quot;first&quot;)))print(&quot;针对'one'列除第一次出现外删除重复的\\n{}&quot;.format(df2.drop_duplicates(&quot;one&quot;, keep=&quot;first&quot;)))print(&quot;针对'one'列删除最后一次出现的重复项\\n{}&quot;.format(df2.drop_duplicates(&quot;one&quot;, keep=&quot;last&quot;)))print(&quot;针对'one'列删除全部的重复项\\n{}&quot;.format(df2.drop_duplicates(&quot;one&quot;, keep=False)))","link":"/2020/01/26/pandas-base/"},{"title":"aix","text":"偏微分方程 学的时候记得笔记都是英语的加上又懒得翻译就只好拖到了现在 General 偏微分方程（PDE, partial differential equation）的解是一个关于时间和空间的方程 $u(x, t)$，我们用 u 代表在特定时间和空间的函数值。 在常微分方程的数值解中，我们是通过将 0-T 划分为若干个 $\\Delta t$，通过计算每个 $\\Delta t$ 位置的值来计算 $u(t)$。在偏微分方程中，我们构造下面的图形（mesh）来辅助我们的计算： 我们用 mesh 网格图上的 u 值来近似计算偏微分的值，我们观察临近的矩形，他们构成偏导的近似值。这样我们将偏微分方程的空间离散化，转换为常微分方程的系统。 空间离散化的方案(spatial discretization schemes)有： 有限元法（Finite Element Methods） 有限差分法（Finite Difference Methods） 有限体积法（Finite Volume Methods） Finite Difference Formulas 我们以一个简单的偏微分方程为例： $$ \\frac{\\partial u}{\\partial t} = k \\frac{\\partial^2 u}{\\partial x^2} $$ k 代表导热系数。 假设网格在空间上的距离为 h，那么我们有: 一阶偏导的前向差分(Forward difference for first spatial derivative) $$ \\frac{\\partial u}{\\partial x} \\Big|{x_i} \\approx \\frac{u(x{i+1}, t)-u(x_i, t)}{h} $$ 一阶偏导的向后差分(Backward difference for first spatial derivative) $$ \\frac{\\partial u}{\\partial x} \\Big|{x_i} \\approx \\frac{u(x{i}, t)-u(x_{i-1}, t)}{h} $$ 一阶偏导的中心差分(Central difference for first spatial derivative) $$ \\frac{\\partial u}{\\partial x} \\Big|{x_i} \\approx \\frac{u(x{i+1}, t)-u(x_{i-1}, t)}{2h} $$ 二阶偏导的中心差分(Central difference for second spatial derivative) $$ \\frac{\\partial^2 u}{\\partial x^2} \\Big|{x_i} \\approx \\frac{\\frac{u(x{i+1}, t)-u(x_{i}, t)}{h}-\\frac{u(x_{i}, t)-u(x_{i-1}, t)}{h}}{h} \\ \\quad \\quad \\quad \\quad \\approx \\frac{u(x_{i+1}, t)-2u(x_{i}, t)+u(x_{i-1}, t)}{h^2} $$ Discretization Stencil 我们在网格来近似计算空间函数$u(x, t)$偏导（前向差分，中心差分等等）的这种方法叫做stencil，如果用空间内更多更远的点来近似一个点的偏导值，那么一般情况下误差就会变的更小。但对于有些情况却不同，补充的来说，用更多的点近似来减少误差只对光滑的函数有效，对于那些不连续的函数，相邻点之间的关系很小，使用太多的点反而会影响准确度。 我们用 stencils size 来描述有多少个点被用于近似偏导值。我们的误差和使用的近似方法的阶数成正比关系。我们假设误差为 e，h 为 网格缩小比例，q 是使用方法的阶数，我们有这样的关系：$e \\sim h^q$ 需要注意：减小空间网格的大小的同时也要减小每一步的时间$\\Delta t$来确保稳定性。 Solving PDE 解决 PDE 问题就是解决一个初始边界值问题（initial boundary value problem）：$u(x, t)$ 在给定的初始条件和边界条件下是如何变化的。 我们仍以热传导方程$\\frac{\\partial u}{\\partial t} = k \\frac{\\partial^2 u}{\\partial x^2}$为例。在网格内部的点上，我们可以将求偏导转换为计算一组离散化的点，运用我们上面的二阶中心差分的近似计算： $$ \\frac{\\partial u}{\\partial t} \\Big|{x_i} = k \\frac{u(x{i+1}, t)-2u(x_{i}, t)+u(x_{i-1}, t)}{h^2} $$ 我们想象 i 从 0 到 N-1，总共有 N-1 个类似上面的式子，即我们把 t 时间的 x 范围划分为 N-1 块，每一块都可以通过它临近的点来计算。下面把这 N-1 个式子合成在一起： $$ u(t)=\\begin{bmatrix} u(x_1, t)\\ u(x_2, t)\\ \\vdots \\ u(x_{N-1}, t)\\ \\end{bmatrix} $$ 这样上面的方程就可以写成类似下面的形式： $$ \\frac{du}{dt}=Au+f $$ f包含边界条件的信息。A 是一个 $N-1 \\times N-1$ 的系数矩阵，当x=1和x=N-1的时候都无法计算，所以设置行列式为全 0，需要 f 来辅助确定值以保证边界条件： $$ \\frac{k}{h^2} \\begin{bmatrix} &amp;0 &amp;0 &amp;0 &amp;\\cdots &amp;0 &amp;0 \\quad \\ &amp;1 &amp;-2 &amp;1 &amp;\\cdots &amp;0 &amp;0 \\quad \\ &amp;0 &amp;1 &amp;-2 &amp;1 &amp;\\cdots &amp;0 \\quad \\ &amp;\\vdots &amp;\\vdots &amp;\\vdots &amp;\\vdots &amp;\\vdots &amp;0 \\quad \\ &amp;0 &amp;0 &amp;\\cdots &amp;1 &amp;-2 &amp;1 \\quad \\ &amp;0 &amp;0 &amp;0 &amp;\\cdots &amp;0 &amp;0 \\quad \\end{bmatrix} \\hspace{-0.5cm} \\left.\\begin{matrix} &amp; \\ &amp; \\ &amp; \\ &amp; \\end{matrix}\\right} N-1 $$ 这样我们就可以用 ODE 的方法来解决 PDE 问题，比如说我们运用前向欧拉法： $$ \\boldsymbol{u}{n+1}=\\boldsymbol{u}{n}+\\Delta t(A \\boldsymbol{u}^n+f) $$ We discretize the spatial domain into N spaces with N+1 grid points. How many unknown variables are evolved in the resulting system of ODEs? 答案是 N-1，$u_0$ 和 $u_{N+1}$ 都是边界点（已知），这样在网格的内部就只有 N-1 个未知的点。 下面我们考虑计算的误差：PDE 方程的解的精确度分为空间和时间上的。我们取 e 代表误差，$\\Delta t $ 代表每一步选择迭代的时间差(time_step)，h 代表相邻 x 之间的距离，也可以看做网格大小(mesh_size)，那么有关系：$e \\approx (\\Delta t)p+hq$。其中 p 和 q 分别是我们选择的 ODE 方法的阶数和偏导数值解方法的阶数。如我们选择 FE (forward eluer) + 中心差分（Central Difference），那么 p 值为 1，q 值为 2。因为它们分别是 1 阶和 2 阶精确度的方法。如果 h 减小一半，那么误差就会变为四分之一。 需要注意，我们前面也提到了，一个小的 h 需要同时一个更小的 $\\Delta t$，否则求解将会变得不再稳定。怎么理解呢，我们仍用热传导方程来理解：当我们观察更小的一段的变化的时候，不同段直接的交互会更加的频繁，我们需要用更小的时间来确保可以更加精确的捕获这些变化。 Boundary Conditions Dirichlet conditions Dirichlet conditions fix the value of the solution u(x,t) at the boundary. This is like pinning the solution to a certain value at the boundary. 即在边界指定函数的分布形式 Neumann conditions Neumann conditions fix the value, not of the solution, but of its spatial derivative $\\frac{\\partial u}{\\partial x}$ at the boundary. This is like fixing the stresses at the boundary. 在边界指定外法线方向上的导数的数值 Robin conditions Robin conditions fix the value of a linear combination of the solution itself and its partial derivative at the boundary. 可以看做是第1和2条件的组合，要求偏导和函数本身的数值。 Linear System 对于转换为 ODE 的 PDE 问题，我们也可以用一些隐式的方法求解，如隐式欧拉法 $$ u{n+1}=un+\\Delta t (Au^{n+1}+f) $$ 求解这个方法，移项： $$ (1-\\Delta tA)u{n+1}=un+\\Delta tf $$ 它的每一步相当于求解一个线性系统（linear system）（这不就是线性方程组吗），$M \\boldsymbol u=b$ 这么做的好处在于，这样让我们可以使用更大的 $\\Delta t$ 相比较于显式方法（隐式方法的稳定性，参考 ODE 那节） 求解线性系统有很多的现成方法： A 是一般矩阵（general）：高斯消元（Gaussian elimination），$O(N^3)$ A 是三角矩阵（triangular）：Forward substitution/backward substitution，$O(N^2)$ A 是三对角线矩阵（tri-diagonal）：托马斯算法（Thomas algorithm），$O(N)$ Iterative Algorithms for Linear Systems 当线性系统中的 M 是一个很大的矩阵，又不特殊时，用高斯消元太慢了并且太占用空间。这时就需要一个更高效的方法：迭代法再次上线。我们先猜一个初始值 v，通过计算 Mv 和 b 比较，修改 v 来一步步逼近真实解。 可选的迭代方法有很多，如 Krylov Subspace Method（krylov 子空间算法），conjugate gradients（共轭梯度法），GMRes（广义最小残差法）。 学一下共轭梯度法然后补充在这里 Nonlinear Systems 对于如下非线性形式的 ODEs： $$ \\frac{du}{dt}=f(u) $$ 使用隐式欧拉法得到迭代公式： $$ u_{n+1}=u_n+\\Delta tf(u_{n+1}) $$ 求解$u_{n+1}$等同于在这样一个方程中寻找根:$R(u_{n+1})=u_{n+1}-\\Delta tf(u_{n+1})=0$，常用的计算方法有：二分法，牛顿法 Sample 我们考虑污染物在一维空间的传播问题。令 $u(x, t)$ 表示在 t 时间 x 位置处污染物的浓度。u 的变化用对流扩散方程来定义： $$ \\frac{\\partial u}{\\partial t} = k \\frac{\\partial^2 u}{\\partial x^2} + c\\frac{\\partial u}{\\partial x} $$ 扩散速率$k = 5 \\times 10^{-4} m^2/s$，对流速度$ c= 0.5m/s$ 当 $t=0$ 时污染物的分布图像为: 边界条件是第一类边界条件，在边界的时候$u(x，t)$始终等于 0。 我们采用有限差分法来计算污染物在 $[0, 1]$ 区间内随着时间从 0 变到 1 的变化。首先将偏导全部拆分近似为差分的形式： $$ \\frac{\\partial u}{\\partial t} \\Big|{x_i} = \\frac{k}{h^2}u(x{i+1}, t) + \\frac{-2k+ch}{h^2}u(x_i, t) + \\frac{k-ch}{h^2}u(x_{i-1}, t) $$ 然后用上面的方法转化为求 ODE 问题，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import numpy as npimport mathimport matplotlib.pyplot as pltdef u0(x): # 高斯函数 mean = 0.2 sigma = 0.025 return (1/160)*np.exp(-1 * ((x - mean) ** 2) / (2 * (sigma ** 2))) / (math.sqrt(2 * np.pi) * sigma)# init_ux():# xs = np.linspace(0, 1, 1000)# ys = [u0(x) for x in xs]# plt.plot(xs, ys, &quot;b-&quot;)# plt.ylabel(r&quot;$u_0(x)$&quot;)# plt.yticks([round(x, 2) for x in np.linspace(0, 0.1, 10)])# plt.savefig(&quot;init_ux.png&quot;)# plt.show()sample_num = 5nSpace = 600nTime = 1000xs = np.linspace(0, 1, nSpace-1)k = 5e-4c = -0.5dt = 1/nTimeh = 1/nSpaceA = np.zeros((nSpace-1, nSpace-1))u = np.zeros((nSpace-1, 1))for i in range(nSpace-1): u[i][0] = u0(i*h)for i in range(1, nSpace-1-1): A[i][i-1] = k / (h * h) - c / h A[i][i] = (-2 * k) / (h * h) + c / h A[i][i+1] = k / (h * h)# 采用欧拉方法times = 0t = 0u_record = [u.T.tolist()[0]]while t &lt;= 1: u = u + dt * A.dot(u) t += dt times += 1 # 每 200 次迭代记录一次 if times == nTime/sample_num: u_record.append(u.T.tolist()[0]) times = 0# 采用二阶龙格库塔法u = np.zeros((nSpace-1, 1))for i in range(nSpace-1): u[i][0] = u0(i*h)t = 0times = 0while t &lt;= 1: k1 = A.dot(u) k2 = A.dot(u+k1*dt) u = u + 0.5 * dt * (k1 + k2) t += dt times += 1 if times == nTime/sample_num: u_record.append(u.T.tolist()[0]) times = 0# 绘图print(len(u_record))values_fe = [int(i*250/10) for i in range(10)]values_rk2 = [int(i*250/10) for i in range(10)]colors_fe = [&quot;#%02x%02x%02x&quot; % (120, int(g), 200)for g in values_fe]colors_rk2 = [&quot;#%02x%02x%02x&quot; % (200, int(g), 40)for g in values_rk2]for i in range(sample_num): if i == 0: plt.plot(xs, u_record[i], color=&quot;#000080&quot;, linewidth=2, label=&quot;Init u&quot;) elif i == 1: plt.plot(xs, u_record[i], color=colors_fe[i], linewidth=2, label=&quot;FE Method&quot;) else: plt.plot(xs, u_record[i], color=colors_fe[i], linewidth=2)for i in range(sample_num): if i == 0: plt.plot(xs, u_record[sample_num + i], color=colors_rk2[i], linewidth=2, label=&quot;RK2 Method&quot;) else: plt.plot(xs, u_record[sample_num + i], color=colors_rk2[i], linewidth=2)plt.title(&quot;Evolution of u&quot;)plt.xlabel(&quot;x&quot;)plt.ylabel(&quot;u(x, t)&quot;)plt.legend(loc=&quot;best&quot;)plt.savefig(&quot;ux.png&quot;)plt.show() 向后差分 + 显式欧拉 和 向后差分 + 二阶龙格库塔 方法得到的预测结果，颜色深度的变化代表时间的变化，绘制的图形为每隔 200ms 后在 x 上污染物的分布情况。： FE 误差为 8% 左右，如果我们使用 RK2 代替 FE 方法，误差减小到 0.8%。（用的黑盒函数测的误差，暂时还没复现解析解） 可以尝试修改 nSpace 和 nTime 观察效果。当切换方法为向前差分时，很难让结果稳定，对 nSpace 和 nTime 的要求很苛刻。","link":"/2021/03/02/pde/"},{"title":"pre-learn-of-aix-week-1","text":"Introduction This is the pre-learning record of my ai+x blending courses, there will be 5 weeks before the Base SPOC session starts, and each week, we will get a learning material in order to help us get ready for the upcoming study, here we start the first week’s pre-learning. Interviews with AI Leaders There is a link of a video interview with a leader in the field of Machine Learning and AI. Video: Tomaso Poggio Abstarct: Tomaso is a professor at MIT and is the director of the Center for Brains, Minds, and Machines. Cited over 100,000 times, his work has had a profound impact of intelligence, in both biological neural networks and artificial ones. So, what indeed he said in the video? I record one of the most impressive question: how far we can get in creating intelligent systems without understanding the biological or understanding how the human creates intelligence. It is a difficult problem, we are able to fly without using to much our knowledge about how birds fly. it was important I guess to know that you could have things heavier than air being able to fly like birds in the case of intelligence I think that it’s a bit of a bet right now. …… the question is you can ask people do you think we’ll get there without any knowledge about the human brain. Exercise of Python There are exercise designed for we to learn the basics of Python, help us dignose the level of programming ability. The exercise…too easy 12&gt;&gt;&gt;--44 Python Documentation recommands “Think Python: How to Think Like a Computer Scientist” in the mail, I’ll borrow one from the school library. Software we’ll be using the Python 2.6.x, so why not the Python3? Well, in any case, I need to prepare the environment. It is easy for us the create a Python 2.6.x environment using the virtual environment, I’m so familiar with this, so I’d like to explore something interesting otherwise I will have nothing worth to write this blog. About some problems ImportError: cannot import name _remove_dead_weakref I suggest you see the discussion in StackOverFlow pip-python-importerror-cannot-import-name-remove-dead-weakref in short, just click the pythonw.exe in the python2 floder and repair it! About the virtual environment It is a magic to use different kind of type of Python. Thanks to the PATH which tells the Python interpreter which version and where is the Python.exe we use. When we call the Python interpreter or run the python script xxx.py, shell will search the catalog listed in PATH until it found a python object matched for this command. virtualenv is a package for creating and managing the virtual environment of Python, it use tricks to achieve: change the PATH of current running Shell change the runtime path stored in sys.path to have a clear recognition of this, you can use the python -m site in different environment, you will found that almost everything in sys.path replaced by the path in the venv except the stardard libraries. How we find the package in the “.py” file? The basis repo provide us a package “site” 123import sitesite.getsitepackages()# your site-package path and base of python path","link":"/2020/12/18/pre-learn-of-aix-1/"},{"title":"pre-learn-of-aix-week-2&#x2F;3","text":"Content In this blog, I’ll combine pre learning 2 and 3. Interviews with AI Leaders // watching… Learning Python Complex Python actually has complex numbers as a primitive data type. There are two ways to make a complex number: 1234567891011121314a = complex(1, 2)print type(a)a = 1+2jprint type(a)print a.imagprint a.real&quot;&quot;&quot;result: &lt;type 'complex'&gt;&lt;type 'complex'&gt;2.01.0&quot;&quot;&quot; ps: the textbook mentioned something interesting: You’re probably used to using i for (-1)0.5. Just to confuse you, we’re going to use j instead. Why? Because to an electrical engineer, i stands for current, and there’s no arguing Funtional Style What is Funtional Style? In the prelearning material, it is defined as: In the functional programming style, one tries to use a very small set of primitives and means of combination. We’ll see that recursion is a very powerful primitive, which could allow us to dispense with all other looping constructs (while and for) and results in code with a certain beauty. Another element of functional programming style is the idea of functions as first-class objects. That means that we can treat functions or procedures in much the same way we treat numbers or strings in our programs: we can pass them as arguments to other procedures and return them as the results from procedures. This will let us capture important common patterns of abstraction and will also be an important element of object-oriented programming. A exmple of ancient algorithm: It is an iterative algorithm: it starts with a guess about the square root, and repeatedly asks whether the guess is good enough. It’s good enough if, when we square the guess, we are close to the number, x, that we’re trying to take the square root of. If the guess isn’t good enough, we need to try to improve it. We do that by making a new guess, which is the average of the original guess and x / guess. 12345678910def sqrt(x): def goodEnough(guess): return abs(x-square(guess)) &lt; .0001 guess = 1.0 while not goodEnough(guess): guess=average(guess,x/guess) return guess&gt;&gt;&gt; sqrt(2)1.4142156862745097 Extra: inline function in function. We called it closure in a more professional way. I once write a blog about this, see here *arg, **kwargs we called it Variable Argument, *arg means positional arguments and **kwargs is keyword arguments. We’ve learn it the first day we use Python, but we have overlooked the most important symbol——*(star). the star symbol has two functions: pack and unpack, a sample: 123456789101112def star_wrapper(a, b, *c): print c print type(c)star_wrapper(1, 2, 3, 4, 5)# (3, 4, 5)# &lt;type 'tuple'&gt;star_wrapper(*[1, 2, 4, 5, 6])# (4, 5, 6)# &lt;type 'tuple'&gt; When convey the arguments to a function, * allocate the paramters to the arguments in function in sequence. When the interpretor found a formal parameter with *, it will pack the unallocated actual parameter and convey it as a tuple to the formal parameter. Alike *, the double star(**) pack the keyword into a dictionary.","link":"/2020/12/26/pre-learn-of-aix-2/"},{"title":"Python--闭包","text":"写这个博客还得起源于潜水快一个学期的老班在班群里提的一个问题： 1234567functions = []for i in range(5): def func(x): return x + i functions.append(func)for f in functions: print(f(12)) 输出结果都是16，原因？ 没有运行前我觉得老班说错了（丢人现场），一运行人都傻了，这是为什么呢，可以猜到作为一个全局变量 i，在函数 func 中一定只是作为一个全局的符号存在，而不是一个临时变量，同时返回的 x+i 中 i 的绑定并不是在函数创建的时候就绑定好的，它仅仅在用的时候才会去绑定值，这个时候 i 为 4。 似乎这么就结束了？老班提起闭包和延迟绑定… 闭包（Closure） 基本理解 很多语言都有闭包这一概念，我们单看 python 的，闭包概念可以这么理解： 如果我们在一个函数的内部定义了另一个函数，那么我们称外部的函数为外函数，内部的为内函数。 在一个外函数中定义了一个函数，内函数里运用外函数的临时变量，并且外函数的返回值是内函数的引用，这样就构成了一个闭包。 一般情况下，如果一个函数结束，函数的内部所有东西都会释放掉，还给内存，局部变量都会消失。但是闭包是一种特殊情况，如果外函数在结束的时候发现有自己的临时变量将来会在内部函数中用到，就把这个临时变量绑定给了内部函数，然后自己再结束。 我们稍稍改造一下上面的例子就能得到一个标准的闭包形式： 1234567891011121314def outer(n): functions = [] for i in range(n): def func(x): return x + i functions.append(func) return functionsfs = outer(5)for f in fs: print(f) print(f(12)) 外部函数返回了内部函数的引用：对于每个列表里的元素，都是一个函数指针的引用，他们的地址都不相同，f 就是这个指针的引用，所以我们可以通过 f 调用 func() 函数 外部函数把临时变量绑定给了内部函数：和上面的例子不同了，这次 i 作为一个临时变量存在了（但相对于 func 依旧为全局变量），这时 outer 函数执行完后，理论上 i 应该会被释放啊，但那是通常的情况，闭包是另外的一种情况。外部函数发现自己的临时变量会在将来执行的内部函数中发挥作用，那么自己在结束的时候会将外函数的临时变量送给内函数来绑定，这样不至于执行内函数的时候得到一个 undefined name 的报错。 那这是不是意味对于outer传入不同的参数，最终返回的都是同一个内部函数的引用？ 上面的例子看着不太方便，我们换一个: 12345678910111213def outer(n): def func(x): return x + n return funcf1 = outer(5)f2 = outer(7)print(f1)print(f2)# # &lt;function outer.&lt;locals&gt;.func at 0x000001D2A2BE86A8&gt;# &lt;function outer.&lt;locals&gt;.func at 0x000001D2B1C79950&gt; 明显的看到，每次都创建了一个新的内部函数 python中一切都是对象，虽然函数我们只定义了一次，但是外函数在运行的时候，实际上是按照里面代码执行的，外函数里创建了一个函数，我们每次调用外函数，它都创建一个内函数，虽然代码一样，但是却创建了不同的对象，并且把每次传入的临时变量数值绑定给内函数，再把内函数引用返回。虽然内函数代码是一样的，但其实，我们每次调用外函数，都返回不同的实例对象的引用，他们的功能是一样的，但是它们实际上不是同一个函数对象。 修改外函数的临时变量 我们如果想修改外函数变量的值，就碰到了一个问题 123456789def outer(n): b = 10 def func(): b += 1 print(b) return funcf1 = outer(5)f1()# UnboundLocalError: local variable 'b' referenced before assignment 啊，这。 在基本的 Python 语法中，一个函数可以随意的读取全局的变量，但要修改全局变量就需要声明为 global 了，同样，在修改闭包的变量的时候，我们也需要关键字来辅助我们。 使用关键字 nonlocal 声明 一个变量， 表示这个变量不是局部变量空间的变量，需要向上一层变量空间找这个变量。 修改后的上述代码： 123456789def outer(n): b = 10 def func(): nonlocal b b += 1 print(b) return funcf1 = outer(5)f1() 正常的输出了 b 的值 还有一点需要注意：使用闭包的过程中，一旦外函数被调用一次返回了内函数的引用，虽然每次调用内函数，是开启一个函数执行过后消亡，但是闭包变量实际上只有一个，每次开启内函数都在使用同一份闭包变量。 1234567891011121314def outer(n): def func(y): nonlocal n n += y print(n) return funcf1 = outer(5)f1(3)f1(3)# 结果# 8# 11 延迟绑定 123456789101112131415161718192021222324# code 1functions = []for i in range(5): def func(x): return x + i functions.append(func)for f in functions: print(f(12))# code 2def outer(n): functions = [] for i in range(n): def func(x): return x + i functions.append(func) return functionsfs = outer(5)for f in fs: print(f) print(f(12)) 2 个看起来很相似，但还是有点区别的，个人认为： 通过 dis 模块的 dis 函数来查看 bytecode，我们先看 outer 函数的 code212349 0 LOAD_FAST 0 (x) 2 LOAD_DEREF 0 (i) 4 BINARY_ADD 6 RETURN_VALUE 如果对整个函数进行反编译的话可以看到 LOAD_CLOSURE 加载闭包，直接对应的 i 的一步操作 我们仅仅看内部函数 i 作为一个引用出现 code1123459 0 LOAD_FAST 0 (x) 2 LOAD_GLOBAL 0 (i) 4 BINARY_ADD 6 RETURN_VALUE 对于 code1，i 作为一个全局变量出现，这里我认为仅仅是函数的延迟绑定发挥作用，而和闭包的关系不大","link":"/2020/05/24/python-closure/"},{"title":"Python 网络编程","text":"小学期学了一门课叫做&quot;Web框架技术&quot;，开心的选了，以为要讲 Web 框架，听了课才明白，讲的是 Web 开发，作业是用框架写个个人网站。 我: … 默默拿出自己从图书馆借的书《Python网络编程》，从头开始学习一些 web 开发基础的东西：UDP，TCP，HTTP客户端和服务端，SSL/TLS，以及服务器架构。 虚假的 WEB 框架技术: 使用 vue + django 完成一个个人网站 真正的 WEB 框架技术：学习手撕服务器程序（希望能做到吧） 联动一下 Django 源码的学习的系列 大三感觉比较忙，希望不要鸽 Intro: 从一个简单的API调用说起 调用 API 是我们再熟悉不过的东西了，就举个例子，调取百度地图 API 来获取经纬度。 req1.py123456789101112131415161718192021222324import requests# 百度地图 API文档# http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocodingdef geocode(addr): ak = &quot;xxxxxxxxx&quot; # your ak base = &quot;http://api.map.baidu.com/geocoding/v3/&quot; params = { &quot;address&quot;: addr, &quot;ak&quot;: ak, &quot;output&quot;: &quot;json&quot;, } response = requests.get(base, params) answer = response.json() print(answer[&quot;result&quot;][&quot;location&quot;])if __name__ == &quot;__main__&quot;: address = &quot;北京市丰台区成寿寺路11号&quot; geocode(address)# result# {'lng': 116.45160871298044, 'lat': 39.861847768022734} 我们很熟练的用 requests 库完成了 get 操作，似乎已经足够了，我们并不需要了解具体的实现过程，只需要关心数据正确拿到了就行。 等等，那我们还怎么去更深入的学习？ 协议的使用 request 库确实方便，但它隐藏了很多的实现细节。我们拨开一层看一看。现在我们自己构造 URL 和连接，也就是说使用 HTTP（Hypertext Transfer Protocol）协议来完成这一任务 req2.py123456789101112131415161718192021222324import http.clientimport jsonfrom urllib.parse import quote_plusbase = &quot;http://api.map.baidu.com/geocoding/v3/&quot;ak = &quot;********&quot;def geocode(addr): addr.encode(&quot;utf8&quot;) # quote_plus: 将字符串转化为 url编码，并且将空格转换为加号 path = &quot;{}?address={}&amp;ak={}&amp;output=json&quot;.format(base, quote_plus(addr), ak) connection = http.client.HTTPConnection(&quot;map.baidu.com&quot;) connection.request(&quot;GET&quot;, path) raw_reply = connection.getresponse().read() raw_reply = raw_reply.decode(&quot;utf-8&quot;) reply = json.loads(raw_reply) print(reply)if __name__ == &quot;__main__&quot;: address = &quot;北京市丰台区成寿寺路11号&quot; geocode(address) 首先我们请求连接一个特定的主机，然后手动构造一个带有参数的 GET 查询，最后从 HTTP 连接读取结果。 原始网络会话 你可能会觉得，前面的还是有点高级了。HTTP 协议并非是通过空气来在两台机器中传输数据的，HTTP 协议需要使用一些更加简单抽象的东西来完成操作。现代操作系统中提供了使用 TCP 协议在 IP 网络中的不同程序进行纯文本网络会话的功能，而 HTTP 协议正是使用了这一功能。换句话说，HTTP 协议精准描述了两台主机之间通过 TCP 传输的信息格式。 修改前面的代码，使用更加底层的方法来实现我们的 get 请求。 req3.py12345678910111213141516171819202122232425262728293031323334353637# coding: utf-8import socketfrom urllib.parse import quote_plusrequest_text = &quot;&quot;&quot;GET http://api.map.baidu.com/geocoding/v3/?address={}&amp;ak={}&amp;output=json HTTP/1.1Host: api.map.baidu.comConnection: closeUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept: */*&quot;&quot;&quot;ak = &quot;***********&quot;def geocode(addr): sock = socket.socket() sock.connect((&quot;api.map.baidu.com&quot;, 80)) req = request_text.format(quote_plus(addr), ak) # sock.sendall(req.encode()) header = req.split(&quot;\\n&quot;) print(header) for i in header: sock.send((i+&quot;\\r\\n&quot;).encode()) sock.send(&quot;\\r\\n&quot;.encode()) raw_reply = b'' while True: more = sock.recv(4096) if not more: break raw_reply += more print(raw_reply.decode(&quot;utf-8&quot;))if __name__ == &quot;__main__&quot;: address = &quot;北京市丰台区成寿寺路11号&quot; geocode(address) 我们使用主机操作系统提供的原始 socket() 函数来支持 IP 网络的通信，我们将在后面更加详细的了解 socket。 ps: 注意几个细节： 使用 sendall() 函数会出现 400(Bad Request) 的错误，这时可以采用逐条 send 的方法发过去，记得一定要有一个空的行(“\\n\\r”) 请求头中指定允许的压缩方式的话如果你不进行解压将会有字符无法被 utf8 解码，平常这些操作都是浏览器完成的，你都没碰到过。所以现在没有浏览器自动帮你还原数据，最好还是不要指定允许的压缩方式了(Accept-Encoding 头字段) 你说这还不够原始？好吧，拿出你的《计算机网络》… 层层深入 socket 并非是这个操作的最底层协议，套接字（socket）其实也是抽象与更加底层的协议，只不过这些协议由操作系统来管理，而非Python。拿出你的《操作系统》 在 socket() API 之下有: 传输控制协议（TCP），该层通过发送（也有可能重发），接收以及重排数据包，支持由字节流组成的双向网络会话。 网际协议（IP），该层处理不同计算机之间数据包的发送。 最底层，“链路层”，该层负责在直接相连的计算机之间发送物理信息，由网络硬件设备组成，如以太网端口和无线网卡。 一些简单的基础知识我们忽略掉，比如说 python 编码和解码，什么是 ip 地址。 我们首先要对网络传输有一个大致的理解： 数据包 网络设备之间共享的基本单元是数据表（packet）。数据包就像流通的货币，只要需要就可以交换。一个数据包是一串长度在几字节到几千字节之间的字符串，他们是网络传输的基本单元 数据包在物理层面只有2个属性，包含的字节数以及目标传输地址。物理数据包的地址一般是一个唯一标识符，它标识在计算机传输数据包的过程中，插入同一以太网的其他网卡或无线信道。网卡负责发送并接收这样的数据包，操作系统并不关心信号，网线等等细节。 由于 IP 支持的数据包极大，最大可以至 64KB，但是构建于 IP 网络之上的设备通常并不支持这么大的数据包，所以往往采用分组的方法。例如，以太网只支持 1500B 的数据包，因此网络数据包中包含一个表示“不分组（DF, Don’t Fragment）”的标记，在源计算机与目标计算机之间的某条物理网络无法容纳这么大的数据包的时候，发送者可以通过这个标记来表示是否分组： 如果没有设置 DF 标记，那么表示允许分组，当数据包超过上限的时候，网关能够将其分为多个小的数据包，并进行标记，接收方在收到后会重组为大的数据包 如果设置了 DF 标记，此时不允许分组，网络容纳不下的超出部分将会直接被丢弃，并发回一个错误信息。错误信息是由一种特殊的信号数据包表示的，这种数据包叫做 Internet 控制报文协议（ICMP, Internet Control Message Protocol）数据包。发送方在收到信息错误后会尝试将信息分割为较小的数据包然后重发。 DF 的设置由操作系统来完成，粗略的说，系统通常使用的逻辑是：如果正在进行一个由网络间传输的独立数据组成的 UDP 会话，操作系统不会设置 DF，如果是 TCP 会话，而 TCP 会话是由可能多达成百上千的数据包组成的长数据流，那么操作系统会设置 DF 标记，这样操作系统可以选择正确的数据包大小，使得 TCP 会话顺畅进行。否则，数据包将会在中途不断被分组，从而使得会话较为低效。 路由 一旦应用程序请求操作系统向某一特定的 IP 地址发送数据，操作系统就要决定如何使用该机器连接的某一物理网络来传输数据。这一决定（根据目的 IP 地址选择将 IP 数据包发往何处）就叫做路由（routing） 我们编写的大部分代码，都会运行在网络边缘，会有一个网络接口将程序与互联网相连，对于运行这些程序的机器来说，路由的决定就很简单。 如果 IP 地址是 127.*，*，*，那么操作系统知道数据包的目的地址是本机上运行的另一个应用程序，这个数据包甚至不会被送给物理网络设备，而是直接通过操作系统的内部数据复制转交给另一个程序。 如果目的 IP 地址与本机处于同一子网，那么可以通过简单的查找本地以太网段，无线信道或者是其他任何网络信息来找到目标主机，然后就可以将数据发给本地连接的服务器。 否则计算机将数据包转发给一台网关机器（gateway machine），这台机器将本地子网连接至互联网，然后在决定将该数据包发往何处。 对于组成互联网骨干网络的专用设备来说，路由决定就会复杂很多。 由 IP + 子网掩码来表示子网。 关于子网掩码的数字表示： 127.0.0.0/8： 此模式描述预留给本机的 IP 地址段，该模式下前8位也是1字节，必须与127匹配，余下的24位可以是任何值 192.168.0.0/16：匹配 192.168私有地址段的任何 IP，后16位可以是任意值 192.168.5.0/24：这里明确了一个独立的子网，这可能是互联网上最常见的子网掩码，前3个字节被明确指出，用来匹配 ip。允许有8位（最后一个字节）不同，共256个不同的地址。通常说 .0 表示子网名，.255 作为广播数据包的目标地址，广播数据包会被发到子网内网中所有主机，.1 通常用于连接外网的网关。","link":"/2020/09/21/python-web-1/"},{"title":"Python网络编程——UDP","text":"UDP IP 协议只负责尝试将每个数据包传输到正确的机器。如果2个独立的应用程序要维护一个会话的话，还需要两个额外的特性。这两个特性是由 IP 层以上的协议来提供的。 需要为两台主机之间传输的大量数据包打上标签，这样就可以将网页的数据包和用于电子邮件的数据包区分开来，而这两种数据包也可以与该机器正在进行的其他网络会话使用的数据包分隔开，这一过程叫做多路复用（multiplexing） 对两台主机间独立传输的数据包流发生任何错误，都需要进行修复，而丢失的数据包也需要进行重新传输，直至成功发送到目的地。另外，如果数据包到达时顺序错乱，则要将这些包重组回正常的顺序。最后要丢弃重复的数据包，以保证数据流中的信息没有冗余，提供这些保证的特性叫做可靠传输（reliable transport） 第一个是用户数据报协议（UDP），UDP协议只解决上述的第一个问题，UDP 协议提供了一个端口号，用于对目标为同一机器上的不同服务的多个数据包进行适当的多路分解。虽然支持多路复用和分解，但使用 UDP 协议的网络程序仍需要自己处理丢包重包和包的乱序问题。 第二个是传输控制协议（TCP），TCP 解决了上述2个问题，它跟 UDP 一样，使用了端口号来支持多路复用和 分解。除此之外，TCP 还保证数据流的顺序以及可靠传输，这样一来，尽管连续的数据流在传输时被分为多个数据包吗，而后在接收端再进行重组，但是这些细节都对应用层隐藏了。 端口号 在计算机网络和电磁信号理论中，对共享同一通信的多个信号进行区分是个常见的问题。多路复用（multiplexing） 就是允许多个会话共享同一介质或机制的一种解决方案。UDP 的设计者从数字领域分析，为每个 UDP 数据包分配了一对无符号16位端口号（port number），从0到65536。源端口（source port）标识了源机器上发送数据包的特定程序或者进程，而目标端口（destination port）则标识了目标 IP 地址上进行该会话的特定应用程序。 Source(IP: port number) -&gt; Destination(IP: port number) UDP 就仅仅使用 IP 地址和端口号进行标识，将数据包发送至目标地址。客户端想要获悉这些需要连接的端口号，会采用下面的方法: 惯例：互联网号码分配机构（IANA, Internet Assigned Number Authority），为许多专用服务分配了官方端口，如 DNS 默认为53号 UDP 端口。一般0-1023都被分配给了最重要最常用的服务。而1024-49151这些注册端口，在操作系统层没有任何特别之处，你可以占用，但一般会有一些应用申请或者默认端口选择在这里。剩余的就是可以随意使用的端口，当客户端无需指定特殊的端口时，现代操作系统会维护一个端口池来随机选取端口提供给该应用。 自动配置，如通过 DHCP 这样的协议获取一些重要服务的 IP，和知名端口号结合就可以访问这些基础服务。 手动配置，即手动配置 IP 地址或相应的服务域名。 例子 我们使用 socket 来实现一个简单的 udp 客户端和服务端 udp_local.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 使用自环接口的 udp服务器和客户端.pyimport argparseimport socketfrom datetime import datetimeMAX_BYTES = 65536def server(port): sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) sock.bind((&quot;127.0.0.1&quot;, port)) print(&quot;Listening at {}&quot;.format(sock.getsockname())) while True: data, address = sock.recvfrom(MAX_BYTES) text = data.decode(&quot;ascii&quot;) print(&quot;The client at {} says {!r}&quot;.format(address, text)) text = &quot;Your data was {} bytes long&quot;.format(len(data)) data = text.encode(&quot;ascii&quot;) sock.sendto(data, address)def client(port): sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) text = &quot;The time is {} seconds&quot;.format(datetime.now()) data = text.encode(&quot;ascii&quot;) sock.sendto(data, (&quot;127.0.0.1&quot;, port)) print(&quot;The OS assigned me the address {}&quot;.format(sock.getsockname())) data, address = sock.recvfrom(MAX_BYTES) # !Danger text = data.decode(&quot;ascii&quot;) print(&quot;The server {} replied {!r}&quot;.format(address, text))if __name__ == &quot;__main__&quot;: choices = {&quot;client&quot;: client, &quot;server&quot;: server} # 函数列表 # argparse 是一个用来解析命令行参数的 Python 库 # 创建解析器对象并且加上描述 parser = argparse.ArgumentParser(description=&quot;Send and receive UDP locally&quot;) parser.add_argument(&quot;role&quot;, choices=choices.keys(), help=&quot;which role to play&quot;) parser.add_argument(&quot;-p&quot;, metavar=&quot;PORT&quot;, type=int, default=1060, help=&quot;UDP port (default 1060)&quot;) # action参数的'store_true'指的是：触发 action时为真，不触发则为假。即储存了一个bool变量，默认为 false，触发不用赋值即变为true # type 指定参数类别 默认是str 传入数字要定义 # help 是一些提示信息 # default 是默认值 # metavar 在 usage 说明中的参数名称，对于必选参数默认就是参数名称，对于可选参数默认是全大写的参数名称 # https://docs.python.org/zh-cn/3/library/argparse.html args = parser.parse_args() func = choices[args.role] func(args.p) 首先使用 socket() 创建了一个空套接字，标记了所属的特定的类别：协议族 AF_INET 以及数据类型 SOCK_DGRAM，后者表示在 IP 网络上使用 UDP 协议。需要注意的是，数据报（datagram）是用来表示应用层数据块传输的官方术语。操作系统的网络栈并不保证传输线路上的单个数据包实际表示的就是单个数据报。 服务程序是一个循环，不断运行 recvfrom(), recvfrom(MAX_BYTES)表示可以最大接受 65535 字节的数据，在没有数据之前，recvfrom() 将永远保持等待。一旦接受到数据报，recvfrom() 返回两个值，第一个是发送数据的客户端地址，第二个是字节表示的数据报内容。与之相对的是客户端函数 sendto()，指定发送信息和目标地址。 123456(venv) D:\\my_py36\\Python-Web\\udp&gt;python udp_local.py serverListening at ('127.0.0.1', 1060)# 执行一次客户端The client at ('127.0.0.1', 51384) says 'The time is 2020-09-28 16:16:34.259636 seconds'# 执行第二次客户端The client at ('127.0.0.1', 51385) says 'The time is 2020-09-28 16:16:44.724149 seconds' 123456789101112131415(venv) D:\\my_py36\\Python-Web\\udp&gt;python udp_local.py serverTraceback (most recent call last): File &quot;udp_local.py&quot;, line 48, in &lt;module&gt; func(args.p) File &quot;udp_local.py&quot;, line 11, in server sock.bind((&quot;127.0.0.1&quot;, port))OSError: [WinError 10048] 通常每个套接字地址(协议/网络地址/端口)只允许使用一次。# 执行第一次客户端程序(venv) D:\\my_py36\\Python-Web\\udp&gt;python udp_local.py clientThe OS assigned me the address ('0.0.0.0', 51384)The server ('127.0.0.1', 1060) replied 'Your data was 46 bytes long'# 执行第二次客户端程序(venv) D:\\my_py36\\Python-Web\\udp&gt;python udp_local.py clientThe OS assigned me the address ('0.0.0.0', 51385)The server ('127.0.0.1', 1060) replied 'Your data was 46 bytes long' 混杂客户端与垃圾回复 上面的例子看起来很美好，但实际上有很大的问题，客户端并不会去校验这条消息有没有发给服务端，假如我们暂停服务器一会，开启一个新的程序起一个新的socket，向客户端地址发消息，那么客户端就会认为是服务器发的。这样他人就可以轻松的伪造成服务端。 需要注意，客户端面对任何可以向其发送 UDP 数据包的终端都是脆弱的，这与中间人攻击（http面临的问题）不同，中间人攻击是取得了网络的控制权后从非法的地址发送伪造的数据包，这种情况只能通过加密来保护。 像这样不考虑地址是否正确，接受并且处理所有收到的数据包的网络监听器客户端在技术上叫做**混杂模式（Promiscuous）**客户端，有时我们也会需要这样的客户端，如进行网络监控的时候，需要监控到达某一个接口的所有数据包。 不可靠性，退避，阻塞和超时 我们的例子运行在同一个机器上，客户端和服务端通过自环接口来进行通信，而没有使用可能会产生信号故障的网卡，因此数据包不可能丢失，我们模拟一下丢包的情况，重新写这个客户端和服务端程序： udp_remote.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import argparseimport socketimport randomimport sysfrom datetime import datetimeMAX_BYTES = 65536def server(interface, port): sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) sock.bind((interface, port)) print(&quot;Listening at {}&quot;.format(sock.getsockname())) while True: data, address = sock.recvfrom(MAX_BYTES) if random.random() &lt; 0.5: print(&quot;Pretending to drop packet from {}&quot;.format(address)) continue text = data.decode(&quot;ascii&quot;) print(&quot;The client at {} says {!r}&quot;.format(address, text)) text = &quot;Your data was {} bytes long&quot;.format(len(data)) data = text.encode(&quot;ascii&quot;) sock.sendto(data, address)def client(hostname, port): sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) hostname = sys.argv[2] sock.connect((hostname, port)) print(&quot;client socket name is {}&quot;.format(sock.getsockname())) text = &quot;The time is {} seconds&quot;.format(datetime.now()) data = text.encode(&quot;ascii&quot;) delay = 0.1 while True: sock.send(data) print(&quot;Waiting up to {} seconds for a reply&quot;.format(delay)) sock.settimeout(delay) try: data = sock.recv(MAX_BYTES) except socket.timeout: delay = delay * 2 # 等待更久 if delay &gt; 2.0: raise RuntimeError(&quot;May be the server is down&quot;) else: break print(&quot;The server says {!r}&quot;.format(data.decode(&quot;ascii&quot;)))if __name__ == &quot;__main__&quot;: choices = {&quot;client&quot;: client, &quot;server&quot;: server} parser = argparse.ArgumentParser(description=&quot;Send and receive UDP, pretending packet dropped in transmission&quot;) parser.add_argument(&quot;role&quot;, choices=choices.keys(), help=&quot;which role to take&quot;) parser.add_argument(&quot;host&quot;, help=&quot;interface the server listens at / host the client sends to&quot;) parser.add_argument(&quot;-p&quot;, metavar=&quot;PORT&quot;, type=int, default=1060, help=&quot;UDP port (default 1060)&quot;) args = parser.parse_args() func = choices[args.role] func(args.host, args.p) UDP 客户端要处理丢包现象，由于不确定没有收到包是因为响应时间过长还是丢失响应，首先要选择一个等待时间，超过等待时间间隔还没有响应就重新发送请求，我们例子中设定 delay = 0.5s，设置 timeout 时间，当超时时捕获抛出的异常。当然，我们不希望不断发一个会丢失的数据包，所以尝试重发数据包的频率应该越来越低，这就是**指数退避（exponential backoff）**技术，我们例子中是一种简单的方法，每次延长2倍时间等待，当延长时间到达一定数量时可以认为服务器宕机了（当然 UDP 是无法判断是否真的宕机了，只能推测）。 当然，编写需要不断重发数据包的守护程序代码时就不要遵循指数退避策略，这样很容易导致延时被拉的很大，最好的办法就是设置一个最大值，超过后每次都使用最大值作为等待时间，这样保证计算机长时间离线恢复之后也可以较快的尝试重发。 请求 ID 重发可以解决丢包问题，但带来的是冗余问题，假设我们发送了请求A，很久之后也没得到相应，于是就重发，然后得到了响应A，这时如果你发一个请求B，拿到了一个响应，假如第一次发的A包真的丢失了，没有任何问题；但如果没有丢失只不过是响应很慢，这样有可能你第二次请求拿到了第一次响应的结果，而这次请求B有可能回来的结果是A请求的结果，这样就彻底乱套了。 使用请求 ID 就是为了解决这种问题，我们给A，B请求不同的 ID，接受响应只收对应 ID 的，这样就可以解决重复问题，当然我们设定一个 ID 的范围，在一定程度上也可以防止一些伪造响应或者请求。 UDP 分组 程序中 UDP 数据包最大可以达到 64KB，而以太网和无线网卡只能处理 1500B 左右的数据包。事实上，UDP 必须把较大的 UDP 数据报分为多个较小的数据报，这样就能够以单独 IP 数据包的形式在网络中发送这些数据。这意味着，较大的数据包在传输过程中更容易发生丢包现象，因为只要它分割出任一小数据包没有传至目标地址，便无法重组出原始的大数据包。 如果运行了防火墙，那么本机主机通常可以自动检测出与远程主机的 MTU（最大传输单元，最大数据包容量），如果不注意的话，较大的 UDP 数据包可能会被遗忘。 UDP 广播 UDP 支持广播，通过广播可以将数据的目标地址设置为本机连接的整个子网，然后使用物理网卡将数据报广播，这样就无需再复制该数据包并单独发给所有连接至该子网的主机了。由于有了**多播（multicast）**的技术，广播被认为是过时了，经过多播，现代操作系统能够更好的利用网络以及网络接口设备提供的许多只能信息，另外多播支持费本地子网上的主机。不过想用一种简单的方法在本地 LAN 上完成一些偶尔允许丢包的功能（如游戏客户端货值自动实时记分牌）的话，UDP 广播是个简单易行的选择。 udp_broadcast.py123456789101112131415161718192021222324252627282930313233import argparseimport socketBUFSIZE = 65536def server(interface, port): sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) sock.bind((interface, port)) print(&quot;Listening for datagram at {}&quot;.format(sock.getsockname())) while True: data, address = sock.recvfrom(BUFSIZE) text = data.decode(&quot;ascii&quot;) print(&quot;The client at {} says: {!r}&quot;.format(address, text))def client(network, port): sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) text = &quot;Broadcast datagram!&quot; sock.sendto(text.encode(&quot;ascii&quot;), (network, port))if __name__ == &quot;__main__&quot;: choices = {&quot;client&quot;: client, &quot;server&quot;: server} parser = argparse.ArgumentParser(description=&quot;Send, receive UDP broadcast&quot;) parser.add_argument(&quot;role&quot;, choices=choices.keys(), help=&quot;which role to take&quot;) parser.add_argument(&quot;host&quot;, help=&quot;interface the server listens at / host the client sends to&quot;) parser.add_argument(&quot;-p&quot;, metavar=&quot;PORT&quot;, type=int, default=1060, help=&quot;UDP port (default 1060)&quot;) args = parser.parse_args() func = choices[args.role] func(args.host, args.p) 连着网络然后查查本机在内网的 IP 地址，运行客户端，将ip地址前一部分不变，最后改为 .255 （广播段），然后用 wireshark 之类的抓包工具就可以看到你发的这个 UDP 广播，当然你也可以邀请你的小伙伴跑一下server（在 0.0.0.0）来看看有没收到这个包。","link":"/2020/09/27/python-web-2/"},{"title":"Python网络编程——DNS","text":"DNS 协议 域名系统（DNS, Domain Name Service）是成千上万互联网主机相互协作，对主机名与 IP 地址映射关系查询做出响应的一种机制。 DNS协议 目的: 解析主机名，返回 IP 地址 标准: RFC 1034与 RFC 1035 传输层协议: UDP/IP与 TCP/IP 端口号: 53 以 www.python.org 这一域名为例。如果网络浏览器需要解析该域名，那么浏览器就会运行一个类似于 getaddrinfo() 的调用，请求操作系统对该域名进行解析。系统本身知道其是否运行了自己的名称服务器，以及连接的网络是否会提供名称服务。如今，我们的机器常常会在连接网络的同时通过 DHCP 自动配置名称服务器信息。可以通过公司办公室或者教育机构的 LAN，也可以通过无线网络，还可以通过家庭电缆或 DSL 连接到网络。在其余情况下，系统管理员设置机器时会手动配置 DNS 服务器的 IP 地址。有时，由于人们对于 ISP 提供的 DNS 及其性能并不满意，他们会选择自己配置一个第三方的DNS服务器，比如说谷歌运行的8.8.8.8或8.8.4.4。即使不查询域名服务，计算机也知道一些主机名对应的 IP 地址。当我们调用内置函数 getaddrinfo() 时，操作系统做的第一件事并非是去向 DNS 服务器查询。如果使用的是 POSIX 系统，那么要查询的文件取决于 /tc/nsswitch.conf 文件的 hosts 条目，如果是 Windows，那么会取决于控制面板的选项。如 Linux 系统会先查询 /etc/conf。 然后会尽可能地使用一种叫做多播 DNS 的专用协议。 假如我们的电脑里面并没有定义 www.python.org 这一域名，也没有在足够短的时间内访问过该域名（意味着并没有缓存），这时计算机就会去查询真正的域名解析服务器，它通常会发一个基于 UDP 的 DNS 数据查询包。DNS 服务器它会首先检查自己最近查询域名的缓存，如果有就可以马上返回 IP 地址。如果没有，就会从世界上 DNS 服务器层级结构的最顶层开始递归查询 www.python.org。根节点的名称服务器可以识别所有的顶级域名(TLD)，如.com, .net 并且存储了负责相应顶级域名的服务群信息。为了能够在实际连接至域名系统之前找到域名服务器，名称服务器软件通常内置了这些顶级服务器的 IP 地址。这样经过一次 UDP 往返之后 DNS 服务器就能够获取保存完整 .org 域名索引的服务器了。 现在将发送第二个 DNS 请求，这次是发给某一个 .org 服务器，用来询问保存 python.org 域名信息的服务器，可以使用 whois 工具来获取相关信息（电脑里没这个命令的话可以在web上查） 类似这个样子: 无论我们在哪里，我们对任何属于 python.org 的主机名的 DNS 请求都会被发到里面的 DNS 服务器当中的一个，他们会直接返回查询结果，这样DNS 服务器就会向浏览器返回一个包含 www.python.org 的 IP 地址的 UDP 包。根据不同的配置，DNS 服务器往往还需要进行查询的次数也不同，有可能在进行一次查询就够用了（第三次查询），但如果机构较为庞大，很多部门都有自己的子 DNS 服务器，就可能把请求分配到各个部门的自己的 DNS 服务器，这就需要更多次查询。 一个解析邮箱域名的例子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import argparseimport dns.resolver# pip install dnspython3def resolve_hostname(hostname, indent=&quot;&quot;): &quot;&quot;&quot; print an A or AAAA for `hostname`; follow CNAMEs if necessary. :param hostname: :param indent: :return: &quot;&quot;&quot; indent = indent + &quot; &quot; answer = dns.resolver.query(hostname, 'A') # A 代表 ipv4地址 if answer.rrset is not None: for record in answer: print(indent, hostname, &quot;has A address &quot;, record.address) return answer = dns.resolver.query(hostname, &quot;AAAA&quot;) # AAAA 代表 ipv6 地址 if answer.rrset is not None: for record in answer: print(indent, hostname, &quot;has AAAA address &quot;, record.address) return answer = dns.resolver.query(hostname, &quot;CNMAE&quot;) if answer.rrset is not None: record = answer[0] cname = record.address print(indent, hostname, &quot;is a CNAME alias for &quot;, cname) resolve_hostname(cname, indent) # 递归查询 return print(indent, &quot;ERROR: no A, AAAA, or a CNMAE alias for &quot;, hostname)def resolve_email_domain(domain): &quot;&quot;&quot; For an email address `name@domain` find its mail server IP address :param domain: :return: &quot;&quot;&quot; try: answer = dns.resolver.query(domain, &quot;MX&quot;, raise_on_no_answer=False) except dns.resolver.NXDOMAIN: print(&quot;ERROR: No such domain &quot;, domain) return if answer.rrset is not None: records = sorted(answer, key=lambda record: record.perference) for record in records: name = record.exchange.to_text(omit_final_dot=True) print(&quot;Priority &quot;, record.perference) resolve_hostname(name) else: print(&quot;This domain has no explicit MX records&quot;) print(&quot;Attempting to resolve it as an A, AAAA, or CNAME&quot;) resolve_hostname(domain)if __name__ == &quot;__main__&quot;: parser = argparse.ArgumentParser(description=&quot;Find mail-server IP address&quot;) parser.add_argument(&quot;domain&quot;, help=&quot;domain that you want to send mail to&quot;) resolve_email_domain(parser.parse_args().domain) 简要的来说，解析邮箱域名的规则是这样的: 如果存在 MX 记录，就必须尝试与这些 SMTP 服务器进行通信。如果没有任何 SMTP 服务接收消息，那么必须向用户返回一个错误（或者将该消息放入重发队列里）。如果优先级不同，那就按照优先级序号从大到小尝试这些服务器。如果不存在 MX 记录，但是域名提供了 A 或 AAAA 记录，那么可以尝试向这些记录发起连接，如果域名没有提供上述任何一记录但给出了 CNAME，那么应该使用相同的规则搜索该 CNAME 对应的 MX 记录或 A 记录。 MX: 邮件交换记录 (MX record)是域名系统(DNS)中的一种资源记录类型，用于指定负责处理发往收件人域名的邮件服务器。MX记录允许设置一个优先级，当多个邮件服务器可用时，会根据该值决定投递邮件的服务器。简单邮件传输协议（SMTP）会根据MX记录的值来决定邮件的路由过程。 CNAME: CNAME 被称为规范名字。这种记录允许您将多个名字映射到同一台计算机。 通常用于同时提供 WWW 和 MAIL 服务的计算机。例如，有一台计算机名为&quot;r0WSPFSx58.&quot;（A记录）。 它同时提供 WWW 和 MAI L服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：WWW 和 MAIL 更好的方法当然是使用我们的 getsockaddr() 而不是自己尝试解析服务器的主机名。","link":"/2020/10/09/python-web-4/"},{"title":"python-web-5","text":"网络数据和网络错误 如果只想通过网络发送文本的话，那么只需要考虑编码与封帧问题就可以了，但这时一个新的问题就出来了：字节顺序的问题。 比如说 4523。尽管所有处理器都认同内存中的字节要有序，它们也都会以 4 作为开始字符，以 3 作为结束的字符，但是它们存储二进制数字的字节顺序是不同的。一些计算机使用大端（big-endian），将最高位存储在最前面。其他处理器（如x86架构）则使用小端（little-endian），将最低位字节存储在前面。（前面指内存低地址字节） 1234567import structprint(struct.pack(&quot;&lt;i&quot;, 4353)) # 小端print(struct.pack(&quot;&gt;i&quot;, 4353)) # 大端# b'\\x01\\x11\\x00\\x00'# b'\\x00\\x00\\x11\\x01' 封帧与引用 如果使用 UDP 数据进行通信，那么协议本身就会使用独立的，可识别的的快进行数据传输。不过，如果网络出现了问题，我们就必须自己重新排列并重新发送这些数据块。然而如果我们使用更为常用的 TCP 进行通信，那么我们就要应对**封帧（framing）**问题，即如何分割消息使得接收方可以识别消息的开始和结束。 由于传递给 sendall() 的数据可能在实际网络中传输时被分割为多个数据包，接收消息的程序可能需要进行多个 recv() 调用才能读取完整的信息。如果个包传达时，操作系统都能够再次调度运行 recv() 的进程，那么可能不需要进行多个 recv() 的调用。 关于封帧，需要考虑的问题是这样的：接收方何时最终停止调用 recv() 才是安全的？整个消息或数据何时才能完整无缺的传达？何时才能将接收到的信息作为一个整体来处理？ 模式一 这个方法用于一些及其简单的网络协议，只涉及数据的发送，而不关注响应。因此，接收方永远不会认为数据已经够了，然后向发送方发送响应。在这种情况下，可以使用这种模式：发送方循环发送数据，直到所有的数据都被传递给 sendall() 为止，然后使用 close() 关闭套接字。接收方不断的调用 recv()，直到最后返回一个空字符串（表示发送方已经关闭了套接字）为止。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import socketfrom argparse import ArgumentParserdef server(address): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # 加入socket配置，重用ip和端口 sock.bind(address) sock.listen(1) print(&quot;Run this script in another window with \\&quot;-c\\&quot; to connect&quot;) print(&quot;Listening at: &quot;, sock.getsockname()) sc, sockname = sock.accept() # 接受客户端的连接 print(&quot;Accepted connection from: &quot;, sockname) sc.shutdown(socket.SHUT_WR) message = b&quot;&quot; while True: more = sc.recv(8192) # 8k if not more: # recv 返回 &quot;&quot; print(&quot;Received zero bytes - end of file&quot;) break print(&quot;Received {} bytes&quot;.format(len(more))) message += more print(&quot;Message:\\n&quot;) print(message.decode(&quot;ascii&quot;)) sc.close() sock.close()def client(address): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect(address) # 只停止在某个方向上的数据传输，而一个方向上的数据传输继续进行 # SHUT_RDWR:关闭读写,即不可以使用send/write/recv/read # SHUT_RD:关闭读,即不可以使用recv/read # SHUT_WR:关闭写,即不可以使用send/write sock.shutdown(socket.SHUT_RD) sock.sendall(b&quot;Beautiful is better than ugly.\\n&quot;) sock.sendall(b&quot;Explicit is better than implicit.\\n&quot;) sock.sendall(b&quot;Simple is better than complex.\\n&quot;) sock.close() if __name__ == &quot;__main__&quot;: parser = ArgumentParser(description=&quot;Transmit &amp; receive a data stream&quot;) parser.add_argument(&quot;hostname&quot;, nargs=&quot;?&quot;, default=&quot;127.0.0.1&quot;, help=&quot;IP address or hostname (default:%(default)s&quot;) parser.add_argument(&quot;-c&quot;, action=&quot;store_true&quot;, help=&quot;run as a client&quot;) parser.add_argument(&quot;-p&quot;, type=int, metavar=&quot;port&quot;, default=1060, help=&quot;TCP port number (default:%(default)s&quot;) args = parser.parse_args() function = client if args.c else server function((args.hostname, args.p)) 运行一下服务端然后再开一个另外的命令行窗口加上 -c 参数来运行客户端程序，得到下面的输出 1234567891011(venv) D:\\my_py36\\Python-Web\\network_data&gt;python streamer.pyRun this script in another window with &quot;-c&quot; to connectListening at: ('127.0.0.1', 1060)Accepted connection from: ('127.0.0.1', 56077)Received 96 bytesReceived zero bytes - end of fileMessage:Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex. 使用客户端关闭套接字后形成的文件结束符来表示这次通信唯一需要的一个帧。 需要注意的是，由于这个套接字并没有准备接收任何数据，因此当客户端和服务端不在进行某一方向的通信时会立即关闭该方向的连接。这一做法避免了在另一方向上使用套接字。否则的话，可能会由于在缓冲队列中填入太多的数据从而导致最终死锁。客户端和服务器至少其中一方调用 shutdown() 方法是相当必要的。 模式二 使用定长消息。可以使用 sendall() 发送字节字符串，然后使用自己设计的 recv() 循环来确保接受完整的消息。 12345678def recvall(sock, length): data = &quot;&quot; while len(data) &lt; length: more = sock.recv(length - len(data)) if not more: raise EOFError(&quot;socket closed {} bytes into a {}-byte message&quot;.format(len(data), length)) data += more return data 模式三 使用特殊的字符来划分消息的边界，如果可以确保消息中的字节或字符在特定的有限范围内，那么自然就可以选择该范围外的某个符号作为消息的结束符，比如如果正在发送 ascii 字符，那么可以选择空字符 '\\0' 作为定界符，也可以选择像 \\xff 这种处于ascii字符之外的字符。 模式四 在每个消息前加上其长度作为前缀。如果使用该模式则无需进行分析，引用或者插入就能够一字不差的发送二进制数据块。因此对于高性能协议来说，这是一个很流行的选择。当然消息长度本身需要使用帧封装。封帧时可以使用前面提到的方法。通常会使用一个定长的二进制整数或者是在变长的整数字符串后面加上一个文本定界符来表示长度。无论哪种方法，只要对方读取并解码了长度，就能够进入循环，重复 recv() 直到整个消息都传达为止。 模式五 使用这个模式时，我们并非只发送单个信息，而是会发送多个数据块，而且在每个数据块前加上数据块长度作为其前缀。这意味着每个新的信息块对于发送者来说都是可见的，可以使用数据块的长度为其打上标签，然后将数据块置于发送流中，抵达信息结尾时，发送方可以发送一个与接收方事先约定好的信号告知发送完毕。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import socket, structfrom argparse import ArgumentParser# 等于声明一个包含一个 unsigned int变量的结构体header_struct = struct.Struct(&quot;!I&quot;) # message up to 2**23 - 1 in lengthdef recvall(sock, length): blocks = [] while length: block = sock.recv(length) if not block: raise EOFError(&quot;socket closed with %d bytes left in this block&quot;.format(length)) length -= len(block) blocks.append(block) return b''.join(blocks)def get_block(sock): data = recvall(sock, header_struct.size) (block_length, ) = header_struct.unpack(data) # 解包 return recvall(sock, block_length)def put_block(sock, message): block_length = len(message) sock.send(header_struct.pack(block_length)) # 打包数据对象转化为流 sock.send(message)def server(address): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind(address) sock.listen(1) print(&quot;Run this script in another window with \\&quot;-c\\&quot; to connect&quot;) print(&quot;Listening at: &quot;, sock.getsockname()) sc, sockname = sock.accept() print(&quot;Accepted connection from: &quot;, sockname) sc.shutdown(socket.SHUT_WR) while True: block = get_block(sc) if not block: break print(&quot;Block says: &quot;, repr(block)) sc.close() sock.close()def client(address): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect(address) sock.shutdown(socket.SHUT_RD) put_block(sock, b&quot;Beautiful is better than ugly.&quot;) put_block(sock, b&quot;Explicit is better than implicit&quot;) put_block(sock, b&quot;Simple is better than complex&quot;) put_block(sock, b&quot;&quot;) sock.close()if __name__ == &quot;__main__&quot;: parser = ArgumentParser(description=&quot;Transmit &amp; receive over TCP&quot;) parser.add_argument(&quot;hostname&quot;, nargs=&quot;?&quot;, default=&quot;127.0.0.1&quot;, help=&quot;IP address or hostname (default:%(default)s&quot;) parser.add_argument(&quot;-c&quot;, action=&quot;store_true&quot;, help=&quot;run as a client&quot;) parser.add_argument(&quot;-p&quot;, type=int, metavar=&quot;port&quot;, default=1060, help=&quot;TCP port number (default:%(default)s&quot;) args = parser.parse_args() function = client if args.c else server function((args.hostname, args.p)) 和上面的例子同样的运行方法 1234567(venv) D:\\my_py36\\Python-Web\\network_data&gt;python blocks.pyRun this script in another window with &quot;-c&quot; to connectListening at: ('127.0.0.1', 1060)Accepted connection from: ('127.0.0.1', 56069)Block says: b'Beautiful is better than ugly.'Block says: b'Explicit is better than implicit'Block says: b'Simple is better than complex' struct 是 Python 的一个内置库，用于定义结构体以处理网络流，文件流的一些问题 按照指定格式将 Python 数据转换为字符串,该字符串为字节流,如网络传输时,不能传输 int,此时先将 int转化为字节流,然后再发送; 按照指定格式将字节流转换为 Python指定的数据类型; 处理二进制数据,如果用 struct 来处理文件的话,需要用’wb’,’rb’以二进制(字节流)写,读的方式来处理文件; 处理c语言中的结构体; Struct 参数文档 Pickle 与自定义定界符格式 通过网络发送的某些数据可能已经包含了某种形式的内置定界符，如果要传输这样的数据，那么就不必再数据已有定界符的基础上再设计我们自己的封帧方案了。 一个很有意思的事情是，如果我们使用 pickle 的 load() 函数从文件中读入数据，那么文件指针会停留在 pickle 数据结尾，可以从结尾处开始读取后面的内容。 12345678910&gt;&gt;&gt;from io import BytesIO&gt;&gt;&gt;import pickle&gt;&gt;&gt;f = BytesIO(b&quot;\\x80\\x03]q\\x00(K\\x05K\\x06K\\x07e.balalabalabala)&quot;)&gt;&gt;&gt;pickle.load(f)[5, 6, 7]&gt;&gt;&gt;f.tell()14&gt;&gt;&gt;f.read()b'balalabalabala)' 压缩 GNU 的 zilb 仍是当今互联网最普遍的压缩形式之一。能够自己进行封帧是 zlib 一个很有意思的特点。在传递一个压缩过的数据流时，zlib 能够识别出压缩数据何时达到结尾，如果后面还有未经压缩的数据，用户也可以直接访问。 123456&gt;&gt;&gt;import zlib&gt;&gt;&gt;data = zlib.compress(b&quot;Python&quot;) + b&quot;.&quot; + zlib.compress(b&quot;zlib&quot;)&gt;&gt;&gt;datab'x\\x9c\\x0b\\xa8,\\xc9\\xc8\\xcf\\x03\\x00\\x08\\x97\\x02\\x83.x\\x9c\\xab\\xca\\xc9L\\x02\\x00\\x04d\\x01\\xb2'&gt;&gt;&gt;len(data)27 网络异常 要捕获异常，有两种基本方法：granular 异常处理和 blanket 异常处理。 granular 方法就是针对每个网络调用都采用 try…except 语句捕获异常，尽管对小的程序很好用，但在大项目里就显得有些冗余。 blanket 方法从程序外部调用这些方法时捕获异常，这需要我们识别出完成特定操作的代码块，以及其外部调用处。这种方法方便整体重新进行操作。如发邮件失败，在调用函数处捕获到了异常，就可以规定时间重新发送邮件，而不像内部出现错误而无法便于程序员编写代码来重复整个代码操作。","link":"/2020/10/13/python-web-5/"},{"title":"python-web-6","text":"Telnet 和 SSH Telnet Telnet 取名自 Telecommunications 和 Networks 的联合缩写，这是一种在 UNIX 平台上最为人所熟知的网络协议。 Telnet 使用端口 23，它是专门为局域网设计的。 Telnet 不是一种安全通信协议，因为它并不使用任何安全机制，通过网络/互联网传输明文格式的数据，包括密码，所以谁都能嗅探数据包。 Telnet 中没有使用任何验证策略及数据加密方法，因而带来了巨大的安全威胁，这就是为什么telnet不再用于通过公共网络访问网络设备和服务器。 SSH SSH 取名自安全外壳(Secure Shell)，它现在是通过互联网访问网络设备和服务器的唯一的主要协议。 SSH 默认情况下通过端口22运行，该端口号可以更改。 SSH 是一种非常安全的协议，因为它共享并发送经过加密的信息，从而为通过互联网等不安全的网络访问的数据提供了机密性和安全性。 一旦通讯的数据使用 SSH 经过加密，就极难解压和读取该数据，所以我们的密码在公共网络上传输也变得很安全。 SSH 还使用公钥用于对访问服务器的用户验证身份，这是一种很好的做法，为我们提供了极高的安全性。 终端的特别之处 在使用 Python 进行远程连接的时候，可能会和除了 shell 以外的其他程序进行交互。对于接收到的数据流，往往需要进行观察，以获取所运行的命令生成的数据或错误信息。有时候还需要返回数据，用作远程程序的输入或是远程程序提出问题的响应。 进行上面这些操作时，有时可能会发现程序被无限期地挂起了，始终无法接收到需要的内容。同样地，发送的数据也可能无法被成功传输。为了解决这一问题，这里简要介绍一下 UNIX 终端。 终端是这样一台设备：用户可以通过终端来输入文本，而计算机的响应也会显示在终端的屏幕上。如果 UNIX 机器拥有能够支持物理终端的物理序列端口，那么该设备的目录中就会包含类似 /dev/ttyS1 的项。程序可以用它来向终端发送字符串或者从终端来接收字符串。不过，现在大多数终端其实就是其他程序如：xterm 终端，Gnome 或 KDE 终端程序，或者 Windows 机器上的 PuTTY 客户端。 在计算机终端运行的程序，往往会自动检测正在与其交互的是否是人类用户。只有连接到终端设备时，这些程序才会对其输入进行格式化，使之便于人类用户理解。因此，UNIX 操作系统提供了一些列的 “伪终端” 设备（虚拟终端），其名称类似于 /dev/tty42。如果希望程序认定其在与人类用户进行交互的话，也可以将运行程序的进程连接到这些&quot;伪终端&quot;设备。当启动一个 xterm 或者通过 SSH 进行连接时，其进程会新建一个伪终端，并且对其进行配置，然后运行绑定到 xterm 或者 SSH 的 shell。该 shell 会检查标准输入，如果来自另一个终端，则认为与其交互的是人类用户，并显示命令提示符。 12345678910111213$ cat | bashecho Here we are inside of a bash, with no prompt# 立即输出Here we are inside of a bash, with no promptpython3print(&quot;Hello World&quot;)import sysprint(&quot;Is this a terminal?&quot;, sys.stdin.isatty())# Ctrl + D 后出现输出Hello WorldIs this a terminal? False 不仅 bash 不会显示命令提示符，Python 也没有了。但至少 bash 可以对 echo 做出回应。 由于输入并非来自终端，导致 Python 认为它只需要无条件从标准输入读取整个 Python 脚本即可。毕竟输入是一个文件，而文件包含了整个脚本，Python 可能会进行无限的读取操作，直到读到文件的结尾。我们按下 Ctrl + D 就给 cat 发送了文件结束的信号，结束了 cat 自身的输出，完成了整个操作。同时关闭了 Python 的输入，这样就拿到了输出。 在 Python 中，通过调用前面提到的 isatty() 来检查程序是否在和终端交互，然后根据该调用的返回值来设计程序的具体行为。下面是几种常见行为： 交互式程序在与终端进行交互时会显示易于人类用户理解的命令行提示符。当程序认为其输入来自文件的时候，就不会显示命令行提示符。防止屏幕中出现大量冗余的命令行提示符。 当程序不由终端控制时，会关闭命令行编辑功能，并且将控制字符也当做输入流中的普通字符。 人类用户往往希望在键入一条命令后马上能得到响应，因此许多程序在读取终端的输入时会每次只读取一行的输入。但从管道或者文件读取输入时，这些程序会一次性读取大量的字符，然后再对读取的输入进行解释。从前面看到，bash 每次只读一行而 Python 就会一次性读完整个脚本然后从第一行开始执行。 多数程序会根据是否在与终端进行通信来对输出进行调整。如果与程序交互的只是文件或管道，那么程序会等待整块输入都读完后再一次性发送整块输入的响应。 最后两点都涉及了缓冲。最常见的当我们执行到 print() 函数时，并没有立刻在终端显示字符。这是由于 print() 会先将输出结果存入缓冲区，等缓冲区满了才会一次性输出。我们可以调用 flush() 来清空输出的缓冲区。 同样，UNIX 终端设备会对键盘输入进行缓冲，每次读取一行输入。如果只希望每次从输入读入一个字符，可以使用 stty 关闭标准处理模式(每次处理一行) stty -icanon ps:记得使用 reset 重置回来。 Telnet 123456789101112131415161718192021222324252627282930313233import argparseimport getpassimport telnetlibdef main(hostname, username, password): t = telnetlib.Telnet(hostname) # t.set_debuglevel(1) t.read_until(b&quot;login:&quot;) t.write(username.encode(&quot;utf-8&quot;)) t.write(b&quot;\\n&quot;) print(t.read_all()) t.read_until(b&quot;assword:&quot;) # Password or password t.write(password.encode(&quot;utf-8&quot;)) t.write(b&quot;\\n&quot;) # br: b 二进制 r 不转义原生字符 n, match, previous_text = t.expect([br&quot;Login incorrect&quot;, br&quot;\\$&quot;], 10) if n == 0: print(&quot;Username and password failed - giving up&quot;) else: t.write(b&quot;exec uptime\\n&quot;) print(t.read_all().decode(&quot;utf-8&quot;)) # read until the socket closesif __name__ == '__main__': parser = argparse.ArgumentParser(description=&quot;Use Telnet to login&quot;) parser.add_argument(&quot;hostname&quot;, help=&quot;Remote host to telnet to&quot;) parser.add_argument(&quot;username&quot;, help=&quot;Remote username&quot;) args = parser.parse_args() # Prompt the user for a password without echoing # https://docs.python.org/3/library/getpass.html password = getpass.getpass(&quot;Password: &quot;) main(args.hostname, args.username, password) 注意：这个只是针对 Linux 的连接方法（书上的），现在的很多的服务器不支持23端口的telnet了（尤其是云服务器为了安全就关闭了23端口，改用了22的ssh），所以大部分情况下感觉还是使用 telnet 连接 winserver 的情况多，需要注意的是换行符，不同的系统是不同的，还有一些小的细节问题，比如说 winserver 返回的内容需要用 gbk 来解码等等。 SSH","link":"/2020/10/18/python-web-6/"},{"title":"sprint","text":"双周总结 吐槽 新增计划双周参加一次周赛（你问我为啥不参加单周每次的？ 白天学别的去了） 软工第四周作业，实战图形识别，虽然代码主体是老师给的，不过研究了研究做了小优化提升了一点准确率，还是有点成就感的。 https://www.cnblogs.com/chmod000/p/13909891.html mini os 学不懂了，缓缓 吐槽大三的专业课：软件工程——人工智能导论（不想吐槽了），操作系统——哲学+天书，今天讲装载链接听得我觉得白看了《程序员的自我修养》，完全听不懂在说啥，课本写的也很玄乎，感觉自己不像在学操作系统，像在学操作系统设计的哲学。就拿今天讲装载链接，听完之后还是讲不出来 cpp 咋变成 exe 的，我还不如翻翻之前的读书笔记… LeetCode 刷题记录，个人较菜，慢慢努力进步，做题时随手的记录，这里收录一些有意思的题目。 120. 三角形最小路径和 经典dp问题，倒着算可以省下来很多多余的判断 123456789class Solution: def minimumTotal(self, triangle: List[List[int]]) -&gt; int: if len(triangle) == 1: return min(triangle[0]) for row in range(len(triangle)-2, -1, -1): # 每一行有 row+1 个数 for col in range(row+1): triangle[row][col] += min(triangle[row+1][col], triangle[row+1][col+1]) return triangle[0][0] 1638. 统计只差一个字符的子串数目 暴力，寻找两个字符串中的不相同的字母，然后从这个位置开始左右寻找最大的相同的左右位置，就可以得到由这组不相同的字符生成的不同子字符串个数为(l+1)*(r+1) 暴力天下第一！ 双百解答（可能是因为交的人太少了） 12345678910111213141516def countSubstrings(self, s: str, t: str) -&gt; int: result = 0 for index_s, alpha_s in enumerate(s): for index_t, alpha_t in enumerate(t): # 寻找每一个不相同的数左右扩展比较 if alpha_s == alpha_t: pass else: l = 1 r = 1 while index_s-l &gt;= 0 and index_t-l &gt;= 0 and s[index_s - l] == t[index_t - l]: l += 1 while index_s + r &lt; len(s) and index_t + r &lt; len(t) and s[index_s + r] == t[index_t + r]: r += 1 result += l*r return result 1639. 通过给定词典构造目标字符串的方案数 动态规划，dp[i][j]表示使用前 i 个下标，组成 target 第 j 个字符 dp[i][j]由不使用第 i 个字符就组成这 target 中 j 个字符的个数 + 使用 i-1 个组成了 j-1 个字符，然后使用第i个匹配target第j个字符。 …后面的样例很大，算法优化的不好很容易超时。推荐预先记录一下第 i 位每个字母出现的次数，省略多次循环的不必要计算 可以预处理 words，将 words 各字符串的每一位合并，并计算该位置上每种字符数量，得f[][]数组 123456789101112131415161718192021222324252627def numWays(self, words: List[str], target: str) -&gt; int: alphas = [0 for k in range(26)] MOD = 10**9+7 word_num = len(words[0]) target_num = len(target) dp = [[0]*target_num for i in range(word_num)] num = 0 for word in words: if word[0] == target[0]: num += 1 dp[0][0] = num # dp[0][j&gt;0] = 0无法构成 for i in range(1, word_num): for a in range(26): alphas[a] = 0 # alpha 数组为后面的循环做准备，降低时间复杂度 ss = 0 for word in words: alphas[ord(word[i])-ord('a')] += 1 ss += word[:i+1].count(target[0]) dp[i][0] = ss # 使用前i个字符拼成 target 第 0 个字符的个数 # 超过 word_num 的部分无法匹配出 for j in range(1, min(target_num, word_num)): # words中第 i位中有多少个可以作为 target 第j位的选择 num = alphas[ord(target[j])-ord('a')] dp[i][j] = (dp[i-1][j] + dp[i-1][j-1] * num) % MOD return dp[word_num-1][target_num-1] 6328ms 37.7MB 尝试用评论里的思路优化一下 修改dp[i][j]的含义，改为使用前 i-1 位构成 target 前 j-1 位的方案数 dp[i][0]=1表示target 空字符只有一个构成方法（这样刚好对，不知道为什么这么设置） 优化代码如下： 12345678910111213141516171819202122class Solution: def numWays(self, words: List[str], target: str) -&gt; int: alphas = [0 for k in range(26)] MOD = 10**9+7 word_num = len(words[0]) target_num = len(target) dp = [[0]*(target_num+1) for i in range(word_num+1)] dp[0][0] = 1 for i in range(1, word_num+1): for a in range(26): alphas[a] = 0 # alpha 数组为后面的循环做准备，降低时间复杂度 for word in words: alphas[ord(word[i-1])-ord('a')] += 1 dp[i][0] = 1 # 超过 word_num 的部分无法匹配出 for j in range(1, min(target_num+1, word_num+1)): # words中第 i位中有多少个可以作为 target 第j位的选择 num = alphas[ord(target[j-1])-ord('a')] dp[i][j] = (dp[i-1][j] + dp[i-1][j-1] * num) % MOD return dp[word_num][target_num] 时间2348ms，提升很大（确实这样避开了原方案中dp[i][0]的循环计算） 剑指 Offer 03. 数组中重复的数字 个人代码: 12345678910def find_repeat_number(nums: list) -&gt; int: nums.sort() last = nums[0] for i in range(1, len(nums)): # 统计出现次数大于 2的数字 if nums[i] == last: return nums[i] else: last = nums[i] return -1 思路挺容易想到，先对列表排序，然后找到第一个重复出现的数字就好了，记录一下前一个数字，遍历和列表的元素对比，顺便直接使用 nums[i] == num[i+1] 由于多次取数组元素会导致速度慢。时间复杂度 O(nlogn)，空间复杂度 O(1) 评论提供了更好的思路: 使用字典自带的哈希表来处理，优点是速度快,对于每个元素 hash() 完成后只需要遍历一遍搜索有无重复即可，时间复杂度 O(n)，但需要另外建立n大小的表，空间复杂度 O(n),代码如下 12345678def findRepeatNumber(self, nums: List[int]) -&gt; int: repeat_dict = {} for i in nums: if i in repeat_dict: return i else: repeat_dict[i] = 1 return -1 原地哈希方法，时间复杂度 O(n)，空间复杂度 O(1)，很巧妙。具体做法就是因为题目中给的元素是小于 n-1 的，所以我们可以让位置i的地方放元素i。如果位置 i 的元素不是 i 的话，那么我们就把 i 元素的位置放到它应该在的位置，即 nums[i] 和 nums[nums[i]] 的元素交换，这样就把原来在nums[i]的元素正确归位了。如果发现要正确归位的时候，位置上已经有和自己一样的元素了，说明就重复了。相当于将原列表中每个元素 hash() 到列表索引的位置，由于使用原列表，空间复杂度就很小。 123456789101112def findRepeatNumber(self, nums: List[int]) -&gt; int: for i, v in enumerate(nums): while i != v: # 交换 v_pos = nums[v] if nums[v_pos] == v: return v else: # 将 v 放到属于自己的位置 nums[i] = nums[v_pos] nums[v_pos] = v return -1 剑指 Offer 16. 数值的整数次方 比较重要的一个地方 int 的范围是 -2147483648 到 2147483647，如果对 -2147483648 取绝对值会导致 int 型溢出，而2147483647(01111…1) 溢出后还是 -2147483648(100…0) 需要扩大数据类型。（python表示从不关心这个） 本题涉及到快速幂 快速幂一般处理那种指数爆炸的题目，往往要取余 (a * b) % p = (a % p * b % p) % p 快读幂原理 base^exponent = (base*base)^exponent/2 当指数为 1 时就减去 1 base^exponent = base*(base^exponent-1) 然后还可以重复上面的操作 python 自带的 pow 就是快速幂，用不着自己写（比你写的快） 原理就是降指数，变换为底数的平方 给个 c++的样例写法 12345678910long long fastPower(long long base, long long power) { long long result = 1; while (power &gt; 0) { if (power &amp; 1) {//此处等价于if(power%2==1) result = result * base % 1000; } power &gt;&gt;= 1;//此处等价于power=power/2 base = (base * base) % 1000; } return result; 矩阵快速幂 先贴个代码，太晚了先睡了，原理有空再整出来 123456789101112131415161718192021222324252627def matrix_multiply(a, b): res = [] for i in range(len(a)): rows = [] for j in range(len(a[i])): temp = 0 for k in range(len(a[i])): temp = (temp + a[i][k] * b[k][j]) rows.append(temp) res.append(rows) return resdef matrix_quick_pow(a, n: int): # 单位矩阵 res = [[1 if i == j else 0 for j in range(len(a))] for i in range(len(a))] while n: if n &amp; 1: res = matrix_multiply(res, a) a = matrix_multiply(a, a) n = n &gt;&gt; 1 return res","link":"/2020/11/03/sprint/"},{"title":"runtime-test","text":"一般来说，我们的测试代码是测试自己写的代码，测试模块的功能，但如果我们想自动化测试一个.py文件或者exe程序，就完全不一样了 如何自己写一个简易的测评姬？就是实现自动读取样例和输出样例对比来确定程序是否正确 思路：启动一个子线程，将子线程的输入输出流重定向方便我们获取，然后样例标志答案保存至文件，读取即可。 需要用到Python的subprocess模块 subprocess模块 运行python的时候，我们都是在创建并运行一个进程。像Linux进程那样，一个进程可以fork一个子进程，并让这个子进程exec另外一个程序。在Python中，我们通过标准库中的subprocess包来fork一个子进程，并运行一个外部的程序。 subprocess包中定义有数个创建子进程的函数，这些函数分别以不同的方式创建子进程，所以我们可以根据需要来从中选取一个使用。另外subprocess还提供了一些管理标准流(standard stream)和管道(pipe)的工具，从而在进程间使用文本通信。 subprocess.call() 父进程等待子进程完成 返回退出信息(return code，相当于Linux exit code) subprocess.check_call() 父进程等待子进程完成并返回0 检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性，可用try…except…来检查 subprocess.Popen() 启动一个子线程，它有一个复杂的构造函数 1234567def __init__(self, args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *, encoding=None, errors=None) 经常用到的参数也不多： 参数 解释 args 要执行的shell命令，可以是字符串，也可以是命令各个参数组成的序列。当该参数的值是一个字符串时，该命令的解释过程是与平台相关的，因此通常建议将args参数作为一个序列传递。 bufsize 指定缓存策略，0表示不缓冲，1表示行缓冲，其他大于1的数字表示缓冲区大小，负数 表示使用系统默认缓冲策略。 stdin，stdout 用于重定向标准的流。 shell 该参数用于标识是否使用shell作为要执行的程序，如果shell值为True，则建议将args参数作为一个字符串传递而不要作为一个序列传递。 universal_newlines 不同系统的换行符不同。若True，则该文件对象的stdin，stdout和stderr将会以文本流方式打开；否则以二进制流方式打开。 比较特殊的地方是，我们可以指定使用subprocess.PIPE 并可以利用subprocess.PIPE将多个子进程的输入和输出连接在一起，构成管道(pipe)，这实际就是建立了一块缓冲区 Popen的方法： 函数 解释 Popen.poll() 用于检查子进程是否已经结束。设置并返回returncode属性。 Popen.wait() 等待子进程结束。设置并返回returncode属性。 Popen.send_signal(signal) 向子进程发送信号。 Popen.terminate() 停止(stop)子进程。在windows平台下，该方法将调用Windows API TerminateProcess（）来结束子进程。 Popen.kill() 杀死子进程。 Popen.stdin() 如果在创建Popen对象时，参数stdin被设置为PIPE，Popen.stdin将返回一个文件对象用于向子进程发送指令。否则返回None。 Popen.stdout 类似上 Popen.pid 获取子进程的进程ID。 Popen.returncode 获取进程的返回值。如果进程还没有结束，返回None。 Popen.communicate() 用于获取缓冲区的数据并且避免死锁情况： 如果 stdout或 stderr 参数是 pipe，并且程序输出超过操作系统的 pipe size时，如果使用 Popen.wait() 方式等待程序结束获取返回值，会导致死锁，程序卡在 wait() 调用上。 需要注意的是，communicate获取到的是一个元组，包含stdout和stderr 同时communicate()是Popen对象的一个方法，该方法会阻塞父进程，直到子进程完成，所以不需要wait了 重定向标志流 sys.stdin = 文件流即可 获取文件的路径 使用sys.getcwd(),得到的就是你文件的所在文件夹路径 简单测评姬的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class VirtualTestGirl: &quot;&quot;&quot; 测评姬, 仅供此次爱特国庆作业的测评使用 存在安全问题 &quot;&quot;&quot; def __init__(self, stdin_file_list, code_file_path, q_number): &quot;&quot;&quot; 文件的格式标准: qx_x.txt存储样例 qx_x_out.txt 存储标准输出 :param stdin_file_list:标准输入的文件的文件名列表 :param code_file_path: 待测试的代码的文件的绝对路径 :param q_number: 题目的编号 &quot;&quot;&quot; self.q_number = q_number # 获取绝对路径 absolute_path = (os.getcwd() + '/{}/'.format(q_number)).replace('\\\\', '/') self.stdin_file_list = [absolute_path + x for x in stdin_file_list] self.code_file_path = code_file_path self.error_file = &quot;log.txt&quot; def _test(self, stdin_file): &quot;&quot;&quot; 测试某个样例 :param stdin_file: 标准数据的文件名 :return: &quot;&quot;&quot; error_fp = open(self.error_file, 'a+', encoding='utf-8') fp_in = open(stdin_file) output_path = stdin_file.split('.')[0] + &quot;_out.txt&quot; std_out_fp = open(output_path, encoding=&quot;utf-8&quot;) std_out = std_out_fp.read() std_out_fp.close() error_fp.write(&quot;----测试----\\n&quot;) child_proc = subprocess.Popen(&quot;python {}&quot;.format(self.code_file_path), stdin=fp_in, stdout=subprocess.PIPE, stderr=error_fp) print(&quot;pid:&quot;, child_proc.pid) # 接受子线程的返回 print(child_proc.returncode) # 获取输出 # 主线程等待子线程的完成, 此时会阻塞主线程 out_put = child_proc.communicate()[0].decode(&quot;utf-8&quot;) # 删除文件读出内容结尾的\\r\\n out_put = out_put.rstrip(&quot;\\n&quot;) out_put = out_put.rstrip(&quot;\\r&quot;) out_put = out_put.replace('\\r', '') # print(&quot;标准答案:&quot;, std_out) # print(&quot;测试答案:&quot;, out_put) if out_put == std_out: print(&quot;通过!&quot;) else: if out_put.strip() == std_out.strip(): print(&quot;格式错误&quot;) else: pass print(&quot;未通过&quot;) fp_in.close() error_fp.close() print(&quot;------&quot;) def start_test(self): for stdin_file in self.stdin_file_list: self._test(stdin_file) 需要注意的是，不同平台下的换行符不同，MAC下是\\r， Windows下默认是\\r\\n，Linux下是\\n 有神奇的一个地方是，print函数打印出来的是\\n， 但定向输出到PIPE里然后再读出时变成了\\r\\n（可以split切一下\\n看看会发现每行多了一个\\r），推测为写入内存里的时候发生了替换，因为Windows下是\\r\\n rstrip()会去除字符串末尾的指定字符，而strip()是删去字符串中所有匹配到的指定字符(默认删除\\r\\n)","link":"/2019/09/26/runtime-test/"},{"title":"Start Up Today","text":"2019-5-29 创建了自己的github博客 之前的笔记主要都记在本本上，还有onenote，在同学的“强烈建议”下搞了一个hexo+icarus的博客，稍稍个性化了一下（在Link处加入了Qzone等） 什么时候能读明白这个框架的源码啊QAQ 坚信只要不断努力，自己可以做到自己想做的事 日后会慢慢转移onenote到这里，以及自己笔记本上的东西，顺便再复习一下","link":"/2019/05/28/start-up/"},{"title":"summary-of-2020-autumn","text":"封面：恭喜记录的地平线第三季定档2021，狂喜 😆 发出来才发现不支持 emoji，回来看看能不能配一下吧 2020/12/12 更新，增加了 emoji 支持，参考博客 markdown emoji 2020 年秋学期总结 2020 年要结束了，2020 秋季学期也要结束了，没啥好说的，总结一下过去的这个学期吧 什么？你问为啥没有上半年？上半年在家摸了，荒废了没啥好说的 看了啥书 看完了《程序员的自我修养》 马上看完《浪潮之巅》了（思修课无聊都是那段时间看的） 开始看《一个64位操作系统的设计与实现》，正在学习如何写一个操作系统（还停留在进程创建那里，看的是真的慢） Accel World，实教… 干了点啥 各种专业课实验（这个其实不算） 软工课设，鸟类识别分享交流平台项目，个人负责 CV 模型，从此开始接触炼丹…，个人还是挺喜欢的，学习了 RestNet， VGG， BCNN， Inception， EfficientNet 等一些模型，但大部分都是看了看就直接用别人写好的了，自己其实学到的不多，后来做出来第一版模型后开始返回来读论文，感觉自己离 CV 方向的大门还差点，研究生是打算做人工智能，不一定是 CV，但多学点也不差么，毕竟有些是共通的（其实根本没学明白，哪里来谈共同性？）。客串了前端组（项目前期就我在干前端的活！），为了应用学习了 Vue，超级不系统，基本上是到处 copy，后来好了一点，开始自己写一些代码，自己封装组件，慢慢的也开始熟悉了一点用 Vue 做项目。 小学期国赛准备期间学了很多数学模型和 Python 的科学计算 LeetCode 刷题之旅开始了！漫漫长路，但起码坚持打双周晚周赛吧！算法菜再不学就没救了 打通了 Rance 10 打算接下来（学期末到寒假）干啥 冲分，求保研，拼命考试 假期复习《程序员的自我修养》，起码画思维导图吧，之前还想自己实现点东西的，这个看时间了 《一个64位操作系统的设计与实现》接着看，不着急，但每一大章后做个总结，代码一定要自己照着写然后跑一下 计网自顶而下，和期末考试复习一起食用吧 整理 Python 科学计算的代码，以及自己实现的黄书里面的一些算法和调库的例子，备战美赛 接着刷题，频率最好提高，每天刷不现实，假期能隔几天刷一上午一下午那种感觉就可以 英语听力，磨耳朵，多听吧 为下学期编译原理打打基础吧，可以翻出来 CSAPP 看看了 入坑 Rance 系列！！！（不是） 一点感想？ 接触 CV 感受到了自己有多菜了，终于明白了那些本科都做这个研究的人有多强，尤其是看论文的时候深感自己的数学和英语多差了，海，自己耗子尾汁吧，要补了。但我自己计划也就这学期这门课的时间多学一点了，毕竟不是我当前的目标，保了大四有的是时间学这些，现在就打基础+拼分就好了 😑 😑 😑 😑 😑 总之就是 T5（大三上）努力拉高成绩，T6 结束后直接走夏令营线，T7 保研，然后用空出来大量时间点研究生的技能就好了，希望 A 结局能稳。 你写完了年末总结，感觉自己充满了决心！ ✊","link":"/2020/12/12/summary-of-2020-autumn/"},{"title":"win32-API","text":"C++控制台编程 我们的控制台文本窗口是基于win32 api实现的 我们以例子来学习这种编程的方法： 控制台程序的外观和操作就像MS-DOS窗口一样，控制台有一个输入缓冲区以及一个或多个屏幕缓冲区： 输入缓存区（input buffer）包含一组输入记录（input records），其中每个记录都是一个输入事件的数据。输入事件的例子包括键盘输入，鼠标点击，以及用户调整控制台窗口大小 屏幕缓冲区（screen buffer）是字符与颜色数据的二维数组，他会影响控制台窗口文本的外观 例1： 123456789#include &lt;stdio.h&gt;#include &lt;windows.h&gt;int main(){ printf(&quot;Hello World!\\n&quot;); Sleep(1000); system(&quot;cls&quot;); return 0;} 我们发现这个程序和我们的一般的hello world程序不同，它实现的功能是在1000ms后清空控制台的内容，使用了sleep和system命令。 例2： 12345678#include &lt;windows.h&gt;#include &lt;stdio.h&gt;int main(void){ SetConsoleTitle(L&quot;hello world!&quot;); // 设置窗口标题 printf(&quot;hello world!&quot;); return 0;} 我们的使用了windows.h里的函数，我们想要编写控制台应用肯定需要用到这个库 SetConsoleTitle 用于设置窗口标题，这里L代表宽字符，用L标识的是宽字符，标准的字符是一个字符一个字节，宽的是一个字符两个字节。 用于控制台窗口操作的API函数如下： GetConsoleScreenBufferInfo 获取控制台窗口信息 GetConsoleTitle 获取控制台窗口标题 ScrollConsoleScreenBuffer 在缓冲区中移动数据块 SetConsoleScreenBufferSize 更改指定缓冲区大小 SetConsoleTitle 设置控制台窗口标题 SetConsoleWindowInfo 设置控制台窗口信息 例3： 123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;windows.h&gt;using namespace std;int main(){ HANDLE hOutput = GetStdHandle(STD_OUTPUT_HANDLE); //获取句柄 CONSOLE_SCREEN_BUFFER_INFO bInfo; //声明保存控制台信息结构体指针 GetConsoleScreenBufferInfo(hOutput, &amp;bInfo); // 获取信息 SMALL_RECT rc = {0, 0, 10, 10}; // 坐标位置结构体初始化,分别表示左上右下 SetConsoleWindowInfo(hOutput, true ,&amp;rc); //设置区域坐标 cout &lt;&lt; &quot;窗口显示坐标位置：&quot; &lt;&lt; bInfo.srWindow.Left &lt;&lt; &quot;, &quot; &lt;&lt; COORD dSiz = {80, 80}; //设置coord，表示一个字符在控制台屏幕上的xy坐标 SetConsoleScreenBufferSize(hOutput, dSiz); CloseHandle(hOut); // 关闭标准输出设备句柄 return 0;} GetConsoleScreenBufferInfo(HANDLE hConsoleOutput, CONSOLE_SCREEN_BUFFER_INFO *bInfo) 第一个参数hConsoleOutput参数(标准控制句柄)通过GetStdHandle()函数返回值获得 第二个参数CONSOLE_SCREEN_BUFFER_INFO 保存控制台信息结构体指针 属性如下: COORD dwSize; // 缓冲区大小 COORD dwCursorPosition; //当前光标位置 WORD wAttributes; //字符属性 SMALL_RECT srWindow; //当前窗口显示的大小和位置 COORD dwMaximumWindowSize; //最大的窗口缓冲区大小 若bInfo是一个CONSOLE_SCREEN_BUFFER_INFO类型的结构体，那么访问属性的方法如下： bInfo.srWindow.Top 获取窗口相对于Top位置 bInfo.srWindow.Right 获取窗口相对于Right的位置 bInfo.dSiz.X 获取缓存区的X位置 其余一些原型如下： SetConsoleWindowInfo(HANDLE, BOOL, SMALL_RECT *); SetConsoleScreenBufferSize(HANDLE hConsoleOutput, COORD dwSize) GetConsoleTitle(LPTSTR lpConsoleTitle, DWORD nSize) lpConsoleTitle为指向一个缓冲区指针以接收包含标题的字符串；nSize由lpConsoleTitle指向的缓冲区大小 例4 1234567891011#include &quot;stdafx.h&quot;#include&lt;windows.h&gt;int main() { HWND window; //定义一个窗口句柄变量，用来储存窗口句柄 /*FindWindow(&quot;这里填窗口类名&quot;,&quot;这里填窗口标题名&quot;) 窗口类名和窗口标题名可以只填一个，不填的用NULL填充*/ window = FindWindow(NULL,&quot;文本.txt&quot;); //查找标题为&quot;文本.txt&quot;的窗口 SendMessage(window,WM_CLOSE,0,0); //向窗口发送关闭指令 return 0;} 句柄不用多说，在Windows中，句柄是一个系统内部数据结构的引用。例如当你操作一个窗口时系统会给你一个该窗口的句柄，系统会通知你：你正在操作142号窗口，就此你的应用程序就能要求系统对142号窗口进行操作——移动窗口、改变窗口大小、把窗口最小化等等。 例5 操作文本输出函数有： 12345678910111213141516171819202122232425262728293031323334BOOL FillConsoleOutputCharacter( // 填充指定数据的字符HANDLE hConsoleOutput, // 句柄TCHAR cCharacter, // 字符DWORD nLength, // 字符个数COORD dwWriteCoord, // 起始位置LPDWORD lpNumberOfCharsWritten);// 已写个数BOOL WriteConsole( // 在当前光标位置处插入指定数量的字符HANDLE hConsoleOutput, // 句柄CONST VOID *lpBuffer, // 字符串DWORD nNumberOfCharsToWrite, // 字符个数LPDWORD lpNumberOfCharsWritten, // 已写个数LPVOID lpReserved);// 保留BOOL WriteConsoleOutput( // 向指定区域写带属性的字符HANDLE hConsoleOutput, // 句柄CONST CHAR_INFO *lpBuffer, // 字符数据区COORD dwBufferSize, // 数据区大小COORD dwBufferCoord, // 起始坐标PSMALL_RECT lpWriteRegion );// 要写的区域BOOL WriteConsoleOutputCharacter( // 在指定位置处插入指定数量的字符HANDLE hConsoleOutput, // 句柄LPCTSTR lpCharacter, // 字符串DWORD nLength, // 字符个数COORD dwWriteCoord, // 起始位置LPDWORD lpNumberOfCharsWritten); // 已写个数BOOL ScrollConsoleScreenBuffer( //移动文本位置位置HANDLE hConsoleOutput, //句柄CONST SMALL_RECT* lpScrollRectangle, //裁剪区域CONST SMALL_RECT* lpClipRectangle, //目标区域COORD dwDestinationOrigin, //新的区域CONST CHAR_INFO* lpFill); //填充字符 看例子： 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;windows.h&gt;using namespace std;int main(){ HANDLE hOut = GetStdHandle(STD_OUTPUT_HANDLE); // 获取标准输出设备句柄 WORD wr1 = 0xfa;//定义颜色属性；第一位为背景色，第二位为前景色 SetConsoleTextAttribute(hOut, wr1); cout &lt;&lt; &quot;hello world!&quot; &lt;&lt; endl; WORD wr2 = FOREGROUND_RED | FOREGROUND_INTENSITY;//方法二用系统宏定义颜色属性 SetConsoleTextAttribute(hOut, wr2); cout &lt;&lt; &quot;hello world!&quot; &lt;&lt; endl; //输出文本 SetConsoleTextAttribute(hOut, 0x0f); cout &lt;&lt; &quot;00000000000000000000000000000&quot; &lt;&lt; endl; cout &lt;&lt; &quot;00000000000000000000000000000&quot; &lt;&lt; endl; cout &lt;&lt; &quot;00000000000000000000000000000&quot; &lt;&lt; endl; cout &lt;&lt; &quot;00000000000000000000000000000&quot; &lt;&lt; endl; SMALL_RECT CutScr = {1, 2, 10, 4}; //裁剪区域与目标区域的集合行成剪切区域 SMALL_RECT PasScr = {7, 2, 11, 9}; //可以是NULL，即全区域 COORD pos = {1, 8}; //起点坐标，与裁剪区域长宽构成的区域再与目标区域的集合为粘贴区 //定义填充字符的各个参数及属性 SetConsoleTextAttribute(hOut, 0x1); CONSOLE_SCREEN_BUFFER_INFO Intsrc; GetConsoleScreenBufferInfo(hOut, &amp;Intsrc); CHAR_INFO chFill = {'A', Intsrc.wAttributes}; //定义剪切区域填充字符 ScrollConsoleScreenBuffer(hOut, &amp;CutScr, &amp;PasScr, pos, &amp;chFill); //移动文本 CloseHandle(hOut); // 关闭标准输出设备句柄 return 0;} 由于剪切区域是两个区域的集合，我们第一行到第三行的第7个0到第11个0会被剪掉（前面有2行helloworld），注意，这里的rect的位置为其前面的字符个数或行数 例6 123456789101112131415161718#include &lt;iostream&gt;#include &lt;windows.h&gt;using namespace std;int main(){ cout &lt;&lt; &quot;hello world!&quot; &lt;&lt; endl; Sleep(2000);//延时函数 HANDLE hOut = GetStdHandle(STD_OUTPUT_HANDLE); COORD w = {0, 0}; SetConsoleCursorPosition(hOut, w); CONSOLE_CURSOR_INFO cursorInfo = {1, FALSE}; Sleep(2000); SetConsoleCursorInfo(hOut, &amp;cursorInfo); CursorInfo.bVisible = false; //隐藏控制台光标 Sleep(2000); CloseHandle(hOut); // 关闭标准输出设备句柄 return 0;} 输出hello world！后延时两秒，光标从第二行移到行首，再2秒后光标隐藏不显示，再过2秒程序结束 12345678//设置光标位置SetConsoleCursorPosition(HANDLE hConsoleOutput,COORD dwCursorPosition);//设置光标信息BOOL SetConsoleCursorInfo(HANDLE hConsoleOutput, PCONST PCONSOLE_CURSOR_INFO lpConsoleCursorInfo);//获取光标信息BOOL GetConsoleCursorInfo(HANDLE hConsoleOutput, PCONSOLE_CURSOR_INFO lpConsoleCursorInfo);//参数1：句柄；参数2：CONSOLE_CURSOR_INFO结构体://DWORD dwSize;(光标大小取值1-100)BOOL bVisible;（是否可见) 例7 GetCursorPos和SetCursorPos一组可以获取和设置鼠标的位置 SetCursorPos给一组x，y就可以设置 需要注意的是GetCursorPos： POINT mouse; //用来储存鼠标的x y坐标 GetCursorPos(&amp;mouse); //调用GetCursorPos函数获取坐标值 printf(&quot;%d,%d\\n&quot;,mouse.x,mouse.y); 当要设置控制台光标的时候，使用SetConsoleCursorPosition 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;windows.h&gt;#include &lt;conio.h&gt;using namespace std;HANDLE hOut;//清除函数void cle(COORD ClPos){ SetConsoleCursorPosition(hOut, ClPos); cout &lt;&lt; &quot; &quot; &lt;&lt; endl;}//打印函数void prin(COORD PrPos){ SetConsoleCursorPosition(hOut, PrPos); cout &lt;&lt; &quot;@&quot; &lt;&lt; endl;}//移动函数void Move(COORD *MoPos, int key){ switch(key) { case 72: MoPos-&gt;Y--;break; case 75: MoPos-&gt;X--;break; case 77: MoPos-&gt;X++;break; case 80: MoPos-&gt;Y++;break; default: break; }}int main(){ cout &lt;&lt; &quot;用方向键移动下行输出内容&quot; &lt;&lt; endl; hOut = GetStdHandle(STD_OUTPUT_HANDLE);//取句柄 COORD CrPos = {0, 1};//保存光标信息 prin(CrPos);//打印 //等待键按下 while(1) { if(kbhit()) { cle(CrPos);//清除原有输出 Move(&amp;CrPos, getch()); prin(CrPos); } } return 0;} 例8 读取键盘信息操作 键盘事件通常有字符事件和按键事件，这些事件所附带的信息构成了键盘信息。它是通过API函数ReadConsoleInput来获取的，其原型如下： BOOL ReadConsoleInput( HANDLE hConsoleInput, // 输入设备句柄 INPUT_RECORD lpBuffer, // 返回数据记录 DWORD nLength, // 要读取的记录数 LPDWORD lpNumberOfEventsRead // 返回已读取的记录数 ); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#include &lt;windows.h&gt;#include &lt;stdio.h&gt;int main(void){ // 获取标准输入输出设备句柄 HANDLE hOut = GetStdHandle(STD_OUTPUT_HANDLE); HANDLE hIn = GetStdHandle(STD_INPUT_HANDLE); DWORD dwRes, dwState=0; INPUT_RECORD keyRec; COORD crHome={0, 0}, crPos; bool bCaps, bNum, bScroll; char ch; CONSOLE_SCREEN_BUFFER_INFO bInfo; // 输出三个灯的初始状态 printf(&quot;状态：CAPS LOCK:CLOSE NUM LOCK:CLOSE SCROLL LOCK:CLOSE\\n&quot;); while (1) // 消息循环 { ReadConsoleInput(hIn, &amp;keyRec, 1, &amp;dwRes); if (keyRec.EventType == KEY_EVENT) { // 只在按下时判断，弹起时不判断 if (keyRec.Event.KeyEvent.bKeyDown) { // 当三个灯的状态发生改变 if (dwState != keyRec.Event.KeyEvent.dwControlKeyState) { dwState = keyRec.Event.KeyEvent.dwControlKeyState; bCaps = bNum = bScroll = false; // 判断三个灯是否有亮 if (dwState &amp; CAPSLOCK_ON) { bCaps = true; } if (dwState &amp; NUMLOCK_ON) { bNum = true; } if (dwState &amp; SCROLLLOCK_ON) { bScroll = true; } // 得到控制台信息（包括输出前光标的位置） GetConsoleScreenBufferInfo(hOut, &amp;bInfo); SetConsoleCursorPosition(hOut,crHome); // 输出三个灯的状态 printf(&quot;状态：CAPS LOCK:%s NUM LOCK:%s SCROLL LOCK:%s\\n&quot;, bCaps?&quot;OPEN &quot;:&quot;CLOSE&quot;, bNum?&quot;OPEN &quot;:&quot;CLOSE&quot;, bScroll?&quot;OPEN &quot;:&quot;CLOSE&quot;); // 还原光标位置 SetConsoleCursorPosition(hOut, bInfo.dwCursorPosition); } // -- 基础功能键 switch(keyRec.Event.KeyEvent.wVirtualKeyCode) { case VK_RETURN: // 按回车时跳到下一行 printf(&quot;\\n&quot;); break; case VK_SPACE: // 按空格时输出一个空格 printf(&quot; &quot;); break; case VK_BACK: // 按删除时删掉一个字符(只能当前行操作) GetConsoleScreenBufferInfo(hOut, &amp;bInfo); crPos = bInfo.dwCursorPosition; if (crPos.X!=0) { crPos.X -= 1; } SetConsoleCursorPosition(hOut,crPos); printf(&quot; &quot;); SetConsoleCursorPosition(hOut,crPos); break; case VK_ESCAPE: // 按ESC键时退出 CloseHandle(hOut); // 关闭标准输出设备句柄 CloseHandle(hIn); // 关闭标准输入设备句柄 return 0; default: break; } // -- 打印字符 ch = keyRec.Event.KeyEvent.uChar.AsciiChar; // 输出可以打印的字符（详参ASCII表） if (ch&gt;0x20 &amp;&amp; ch&lt;0x7e) { putchar(ch); } } } } return 0;} EventType有5种，当要使用键盘事件时，应该先判断 EventType 是否为 KeyEvent，然后使用 KEY_EVENT_RECORD，判断现在的键盘是什么情况。其他事件也是一样的（一般只使用键盘和鼠标事件） FOCUS_EVENT KEY_EVENT // 键盘事件 MENU_EVENT MOUSE_EVENT // 鼠标事件 WINDOW_BUFFER_SIZE_EVENT 键盘的结构如下： typedef struct _KEY_EVENT_RECORD { BOOL bKeyDown; // TRUE表示键按下，FALSE表示键释放 WORD wRepeatCount; // 按键次数 WORD wVirtualKeyCode; // 虚拟键代码 WORD wVirtualScanCode; // 虚拟键扫描码 union { WCHAR UnicodeChar; // 宽字符 CHAR AsciiChar; // ASCII字符 } uChar; // 字符 DWORD dwControlKeyState; // 控制键状态 }KEY_EVENT_RECORD; 所以当我们想要打印字符的时候，就使用 12345ch = keyRec.Event.KeyEvent.uChar.AsciiChar;// 输出可以打印的字符（详参ASCII表）if (ch&gt;0x20 &amp;&amp; ch&lt;0x7e){ putchar(ch);}","link":"/2019/08/24/win32-API/"},{"title":"unit-test","text":"自动化测试 不同于C和Java等语言编写的程序，Python只有在运行中才会检查一些错误，因此只有在运行和测试程序时，才会知道它是否能够正常的运行。 为了解决这个问题，就有了用于测试，调试和探查Python代码的技术和库模块。 文档字符串和doctest模块 如果函数，类，模块的第一行是一个字符串，那么这个字符串就是文档字符串，当调用help（）时，这些文档将会展示出来。 由于程序员倾向于在交互式shell中进行试验时查看文档字符串，所以这些字符串中通常会包含简短的交互式例子 splitter.py12345678910111213141516171819def split(line, types=None, delimiter=None): &quot;&quot;&quot;Splits a line of text and optionally performs type conversion. For example: &gt;&gt;&gt; split('GOOG 100 490.50') ['GOOG', '100', '490.50'] &gt;&gt;&gt; split('GOOG 100 490.50', [str, int, float]) ['GOOG', 100, 490.5] By default, splitting is performed on whitespace, but a different delimiter can be selected with the delimiter keyword argument: &gt;&gt;&gt;split('GOOG,100,490.50', delimiter=',') ['GOOG', '100', '490.50'] &gt;&gt;&gt; &quot;&quot;&quot; fields = line.split(delimiter) if types: fields = [ty(val) for ty, val in zip(types, fields)] return fields 上面这个demo中，封装了一下Python的split函数，使其可以直接在切完后进行类型转换，就写了一个文档来告诉看这个代码或者使用help的程序员 但这样存在一个问题，如果忘记更改这个文档字符串了怎么办？可以使用doctest模块来解决这个问题。我们可以新建一个.py文件来测试它，或者直接测试本身 123456789# 新开文件测试import splitterimport doctestnfail, ntests = doctest.testmod(splitter) # 指定模块上运行测试# 直接测试本身if __name__ == '__main__': import doctest doctest.testmod() doctest要求函数输出与从交互解释器得到的输出完全一致，所以需要特别重视精度问题 单元测试和unittest模块 对于更全面的程序测试，可以使用unittest模块来进行测试。如果进行单元测试，开发人员会为程序每个组成元素（函数，类，方法，模块）编写独立的测试案例。然后运行这些测试来组成更大的测试框架和工具 我们试着编写单元测试来测试我们封装的split(）函数 testsplitter123456789101112131415161718192021222324252627import unittestimport splitterclass TestSplitterFunction(unittest.TestCase): def setUp(self) -&gt; None: # 执行设置操作 pass def tearDown(self) -&gt; None: # 执行清除操作 pass def test_simple_string(self): r = splitter.split('GOOG 100 490.50') self.assertEqual(r, ['GOOG', '100', '490.50']) def test_type_convert(self): r = splitter.split('GOOG 100 490.5', [str, int, float]) self.assertEqual(r, ['GOOG', 100, 490.50]) def test_delimiter(self): r = splitter.split('GOOG,100,490.50', delimiter=',') self.assertEqual(r, ['GOOG', '100', '490.50'])if __name__ == '__main__': unittest.main() 运行时完毕得到了这样的结果，说明样例的测试成功 Ran 3 tests in 0.003s OK unittest的基本使用包括定义一个继承自unittest.TestCase的类，这个类中，各种测试由以名称test开头的方法定义，如上面的函数（可以随意命名，但必须是以test来开头），在各个测试中，使用断言来检查不同的条件 经常使用的是unittest.TestCase的实例t的以下方法 123456789101112131415161718192021222324252627282930# 在运行任何测试方法前, 调用它来执行设置步骤t.setUp()# 在运行测试之后，调用它来执行清除操作t.tearDown()# 比较是否相等t.assertEqual(expr [, msg])# 如果expr的计算结果为false，发出提示msgt.failUnless(expr [, msg])# x,y不相等就测试失效t.faillIfEqual(x, y [, msg])t.assertNotEqual(x, y [, msg])# 如果数字x和y未包含在对方的places小数位中, 则表明测试失败t.faillIfAlmostEqual(x, y [,places [, msg]])t.assertNotAlmostEqual(x, y [,places [, msg]])# 如果可调用对象callable未引发异常exc,表示测试失效。可以使用元组传递多个异常类型t.assertRaises(exc, callable, ...)t.failUnlessRaises(exc, callable, ...)# 当expr的布尔值为true时表示测试失效t.failIf(expr [, msg])# 表明测试失败t.fail([msg]) 调优与优化 进行计时测量 如果只是想要对长时间运行的Python程序进行计时，最简单的方法通常是在UNIX time等命令的控制下运行它。如果需要对一组长时间运行的语句进行计时，可以插入time.clock()的调用来获取CPU时间的最新读数，或者插入time.time()的调用来读取最新的时钟时间 当然如果仅仅想对一个特定的语句进行测试，可以使用timeit模块的timeit(code [, setup])函数 如: 12345&gt;&gt;&gt; from timeit import timeit &gt;&gt;&gt; timeit('math.sqrt(2.0)', 'import math')&gt;&gt;&gt; 0.1086882&gt;&gt;&gt; timeit('sqrt(2.0)', 'from math import sqrt')&gt;&gt;&gt; 0.09106120000000217 setup语句用于设定环境，该函数会报告执行时间（使用默认执行次数），当然使用number=count参数也可以自己指定测试的重复次数 进行内存测量 sys模块有getsizeof()函数，用于分析各个Python对象内存的占用（以字节为单位） 123456789&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.getsizeof(1)28&gt;&gt;&gt; sys.getsizeof(&quot;Hello World&quot;)60&gt;&gt;&gt; sys.getsizeof([1,2,3,4])96&gt;&gt;&gt; sum(sys.getsizeof(x) for x in [1,2,3,4])112 对于列表和元组，字典等容器，报告的大小只是容器对象本身的大小，而不是容器中包含的所有对象的累计大小。 getsizeof()只是粗略的计算内存使用量，而在内部，解释器会通过引用计数来频繁的共享对象，所以消耗的实际内存会比想象中的小。 ps：为什么int型有28个字节 参考 int 类型在python中是动态长度的。因为python3中int类型是长整型，理论支持无限大的数字，但它的结构其实也很简单, 在 longintepr.h 中定义： 1234struct _longobject { PyObject_VAR_HEAD digit ob_digit[1];}; 这结构是什么意思呢，重点在于 ob_digit 它是一个数组指针。digit 可认为是 int 的别名。python的整型存储机制是这样的。比方要表示一个很大的数: 123456789 。而每个元素最大只能表示3位十进制数（为理解打的比方）。那么python就会这样存储： 123ob_digit[0] = 789ob_digit[1] = 456ob_digit[2] = 123 低位存于低索引下。python中整型结构中的数组，每个元素最大存储 15 位的二进制数（不同位数操作系统有差异32位系统存15位，64位系统是30位）。 因此，sys.getsizeof(0) 数组元素为0。此时占用24字节（PyObject_VAR_HEAD 的大小）。 sys.getsizeof(456) 需使用一个元素，因此多了4个字节。 反汇编 dis模块可以将Python函数，方法，类反汇编为低级的解释器指令。使用dis模块的dis()函数 调优策略 使用__slot__来限制实例内存 尽量避免使用(.)进行属性查找, 比较常用的是当大量使用某个库的某个函数是，from xxx import xx而非import xxx, 使用xxx.xx来访问 避免对常见情况使用异常，使用if来规避异常，使用异常来处理不常见的情况 鼓励函数式编程和迭代，多使用列表推导，生成器表达式，生成器，协程，闭包。手动迭代数据往往不如使用列表推导和生成器 使用装饰器和元类用于修改函数和类","link":"/2019/09/17/unit-test/"},{"title":"winter-2021","text":"诈尸 操作系统考炸了没心情。 记下没填出来的空，也没啥用 操作系统是一组：能有效组织和管理四大资源的，合理地对各类作业进行调度和控制的，方便用户使用计算机的软件。 对于用户，文件系统实现按名存取 嗳，就考你背诵，写不上，那你操作系统学了点啥（老师你讲了啥（笑））！！！以上是内心活动 来规划一下寒假做啥 目标 在 2 月 23 左右开学的时候来 check [x] 考完试平安到家（其实这仅仅是个 checkbox 的测试，写的这天没考完也没到家） ai+x blending courses [] 课听完 [] 每个 Module 整理笔记，写全英的博客 [] Live Session 整理讲的内容，尽可能反复听，最后整理一篇出来 CV [] 图形学教材老师推荐的整一本看，能看多少算多少吧 计科 [] 龙书看起来，算是提前预习，至少看 3-4 章吧 [] 自己动手写一个 64 位操作系统接着看，基础部分必须看完 + 内容整理完 [] 尝试实践自己在程序员的自我修养书中学到的编译链接的知识 其他 准备夏令营 [] 简历 [] 自我介绍（中+英） [] 项目（中+英） [] 下学期给社团新生讲课的 PPT [] 整理数学建模学到的知识 日志 假期有啥想写的了（感想啥的）放这里","link":"/2021/01/16/winter-2021/"},{"title":"程序员的自我修养——温故而知新","text":"开新坑，记录我学习《程序员的自我修养》这本书的笔记，加上自己的实践和好的例子 更新不会很快，大二太忙了 配合计算机系统基础这门专业课程一起学习 引言 《程序员的自我修养》这本书讲的主要是操作系统内核，装载，链接等一些技术，理解操作系统如何让一段代码工作起来，如何让不同的二进制模块协同工作。 你可以不自己造轮子，但你应该了解轮子的构造，而且越详尽越好，这就是程序员的自我修养吧。————《程序员的自我修养》 推荐书籍 《深入理解计算机系统》（Computer System A Programmer’s Perspective, Randal E. Bryant和David O’Halaron著） 《Advanced Programing in the UNIX Environment, Second Edition》（UNIX程序设计的“圣经”） 温故而知新 hello.c123456#include &lt;stdio.h&gt;int main(){ printf(&quot;Hello World\\n&quot;); return 0;} 思考下面问题： 程序为什么要编译后才能运行？ 编译器在把C语言变成可执行的机器码中做了什么？怎么做的？ 最后编译出来的可执行文件里面时是什么？除了机器码还有什么？它们怎么存放？怎么组织？ #include &lt;stdio.h&gt;是什么意思，C语言库是什么？怎么实现的？ 不同的编译器（Microsoft VC，GCC）和不同的硬件平台（x86，SPARC，MIPS，ARM）以及不同的操作系统（Windows，Linux，UNIX）最终编译出来的结果一样吗？为什么？ Hello World程序怎么运行起来的？操作系统如何装载它？从哪里开始执行？到哪儿结束？main函数之前发生了什么，结束之后又发生了什么？ 没有操作系统，Hello World可以实现吗？如果要在一台没有操作系统的机器上运行Hello World需要什么？怎么实现？ printf怎么实现？它为什么可以有不定量的参数？为什么可以在终端上输出字符串？ Hello World程序在运行时，它在内存中是什么样子的？ 等到看完整本书后，再次提问自己这些问题，再次给出解答 ，这里记录一下目前我的理解，不一定正确： 1.CPU无法识别高级语言，需要经过“虚拟机”来将高级语言转化为机器语言，编译就是为了实现这个转化的一部分（高级到汇编） 4.由于不同的CPU的指令集架构不同（如x86和arm），所以编译处出来的汇编代码不一样 8.printf把要打印的参数压栈，一个一个取出来，由CPU控制传输给显示屏幕，在对应的位置打印出字符，如果为汉字，将打印字符点阵（如何在对应位置打印不了解） 计算机硬件 南北桥 早期的计算机没有复杂的图形功能，CPU的核心频率不高，和内存的频率一样，它们都是直接连接在同一个总线（Bus）上。为了协调I/O设备与总线之间的速度，也为了能够让CPU能够和I/O设备进行通信，一般每个设备都会有一个相应的I/O控制器。 后来由于CPU核心频率的提升，导致内存跟不上CPU的速度，于是产生了和内存频率一致的系统总线，而CPU采用倍频的方式与系统总线进行通信。为了协调CPU，内存和高速的图形设备，人们专门设计了一个高速的北桥芯片（Northbridge，PCI Bridge），以便它们之间能够高速地交换数据。 由于北桥运行的速度比较高，对于低速数据，人们专门设计了南桥芯片（Southbridge）磁盘，USB，键盘，鼠标等设备都连在南桥上。 SMP与多核 由于工艺的限制，CPU频率在短时间里不会有很高的提高余地。于是人们就想办法从另一个角度来提高频率：增加CPU的数量。很早以前就有了多CPU的计算机，其中最常见的一种形式就是对称多处理器（SMP，Symmetrical Muti-Processing），简单来讲就是每个CPU在系统中所处地位和发挥的功能都是一样的，是相互对称的。多核的处理器应用最多的是在商用服务器和需要处理大量计算的环境，而在个人电脑中，它们共享一个缓存部件，打包成一个处理器，这就是多核处理器（Muti-core Processor） 计算机软件体系结构 计算机系统软件体系结构采取一种层的结构，就是我们所说的应用层，系统层，硬件层。每个层之间需要相互通信，有协议去规范，这就称为接口（Interface）。 开发工具和应用程序–调用–&gt;应用程序接口（Application Programming Interface，运行库提供） 如Win32，Linux下Glibc库提供POSIX的API 运行库–调用–&gt;系统调用接口（System call Interface，操作系统提供） 系统调用接口在现实中往往以**软件中断（Software Interrupt）**的方式提供，如Linux使用0x80号中断作为系统调用接口 操作系统 操作系统的一个功能就是提供抽象的接口，另一个就是管理硬件资源 CPU 多道程序 早期的时候，为了让CPU等待的时间有事干，人们编写了一个监控程序，当某个程序暂时无需使用CPU时，监控程序就把另外一个等待CPU资源的程序启动，这被称为多道程序（Multiprogramming），虽然使得CPU得到充分利用，但任务调度没有轻重缓急，有些程序紧急需要CPU来完成一些任务，有时会需要等上很长时间。 分时系统 每个程序运行一段时间以后都主动让出CPU给其他程序，使得一段时间内每个程序都有机会运行一小段时间。这种程序协作模式就叫分时系统（Time-Sharing System）。但如果一个程序在进行一个很耗时的计算，或者进入死循环，那么操作系统也没办法，其他程序都只有等着。 多任务系统 多任务（Multi-tasking） 系统中，操作系统接管了所有的硬件资源，并且本身运行在一个受硬件保护的级别。所有的应用程序都以 **进程（Process）**的方式运行在比操作系统权限更低的级别，每个进程都有自己的独立的地址空间，使得进程之间的地址空间相互隔离。 CPU由操作系统统一分配，每个进程根据优先级都有机会获得CPU，但是如果运行时间超出了一定的时间，操作系统会暂停该进程，将CPU资源分配给其他等待运行的进程。这种CPU分配方式叫做抢占式（Preemptive） 当操作系统分给每个进程的时间都很短，即CPU在多个进程之间快速切换，从而造成很多进程都在同时运行的假象。 设备驱动 操作系统作为硬件层的上层，它是对硬件的管理和抽象。对于操作系统上面的运行库和应用程序来说，它们希望看到的是一个统一的硬件访问模式。作为应用程序的开发者，它们不希望在开发应用程序时直接做读写硬件接口，处理硬件中断等繁琐的事。由于硬件之间千差万别，这时候就需要一种统一的接口。 当成熟的操作系统出现以后，硬件逐渐被抽象成了一种概念。在UNIX中，硬件设备的访问跟访问普通的文件形式一样，而在Windows中，图形硬件被抽象成了GDI，声音和多媒体设备被抽象成了DirectX，磁盘被抽象成了普通的文件系统。硬件的细节全部由操作系统中的**硬件驱动（Device Driver）**程序来完成。 驱动可以看做是操作系统的一部分，它往往和操作系统内核一起运行在特权级。 以文件读写为例： 文件系统这个操作系统中最重要的组成部分之一，文件系统管理着磁盘中文件的存储方式，比如我们在Linux系统下有一个文件/home/user/test.dat，长度为8000字节，那么创建这个文件的时候，Linux的ext3文件系统可能将这个文件安照这样的方式存储： 文件的前4096字节存储在磁盘的1000号扇区到1007扇区，每个扇区512字节，8个扇区刚好4096字节，文件的第4097个字节到第8000个字节存储在磁盘的2000号扇区到2007号扇区，没存满的扇区剩余字节无效。 关于硬盘的结构 硬盘的基本存储单位为扇区（Sector），每个扇区512字节。一个硬盘往往有多个扇片，每个盘片分2面，每面按照同心圆划分为若干个磁道（通常说的硬盘坏道就是这个道），每个磁道划分为若干的扇区。 如有一个硬盘有2个盘片，每个盘片分65536（2^16）个磁道，每个磁道分1024个扇区，则容量就是2 * 2 * 65536 * 1024 * 512 = 128GB 当我们在Linux系统下想要读取文件时，就会使用一个read的系统调用，文件系统受到read的时候，判断文件的字节的位置，就向硬盘驱动发出一个读取逻辑扇区的命令，驱动再向硬盘发出硬件命令（方式有很多，最常见的是读写I/O端口寄存器来实现。CPU的in和out指令来实现对端口的读写） 内存 如何将计算机上有限的物理内存分给多个程序？如果简单的按照把ab的内存分给一个程序，bc的内存分给另一个程序，会造成如恶意修改别的程序的内存等问题。 这时候我们就需要加一层中间层————虚拟地址（virtual Address），然后通过一些映射来将虚拟地址转换为实际的物理地址。达到地址空间隔离。 分段（Segmentation） 基本思路就是映射程序需要的内存空间到某个地址空间 当程序A试图访问超出虚拟地址的别的区域，那么硬件就会判断这是一个非法请求，并报告给操作系统或监控程序。 分页（Paging） 仅仅分段仍存在效率问题，若程序只是频繁的使用一小部分数据，没有必要每次读写所有的数据。为了解决效率问题，就创造了分页的方法，简单来说就是更小粒度的分割和映射。 在学习汇编的时候简单了解过，分页就是把地址空间人为的分成固定大小（一般为4K）的页。每次系统装载一定的页（页里有代码和数据），当该页的代码或数据不活跃时，系统便会把他们替换掉，加载立即请求的代码和数据。 以下图为例： 当我们把进程的虚拟地址空间按页分割，把常用的数据和代码装载到内存中，把不常用的代码和数据保存在磁盘里，当需要用到的时候再把它从磁盘里读出来。 我们假设有两个进程 Process1 和 Process2，它们进程中的部分虚拟页面被映射到了物理页面，比如VP0，VP1和VP7映射到PP0，PP2，PP3（PP，physical page）。（VP virtual page）而部分页面仍在磁盘中，比如VP2和VP3位于磁盘中的DP0和DP1中（DP，disk page），另外有些页面如VP4，VP5和VP6可能尚未被用或访问到。 当进程需要VP2和VP3时，硬件会捕获这个消息，就是所谓的页错误（Page Fault），然后操作系统接管进程，负责将VP2和VP3从磁盘中读出来并且装入内存，然后将内存中的这两个页与VP2和VP3之间建立映射。 当然，分页也有一个好处就是保护 简单来说就是为每个页设置权限属性，只有操作系统有权限修改这些属性，这样就保护了进程和数据。 线程（Thread） 有时也称轻量级进程（Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针（PC），寄存器集合和堆栈组成。 线程访问权限 线程私有 线程共享（进程所有） 局部变量 全局变量 函数参数 堆上的数据 TLS（Thread Local Storage）数据 函数里的静态变量 程序代码 打开的文件，A线程打开的文件可以由B线程读写 线程调度 处于运行中的线程拥有一段可以执行的时间，这段时间成为时间片（Time Slice），当时间片用尽的时候，该进程将进入就绪状态。如果时间片用尽之前进程就开始等待某事件，那么他将进入等待状态。每当一个线程离开运行状态时，调度系统就会选择一个其他的就绪的线程继续执行。 通常情况下，频繁地进入等待状态（进入等待状态，会放弃之后仍然可占用的时间份额）的线程（例如处理I/O的线程）比频繁进行大量计算，以至于每次都要把时间片用尽的线程要受欢迎得多。频繁等待的线程会占用很少的时间，CPU也喜欢捏软柿子。 我们把频繁等待的线程称为IO密集型线程（IO Bound Thread），而把很少等待的线程称为CPU密集型线程（CPU Bound Thread）。IO密集型线程总是比CPU密集型线程容易得到优先级的提升。 在优先级调度的环境中，线程的优先级改变一般有三种方式： 用户指定优先级 根据进入等待状态的频繁程度提升或者降低优先级 长时间得不到执行而提升优先级（防止线程被饿死（Starvation）） 可抢占线程和不可抢占线程 线程用尽时间片之后会被强制剥夺继续执行的权利，而进入就绪的状态，这个过程叫做抢占（Preemption），即之后执行的线程抢占了当前的线程。 Windows对进程和线程的实现十分标准，Windows内核有明确的线程和进程的概念。在Windows API中，你可以使用CreateProcess和CreateThread来创建进程和线程，并且有一系列的API来操纵。而对于Linux来说，并没有真正意义的线程概念。Linux将所有的执行实体都称为任务（Task） 线程安全 竞争与原子操作 对于一些体系，++i的实现方法会如下： 1.读取i到某个寄存器X 2.X++ 3.将X的内容存储回i 这样就会存在问题：由于不只有一条命令，因此在多线程环境中很有可能只执行了一半就被调度系统打断，去执行别的代码。 我们把单指令的操作称为原子的（Atomic），单条指令是不会被打断的。很多体系结构都提供了一些常用的原子操作指令，如i386就有一条inc指令可以直接增加一个内存单元值。 原子操作指令对于复杂的数据结构操作十分麻烦，就需要更加通用的手段 同步与锁 为了避免多个线程同时读写一个数据产生不可预料的后果，我们要将各个线程对于同一个数据的访问同步（Synchronization），所谓同步，即指在一个线程访问数据未结束时，其他线程不得对同一个数据进行访问。 同步的最常见方式是使用锁（Lock）。锁是一种非强制机制，每个线程在访问数据或资源之前首先试图**获取（Acquire）锁，并在访问结束后释放（Release）**锁。在锁已经被占用时试图获取锁，线程会等待，直到锁重新可用。 二元信号量 **二元信号量（Binary Semaphore）**是一种最简单的锁，它只有两种状态：占用与非占用。它适合只能唯一一个线程独占访问的资源。当二元信号量处于非占用的状态时，第一个试图获取该二元信号量的线程会获得该锁，并将二元信号重置为占用状态，此后其他所有试图获取该二元信号量的线程将会等待，直到该锁被释放。 对于允许多个线程并发访问的资源，多元信号量简称信号量（Semaphore），它是一个很好的选择。一个初始值为N的信号量允许N个线程并发访问。线程访问资源的时候首先获取信号量，进行如下操作。 将信号量的值减1 如果信号量的值小于0，则进入等待状态，否则继续执行 访问完后，线程释放信号量，进行如下操作 将信号量的值加1 如果信号量的值小于1，唤醒一个等待中的线程 互斥量 **互斥量（Mutex）**和二元信号量很相似，资源仅允许一个线程访问，但和信号量不同的是，信号量在整个系统可以被任意线程获取并释放，也就是说，同一个信号量可以被系统中的一个线程获取之后由另一个线程释放。而互斥量则要求哪个线程获取了互斥量，哪个线程就要负责释放这个锁，其他线程无法释放。 临界区 临界区（Critical Section），在术语中，把临界区的锁的获取称为进入临界区，而把锁的释放称为离开临界区。临界区的作用范围仅限于本进程，其他的进程无法获取该锁。而互斥量和信号量在系统的任何进程里都是可见的 读写锁 **读写锁（Read-Write Lock）**致力于一种更加特定的场合同步。对于一段数据，多个线程可以同时读取，但一段时间内仅有一个线程可以去写。如果使用上述的类型会显得十分低效。读写锁可以避免这个问题。对于同一个锁，读写锁有两种获取方式：共享的（Shared）或者独占的（Exclusive） 读写锁状态 以共享方式获取 以独占方式获取 自由 成功 成功 共享 成功 等待 独占 等待 等待 条件变量 **条件变量（Condition Variable）**作为一种同步手段，作用类似于一个栅栏。对于条件变量，线程可以有两种操作，首先可以被多个线程等待。其次，线程可以唤醒条件变量，此时某个或所有等待此条件变量的线程都会被唤醒并继续支持。也就是说，使用条件变量可以让多线程一起等待某个事件的发生，然后一起恢复执行 可重入与线程安全 一个函数被可重入（Reentrant），表示这个函数没有被执行完成，由于外部因素或内部调用，又一次进入该函数的执行。一个函数被重入，只有两种情况： (1)多个线程同时执行这个函数 (2)函数自身（可能是经过多层调用之后）调用自身 一个函数要成为可重入的，必须有下面的几个特点： 不使用任何（局部）静态或全局的非静态非const变量 不返回任何（局部）静态或全局的非const变量的指针 仅依赖于调用方提供的参数 不依赖任何单个资源的锁（mutex等） 不调用任何不可重入的函数 过度优化 过度优化往往发生在： 编译器为了提高速度把变量缓存在寄存器中而不回写导致即使正确使用了锁也会有线程的修改被抹除 编译器为了提高执行效率而交换了两条毫不相干的相邻指令，如下： 1234x = y = 0Thread1 Thread2x = 1; y = 1;r1 = y; r2 = x; 虽然看上去r1和r2不肯能同时为0，但编译器的优化可能导致指令顺序的交互，成了下面这样: 1234x = y = 0Thread1 Thread2r1 = y; y = 1;x = 1; r2 = x; 可以使用volatile关键字来试图阻止过度优化 但对CPU的动态调整调度顺序并没有办法 如下面这个典型的例子： Singleton_doubleCheck1234567891011volatile T* pInst = 0;T* getInstance(){ if (pInst == NULL){ lock(); if (pInst == NULL){ pInst = new T; } unlock(); } return pInst;} 说明： 构造时上锁，确保只有一个实例被构造出来，否则并非时会导致构造了多个实例。 最外面多一层if判断是为了优化，如果没有，每次调用获取实例的时候都会上锁，导致效率的降低。 但实际上这样的代码是有问题的，问题来源于CPU乱序执行。C++的new包含2个步骤： (1) 分配内存 (2) 调用构造函数 所以pInst = new T包含了3个步骤： (1) 分配内存 (2) 调用构造函数 (3) 将内存的地址赋给pInst 这3步中（2）和（3）的顺序可以颠倒，所以完全可能出现这样的情况：pInst已经指向了内存块但构造仍未完成，这时有个线程调用getInstance()，就会导致错误的发生。 解决这个问题需要使用CPU的一个barrier指令，在不同的体系结构中他的名字可能不相同，但它会阻止CPU把在此之前的指令交换到这之后。 Singleton_doubleCheck1234567891011121314#define barrier() __asm__ volatile (&quot;lwsync&quot;)volatile T* pInst = 0;T* getInstance(){ if (pInst == NULL){ lock(); if (pInst == NULL){ T* temp = new T; barrier(); pInst = temp; } unlock(); } return pInst;} 多线程内部情况 一对一模型：一个用户使用的线程对应唯一一个内核使用的线程，一个线程阻塞不会影响其他的 多对一模型：多个用户的线程映射到一个内核使用的线程上，线程切换由用户的代码来进行 多对多模型：多个用户的线程映射到少数但不止一个内核线程上 写在后面 第一章的理论知识好多啊，整理的时间比我想象的多了好久，才不是鸽子精","link":"/2019/10/06/Linkers-Loaders-1/"},{"title":"程序员的自我修养—目标文件里有什么","text":"2020.2.2 更新补充内容 迟到的更新 在开始这一章之前，先复习一下gcc的操作 复习 -c 只编译，不链接成为可执行文件。编译器只是由输入的 .c 等源代码文件生成 .o 为后缀的目标文件，通常用于编译不包含主程序的子程序文件。 -o output_filename 确定输出文件的名称为output_filename。同时这个名称不能和源文件同名。如果不给出这个选项，gcc就给出默认的可执行文件 a.out -g 产生符号调试工具（GNU的 gdb）所必要的符号信息。想要对源代码进行调试，就必须加入这个选项。 -O 对程序进行优化编译、链接。采用这个选项，整个源代码会在编译、链接过程中进行优化处理，这样产生的可执行文件的执行效率可以提高。 -O2 比 -O 更好的优化编译、链接。当然整个编译链接过程会更慢。 -E 预编译后停下来，生成后缀为 .i 的预编译文件。 -c 编译后停下来，生成后缀为 .o 的目标文件。 -S 汇编后停下来，生成后缀为 .s 的汇编源文件。 整体来看的话： 第一步：进行预编译，使用 -E 参数 gcc -E test.c -o test.i 查看 test.i 文件中的内容，会发现 stdio.h 的内容确实都插到文件里去了，而其他应当被预处理的宏定义也都做了相应的处理。 第二步：将 test.i 编译为目标代码，使用 -c 参数 gcc -c test.c -o test.o 第三步：生成汇编源文件 gcc -S test.c -o test.s 第四步：将生成的目标文件链接成可执行文件 gcc test.o - o test 目标文件里有什么 目标文件的格式 现在PC平台流行的**可执行文件格式（Executable）**主要是Win下的PE（Portable Executable）和Linux下的ELF（Executable Linkable Format），它们都是COFF（Common File Format）格式的变种。而目标文件就是源代码编译后但未链接的中间文件。 不光是可执行文件按照可执行文件格式存储。动态链接库（DLL，Dynamic Linking Library）如Win下的.dll，Linux下的.so 文件也按照可执行文件格式存储。但静态链接库稍稍有些不同，它是把很多目标文件捆绑在一起形成一个文件，再加上一些索引，可以简单的理解为一个包含有很多的目标文件的文件包。 ELF文件类型 说明 实例 可重定文件（Relocatable File） 这类文件包含了代码和数据，可以被用来链接生成可执行文件或共享目标文件，静态链接库可以归在这一类 Linux下的.o，Win下的.obj 可执行文件（Executable File） 直接的机器码，一般没扩展名 /bin/bash文件，Win下的.exe 共享目标文件（Shared Object File） 这种文件包含了代码和数据，可以在两种情况下使用，一种是链接器可以使用这种文件和其他的可重定位文件和共享目标文件链接，产生新的目标文件。第二种是动态链接器可以将几个这种共享目标文件与可执行文件结合，作为进程映像的一部分 Linux的.so，Win下的DLL 核心转存储文件（Core Dump File） 当进程意外终止时，系统可以将该进程的地址空间的内容及终止时的一些其他信息转储到核心转储文件 Linux下的core dump 使用file命令可以查看文件格式 1234567&gt; vim foo.c&gt; gcc -c foo.c -o foo.o&gt; file foo.ofoo.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped&gt; gcc foo.c -o foo&gt; file foofoo: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/l, for GNU/Linux 3.2.0, BuildID[sha1]=27a7f2f6cccacc9d1c828c6399a0035790b551f8, not stripped 发现一个神奇的东西/lib64/l，进到目录里看 1234567&gt; cd /lib64/lib64$ lsld-linux-x86-64.so.2/lib64$ file ld-linux-x86-64.so.2ld-linux-x86-64.so.2: symbolic link to /lib/x86_64-linux-gnu/ld-2.27.so/lib64$ file /lib/x86_64-linux-gnu/ld-2.27.so/lib/x86_64-linux-gnu/ld-2.27.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, BuildID[sha1]=64df1b961228382fe18684249ed800ab1dceaad4, stripped 看到ld-linux-x86-64.so是我们想找到的共享的动态链接库，但ld-linux-x86-64.so.2又是什么呢？ ld-linux.so.2 是linux下的动态库加载器/链接器 当需要动态加载时，操作系统将控制权交给这个interpreter，用来定位和加载所有的动态库（注意&gt; file foo给出的dynamically linked, interpreter /lib64/l） 还有一点值得留意，我们发现gcc foo.c -o foo生成了一个共享目标文件，经过查询得到了一定的了解 如果想要生成可执行文件，需要使用-no-pie指令来禁掉一个gcc的默认选项 Position-Independent-Executable是Binutils,glibc和gcc的一个功能，能用来创建介于共享库和通常可执行代码之间的代码–能像共享库一样可重分配地址的程序，这种程序必须连接到Scrt1.o。标准的可执行程序需要固定的地址，并且只有被装载到这个地址时，程序才能正确执行。PIE能使程序像共享库一样在主存任何位置装载，这需要将程序编译成位置无关，并链接为ELF共享对象。 引入PIE的原因是让程序能装载在随机的地址，通常情况下，内核都在固定的地址运行，如果能改用位置无关，那攻击者就很难借助系统中的可执行码实施攻击了。类似缓冲区溢出之类的攻击将无法实施。而且这种安全提升的代价很小 目标文件是什么样子 假设可执行文件（目标文件）的格式是ELF，从图来看，ELF文件的开头是一个“文件头”，它描述了一个文件是否可以执行，是静态链接还是动态以及入口地址，目标硬件，目标操作系统等信息。同时，文件头还包括一个段表（Section Table），段表其实就是一个描述文件中各个段的数组。段表描述了文件中各个段在文件中的偏移位置及段的属性等。 C语言编译后执行语句都编译成机器代码，保存在.text段 已经初始化的全局变量和局部静态变量都保存在.data段 未初始化的全局变量和局部静态变量一般放在.bss段里，这个段只是为未初始化的全局变量和局部变量预留位置而已，它并没有内容，所以在文件里不占据空间 未初始化的全局变量和局部静态变量默认值都是0，本来都可以放在.data段里，但因为都是0，所以在.data段分配空间并且存0没有意义，但运行时还要占空间，所以放在了.bss段 总的来说，程序的源代码被编译以后主要分成两种段：程序指令和程序数据。代码段属于程序指令，而数据段和.bss段属于程序的数据，为什么要这么麻烦呢？ 程序被装载后，数据和指令分别被映射到两个虚存区域。由于数据区对于进程来说可读可写，而指令区对于进程来说只可读，这样划分段便于分权 对现代CPU的缓存（Cache）有益，现代的CPU一般都设计成数据缓存和指令缓存分离，分离段可以提高缓存的命中率 和操作系统节省内存空间相关：当系统中运行着多个该程序的副本时，他们的指令一样，所以内存中只用保存一份该程序的指令部分（只读的），当然对于只读数据也是这样的，如程序里的图标，文本，图片也是可以共享的。当然，进程的数据私有。 挖掘.o文件 123456789101112131415161718int printf(const char* format, ...);int global_init_var = 84;int global_uninit_var;void func1(int i){ printf(&quot;%d\\n&quot;, i);}int main(void){ static int static_var = 85; static int static_var2; int a = 1; int b; func1(static_var + static_var2 + a + b); return a;} 出了最基本的代码段，数据段和 BSS 段以外，还有 3 个段分别是只读数据段(.rodata)，注释信息段(.comment)，堆栈提示段(.note.GNU-stack)，我们暂时不研究这三个段，把重点放在属性上：属性有长度(size)，位置(file offset)，每个段的第二行中的 “CONTENTS” 表示该段在文件中存在。 BSS 段就没有这个属性。 还有一个大小为 0 的堆栈提示段，也同样暂时忽略，这样我们就大致得到了文件的结构（可能会由于编译器版本和机器平台导致大小不太一致） |–|–| |elf header|0x0~0x34| |.text|0x34~0x90(这里应该是对齐了边界)| |.data|0x90~0x98| |.rodata|0x98~0x9c| |.comment|0x9c~0xc6| |other data|…| 代码段 使用 objdump -s -d xxx 来查看16进制的段内容和反汇编 数据段和只读数据段 .data 段保存了初始化了的全局静态变量和局部静态变量。分别是 static_var， global_init_var 共 8 字节。 在调用 printf 时，格式化字符是以只读存入的，故被放入了 .rodata 段， %d\\n 再加上 '\\0' 是 4 字节。 rodata 段在语义上支持了 const 关键字，也为操作系统处理只读提供了方便，保证程序的安全 BSS 段 存放为初始化的全局变量和局部静态变量， .bss 段为他们预留了空间，但 global_uninit_var， static_var2 应为 8 字节，实际只存储了 4 字节，这是因为符号表(Symbol Table)，实际上只有 static_var2 被放在了 bss 段，而 global_uninit_var 只是一个未定义的 COMMON 符号。而且这会因不同编译器的实现而不同，有些编译器会将全局未初始化的变量存在 bss 段，而有些仅仅只会预留一个未定义的全局变量符号 其他段 段名 说明 .rodata1 和.rodata一样 .comment 存放编译器的版本信息 .debug 存放调试信息 .dynamic 动态链接信息 .hash 符号哈希表 .line 调试时的行号表，即源代码行号与编译后指令的对应表 .note 额外的编译器信息，如公司名，发布版本号 .strtab String Table 字符串表，用于存放ELF中用到的各种字符串 .symtab Symbol Table 符号表 .shstrtab Section String Table 段名表 .plt &amp; .got 动态链接的跳转表和全局入口表 .init &amp; .fini 程序初始化与终结代码段 当然应用程序也可以使用一些非系统保留的名字作为段名，如加入一个 music 段来存放一些音乐的信息。这样这个文件只有你自己写的读取程序可以解析。但注意应用程序定义的段名不能用. 前缀。 还有些段名是历史遗留问题，不用理会，如 .sdata, .confict, … 补充 如何在 64 位的电脑编译 32 位的程序呢，如果直接使用 gcc -c 得到的是 elf64-x86-64 的 64 位格式的文件，这时我们需要 gcc -m32 -c 这样得到的就是 elf32-i386 格式的文件 但是这个文件我们查看结构和书上的并不完全一样 - .group 段: ??? - .eh_frame 段: 调试信息段 ELF 文件结构描述 ELF 目标文件格式最前部是 ELF 文件头(ELF Header)， 其包含了描述整个文件的基本属性，比如 ELF 文件版本，目标机器型号，程序入口地址等。ELF 文件中与段有关的重要结构就是段表(Section Header Table)，该表描述了 ELF 文件包含的所有段的信息，比如每个段的段名，段长度，文件中的偏移位置，读写权限以及其他属性。 文件头 readelf -h xx 查看 ELF 文件头 ELF 文件头结构及相关常数被定义在 “/usr/include/elf.h” 里，因为 ELF 文件在各种平台下都通用，ELF 文件有 32 位版本和 64 位版本。内容一样但是有些成员的大小不一样。 elf.h 中使用 typedef 定义了一套自己的变量，ELF 详细的定义可以在 ELF 标准文档里找到。 1234567891011121314151617typedef struct{ unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf32_Half e_type; /* Object file type */ Elf32_Half e_machine; /* Architecture */ Elf32_Word e_version; /* Object file version */ Elf32_Addr e_entry; /* Entry point virtual address */ Elf32_Off e_phoff; /* Program header table file offset */ Elf32_Off e_shoff; /* Section header table file offset */ Elf32_Word e_flags; /* Processor-specific flags */ Elf32_Half e_ehsize; /* ELF header size in bytes */ Elf32_Half e_phentsize; /* Program header table entry size */ Elf32_Half e_phnum; /* Program header table entry count */ Elf32_Half e_shentsize; /* Section header table entry size */ Elf32_Half e_shnum; /* Section header table entry count */ Elf32_Half e_shstrndx; /* Section header string table index */} Elf32_Ehdr; ELF 魔数 “Magic”，这 16 个字节被 ELF 标准规定用来标识 ELF 文件的平台属性，比如这个 ELF 的字长（32/64），字节序，ELF 文件版本。 最开始的 4 个字节是所有 ELF 文件必须相同的标识码，分别为 0x7F，0x45，0x4c，0x46，第一个字节对应的 ASCII 字符里的 DEL 控制符，后面三个是 ELF 这三个字母的 ASCII 码。魔数用来确认文件的类型，操作系统在加载可执行文件时会确认魔数是否正确，否则拒绝加载。 接下来的一个字节用来标识 ELF 的文件类，0x01 表示为32位， 0x02 表示为64位，第6个字是字节序，规定大端还是小端。第7个字节规定 ELF 文件的主版本号，一般是1。 ELF 对后面的9个字节没有标准，一般是0，有些平台会使用这9个字节作为扩展标志。 文件类型 常量 值 含义 ET_REL 1 可重定位文件，一般为.o ET_EXEC 2 可执行文件 ET_DYN 3 共享目标文件，一般为.so 段表 使用 readelf -S xxxx.o 来查看段表，它是一个以 “Elf32_Shdr” 结构体为元素的数组。其被定义在 elf.h 中 段表是 ELF 中除了文件头以外的最重要的结构，它描述了 ELF 各个段的信息，比如说段名，段长度，在文件中的偏移，读写权限以及段的其他属性。也就是说，ELF 文件的段结构就是由段表决定的，编译器，链接器和装载器都是依赖段表来定位和访问各个段的属性的。段表在文件中的偏移位置由 ELF 文件头中的 “e_shoff” 成员决定。 1234567891011121314151617181920212223242526272829303132333435/* Type for a 16-bit quantity. */typedef uint16_t Elf32_Half;/* Types for signed and unsigned 32-bit quantities. */typedef uint32_t Elf32_Word;typedef int32_t Elf32_Sword;/* Types for signed and unsigned 64-bit quantities. */typedef uint64_t Elf32_Xword;typedef int64_t Elf32_Sxword;/* Type of addresses. */typedef uint32_t Elf32_Addr;/* Type of file offsets. */typedef uint32_t Elf32_Off;/* Type for section indices, which are 16-bit quantities. */typedef uint16_t Elf32_Section;typedef uint16_t Elf64_Section;/* Section header. */typedef struct{ Elf32_Word sh_name; /* Section name (string tbl index) */ Elf32_Word sh_type; /* Section type */ Elf32_Word sh_flags; /* Section flags */ Elf32_Addr sh_addr; /* Section virtual addr at execution */ Elf32_Off sh_offset; /* Section file offset */ Elf32_Word sh_size; /* Section size in bytes */ Elf32_Word sh_link; /* Link to another section */ Elf32_Word sh_info; /* Additional section information */ Elf32_Word sh_addralign; /* Section alignment */ Elf32_Word sh_entsize; /* Entry size if section holds table */} Elf32_Shdr; 虚拟地址涉及一些映像文件的加载的概念，会在后面解释说明 段的名称对于编译器，链接器是有意义的，但对于操作系统没有实质的意义，对于操作系统来说，一个段该如何处理取决于它的属性和权限，即由段的类型和标志这两个成员决定。 段的类型(sh_type) 常量 值 含义 SHT_NULL 0 无效段 SHT_PROGBITS 1 程序段，代码段，数据段都是这种类型 SHT_SYMTAB 2 表示该段的内容为符号表 SHT_STRTAB 3 表示该段的内容为字符表 SHT_RELA 4 重定位表，该段包含重定位的信息 SHT_HASH 5 符号的哈希表 SHT_DYNAMC 6 动态链接信息 SHT_NOTE 7 提示性信息 SHT_NOBITS 8 表示该段在文件中没有内容，如.bss SHT_REL 9 该段包含重定位信息，会在后面说到 SHT_SHLIB 10 保留 SHT_DNYSYM 11 动态链接的符号表 段的标志位(sh_flag) 表示该段在进程虚拟地址空间中的属性，比如是否可写，是否可执行 |常量|值|含义| |SHF_WRITE|1|表示该段在进程空间中可写| |SHF_ALLOC|2|表示该段在进程空间需要分配空间，像代码段，数据段，.bss段都会有| |SHF_EXECINSTR|4|表示该段在进程空间可以被执行，一般指代码| 段的链接信息(sh_link, sh_info) 如果段的类型与链接相关，比如重定位表，符号表，那么这两个成员所包含的含义为： SHT_DYNAMIC: link: 该段所使用的字符串表在段表中的下标，info: 0 SHT_HASH: link: … 符号表 …， info: 0 SHT_REL &amp; SHT_RELA: link: 使用的符号在段表中的下标，info: 重定位表作用的段在段表中的下标 SHT_SYMTAB &amp; SHT_DYNSYM: link &amp; info: 操作系统相关 重定位表 对于每个需要重定位的代码段或数据段都会有一个对应的相应的重定位表 - .rel.text 就是针对 .text 的重定位表，我们也可以通过 info 来看其对应的重定位的段 字符串表 ELF 文件中用到了很多字符串，比如段名，变量名等，因为字符串的长度往往不定，所以就集中起来然后用在表中的偏移量来引用字符串，偏移量表示头，'\\0’表示结尾 一般字符串表在 ELF 中也以段的形式保存，常见的段名为 .strtab 或 .shstrtab 前一个存普通的字符串，后一个存储段表用到的字符串，如 sh_name 我们回头看 ELF 文件头里的 “e_shstrndx”(Section header string table index)的缩写，其表示 .shstrtab 在段表（数组）中的下标，即段表字符串表在段表中的下标。这样我们分析 ELF 文件头就可以得到段表，而通过段表里索引的段字符表值以及段字符表的位置，我们就可以解析整个 ELF 文件了。","link":"/2020/02/02/Linkers-Loaders-3/"},{"title":"程序员的自我修养-可执行文件的装载","text":"可执行文件的装载与进程 可执行文件只有装载到内存以后才能被 CPU 执行。早期的程序装载十分简陋，装载的基本过程就是把程序从外部存储器中读取到内存中的某个位置。随着硬件 MMU 的诞生，多进程，多用户，虚拟存储的操作系统出现，可执行文件的装载过程变得非常复杂。 进程虚拟地址空间 我们知道每个程序被运行起来以后，它将拥有自己独立的虚拟地址空间（Virtual Address Space），这个虚拟地址空间的大小将由计算机的硬件平台决定，具体地说是由 CPU 的位数决定。硬件决定了地址空间的最大理论上限。如32位 CPU 具有32位寻址能力，4GB 的虚拟空间大小。 进程只能使用那些操作系统分配给进程的地址，如果访问未经允许的空间，那么操作系统就会捕获这些访问，将进程的这种访问当做非法操作，强制结束进程。 对于 Linux 系统来说，默认情况下 Linux 操作系统将进程的虚拟空间分为2部分，操作系统使用从 0xC0000000 到 0xFFFFFFFF 的空间，而剩下的空间应用程序使用。但是对于某些程序，这样的内存大小太小了，怎么办？ PAE 从硬件层面讲，原先的32位地址线只能访问最多4GB的物理内存。但自从扩展至36位地址线之后，Intel 修改了页映射的方式，使得新的映射方式可以访问到更多的物理内存。 Intel 把这个地址扩展方式叫做 PAE（Physical Address Extension） 当然扩展的物理地址空间，对于普通应用程序来说正常情况下感觉不到它的存在，因为这主要是操作系统的事，在应用程序中，只有32位的虚拟地址空间，那么应用程序该如何使用这些大于常规的内存空间？一个很常见的方法就是操作系统提供一个窗口映射的方式把这些额外的内存映射到进程地址空间来。应用程序可以根据自己的需要来选择申请和映射，比如一个应用程序中 0x10000000~0x20000000 这一段256MB的空间用来做窗口，程序可以从高于4GB的物理空间中申请多个大小为256MB的物理空间，编号为A，B，C等，然后根据需要将这个窗口映射到不同的物理空间块，用到 A 时将 0x10000000~0x20000000 映射到 A，用到 B 时就映射到 B。在 Windows 下，这种内存的操作方式叫做 AWE（Address Windowing Extensions），而像 UNIX 类操作系统则采用 mmap() 系统调用来实现。 装载的方式 程序执行时所需要的指令和数据必须在内存中才能正常运行，最简单的方法就是将程序运行需要的指令和数据全部装入内存中，虽然这样程序就可以顺利运行，但是实际情况很多时候是内存不够。为了尽可能高效利用内存，我们可以将程序的最常用的部分驻留在内存，而将一些不常用的数据存放到磁盘里，这就是动态装入的基本原理。动态装入的方式有覆盖装入（Overlay），页映射（Paging） 覆盖装入 比较老的方法，这个方法需要人工的将程序分割为若干块，然后编写一个小的辅助代码来管理这些模块该何时驻留内存而该何时被替换掉。这个小的辅助代码就是所谓的覆盖管理器（Overlay Manager）。太老了不多介绍，我们把精力放在页映射中。 页映射 页映射是虚拟存储机制的一部分，它随着虚拟内存的发明而诞生。前面我们已经介绍了页映射的基本原理，这里我们再结合可执行文件的装载来阐述一下页映射是如何被应用的。与覆盖装入的原理相似，页映射也不是一下子就把程序的所有的数据和指令都装入内存，而是将内存和所有磁盘中的数据和指令按照 “页” 为单位划分为若干个页，以后所有的装载和操作的单位就是页。 现在我们假设我们的32位机器有16KB的内存，每个页的大小为4096字节，则共有4个页。 页编号 地址 F0 0x00000000~0x00000FFF F1 0x00001000~0x00001FFF F2 0x00002000~0x00002FFF F3 0x00003000~0x00003FFF 假设程序所有的指令和数据总和为32KB，那么程序总共被分为8个页。我们将它们编号为 P0~P7。明显，16KB的内存无法同时将32KB的程序装入，那么我们将按照动态装入的原理来进行整改装入过程，如果程序刚开始执行时的入口地址为 P0，这时装载管理器（我们假设装载过程由一个叫装载管理器的控制程序），发现 P0 不在内存中，就将内存 F0 分配给 P0，并将 P0 的内容装入 F0 。一段时间后，又用到了 P5，于是装载管理器将 P5 装入 F1，就这样，当需要的时候装入。如果满了，就需要放弃正在使用的一个内存页来装入新的内存页，这时有多种算法来决定选择舍弃哪个。（舍弃先装入的，舍弃不常用的）。 这个所谓的装载管理器就是现代的操作系统，更具体的说，就是操作系统的存储管理器。目前几乎所有的主流操作系统都是按照这种方式装载可执行文件的。 从操作系统的角度看可执行文件的装载 进程的建立 很多时候，一个程序的执行同时都伴随着一个新的进程的创建，那么我们就来看看这种最通常的情形：创建一个进程，然后装载相应的可执行文件并且执行。在有虚拟内存的情况下，上述过程最开始只需要做这三件事： 创建一个独立的虚拟地址空间 读取可执行文件头，并且建立虚拟空间与可执行文件的映射关系 将 CPU 的指令寄存器设置成可执行文件的入口地址，启动运行 首先是创建虚拟地址空间。一个虚拟空间由一组页映射函数将虚拟空间的各个页映射至相应的物理空间，那么创建一个虚拟空间实际上并不是创建空间而是创建映射函数所需要的相应的数据结构。在 i386 的 Linux 下，创建虚拟地址空间实际上只是分配了一个页目录（Page Directory）就可以了，甚至不需要设置页映射关系，这些映射关系等到程序发生页错误的时候再去设置。 读取可执行文件头，并且建立虚拟空间与可执行文件的映射关系。上面那一步的页映射关系函数是虚拟空间到物理内存的映射关系，这一步所做的是虚拟空间与可执行文件的映射关系。我们知道，当程序执行发生页错误时，操作系统将从物理内存中分配一个物理页，然后将缺页的部分读取入内存，再设置映射关系，这样程序就可以正常运行。但是它如何知道程序当前所需要的页在可执行文件中的哪个位置？ 由于可执行文件在装载时实际是被映射的虚拟空间，所以可执行文件很多时候也被称为映像文件（Image） 让我们考虑一个最简单的情况，假设我们的 ELF 可执行文件只有一个代码段，它的虚拟地址为0x08048000，它在文件中的大小为0x000e1，对齐为0x1000。由于虚拟存储的页映射都是以页为单位的，在32位的 Intel IA32 下一般为4096字节，所以32位 ELF 的对齐粒度为 0x1000。由于该代码段大小不到一个页，考虑到对齐该段占用一个段。所以一旦该文件被装载，可执行文件与执行该文件进程的虚拟空间的映射关系如图 这种数据关系只是保存在操作系统内部的一个数据结构。 Linux 中将进程虚拟空间中的一个段叫做虚拟内存区域（Virtual Memory Area），操作系统创建进程后，会在进程相应的数据结构中设置一个有 .text 段的 VMA，它对于 ELF 文件中的 .text。 将 CPU 指令寄存器设置为可执行文件入口，启动运行。这一步看似简单：设置 CPU 指令寄出器的值为 ELF 文件头中的入口地址。实际在操作系统层面比较复杂，它涉及内核堆栈和用户堆栈的切换， CPU 运行权限的切换。 页错误（Page Fault） 上面的步骤执行完后，可执行文件真正的指令和数据还保留在硬盘里。操作系统知识通过可执行文件头部的信息建立起可执行文件和进程虚存之间的映射关系。假设在上面的例子中，程序的入口地址为 0x08048000，即刚好是 .text 段的起始地址。当 CPU 开始打算执行这个地址指令时，发现页 0x08048000~0x08049000 是个空页面，于是它认为这是一个页错误， CPU 将控制权交给操作系统，操作系统有专门的页错误处理例程来处理这种情况。这时操作系统将查询装载过程建立的数据结构，找到空页面所在的 VMA，计算出响应页面在可执行文件中的偏移，然后在物理内存中分配一个物理页面，将进程中该虚拟页与分配的物理页之间建立映射关系，然后把控制权再还给进程，进程从刚才页错误的位置重新开始执行。 进程虚拟空间分布 前面的例子中，可执行文件中只有一个代码段，当其被装载时对应的只有一个 VMA，实际情况会复杂的多，在一个正常的进程中，可执行文件中往往不止包含了代码段，还有数据段，BSS 等。所以映射到进程虚拟空间的往往不止一个段。当段的数量增多时。一个段的多余部分往往也会占一个页，一个文件中往往有十几个段，浪费了大量的空间。 为了节约空间，一个很简单的方法是：对于相同的权限的段，把他们合并到一起当做一个段来映射。因为操作系统只关心一些和装载有关的问题，最主要的是段的权限（可读，可写，可执行） 在将目标文件链接成可执行文件的时候，链接器会尽量把相同权限属性的段分配在同一空间。比如可读可执行的段都放在一起，这种段的典型是代码段，可读可写的段放在一起，这种段的典型就是数据段。在 ELF 文件中把这些属性相似的，又连在一起的段叫做 “Segment”, 而系统正是按照它来映射可执行文件的。 可以使用 readelf -l 来查看 ELF 如何被操作系统映射到进程的虚拟空间 123456789101112131415161718192021222324......Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x00000000000b584e 0x00000000000b584e R E 0x200000 LOAD 0x00000000000b6120 0x00000000006b6120 0x00000000006b6120 0x00000000000051b8 0x00000000000068e0 RW 0x200000 NOTE 0x0000000000000190 0x0000000000400190 0x0000000000400190 0x0000000000000044 0x0000000000000044 R 0x4 TLS 0x00000000000b6120 0x00000000006b6120 0x00000000006b6120 0x0000000000000020 0x0000000000000060 R 0x8 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 0x10 GNU_RELRO 0x00000000000b6120 0x00000000006b6120 0x00000000006b6120 0x0000000000002ee0 0x0000000000002ee0 R 0x1 Section to Segment mapping: Segment Sections... 00 .note.ABI-tag .note.gnu.build-id .rela.plt .init .plt .text __libc_freeres_fn __libc_thread_freeres_fn .fini .rodata .stapsdt.base .eh_frame .gcc_except_table 01 .tdata .init_array .fini_array .data.rel.ro .got .got.plt .data __libc_subfreeres __libc_IO_vtables __libc_atexit __libc_thread_subfreeres .bss __libc_freeres_ptrs 02 .note.ABI-tag .note.gnu.build-id 03 .tdata .tbss 04 05 .tdata .init_array .fini_array .data.rel.ro .got 在 ELF 可执行文件中有一个数据结构叫做程序头表（Program Header Table） 123456789101112/* Program segment header. */typedef struct{ Elf32_Word p_type; /* Segment type */ Elf32_Off p_offset; /* Segment file offset */ Elf32_Addr p_vaddr; /* Segment virtual address */ Elf32_Addr p_paddr; /* Segment physical address */ Elf32_Word p_filesz; /* Segment size in file */ Elf32_Word p_memsz; /* Segment size in memory */ Elf32_Word p_flags; /* Segment flags */ Elf32_Word p_align; /* Segment alignment */} Elf32_Phdr; 对于 LOAD 类型的 Segment 来说，p_memsz 的值不可以小于 p_filesz，否则就装不下。当大于时，就表示在内存中分配的大小超过文件中的实际大小，多余的部分往往会被赋值为0，这样做的好处是，我们在构造 ELF 可执行文件时不需要额外设立 BSS 段，那些0的内存就是（多出来的内存） BSS。 堆和栈 在操作系统里面，VMA 除了被用来映射可执行文件中的各个 Segment 外，它还有其他的作用，操作系统通过使用 VMA 来对进程的地址空间进行管理。我们知道进程在执行时还需要**栈（Stack）和堆（Heap）**等空间。一个进程中的栈和堆都有相应的 VMA。 $ ./section_mapping.elf &amp; [1] 98 $ cat /proc/98/maps 00400000-004b5000 r-xp 00000000 00:00 23549 ./section_mapping.elf 004b5000-004b6000 r-xp 000b5000 00:00 23549 ./section_mapping.elf 006b6000-006bc000 rw-p 000b6000 00:00 23549 ./section_mapping.elf 006bc000-006bd000 rw-p 00000000 00:00 0 014e1000-01504000 rw-p 00000000 00:00 0 [heap] 7fffe5590000-7fffe5d90000 rw-p 00000000 00:00 0 [stack] 7fffe5f2b000-7fffe5f2c000 r-xp 00000000 00:00 0 [vdso] 第一列是 VMA 的地址范围，第二列是 VMA 的权限（p 表示私有），第三列是偏移，表示 VMA 对应的 Segment 在映像文件中的偏移。第四列表示映像文件所在的主设备和次设备号，第五列表示映像文件的节点号。最后一列是路径。 我们用 malloc 函数分配的空间就是从堆里分配的，堆由系统库管理。每个线程都有自己的堆栈，对于单线程的程序来说，这个 VMA 堆栈全部由它使用。另外地比较特殊的 VMA 叫做 “vdso”，它是一个内核的模块，进程可以通过访问这个 VMA 来跟内核进行一些通信。 由于是子系统，看起来栈和 vdso 都位于内核空间，不知道现在的 Linux 系统是不是也是这样。猜测也是子系统的缘故，堆对于当前 Linux 用户都无法执行（毕竟内核是 Windows 的） Linux 允许一个 VMA 没有映射到任何文件，所以会有上面的一个 VMA 没有映射到任何地方，有什么用呢？ //TODO 查明没有映射的 VMA 的作用 小结 小结一下关于进程虚拟空间的概念：操作系统通过给进程空间划分出一个个 VMA 来管理进程的虚拟空间，基本原则是将相同权限属性的，有相同映像文件的映射成一个 VMA，一个进程基本上可以分为如下几种 VMA 区域： 代码 VMA，只读可执行，有映像文件 数据 VMA，可读可写，有映像文件 堆 VMA，可读可写可执行，无映像文件，匿名，可向上（高地址）扩展 栈 VMA，可读可写，不可执行，无映像文件，匿名，可向下（低地址）扩展 段地址对齐 可执行文件最终是要被操作系统装载运行的，这个装载的过程一般是通过虚拟内存的页映射机制完成。在映射过程中，页是映射的最小单位。对于 Intel 80x86 系列处理器来说，默认的页大小为 4096 字节，也就是说，我们在一段物理内存和进程虚拟地址空间之间建立映射关系，这段空间必须是 4096 的整数倍。如果有大量的不满 4096 的内存空间需要映射，传统的方法就会带来大量的碎片。 为了解决这个问题，有些 UNIX 系统采取了一个方法：让接壤部分共享一个物理页面，然后再将该页面映射两次。 举个例子：假设一个 ELF 文件由3个 Segment（段）需要装载，分别为 SEG0（127字节），SEG1（9899字节），SEG2（1988字节） 这种映射下，一个物理的页面里往往可能包含多个段，在 ELF 文件中，对于任何一个可装载的段，它的 p_vaddr 除以对齐属性的余数等于 p_offset 除以对齐属性的余数。 进程栈初始化 进程刚开始启动的时候，须知到一些进程运行的环境，最基本的就是系统环境变量和进程的运行参数，很常见的一种做法是操作系统在进程启动前将这些信息提前保存到进程虚拟空间的栈中（Stack VMA） 假设我们的系统变量为: HOME=/home/user PATH=/usr/bin 我们运行程序的命令为 prog 123 假设堆栈段底部的地址为 0xBF802000，那么进程初始化后的堆栈就如图： 进程在启动以后，程序的库部分会把堆栈里的初始化信息中的参数信息传递给 main 函数，也就是我们熟知的 argc, argv 参数，分别对应命令行参数数量和命令行参数字符串指针数组。 Linux 内核装载 ELF 过程简介 当我们在 Linux 系统的 bash 下输入一个命令来执行某个 ELF 程序时，在用户层面， bash 进程会调用 fork() 系统调用创建一个新的进程，然后新的进程调用 execve() 系统调用执行 elf 文件。原先的 bash 进程继续返回等待刚才启动的新进程的结束。 sample_bash1 在进入 execve() 系统调用之后，Linux 内核就开始进行真正的装载工作。在内核中，execve() 系统调用相应的入口是 sys_execve()，它被定义在 Process.c 文件中，sys_execve() 进行一些参数的检查复制后，调用 do_execve()，它会先查找文件，然后读取文件的前128个字节，判断文件格式，特别是开头的4个字节（魔数），通过它就能知道文件的格式和类型。比如 ELF 的可执行我呢间格式头4个字节为0x7F（“elf”），java 的为 “cafe”。对于 Shell 脚本或者 Python，它的第一行往往是 “#!/bin/sh” 或 “#!/usr/bin/python”，这时前两个字节 ‘#’ 和 ‘!’ 就构成了魔数。 之后就去搜索和匹配合适的可执行文件装载处理函数。我们这里只关心 ELF 可执行文件的装载，它的主要步骤是: 检查 ELF 可执行文件格式的有效性，比如魔数，程序头表中 Segment 的数量 寻找动态链接的 .interp 段，设置动态链接器路径 根据 ELF 可执行文件的程序头表的描述，对 ELF 文件进行映射，比如代码，数据，只读数据 初始化 ELF 进程环境 将系统调用的返回地址修改为 ELF 可执行文件的入口点，这个入口点取决于程序的链接方式，对于静态链接的 ELF 可执行文件，这个程序入口就是 ELF 文件的文件头中 e_entry 所指的地址，对于动态链接的 ELF 可执行文件，程序入口是动态链接器 这样 EIP 寄存器就会跳到合理的入口，当上述内核程序执行完后，ELF 文件开始执行。","link":"/2020/02/24/Linkers-Loaders-6/"},{"title":"程序员的自我修养——动态链接","text":"趁着借的图书馆的书还没还，赶紧看。写博客记录一下学习的内容便于以后反复看 静态链接使得不同的程序开发者和部门能够相对独立地开发和测试自己的模块。当随着时间，静态链接的问题也暴露出来：如浪费内存和磁盘空间，模块更新困难，这使得人们不得不找一种更好的方式来组织程序的模块。 动态链接 传统的静态链接存在一个问题，如果多个进程需要使用同一个模块时，会造成一个函数在不同进程中存在多个相同的副本。同时，静态链接对程序的更新部署和发布也带来了很多的麻烦。一旦一个 .o 文件更新了，那么程序就需要重新的链接。对于程序的发布商来说，一旦有任何的模块的更新，就需要重新的链接，然后发布给用户，带来很大的不便。 要解决这样的问题，最简单的方法就是把程序的模块相互分割开来，形成独立的文件，而不再将它们静态链接到一起。简单的来说就是，不对那些组成程序的目标文件进行链接，等到程序运行时才进行链接。也就是说，把链接这个过程推迟到运行时再进行，这就是**动态链接（Dynamic Linking）**的基本思想。 假如我们要运行 Program_a， 系统加载 Program_a.o，然后发现里面用到了 lib.o，系统就加载 lib.o，如果 lib.o 里又依赖别的目标文件，系统会安照这样的方法将它们全部加载进内存，这个链接的工作原理和静态链接非常相似，包括符号解析，地址重定位等。完成这些步骤后，系统开始把控制权交给 Program_a.o 的程序入口处，程序开始运行。这时如果我们需要运行另外一个 Program_b，如果其使用到了 lib.o，则就不需要再重新加载，系统要做的只是将它们链接起来。 程序可扩展和兼容性 动态链接还有一个特点就是程序在运行时可以动态地选择加载各种程序模块，这个优点就是后来被人们用来制作程序的插件（Plug-in）。 比如某个公司开发完成了某个产品，它按照一定的规则制定好程序的接口， 其他公司或开发者可以按照这种接口来编写符合要求的动态链接文件。该产品可以动态载入各种由第三方开发的模块，在程序运行的时候动态链接，实现功能的扩展。 动态链接也可以增强程序的兼容性。一个程序在不同的平台运行时可以动态地链接到由操作系统提供的动态链接库，这些动态链接库相当于在程序和操作系统之间增加了一个中间件，从而消除程序对不同平台之间的依赖的差异性。比如操作系统 A 和操作系统 B 对于 printf 函数的实现机制不同，如果我们的程序是静态链接的，那么程序需要分别链接成能够在操作系统 A 和 B 上运行的 2 个版本并且发布，但如果操作系统 A 和 B 都能提供一个动态链接库包含 printf()，并且这个函数使用相同的接口，那么程序只需要有一个版本，在不同的操作系统上运行会动态选择相应的版本。当然这只是理论可行，实际会存在各种问题，动态链接模块之间的兼容性问题也需要考虑。 动态链接的基本实现 动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序。 动态链接涉及运行时的链接及多个文件的装载，必须要有操作系统的支持。因为动态链接的情况下，进程的虚拟地址空间分布会比静态链接情况下更为复杂，还有一些存储管理，内存共享，进程线程等机制在动态链接下也会有一些微妙的变化。目前主流的操作系统几乎都支持动态链接这种方式，在 Linux 中，ELF 动态链接文件被称为动态共享文件（DSO，Dynamic Shared Objects），简称共享对象，他们一般都是以 .so 为扩展名的一些文件；而在 Windows 系统中，动态链接文件被称为动态链接库（Dynamical Linking Library），它就是通常我们平时很常见的 .dll 文件 在 Linux 中，常用的 C 语言的运行库 glibc，它的动态链接形式的版本保存在 “/lib” 目录下，文件名为 “libc.so”，整个系统只保留一份 C 语言的动态链接文件，而所有的 C 语言编写的，动态链接的程序都可以在运行的时候使用它。当程序被装载的时候，系统的动态链接器会将程序所需要的动态链接库装载到进程的地址空间，并将程序中所有的未决议符号绑定到相应的动态链接库中，并进行重定位工作。 简单的动态链接的例子 123456789101112131415161718192021222324252627282930// prog1.c# include &quot;Lib.h&quot;int main(){ foo(1); return 0;}// prog2.c#include &quot;Lib.h&quot;int main(){ foo(2); return 0;}// Lib.c#include &lt;stdio.h&gt;void foo(int i){ printf(&quot;Printing from lib.so %d\\n&quot;, i); getchar(); // 阻塞，防止过快结束无法查看进程地址空间}// Lib.h#ifndef LIB_H#define LIB_Hvoid foo(int i);#endif 使用 gcc -fPIC -shared -o Lib.so Lib.c 编译生成一个共享对象文件 使用 gcc -o prog1 prog1.c ./Lib.so, gcc -o prog2 prog2.c ./Lib.so。分别编译链接两个文件 整个编译和链接的过程可以看做是这样的: 当我们的模块 prog1.c 被编译成为了 .o 文件时，编译器还不知道 foo() 函数的地址，当链接器将 prog1.o 链接生成可执行文件时，这时候就必须确定 foo() 函数的性质。如果它是定义在其他静态目标模块中的函数，链接器按照静态链接的规则将地址引用重定位。如果是一个动态共享对象的函数，那么链接器就会将这个符号的引用标记为一个动态链接的符号，不对他进行重定位，把这个过程留到装载时再进行。 地址空间分布 $./prog1 &amp; [1] 120 Printing from lib.so 1 $cat /proc/120/maps 7f83e65f0000-7f83e67d7000 r-xp 00000000 00:00 161323 /lib/x86_64-linux-gnu/libc-2.27.so 7f83e67d7000-7f83e67e0000 —p 001e7000 00:00 161323 /lib/x86_64-linux-gnu/libc-2.27.so 7f83e67e0000-7f83e69d7000 —p 000001f0 00:00 161323 /lib/x86_64-linux-gnu/libc-2.27.so 7f83e69d7000-7f83e69db000 r–p 001e7000 00:00 161323 /lib/x86_64-linux-gnu/libc-2.27.so 7f83e69db000-7f83e69dd000 rw-p 001eb000 00:00 161323 /lib/x86_64-linux-gnu/libc-2.27.so 7f83e69dd000-7f83e69e1000 rw-p 00000000 00:00 0 7f83e69f0000-7f83e69f1000 r-xp 00000000 00:00 345391 xx/xx/Lib.so 7f83e69f1000-7f83e69f2000 —p 00001000 00:00 345391 xx/xx/Lib.so 7f83e69f2000-7f83e6bf0000 —p 00000002 00:00 345391 xx/xx/Lib.so 7f83e6bf0000-7f83e6bf1000 r–p 00000000 00:00 345391 xx/xx/Lib.so 7f83e6bf1000-7f83e6bf2000 rw-p 00001000 00:00 345391 xx/xx/Lib.so 7f83e6c00000-7f83e6c26000 r-xp 00000000 00:00 161135 /lib/x86_64-linux-gnu/ld-2.27.so … 7f83e7000000-7f83e7001000 r-xp 00000000 00:00 345392 xx/xx/prog1 7f83e7200000-7f83e7201000 r–p 00000000 00:00 345392 xx/xx/prog1 7f83e7201000-7f83e7202000 rw-p 00001000 00:00 345392 xx/xx/prog1 … $ kill 120 程序部分的内存被分为3页，一页为4kb 可以看到总共用了 3 个动态链接库，一个是我们写的，还有 C 语言运行时库(libc-2.27.so)和动态链接器(ld-2.27.so) 我们可以用 readelf -l Lib.so 来查看 Lib.so 的装载属性 $ readelf -l Lib.so Elf file type is DYN (Shared object file) … Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x00000000000006f4 0x00000000000006f4 R E 0x200000 LOAD 0x0000000000000e10 0x0000000000200e10 0x0000000000200e10 0x0000000000000218 0x0000000000000220 RW 0x200000 DYNAMIC 0x0000000000000e20 0x0000000000200e20 0x0000000000200e20 0x00000000000001c0 0x00000000000001c0 RW 0x8 … 文件类型不同，其他和普通的程序很相似，需要注意的是动态链接模块的装载地址是从地址 0x00000000 开始，而在最终运行时的装载地址并不是这个。所以共享对象的最终装载地址在编译时是不确定的，在装载时根据当前地址的空闲情况来动态分配一块足够大的虚拟地址空间给共享对象。 地址无关代码 在共享对象被装载时，我们应该如何去确定它在进程虚拟地址空间中的位置？ 固定装载地址的问题 为了实现动态链接，我们首先会遇到的问题就是共享对象地址的冲突问题。一般的，程序模块的指令和数据中可能会包含一些绝对地址的引用，我们在链接产生输出文件的时候，就要假设模块被装载的目标地址。 很明显，在动态链接的情况下，如果不同的模块目标装载地址都一样是不行的。而对于单个程序来说，我们可以手工指定各个模块的地址，比如说把 0x1000 到 0x2000 分配给模块 A， 把地址 0x2000 到 0x3000 分配给模块 B。但是，管理这些模块会变成一件无比繁琐的事情。比如一个人制作了一个程序，该程序使用模块 B，但不需要模块 A，所以他以为 0x1000-0x2000 是空闲的，就分给了 C 模块。这就产生了冲突，任何人以后将不能在同一个程序里使用模块 A 和 C。 不幸的是，早期确实有些操作系统采取这种做法，这种做法叫做静态共享库（Static Shared Library）。它和**静态库（Static Library）**还是有明显的区别的，静态共享库的做法是将程序的各种模块统一交给操作系统管理，操作系统在某个特定的地址划分出一些地址块，为那些已知的模块预留足够的空间。 这样导致了很多的问题，除了地址冲突外，静态共享库的升级也成了问题，因为升级后的共享库必须保持共享库中全局函数和变量地址的不变。如果应用程序已经链接了这些地址，一旦更改，就必须重新链接应用程序。而且不能增加过多的内容，否则有可能超出被分配的空间。 装载时重定位 为了解决上面的问题，我们就需要让共享对象可以在任意的地址装载。我们首先可以想到的就是静态链接中的重定位。这个想法的基本思路就是，在链接时，对所有绝对地址的引用不做重定位，而把这一步推迟到装载时再完成。一旦模块装载地址确定，即目标地址确定，那么系统就对程序中所有的绝对地址引用进行重定位。 我们在静态链接时提到了重定位，那时的重定位叫做链接时重定位（Link Time Relocation），而现在的这种情况是装载时重定位（Load Time Relocation）。但是，装载时重定位的方法并不适合解决上面的问题。可以想象，动态链接模块被装载映射至虚拟空间后，指令部分是在多个进程之间共享的，由于装载时重定位需要修改指令，所以无法做到同一份指令被多个进程共享，因为指令被重定位后对于每个进程来说是不同的。 当然，动态链接库中的可修改数据部分对于不同的进程来说有很多的副本，就可以用装载时重定位来解决。 Linux 和 GCC 支持这种装载时重定位的方式，我们前面在产生共享对象时，使用了 -shared 和 -fPIC，如果只使用 -shared，那么输出的共享对象就会是使用了装载时重定位的方法。 地址无关代码（PIC） 什么是 -fPIC 参数，它又有什么效果呢？ 装载时重定位是解决动态模块中有绝对地址引用的方法之一，但它的问题就是无法在进程之间共享指令，这样就无法节省内存了。我们还需要一种更好的方法解决共享对象指令中对绝对地址的重定位问题。我们的目的很简单，就是希望程序模块中共享的指令部分在装载时不需要因为装载地址的改变而改变，所以实现的基本想法就是把指令中的那些需要被修改的部分分离出来，和数据放在一起，这样指令部分就可以保持不变，而数据部分可以在每个进程中拥有一个副本，这种方案就是目前被称为**地址无关代码（PIC，Position-independent Code）**的技术。 对现代的机器来说，产生地址无关的代码并不麻烦。我们先来分析模块中各种类型的地址引用方式。这里我们把共享对象模块中的地址引用按照是否为跨模块分成两类：模块的内部引用和模块的外部引用；按照不同的引用方式又可以分为指令引用和数据访问。这样就总共 4 种情况： 模块内部的函数调用，跳转等 模块内部的数据访问，比如模块中定义的全局变量，静态变量 模块外部的函数调用，跳转等 模块外部的数据访问，比如其他模块中定义的全局变量 12345678910111213static int a;extern int b;extern void ext();void bar(){ a = 1; // 2 b = 2; // 4}void foo(){ bar(); // 1 ext(); // 3} 模块内部调用或跳转 相对位置固定，这种指令一般都不需要重定位。生成的汇编代码中 call，或者 jmp 后面跟的就是相对地址，只要相对位置不变，这条指令就是地址无关的。对于全局符号介入的问题，后面会进行讨论。 模块内部数据访问 很明显，指令中不能直接包含数据的绝对地址，那么唯一的方法就是相对寻址。我们知道，一个模块前面一般都是若干个页的代码，后面跟着若干的页的数据，这些页之间的相对位置是固定的，也就是说，任何一条指令与它需要访问的模块内部数据之间的相对位置是固定的，那么只需要相对于当前指令加上固定的偏移量就可以访问模块内部数据了。现代的体系结构中，数据的相对寻址往往没有相对于当前指令地址 PC 的寻址方式，所以 ELF 用了一个很巧妙的方法来得到 PC，最常用的就是调用一个叫__xxx.get_pc_thunk.xx 的函数（如__x86.get_pc_thunk.bx），这个函数的作用就是把返回地址放到 ecx 中（mov (%esp), %ecx）。由于 call 时栈顶就是 PC 的下一条，这样操作我们就获得了 PC 模块间数据访问 模块间的数据访问比模块内部稍微麻烦一点，因为模块间的数据访问目标地址要等到装载时才决定。我们前面提到的要是代码地址无关，基本的思想就是把跟地址有关的部分放到数据段里面，很明显，这些其他模块的全局变量的地址是跟模块装载地址相关的。ELF 的做法是在数据段里面建立一个指向这些变量的指针数组，也被称为全局偏移表（Global Offset Table, GOT），当代码需要引用该全局变量的时候，可以通过 GOT 中相应的项间接引用，它的基本机制如图： 当指令要访问变量的时候，会先去找 GOT，然后会根据 GOT 中变量对应的项找到变量的目标地址。每个变量对应一个4字节的地址，链接器在装载模块的时候会查找每个变量所在的地址，然后填充 GOT 中的各个项以确保每个指针所指向的地址正确，而 GOT 表在数据段，每个进程都有自己的副本而相互不影响。 我们可以使用 objdump -h xx.so 来查看 GOT 表的位置，使用 objdump - R xx.so 来查看动态链接时的重定位项 模块间调用和跳转 可以调用上面的方法，即使用 GOT 表，不同的是，GOT 表中相应的项保存的是目标函数的地址，当模块要调用目标函数时，可以通过 GOT 中的项进行间接跳转。这种方法很简单，但是存在一些性能问题，实际上 ELF 采用了一种更加复杂和精巧的方法，我们将在后面的动态链接优化中进行介绍 小结 各种地址引用方式如下: |–|–|–| ||指令跳转和调用|数据访问| |模块内部|相对跳转和调用|相对地址访问| |模块外部|间接跳转和调用(GOT)|间接访问(GOT)| PIC 与 PIE 地址无关代码除了可以用在共享对象上面，也可以用在可执行文件，一个以地址无关方式编译的可执行文件被称为地址无关的可执行文件（PIE, Position-Independent Executable），与 GCC 的-fPIC 和 -fpic 参数类似，产生 PIE 的参数为-fPIE 或 -fpie -fpic 和 -fPIC 这两个参数从功能上来看是完全一样的，都是指示 GCC 产生地址无关的代码，唯一的区别是， -fPIC 产生的代码要大而 -fpic 产生的代码相对较小，而且较快。我们使用 -fPIC 是因为 -fpic 生成的地址无关代码都是和硬件平台相关，比如全局符号的数量或者代码的长度等，而 -fPIC 则没有这样的限制，为了方便起见，绝大多数情况下我们都使用 -fPIC 参数来产生地址无关代码。 共享模块的全局变量问题 有一种很特殊的情况我们目前还没有解决，就是当一个模块引用了一个定义在共享对象的全局变量的时候，比如一个共享对象定义了一个全局变量 global，而在模块 module.c 中是这么引用的： 1234extern int global;int foo(){ global = 1;} 当编译器处理 module.c 时，它无法根据这个上下文判断 global 是定义在同一个模块的目标文件还是定义在另一个共享对象之中，即无法判断是否为跨模块间的调用。 假设 module.c 是程序可执行文件的一部分，那么在这种情况下，由于程序主模块的代码并不是地址无关代码，也就是说不会使用这种类似 PIC 的机制，它引用这个全局变量的方式就和普通的一样，在链接过程中就去确立这个变量的地址。为了能使链接过程正常进行，链接器会在创建可执行文件时在 .bss 段创建一个 global 变量的副本。那么现在 global 变量定义在原先的共享对象中，而可执行文件的 .bss 段中还有一个副本，一个变量同时存在于多个位置，就无法确定具体的位置。 解决方法只有一个，就是把所有的使用这个变量的指令都指向位于可执行文件的那个副本。 ELF 共享库在编译时，默认都把定义在模块内部的全局变量当作定义在其他模块的全局变量，也就是说是模块外部的数据访问，通过 GOT 表来实现。当共享模块被装载时，如果某个全局变量在可执行文件文件中拥有副本，那么动态链接器就会把 GOT 中的相应地址指向副本，这样，该变量在运行时就会只有一个实例。如果变量在共享模块中被初始化，那么链接器需要将该初始化的值复制到程序主模块中的变量副本；如果该全局变量在程序主模块中没有副本，那么 GOT 中相应地址就指向模块内部的该变量副本。 数据段地址无关地址 通过上面的方法，我们可以保证共享对象中的代码地址无关，但是数据部分也有绝对地址引用的问题。如: static int a; static int *p = &amp;a，如果某个共享对象中有这样一段代码，那么 p 指针的地址就是一个绝对地址，它指向变量 a, 而变量 a 的地址会随共享对象的装载地址的改变而改变，应该怎么解决？ 对于数据段来说，它在每个进程中都有一份独立的副本，所以并不担心被进程改变。从这点来看，我们可以选择装载时重定位的方法来解决数据段中绝对地址引用的问题。对于共享对象来说，如果数据段中有绝对地址引用，那么编译器和链接器就会产生一个重定位表，这个表中包含重定位的入口（类型为 “R_386_RELATIVE” ），当动态链接器装载共享对象时，如果发现该共享对象有这样的重定位入口，那么动态链接器就会对该共享对象进行重定位。","link":"/2020/04/16/Linkers-Loaders-7/"},{"title":"Python-class","text":"2020/10/25更新 整合了内容 Python面向对象编程 ps：相对熟悉的知识就不仔细列出了 定义与实例 class定义一个对象 类的实例是以函数的形式调用类对象来创建的，__init__()为构造函数，__del__()为析构函数 作用域规则 Python类中没有作用域，这与C++，Java不同。而需要显示使用self的原因在于Python没有提供显示声明变量的方式（如：int x；），因此无法知道在方法中要赋值的变量是不是局部变量，或者是否要保存为实例属性，而显示self可以解决这一问题。 继承 super(cls, instance)会返回一个特殊对象，该对象支持在基类上执行属性查找。你可以通过super获取基类，调用基类的函数。在Python3中，super中的参数可以不要。 多继承不要使用不要使用不要使用 多态动态绑定和鸭子类型 动态绑定（在继承背景下使用，也成多态），obj.attr，首先搜索实例本身，然后是实例的类定义，然后是基类，查找会返回第一个匹配项 动态绑定在于其不受对象obj的类型影响，因此如果执行像obj.name这样的查找，对于所有拥有name属性的obj都适用。这种行为有时候被称作“鸭子类型”（duck typing），这个名称来源于一个谚语：“如果看起来，叫声像而且走起路来像鸭子，那么它就是鸭子”。 静态方法和类方法 静态方法是一种普通函数，只不过它们正好位于类定义的命名空间中，它不会对任何实例进行操作。要定义静态方法，使用@staticmethod装饰器，同时调用静态方法只需要类名作为前缀cls.staticmethod 类方法是类本身作为对象进行操作的方法。使用@classmethod装饰器定义，类作为第一个参数传递，例如： 12345678910111213class Times(): factor = 1 @classmethod def mul(cls, x): return cls.factor * xclass TwoTimes(Times): factor = 2x = TwoTimes.mul(4)print(x)#结果为8 特性 通常，访问实例或类的属性时，返回的是存储的相关值。而特性（property）是一种特殊的属性，访问它时会计算它的值。 12345678910111213141516171819202122import mathclass Circle(): def __init__(self, radius): self.radius = radius @property def area(self): return math.pi * self.radius ** 2 @property def perimeter(self): return 2 * math.pi * self.radiusc = Circle(5)print(c.area)print(c.perimeter)#结果#78.53981633974483#31.41592653589793 我们的area和perimeter并非是通过调用函数来计算所得（并没有调用area（）），而是通过radius计算所得，结果作为类的一个属性，但是该属性不能被赋值。 特性还可以截获操作权，以设置和删除属性 下面例子使用property(getf=None, setf=None, delf=None, doc=None)来定义特性。 12345678910111213141516# 定义一个可控属性值 xclass C(object): def __init__(self): self._x = None def getx(self): return self._x def setx(self, value): self._x = value def delx(self): del self._x x = property(getx, setx, delx, &quot;I'm the 'x' property.&quot;) 如果 c 是 C 的实例化, c.x 将触发 getter,c.x = value 将触发 setter ， del c.x 触发 deleter。 如果给定 doc 参数，其将成为这个属性值的 docstring，否则 property 函数就会复制 fget 函数的 docstring（如果有的话）。 下面例子是另一种写法（推荐），将 property 函数用作装饰器可以很方便的创建只读属性： 12345678910111213141516171819202122232425262728class Parrot(object): def __init__(self): self._voltage = 100000 @property def voltage(self): &quot;&quot;&quot;Get the current voltage.&quot;&quot;&quot; return self._voltage # 上面的代码将voltage()方法转化成同名只读属性的getter方法（功能一样，只是名字不一样）。# property的getter,setter和deleter方法同样可以用作装饰器：class C(object): def __init__(self): self._x = None @property def x(self): &quot;&quot;&quot;I'm the 'x' property.&quot;&quot;&quot; return self._x @x.setter def x(self, value): self._x = value @x.deleter def x(self): del self._x 这个代码和第一个例子完全相同，但要注意这些额外函数的名字和property下的一样。 描述符 使用特性后，对对象的访问将通过一系列的用户定义的get，set，delete控制。这种属性将通过描述符对象进一步泛化。描述符就是一个代表属性值的对象。通过实现一个或多个特殊的__get__(), __set__(), __delete__()方法，可以将描述符和属性访问机制挂钩，也可以自定义这些操作。 12345678910111213141516171819202122232425262728class TypedProperty(): def __init__(self, name, type, default=None): #self.name = name self.name = &quot;_&quot; + name self.type = type self.default = default if default else type() def __get__(self, instance, owner): return getattr(instance, self.name, self.default) def __set__(self, instance, value): if not isinstance(value, self.type): raise TypeError(&quot;Must be a %s&quot; % self.type) setattr(instance, self.name, value) def __delete__(self, instance): raise AttributeError(&quot;Can't delete attribute&quot;)class Foo(): name = TypedProperty(&quot;name&quot;, str) num = TypedProperty(&quot;num&quot;, int, 42)f = Foo() a = f.name # 隐式调用Foo.name.__get__(f, Foo)f.name = &quot;cyx&quot; # 调用Foo.name.__set__(f, &quot;cyx&quot;)del f.name # 调用Foo.name.__delete__(f) 个人的理解就是（以上例中的name），创建了一个实例，该实例通过getattr调用str类型的属性，通过调用str的setattr来设置属性。 描述符只能在类级别上进行实例化。不能通过在__init__()和其他方法中创建描述符对象来为每个对象创建描述符。持有描述符的类使用的属性名称比实例存储的属性名称有更高的优先级，描述符对象接受name时对其值略加修改（加了一个下划线），原因就在于此，为了让描述符在实例上存储值，描述符必须挑选一个与它本身所用名称不同的名称。（不懂2333）。 数据封装和私有属性 object # public __object__ # special, python system use, user should not define like it __object # private (name mangling？ during runtime) _object # obey python coding convention, consider it as private 核心风格：避免用下划线作为变量名的开始。 类中的所有已双下滑线开头的名称，无论属性还是方法，都会形成_Classname__xx形式的新名称，这样不会和基类的私有变量发生冲突 尽管这种方法似乎隐藏了数据，但没有严格的机制来实际阻止对类的“私有”属性的访问。特别是如果已知类的名称和相应的私有属性的名称，则可以使用变形后的名称来访问。通过重定义__dir__()方法，类可以降低这些属性的可见性，__dir__()方法提供了对象的dir()所返回的名称列表,如下： 12345678910111213141516class Foo(): __bar = 1 def foo(self): print(self.__bar)a = Foo()a.foo()a._Foo__bar = 5print(a._Foo__bar)a.foo()#结果#1#5#5 这就很神奇，明明我声明了私有变量，你在类外却可以访问，这显然破坏了私有性，不要使用。 12345678910class A(): __x = 2 def __dir__(self): print(dir(A)) return dir(A)[1:]a = A()print(a.__dir__()) 我们对dir的返回结果切片，自定义了__dir__()的返回结果，这样我们就无法在类外知道类里究竟有无私有变量了（私有变量一般会放在最前面） 对象内存管理 我们定义类后得到的实际是一个可以创建新实例的工厂。 __init__&amp;__new__ 实例的创建包括2个步骤，使用特殊方法__new__()创建新的实例，然后使用__init__()初始化 123c = Circle.__new__(Circle, 4)if isinstance(c, Circle): Circle.__init__(c, 4) 类的__new__()方法很少通过用户代码定义。如果定义了它，它的原型 __new__(cls, *args, **kwargs) 所以，__init__ 和 __new__ 最主要的区别在于： 1.__init__ 通常用于初始化一个新实例，控制这个初始化的过程，比如添加一些属性， 做一些额外的操作，发生在类实例被创建完以后。它是实例级别的方法。 2.__new__ 通常用于控制生成一个新实例的过程。它是类级别的方法。 依照Python官方文档的说法，__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass(元类)。 如： 12345678910111213141516class UpperStr(str): def __init__(self, string): string = string.upper()class UpperStrClass(str): def __new__(cls, value): return super().__new__(cls, value.upper())u1 = UpperStr(&quot;hello&quot;)u2 = UpperStrClass(&quot;hello&quot;)print(u1)print(u2)# 结果# hello# HELLO 对象管理 创建实例后，实例将由引用计数来管理。如果引用计数到达0，实例立即被销毁。当销毁时，解释器会先找与对象相关的__del__()并调用。实际上，很少定义该方法。唯一的例外是在销毁对象时需要执行操作的（如关闭文件，关闭网络连接或释放其他系统资源）。即使在这样的情况下，依靠__del__()来完全关闭依然存在风险。更好的方案是定义一个方法，如close（），程序可以使用该方法显示执行关闭操作。 有时，程序使用del语言删除对象引用。如果这导致引用计数为0，则会调用__del__(),但del通常不会直接调用__del__() 尽管定义__del__()很少会破坏垃圾回收器，但在某些编程模式下可能会引起问题，如：“观察者模式”（Observer Pattern） 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Account(): def __init__(self, name, balance): self.name = name self.balance = balance self.observers = set() def __del__(self): for ob in self.observers: ob.close() del self.observers def register(self, observer): self.observers.add(observer) def unregister(self, observer): self.observers.remove(observer) def notify(self): for ob in self.observers: ob.update() def withdraw(self, amount): self.balance -= amount self.notify()class AccountObserver(): def __init__(self, theAccount): self.theAccount = theAccount theAccount.register(self) def __del__(self): self.theAccount.unregister(self) del self.theAccount def update(self): print(&quot;Balance is %0.2f&quot; % self.theAccount.balance) def close(self): print(&quot;Account no longer use!&quot;)a = Account(&quot;Dave&quot;, 1000)a_ob = AccountObserver(a) 看起来似乎没啥毛病，这段代码中Account类允许一组AccountObserver对象监控。每个Account会有一组观察者，而每个观察者会保留对账户的引用。 每个类都定义了__del__()，尝试清除（如注销），但是，这会建立一个引用循环，在这个循环中，引用计数永远不会到0，也永远不会执行清除操作，不仅如此，垃圾回收机器（gc机制）甚至不会清除该类，导致内存永久泄露。 解决方案就是使用弱引用，用一种在不增加引用计数的情况下创建对象的引用方式。 修改后的代码： 123456789101112131415161718import weakrefclass AccountObserver(): def __init__(self, theAccount): self.accounRef = weakref.ref(theAccount) #创建弱引用 theAccount.register(self) def __del__(self): acc = self.accounRef # 获取账户 if acc: # 如果存在则注销 acc.unregister(self) def update(self): print(&quot;Balance is %0.2f&quot; % self.accounRef.balance) def close(self): print(&quot;Account no longer use!&quot;) __slots__ 通过定义特殊变量__slots__，类可以限制对合法实例属性名称的设置，如下: 1234class Account(): __slot__ = (&quot;name&quot;, &quot;balance&quot;) ···· 定义__slot__时，可以将实例上分配的属性名称限制为指定名称，否则引发AttributeError异常。这可以阻止其他人向现有实例增加新属性，或者用户写出属性导致加入新的属性 但实际使用中，__slot__从未被当做一种安全特性来实现。它实际上是对内存和执行速度的一种性能优化。在会创建大量对象的程序中，__slot__的使用可以显著的减少内存占用和执行时间 对象表示和属性绑定 从内部实现上看，实例是用字典实现的，可以使用__dict__()属性访问该字典，这个字典包含的数据对每个实例而言是唯一的。对对象属性的修改会反映在__dict__()中，而直接修改__dict__()也会影响对象的属性。 1234&gt;&gt;&gt;a = Account(&quot;xkx&quot;, 1200)&gt;&gt;&gt;a.__dict__{'balance': 1200, 'name': &quot;xkx&quot;}&gt;&gt;&gt;a.description = &quot;nb&quot; # 会在__dict__()中添加 实例通过特殊属性__class__()链接回类。类本身也可以看做对字典的浅层包装。 &gt;&gt;&gt;a.__class__ &lt;class ‘__main__.Account’&gt; 特殊属性__base__()中将类链接到它们的基类，该属性是一个基类元组。这种底层结构是获取，设置，删除对象属性的所有操作的基础。 当使用obj.name = value时，就会调用特殊方法obj.__setattr__(“name”, value),删除时会调用__delattr__(“name”)，这种默认的行为是修改或删除obj的局部的__dict__()的值。 查找属性时，obj.name, 将调用__getattribute__(“name”)，会检查特性，局部__dict__，类字典，基类。如果该过程失败，则会调用类的__getattr__()方法（如果定义了）来查找，如果还是没有找到，就会抛出AttributeError异常。 一般类很少重新定义属性访问运算符，但在编写通用的包装器和现有对象代理时，会用的上。 元类 类对象的创建方式是由一种名为元类的特殊对象控制的，简而言之，元类就是知道如何去创建和管理类的对象。 12345&gt;&gt;&gt;class Foo(): pass···&gt;&gt;&gt;type(Foo)&lt;class 'type'&gt; 这个例子，控制Foo创建的就是名为type的类 当使用class来定义新类时，将会发生很多事情。首先，类主体将作为其自己的私有字典内的一系列语句来执行。语句的执行和正常代码的执行一样，只是增加了会对私有成员发生名字变形。最后，类的名称，基类列表，字典将传给元类的构造函数，创建响应的类对象。下面例子演示了这一过程： 1234567891011121314151617class_name = &quot;Foo&quot;class_parents = (object, )class_body = &quot;&quot;&quot;def __init__(self, x): self.x = xdef blah(self): print(&quot;Hello World&quot;)&quot;&quot;&quot;class_dict = {}exec(class_body, globals(), class_dict) # 在局部字典中执行类主体Foo = type(class_name, class_parents, class_dict) # 创建对象# 打印一下Foo会得到和class Foo一样的结果# &lt;class '__main__.Foo'&gt; 最后一步调用元类，该元类可以自己定义，如class Foo（mateclass=type） 如果没有显示指定元类，将检查基类元组，元类与第一个基类的类型相同。 如果没有指定基类，class将检查全局变量__metaclass__是否存在。如果有，就会使用其创建类。 最最后，使用默认元类，Python3默认为type() 例子，要求用户定义类的方法必须拥有一个文档字符串： 12345678910class DocMeta(type): def __init__(self, name, bases, dict): for key, value in dict.items(): if key.startwith(&quot;__&quot;): # 跳过私有方法 continue if not hasattr(value, &quot;__call__&quot;): # 跳过不可调用的方法 continue if not getattr(value, &quot;__doc__&quot;): # 检查doc字符属性 raise TypeError(&quot;%s must have a docsting&quot; % key) type.__init__(self, name, bases, dict) 更高级的用法（看看就行了），元类可以在创建类前同时检查和更改类定义的内容，这需要重写__new__(). 1234567891011121314151617181920212223242526class TypedProperty(): def __init__(self, type, default=None): self.name = None self.type = type self.default = default if default else type() def __get__(self, instance, owner): return getattr(instance, self.name, self.default) def __set__(self, instance, value): if not isinstance(value, self.type): raise TypeError(&quot;Must be a %s&quot; % self.type) setattr(instance, self.name, value) def __delete__(self, instance): raise AttributeError(&quot;Can't delete attribute&quot;)class TypeMeta(type): def __new__(cls, name, bases, dict): slots = [] for key, value in dict.items(): if isinstance(value, TypedProperty): value.name = &quot;_&quot; + key slots.append(value.name) dict['__slots__'] = slots return type.__new__(cls, name, bases, dict) part1的一个例子，不同的是我们设置self.name变成了在元类里设置。该例子中，元类扫描类字典，查找TypedProperty的实例，找到的话，设置name属性并在slots中建立名称列表。完成之后__slots__将添加到类字典中，通过type元类的__new__来构造。 类装饰器 有时不用小题大做弄元类来处理一些问题，只用简单的写个修饰器就行。如将类添加到注册表或数据库。 123456789101112131415161718def register(cls): if cls.classification == &quot;A&quot;: # do something pass elif cls.classification == &quot;B&quot;: # do something pass else: # do something pass return cls@registerclass Foo(): classification = &quot;A&quot; pass 这个例子可以对类按自定义的功能划分，进行不同的后续处理（写不同的日志啥的）","link":"/2019/07/15/Python-class-1/"},{"title":"bird-identify","text":"软件工程炼丹心得与体会 其实就是深度学习入门吧 大三上软工项目：鸟类识别与分享平台，项目传送门iBird 在充分了解了深度学习（指前两周看了老师发的视频）后开始尝试构建鸟类识别模型，这篇博客用于记录自己在学习中的一点点收获。 ps:基础太差了，感觉好多时候都是在瞎炼。 一点点准备 Pytorch + Cuda 我的电脑GPU内存不咋够用，所以训练主要放在了 Colab 上 模型训练的数据源于AI 研习社-200种鸟类识别分类 模型的构建 细粒度图像识别 200 种鸟类识别其实是一个细粒度图像识别问题(fine-grained image recognition) 对于现在的模型，识别出物体的大类别（比如：猫，狗，手机，车）比较容易，但如果要进一步去更细的划分物体的类别和名称，难度就大了很多，在这其中，有一些子类别的差异十分的小，如何区分布他们是比较困难的。 目前，精细化分类的方法主要有以下两类： 基于图像重要区域定位的方法：该方法集中探讨如何利用弱监督的信息自动找到图像中有判别力的区域，从而达到精细化分类的目的。 基于图像精细化特征表达的方法：该方法提出使用高维度的图像特征（如：bilinear vector）对图像信息进行高阶编码，以达到准确分类的目的。 举我看的论文里面的例子吧： 在 Bilinear CNN Models for Fine-grained Visual Recognition 这篇论文里提到了： Fine-grained recognition tasks such as identifying the species of a bird … are quite challenging because the visual differences between the categories are small and can be easily overwhelmed by those caused by factors such as pose, viewpoint, or location of the object in the image. 这里提到了，细粒度识别的一个很大的难度在于&quot;细小的差别会被鸟的姿势，视角，拍摄的位置给掩盖掉&quot;（这里是以鸟为例） For example, the inter-category variation(类别间的变化) between “Ringed-beak gull” and a “California gull” due to the differences in the pattern on their beaks(喙) is significantly smaller than the inter-category variation on a popular fine-grained recognition dataset for birds. 论文中举了环嘴鸥（Ringed-beak gull）和加州鸥（California gull）在喙上的差别要明显小于细粒度分别的数据集中的差别。 为了解决这个问题，这篇论文中提出了一个 BCNN 模型来解决，我主要学习的也是这个模型，不过这是后面要说的了。 预处理 在正式写我们的模型前，要先写好读取数据的方法，数据集就用 AI 研习社上的了，先在本地下一份。 对于数据，我们交给模型训练的时候，一般都会进行预处理，预处理的方法有很多，最常用的如下： 平移：一定尺度内平移 旋转：一定角度内旋转 翻转：水平或者上下翻转 裁剪：在原有图像上裁剪一部分 颜色变化：rgb 颜色空间进行一些变换（亮度对比度等） 噪声扰动：给图像加入一些人工生产的噪声 说的高级点好像叫数据增强 123456789101112131415161718from torchvision import transforms as transforms# 随机比例缩放transforms.Resize((100, 200))# 随机位置裁剪transforms.RandomCrop(100)# 中心裁剪transforms.CenterCrop(100)# 随机垂直水平翻转transforms.RandomVerticalFlip(p=1)transforms.RandomHorizontalFlip(p=1) # p表示概率# 随机角度旋转transforms.RandomRotation(45)# 色度，亮度，饱和度，对比度transforms.ColorJitter(brightness=1) # 亮度transforms.ColorJitter(contrast=1) # 对比度transforms.ColorJitter(saturation=0.5) # 饱和度transforms.ColorJitter(hue=0.5) # 色度 数据集 Pytorch 提供内置的图片数据集 ImageFolder，它有一个通用的数据加载器，它加载的数据要求以下面的方式组织： 123456789base_dir = &quot;xxx/xxx&quot;# data_dir 中的图片这样组织# data_dir/dog/xxx1.png# data_dir/dog/xxx2.png# data_dir/cat/xxx1.png# data_dir/cat/xxx2.pngpredict_sets = torchvision.datasets.ImageFolder(os.path.join(base_dir, &quot;data_dir&quot;), transform=your_trans) 这时读入的数据所有在 dog 文件夹下的都被打上了 dog 的标签，同理 cat。简单来说，你要将一类的图片全部放入一个以这个类别命名的文件夹下才能正常的读取。 这对于我们这个显然不太方面，所以就要自己写数据集的加载方式了 All datasets are subclasses of torch.utils.data.Dataset i.e, they have __getitem__ and __len__ methods implemented. Hence, they can all be passed to a torch. utils.data.DataLoader which can load multiple samples parallelly using torch.multiprocessing workers. 就是要我们实现两个函数__getitem__() 和 __len__() 12345678910111213class FirstDataset(data.Dataset):#需要继承data.Dataset def __init__(self): #在这里初始化 pass def __getitem__(self, index): #1 读取一个数据和标签 #2 预处理数据（例如 torchvision.transform） #3 返回数据对（例如图像和标签） pass def __len__(self): # 数据集的大小 pass 有了这个我们思路就很清晰了，由于我们的标签都在一个 .csv 文件中，里面包括图片名对应的标签号，我们用 Pandas 读入然后分列，在我们的__getitem__() 函数里一次取一个就好了（取第 item 个）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import osimport pandas as pdimport torchfrom torchvision.datasets.folder import accimage_loader, pil_loaderdef default_loader(path): from torchvision import get_image_backend if get_image_backend() == 'accimage': return accimage_loader(path) else: return pil_loader(path)class CustomDataset(torch.utils.data.Dataset): def __init__(self, data_path, data_label_path, data_transform, data_loader=default_loader): &quot;&quot;&quot; :param data_path: 要读取的文件的路径 :param data_label_path: 标签数据的路径 :param data_transform: 数据变换模式 :param data_loader: 加载方法 &quot;&quot;&quot; # 在 label文件中注意不要加上第一行列名行 df = pd.read_csv(data_label_path, header=None) self.data_loader = data_loader self.data_transform = data_transform self.data_path = data_path self.img_names = list(df[0]) self.labels = list(df[1]) def __len__(self): return len(self.img_names) # 模型训练的时候调用，返回一组图片和标签用于训练 def __getitem__(self, item): img_name = self.img_names[item] img_path = os.path.join(self.data_path, img_name) label = self.labels[item] img = self.data_loader(img_path) try: img = self.data_transform(img) return img, label-1 except: raise Exception(&quot;cannot transform image: {}&quot;.format(img_name)) 训练函数 Tranier 的写法比较固定，网上有各种各样的，贴一个我找到~~（自己写不来，但改了一下）~~ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970from typing import Tupleimport torchfrom torch.nn import Modulefrom torch.optim.optimizer import Optimizerfrom torch.utils.data import DataLoaderfrom tqdm import tqdmfrom torch.optim.lr_scheduler import ReduceLROnPlateauclass Trainer(object): def __init__( self, model: Module, criterion: Module, optimizer: Optimizer, device: torch.device) -&gt; None: super(Trainer, self).__init__() self.model: Module = model self.criterion: Module = criterion self.optimizer: Optimizer = optimizer self.device: torch.device = device def train(self, loader: DataLoader) -&gt; Tuple[float, float]: total_loss, total_acc = 0.0, 0.0 self.model.train() try: with tqdm(enumerate(loader), total=len(loader), desc='Training') as proc: for _, (inputs, targets) in proc: inputs = inputs.to(self.device) targets = targets.to(self.device) outputs = self.model(inputs) loss = self.criterion(outputs, targets) self.optimizer.zero_grad() loss.backward() self.optimizer.step() _, predicted = torch.max(outputs, 1) total_loss += loss.item() total_acc += (predicted == targets).float().sum().item() / targets.numel() except Exception as e: # 异常情况关闭 print(&quot;Running Error in training, &quot;, e) proc.close() return -1, -1 proc.close() return total_loss / len(loader), 100.0 * total_acc / len(loader) def test(self, loader: DataLoader) -&gt; Tuple[float, float]: with torch.no_grad(): total_loss, total_acc = 0.0, 0.0 self.model.eval() try: with tqdm(enumerate(loader), total=len(loader), desc='Testing ') as proc: for _, (inputs, targets) in proc: inputs = inputs.to(self.device) targets = targets.to(self.device) outputs = self.model(inputs) loss = self.criterion(outputs, targets) _, predicted = torch.max(outputs, 1) total_loss += loss.item() total_acc += (predicted == targets).float().sum().item() / targets.numel() except Exception as e: proc.close() print(&quot;Running Error in validating,&quot;, e) return -1, -1 proc.close() return total_loss / len(loader), 100.0 * total_acc / len(loader) 比较喜欢这个写法，tqdm 是一个 Python 的进度条库，它有个问题是如果代码异常结束，它有时不会被停止，这样在第二次运行时会无法刷新输出窗口，导致看上去就不是一个进度条了，而是进度条每更新一次就打印出来一个新的，原来的还在。我们在套一个 try-catch 在异常的时候正确的关闭这个进度条进程就好了，用 close() 函数。 model.eval() 和 model.train()这两个必须要搞明白 model.train() 会启用 BatchNormalization 和 Dropout 而 model.eval() 不启用 BatchNormalization 和 Dropout。 否则的话，有输入数据，即使不训练，它也会改变权值。这是 model 中含有 batch normalization 层和 dropout所带来的的性质。 想象一下，如果被删除的神经元是唯一促成正确结果的神经元。一旦我们不激活它，其他神经元就需要学习如何在没有这些神经元的情况下保持准确。这种 dropout 提高了最终测试的性能。但它对训练期间的性能产生了负面影响，因为网络是不全的。 数据集加载 用 torch.utils.data.DataLoader 就可以，需要注意的是 Windows 下需要将 num_workers 设置为 0。 dataloader 一次性创建 num_worker 个 worker，他们负责将数据提前读入好内存。num_worker 设置得大，好处是寻 batch 速度快，因为下一轮迭代的 batch 很可能在前面几轮的迭代时已经加载好了。坏处是内存开销大，也加重了 CPU 的负担。num_workers 的经验设置看自己的 CPU 和 RAM 吧，如果 CPU 处理强，内存大，就可以设置得更大些。如果 num_worker 设为 0，意味着每一轮迭代时，dataloader 不再有自主加载数据到 RAM 这一步骤（没有worker了），而是在RAM 中找 batch，找不到时再加载相应的 batch。这样当然是速度慢。 模型 我鸟类识别的模型实现了两个（还有一个出问题了先不管他） BCNN Bilinear CNN Models for Fine-grained Visual Recognition 123456789101112131415161718192021222324252627class BilinearModel(nn.Module): &quot;&quot;&quot;Load model with pretrained weights and initialise new layers.&quot;&quot;&quot; def __init__(self, num_classes: int = 200, pretrained=True) -&gt; None: &quot;&quot;&quot;Load pretrained model, set new layers with specified number of layers.&quot;&quot;&quot; super(BilinearModel, self).__init__() model: nn.Module = models.vgg16(pretrained) self.features: nn.Module = nn.Sequential(*list(model.features)[:-1]) self.classifier: nn.Module = nn.Linear(512 ** 2, num_classes) self.dropout: nn.Module = nn.Dropout(0.5) nn.init.kaiming_normal_(self.classifier.weight.data) if self.classifier.bias is not None: nn.init.constant_(self.classifier.bias.data, val=0) @overrides def forward(self, inputs: torch.Tensor) -&gt; torch.Tensor: outputs: torch.Tensor = self.features(inputs) outputs = outputs.view(-1, 512, 28 ** 2) outputs = self.dropout(outputs) outputs = torch.bmm(outputs, outputs.permute(0, 2, 1)) # bilinear product outputs = torch.div(outputs, 28 ** 2) # normalize outputs = outputs.view(-1, 512 ** 2) outputs = torch.sign(outputs) * torch.sqrt(outputs + 1e-5) # signed square root normalization outputs = nn.functional.normalize(outputs, p=2, dim=1) outputs = self.dropout(outputs) outputs = self.classifier(outputs) return outputs 论文中原本推荐使用两个不同的模型来提取特征值然后使用一个双线性函数来进一步处理提取的特征值，后来又有人指出，使用同源的模型也可以得到不错的效果，所以我就尝试使用了 VGG 作为提取层，然后将处理好的结果使用一个全连接层对应 200 种鸟类。最后正确率在 75% 左右。 EfficientNet With Attention Attention机制还没咋看的（有空再补了），看别人这么用我也就瞎几把组合了一下。 Pytorch 实现的 EfficientNet 论文在此 这个我看懂了（震声！），论文对现有模型提出了反思：如果只是增加模型的深度（有多少层）（depth），宽度（每一层的参数数）（width），还有图像的解析度（输入的大小）（resolution）其中之一对模型的提升不完全而且有时还会导致准确率下降。Google 的研究员们发现当按照一个比率（ratio）同时提升这 3 个值，会让模型更好的提高准确度，也变得更加精简。它通过（经验？）发现这样的原则: $$ depth: d = \\alpha^\\phi \\ width: w = \\beta^\\phi \\ resolution: r = \\gamma^\\phi \\ s.t. \\quad \\alpha * \\beta^2 * \\gamma^2 \\approx 2 \\ \\quad \\quad \\quad \\quad \\quad \\alpha \\geqslant 1, \\beta \\geqslant 1,\\gamma \\geqslant 1 \\ $$ 按照这个原则，Google 提出了 EfficientNet 系列，非常精简并且准确率高的模型。 关于 Attention 机制，还没咋看呢，等待看完了加上。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970from efficientnet_pytorch import EfficientNetfrom torch.optim import lr_schedulerfrom torchvision import transformsimport torchfrom torch import nndef conv3x3(in_planes, out_planes, stride=1): # &quot;3x3 convolution with padding&quot; return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)class ChannelAttention(nn.Module): def __init__(self, in_planes, ratio=16): super(ChannelAttention, self).__init__() self.avg_pool = nn.AdaptiveAvgPool2d(1) # 压缩空间 self.max_pool = nn.AdaptiveMaxPool2d(1) self.fc1 = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False) self.relu1 = nn.ReLU() self.fc2 = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x)))) max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x)))) out = avg_out + max_out # [b, C, 1, 1] return self.sigmoid(out)class SpatialAttention(nn.Module): def __init__(self, kernel_size=7): super(SpatialAttention, self).__init__() assert kernel_size in (3, 7), 'kernel size must be 3 or 7' padding = 3 if kernel_size == 7 else 1 self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): avg_out = torch.mean(x, dim=1, keepdim=True) # 压缩通道 max_out, _ = torch.max(x, dim=1, keepdim=True) # 压缩通道 x = torch.cat([avg_out, max_out], dim=1) # [b, 1, h, w] x = self.conv1(x) return self.sigmoid(x)class EfficientNetWithAttention(nn.Module): def __init__(self, num_classes: int = 200): super(EfficientNetWithAttention, self).__init__() self.eff_model = EfficientNet.from_pretrained(&quot;efficientnet-b7&quot;) self._avg_pooling = nn.AdaptiveAvgPool2d(output_size=1) self._dropout = nn.Dropout(p=0.5, inplace=False) self.fc = nn.Linear(in_features=2560, out_features=num_classes, bias=True) self.ca_head = ChannelAttention(64) self.sa = SpatialAttention() self.ca_tail = ChannelAttention(2560) def forward(self, x): x = self.eff_model.extract_features(x) # 最后一层加入 Attention 机制 x = self.ca_tail(x) * x x = self.sa(x) * x x = self._avg_pooling(x) if self.eff_model._global_params.include_top: x = x.flatten(start_dim=1) x = self._dropout(x) x = self.fc(x) return x 最后准确率在 81% 左右，大小仅仅需要 200+MB，比前一个小多了！ 学习率调整函数 一般来说，我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，使得网络更好的收敛到最优解。 固定步长衰减 使用 torch.optim.lr_scheduler.StepLR 12optimizer_StepLR = torch.optim.SGD(net.parameters(), lr=0.1)StepLR = torch.optim.lr_scheduler.StepLR(optimizer_StepLR, step_size=step_size, gamma=0.65) 其中gamma参数表示衰减的程度，step_size参数表示每隔多少个step进行一次学习率调整 ReduceLROnPlateau 使用 torch.optim.lr_scheduler.ReduceLROnPlateau 他可以基于训练中的某些测量值对学习率进行动态下降。 12torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08) mode 可选择 min 或者 max ，min 表示当监控量停止下降的时候，学习率将减小，max 表示当监控量停止上升的时候，学习率将减小。 factor 学习率每次降低多少。new_lr = old_lr * factor min_lr,学习率的下限 写在最后 感觉软工这个项目确实学到了点深度学习和人工智能的东西，但又说不上来（还是太菜了）。2020 年要结束了，今年的工作绝不拖到明年做！先这样子了，忙去复习期末了，等有空了还会捡起来接着做的！数学不好感觉学不明白… 下一步大概是尝试异元的 BCNN，一个用 EfficientNet 和另一个用 EfficientNet + Attention。还有就是提取特征后使用 SVM 或者一些拟合函数来训练，希望能突破85% 的准确率吧。 参考 腾讯云：细粒度图像识别概述 实战200类鸟类细粒度图像分类|这个我虽然没看懂代码，但学习了点方法 Bilinear CNN Models for Fine-grained Visual Recognition dasguptar/bcnn.pytorch lukemelas/EfficientNet-PyTorch pytorch必须掌握的的4种学习率衰减策略","link":"/2020/12/31/bird-identify/"},{"title":"中国邮递员问题","text":"个人平常不写算法的博客，主要是太懒太菜，前一段时间离散数学小组展示展示中国邮递员问题现场举例的时候翻车了，这次记录一下中国邮递员问题，来让自己铭记准备不充分，理解不透彻，队友两行泪。 ps：对于我的一些理解错误的地方还请就当看个乐子，还有这次博客巨长（md文件竟然有500+行，对于我平常只写200-300左右，我惊了），测试例子的不多，反正课本上的例子过了，不确定是不是 100% 正确太菜了 中国邮递员问题 问题背景 一个邮递员从邮局出发投递信件，他必须在他所管辖范围内的所有街道至少走一次，最后回到邮局，他自然希望选择一条最短的路线完成投递任务，那么如何选择这样的路线呢?这个问题是中国数学家管梅谷先生首先提出的，因而被称作中国邮递员问题，也可以简称为邮递员问题。 数学建模 要解邮递员问题，首先应将该问题用图来描述。构造无向带权图 G={V,E,W}，E 为街道集合，V 中元素为街道的交叉点。街道的长度为该街道对应的边的权，显然所有权均大于0。邮递员问题就变成了求G中一条经过每条边至少一次的回路，使该回路所带权最小的问题，并且称满足以上条件的回路是最优投递路线或最优回路。 理论求解 若G是欧拉图，则最优投递路线为 G 中的任意一条欧拉回路。 若 G 不是欧拉图，则 G 必有奇度顶点，设 G 是连通图，为了消去奇度顶点，必须加若干条重复边，设所得图为 G* ，于是求 G 的最优投递路线就等价于求 G* 的一条欧拉回路。 加入重复的边需要满足一定的条件： G 的每条边在 G* 中至多重复出现一次（否则删掉两条平行边，所有顶点依旧是偶数度，得到了一个总权值更小的欧拉图） G 的每个圈上在 G* 中重复出现的边的权之和不超过该圈权的一半。（用通俗点的话来讲就是，一个圆环周长是4，其上两点之间的劣弧长最多是2） 我们可以证明： 设带正权无向连通图 G={V,E,W} ，V’ 为 G 中奇度顶点集，设 |V’|=2k(k≥0)，F={e|e∈E 且在求 G 的最优回路时加了重复边}，则 F 的导出子图 G[F] 可以表示为以 V’ 中顶点为起点与终点的 k 条不交的最短路径之并。即我们求非欧拉图的中国邮递员问题转换为求 V’ 中顶点为起点和终点的不相交的最短路径的长度 整理一下： n 为 C 中顶点数。 算法步骤如下: 若 G 中无奇度顶点，令 G*=G，转2，否则转3。 求 G* 中的欧拉回路，结束。 -&gt; Fleury 算法 求 G 中所有奇度顶点对之间的最短路径。 -&gt; Floyd &amp; Dijkstra 算法 求出奇度顶点之间组合的最小值（最优匹配） 将 M 中边对应的各最短路径中的边均在 G 中加重复边，得欧拉图G*，转2。 简化问题 问题目前集中到了如何求最小的&quot;组合&quot;，即求奇度顶点集合中顶点为起点和终点的不相交的最短路径的长度之和。顺便也要求出来这个路径经过了那些点，不然就只完成了求最短路径，我们的邮递员还是不知道该怎么走。 算法 暴力 简单易懂，无脑好实现 基本思路是对于奇度顶点，尝试枚举所有的情况的组合来比较得出最小的 我们举例来说明：v2,v4,v6,v8 两两组合，可以有限的枚举出组合 {(v2,v4),(v6,v8)}，{(v2,v6),(v4,v8)}，{(v2,v8),(v4,v6)}，我们比较容易比较出来究竟哪个最小。 看起来很舒服，只需要亿个 for 循环就可以搞得定，但如果奇度点增多，导致组合会更加的多，这时如果盲目的枚举会导致算法的时间复杂度垂直上升，这时候就需要一个巧妙的枚举方法：dp 压缩法 经过在网上的学习，我找到了这样的一个算法，它将所有的奇度顶点按照1234重新编号，将它们对应2进制的1234位（从右到左），这样我们可以用1111来表示一个含有这4个点的集合，1101表示含有重新编号过后的含有134这3个点的集合。那么我们对每个集合求最小的不重复的路径的并，最终1111（十进制的15）这个集合的求出的数就是我们想要的。 那应该怎么求呢，我们以上面的例子为例，我们先对 {v2,v4,v6,v8} 重新编号{1,2,3,4}为首先我们定义一个16大小的数组 dp，全部初始化为最大值，对于每次计算一个位置的值的时候，将索引的二进制表示出来，如要计算dp[7](0111)，我们就去寻找0111代表的集合{123}的不同组合方式 {12,3}, {13,2}, {23,1},这时我们就可以用 d[3] + d[4] 来更新它了。当然求这个组合是没有任何意义的，这只是让我们能更好的理解这个算法的关键思想：用局部的小值更新大的值。 理解了这个算法的本质时，我们在编写的时候实际并不需要对于dp数组的每个元素都求出其值，我们只需要自己构造就行了，简单来说就虽然也是遍历整个dp数组，但我们每次选择x，y（不在当前的组合中）去构造一个更大的，然后用更大的和我们构造的来比较取小值就可以了，比较的方法就是 min{dp[i]+d[x][y],dp[t]}，我们举dp[15]的例子来看，当我们一个2个元素的集合扩充x,y后，比如原本是集合里是{12},加上3和4（对应v6,v8），这时我们比较，如果dp[3]+d[6][8]&lt;dp[15]，则更新dp[15]。 大概就是这样一个思路，对于初始是3元的集合由于找不到y就完全不需要进行计算，这样相当于我们实际有好多的空间时没有用到的，代码实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114# -*- coding:utf-8 -*-import sys# 方法 1 使用动态规划来搜索最小组合def floyd(graph_matrix): n = len(graph_matrix) # 构造 path 数组 path = [] for i in range(n): path.append([]) # 初始化 for i in range(n): for j in range(n): path[i].append(j) for k in range(n): for i in range(n): for j in range(n): if graph_matrix[i][k] == sys.maxsize or graph_matrix[k][j] == sys.maxsize: continue temp = graph_matrix[i][k] + graph_matrix[k][j] if temp &lt; graph_matrix[i][j]: graph_matrix[i][j] = temp # 更新路径 path[i][j] = path[i][k] return graph_matrix, pathdef shortest_path(graph_matrix, d): &quot;&quot;&quot; :param graph_matrix: 邻接矩阵 :param d: 度数组 :return: 最短路径 &quot;&quot;&quot; # 度为奇数的顶点 graph_matrix, _ = floyd(graph_matrix) odd_points = [0] # 初始化包含0便于后续dp数组dp[0]的计算 for i, di in enumerate(d): if di % 2 == 1: odd_points.append(i) # 奇度顶点的个数 odd_num = len(odd_points) - 1 dp = [0] # dp[0] 无一个点所以长度也为0 dp_length = 1 &lt;&lt; odd_num # 初始化数组填入最大的数 for i in range(dp_length): dp.append(sys.maxsize) for i in range(dp_length): x = 1 while (1 &lt;&lt; (x-1)) &amp; i: # 选择不在当前集合的点x x += 1 for y in range(x+1, odd_num+1): # x+1 &lt;= y &lt;= odd_num # 选择不在集合内的与x不同的y if (1 &lt;&lt; (y-1)) &amp; i: continue else: # 计算 binary_pt = i | (1 &lt;&lt; (x-1)) | (1 &lt;&lt; (y-1)) # 新形成的集合 if graph_matrix[odd_points[x]][odd_points[y]] == sys.maxsize: # x,y 不连通 pass elif dp[i] == sys.maxsize: # 对于这个组合无最短路径 pass else: trail = dp[i] + graph_matrix[odd_points[x]][odd_points[y]] # 更新最短路径 dp[binary_pt] = min(dp[binary_pt], trail) # print(dp[dp_length-1]) return dp[dp_length-1]def main(): # 记录的所有路求和 n = 0 d = [] min_length = 0 with open(&quot;中国邮递员问题测试数据1.txt&quot;, 'r') as fp: scales = fp.readline() n, m = map(int, scales.split(' ')) # 初始化 for i in range(n): d.append(0) graph = [[sys.maxsize]*n for _ in range(n)] # 读入数据 for line in fp.readlines(): start_point, end_point, weight = map(int, line.split(' ')) # 点标号从 1 开始 start_point -= 1 end_point -= 1 d[start_point] += 1 d[end_point] += 1 # 无向图 graph[start_point][end_point] = weight graph[end_point][start_point] = weight min_length += weight print(graph) print(&quot;最小路径长度为:&quot;, end='') t = 0 for di in d: if di % 2 == 0: t += 1 if t == n: # 所有点读数都是偶数度，为欧拉图 pass else: min_length += shortest_path(graph, d) print(min_length)if __name__ == '__main__': main() KM 方法1虽然好，但是有个问题是求解最小路径是怎么组合出来的相当的让人头疼，不直观，而且毕竟是暴力，奇度顶点多起来的时候数组就开的更加的大 下面介绍的是课本上的标准解法，它通过 km 算法来求出奇度顶点的最小匹配。小问号你是不是有很多的朋友? 我们慢慢来理这个算法，首先我们需要对基础知识进行一些补充的学习： 补基础 二部图 通俗来将就是把一个图分成2部分，这2个部分内部所有点不相连，只有2部分之间有连起来的边，也叫二分图 二部图中的匹配 通俗的描述为从两个部分各取一个点，满足他们之间相连的这样的组合的集合（你可以理解为找男女对象） 完备匹配 通俗的说就是一个匹配 M，M 中包含二部图的所有的点（男女嘉宾全部牵手成功） 最优匹配 将二部图的每条边赋一个权值，对于不连通的部分赋一个0权的边，这就称为了一个完全带权二部图，最优匹配（最佳匹配）就是求一个完备匹配使得边权值总和最大。 增广路径 KM算法用于选择带权二部图的最佳匹配 匈牙利算法用于寻找二分图的最大匹配（完备匹配） KM 和匈牙利算法都涉及一个很重要的概念：增广路径 增广路径的特点： 有奇数条边 起点在二分图的一侧（x），终点在另一侧（y） 路径的点交替选择x，y侧的点，无重复点 起点终点都是没有匹配的点，其余的点都已经匹配过 路径上所有第奇数边都是目前还没有进入匹配子图的边，第偶数条边都是进入匹配子图中的边 增广路径的性质 加入所有的第奇数条边，删除所有的第偶数条边，匹配数加1 匈牙利算法 匈牙利算法就是一个不断寻找增广路径来使得最终求得的匹配为最大的。 如何找增广路径？ 深度搜索，如果xi要和yi匹配，但yi和xk匹配了，就去为xk找新的匹配点（未被匹配过），如果有yk就可以修改匹配方法为(xi,yi),(xk,yk)，没有就换一个未匹配的yi与xi尝试匹配。举个例子： 我们要求一个完备匹配，就对每个点找增广路径，简单来说，为每个点找个匹配，找不到就尝试调整被匹配的点让他换一个，这样2边都能满足了。 比如说14匹配，现在2要和4匹配，就重新为1（和4匹配）找个新的点，5就可以，这样找如果找不到的话就换一个点匹配，假如删去15之间的边，那么2就没法和4匹配，它只能换下一个点（5）尝试匹配 KM 算法 我们回到 KM 这里，KM算法的流程用文字来描述就是： 对于每个二部图的点，给与一个”顶标”，对于 x 侧，顶标的值记录在 x 数组，第i个元素初始化为 xi 点所有边的最大值，对于y 侧的点，顶标的值初始化为0 用匈牙利算法在相等子图中求完备匹配（相等子图中的点要满足x[i]+y[j]==w[i][j]，即i，j顶标和要为 i，j 之间边的权值） 如果找不到完备匹配，说明某个点 xi 出发在相等子图中没有找到增广路径。此时需要修改顶标值，对于增广路径上的属于 x 侧的点的顶标减去 d，属于 y 侧的点的顶标加上 d，d 的取值为 min{x[i]+y[j]-w[i][j], i属于增广路，j不属于增广路} 重复上面直至匈牙利算法求出来完备匹配 可以证明当相等子图的最大匹配为原图的完备匹配时，匹配边的权值和等于所有顶点的顶标和，此匹配即为最佳匹配 而至于为什么要这样修改顶标的值呢？详细的可以看百科，这里直接复制了： 我们一定找到了许多条从 Xi 出发并结束于 X 部的匹配边与未匹配边交替出现的路径，姑且称之为交错树。我们将路径中 X 部的顶点顶标减去一个值 d，交错树中属于 Y 部的顶点顶标加上一个值 d。那么我们会发现： 两端都在交错树中的边 (i,j)，其顶标和没有变化。也就是说，它原来属于相等子图，现在仍属于相等子图。 两端都不在交错树中的边 (i,j)，其顶标也没有变化。也就是说，它原来属于（或不属于）相等子图，现在仍属于（或不属于）相等子图。 X 端不在交错树中，Y 端在交错树中的边 (i,j)，它的顶标和会增大。它原来不属于相等子图，现在仍不属于相等子图。 X 端在交错树中，Y 端不在交错树中的边 (i,j),它的顶标和会减小。也就说，它原来不属于相等子图，现在可能进入了相等子图，因而使相等子图得到了扩大。 我们修改顶标的目的就是要扩大相等子图。为了保证至少有一条边进入相等子图，我们可以在交错树的边中寻找顶标和与边权之差最小的边,这就是前面说的 d 值。将交错树中属于 X 部的顶点减去 d，交错树中属于 Y 部的顶点加上 d。则可以保证至少有一条边扩充进入相等子图。 举个例子： 首先初始化 x 数组和 y 数组（顶标数组），选的都是边的最大值，相等子图是{16, 63, 25} 我们对1找不到完备匹配，得到了一个交错树{163}，这时我们计算 d 值，选择不在路径中的 y 点和在路径中的 x 点，可求得d=5，修改顶标后 此时相等子图中加入{15}再次寻找,仍无法为3找到匹配，这时我们得到的路径是{152}，可求得d=5，再次修改顶标，这次我们会发现{14, 24}加入了，这时我们已经可以找到最大匹配了，为{14,25,36}，即为最优匹配 优化 原生的KM为 O(n^4) 的时间复杂度： 需要找O(n)次增广路，每次增广最多需要修改O(n)次顶标，每次修改顶标时由于要枚举边来求 d 值，复杂度为O(n^2) 实际上 KM 算法的复杂度是可以做到O(n^3)的。我们给每个 Y 顶点一个&quot;松弛量&quot; slack，每次开始找增广路时初始化为无穷大。在寻找增广路的过程中，检查边(i,j)时，如果它不在相等子图中，则让slack[j]变成原值与 x[i]+y[j]-w[i][j] 的较小值。这样在修改顶标时，取所有不在交错树中的 Y 顶点的 slack 值中的最小值作为 d 值即可。但还要注意一点：修改顶标后要把所有不在交错树中的 Y 顶点的 slack 值都减去d 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110# km.py# 实现的不是太好class KM: lx = {} # 一边的标号 ly = {} # 另一边的标号 visit_x = {} # 该点在增广路匹配过程中是否被尝试过 visit_y = {} match = {} # 匹配的映射关系 slack = {} # slack 优化 def __init__(self, graph: dict): self.graph = graph # 初始化均未被访问 for p in graph.keys(): self.visit_x[p] = False self.lx[p] = -1 self.visit_y[p] = False self.ly[p] = -1 self.match[p] = -1 def _extended_path(self, x): # 寻找增广路径 # x 点被选择 self.visit_x[x] = True for y in self.visit_y.keys(): if self.visit_y[y]: # 结点被访问过了 continue if self.graph[x][y] == sys.maxsize: # 不连通 continue temp = self.lx[x] + self.ly[y] - self.graph[x][y] if temp == 0: # x, y 在相等子图中 self.visit_y[y] = True if self.match[y] == -1 or self._extended_path(self.match[y]): # 如果 y 元素没有对应的匹配或者 y 有新的匹配点 self.match[y] = x return True elif self.slack[y] &gt; temp: # slack 优化 self.slack[y] = temp else: pass # 无增广路径 return False def _solve(self): for x in self.visit_x: # 对所有的 x 寻找增广回路 # 重新初始化 slack 中的数值 for y in self.visit_y: self.slack[y] = sys.maxsize while True: # 求新的增广回路，重新初始化访问数组 for y in self.visit_y: self.visit_y[y] = False for xt in self.visit_x: self.visit_x[xt] = False if self._extended_path(x): # 有增广回路 break # 跳出循环，判断下一个点 else: delta = sys.maxsize # 求得需要对定标进行运算的 d for y in self.visit_y: # y 在交错树外，x 在交错树中（dfs失败x一定在交错树中） if (not self.visit_y[y]) and delta &gt; self.slack[y]: delta = self.slack[y] # 对定标的值修正，下一步一定可以再加入一个点 for xt in self.visit_x: if self.visit_x[xt]: self.lx[xt] -= delta for yt in self.visit_y: if self.visit_y[yt]: self.ly[yt] += delta else: # 修改顶标后，要把所有的slack值都减去delta # 这是因为x点的标定值减小了delta # 根据slack的计算也需要变换和x点相关的点的slack值 self.slack[yt] -= delta def km_solve(self, is_max=True): # 初始化 if not is_max: for v_dict in self.graph.values(): for pv in v_dict: v_dict[pv] = -v_dict[pv] for x in self.lx: # 贪心算法, 初始化为点最大的权的边 self.lx[x] = max(list(self.graph[x].values())) for y in self.ly: self.ly[y] = 0 self._solve() part_match = {} temp_s = 0 for k, v in self.match.items(): temp_s += self.graph[k][v] if k in part_match.keys() or k in part_match.values(): pass else: part_match[k] = v self.match = part_match print(part_match) print(temp_s) # 匹配整体计算了2次 if is_max: return temp_s / 2 else: return -temp_s / 2 一点点细节 到此我们已经可以解决这个问题了，但好像只剩完成了求解长度的部分，那路径呢？？？ 其实这个题目最难的是求回路路径 对于 Floyd 算法，我们求最短的路径时同时要记录节点 适当调整 Fleury 算法的实现：对于带平行边的图的存储，使用邻接矩阵时用a[i][j] = k表示 ij 直接有 k 条平行边，当要删除边时a[i][j]-=1,恢复边的时候a[i][j]+=1 完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163# fleury.pyclass Fleury: def __init__(self, graph): self.graph = graph self.start = -1 self.route = [] self.num = len(graph) # 图中的点数 def solve(self, current, start): flag = False # 是否还有与x关联的边 # 倒回会导致上一个点被多记录一次 if self.route and self.route[-1] == current: pass else: self.route.append(current) for i in range(start, self.num): # 从 start 开始搜索是否有边 if self.graph[i][current] &gt; 0: # i 与 current 有边 flag = True # 删除边 self.graph[i][current] -= 1 self.graph[current][i] -= 1 self.solve(i, 0) # 从 i 开始搜索 break if not flag: # 如果没有边与当前节点 current 相连 print(self.route) self.route.pop() # if len(self.route) == self.num: # return self.route if self.all_zeros(): self.route.append(start) return self.route else: # 回溯 temp = self.route[-1] # 恢复上一次的 2 条边 self.graph[temp][current] += 1 self.graph[current][temp] += 1 new_start = current + 1 # 路径包含所有的点 self.solve(temp, new_start) def all_zeros(self): for i in range(0, self.num): for j in range(0, self.num): if self.graph[i][j] != 0: return False return True# km求解中国邮递员.pyimport sysfrom fleury import Fleuryfrom km import KMdef euler(index, edge): f = Fleury(edge) f.solve(index, index) return f.routedef floyd(graph_matrix): n = len(graph_matrix) # 构造 path 数组 # 如果没有清 0 我们需要手动清0 for i in range(n): graph_matrix[i][i] = 0 path = [] for i in range(n): path.append([]) # 初始化 for i in range(n): for j in range(n): path[i].append(j) for k in range(n): for i in range(n): for j in range(n): if graph_matrix[i][k] == sys.maxsize or graph_matrix[k][j] == sys.maxsize: continue temp = graph_matrix[i][k] + graph_matrix[k][j] if temp &lt; graph_matrix[i][j]: graph_matrix[i][j] = temp # 更新路径 path[i][j] = path[i][k] for i in range(n): graph_matrix[i][i] = sys.maxsize return graph_matrix, pathd = []min_length = 0adjacency_array = [] # 邻接矩阵,用起来完全不是邻接矩阵......不想改了with open(&quot;中国邮递员问题测试数据2.txt&quot;, 'r') as fp: scales = fp.readline() n, m = map(int, scales.split(' ')) # 初始化 for i in range(n): d.append(0) graph = [[sys.maxsize]*n for _ in range(n)] adjacency_array = [[0]*n for _ in range(n)] # 读入数据 # 要求读入的数据要满足邻接表的排布 for line in fp.readlines(): start_point, end_point, weight = map(int, line.split(' ')) # 输入的点标号从 1 开始 start_point -= 1 end_point -= 1 # 构造邻接矩阵 adjacency_array[start_point][end_point] += 1 adjacency_array[end_point][start_point] += 1 d[start_point] += 1 d[end_point] += 1 # 无向图 graph[start_point][end_point] = weight graph[end_point][start_point] = weight min_length += weightt = 0for di in d: if di % 2 == 0: t += 1if t == n: # 所有点读数都是偶数度，为欧拉图 route = euler(0, adjacency_array)else: odd_points = [] # 记录奇数度顶点的数组 for i, di in enumerate(d): if di % 2 == 1: odd_points.append(i) # 奇度顶点的个数 graph_matrix, path = floyd(graph) # 奇度顶点组成子图 sub_graph = {} for odd_p in odd_points: sub_graph[odd_p] = {} for end_p in odd_points: sub_graph[odd_p][end_p] = graph_matrix[odd_p][end_p] km_solution = KM(sub_graph) # 求最小解 min_length += km_solution.km_solve(False) # 删去匹配的边 for k, v in km_solution.match.items(): start = k temp = path[k][v] while True: # 存在中转的情况, 以中转为起点 adjacency_array[start][temp] += 1 adjacency_array[temp][start] += 1 if temp == v: break else: pass start = temp temp = path[temp][v] route = euler(0, adjacency_array)for p in route: print(&quot;({})&quot;.format(p+1), end='')print(&quot;最小路径长度为:&quot;, end='')print(min_length)","link":"/2020/05/04/chinese-postman/"},{"title":"Python网络编程——TCP","text":"2020/10/20 更新问题: UDP 和 TCP 可以绑定在同一个端口吗? 网络是令人捉摸不透的。我们想要传输的数据包有时会被丢弃，有时会被复制，有时顺序会被弄乱。如果仅使用 UDP 提供的数据协议，那么应用程序的代码还需要处理数据传输的可靠性，并提供传输发生错误时的恢复方案。但如果使用 TCP，数据包就被隐藏到协议层之下，应用程序只需要向目标机器发送流数据，TCP 会将丢失的信息重传。 TCP 工作原理 TCP 是如何提供可靠连接的呢? 下面是它的基本工作原理 每个 TCP 数据包都会有一个序列号，接收方通过该序列号讲响应数据包正确排序，也可以通过该序列号发现传输过程中丢失的数据包，并请求重传。 TCP 并不使用顺序的整数作为序号，而是通过一个计数器来记录发送的字节数，例如，如果一个包含1024字节的数据包序列号为7200，那么下一个数据包的序列号就是8224。这意味着，繁忙的网络栈无需记录其是如何将数据流分割为包的，当需要进行重传的时候，可以使用另一种分割方式将数据流分割为多个新数据包，而接收方仍然可以正常的接受数据包。 在一个优秀的 TCP 实现中，初始序列号是随机选择的，一定程度上降低被攻破的风险。 TCP 不通过锁步的方式进行通信，如果使用这种方式，就必须等待每个数据包都被确认接受后才能发送下一个数据包，速度非常的慢。相反，TCP 无需等待响应就能一口气发送多个数据包。在某一时刻发送方希望同时传输的数据量叫做 TCP 窗口的大小 接受方的 TCP 实现可以通过控制发送方的窗口大小来减缓或暂停连接。这叫做流量控制(Flow Control)，这使得接受方在输入缓冲区已满的时候可以禁止更多的数据包的传输。此时如果还有数据到达，将会被舍弃。 TCP 的标准 POSIX 接口（可移植操作系统接口）分为被动监听套接字和主动连接套接字 被动套接字（passive socket）又叫做监听套接字（listening socket），它维护了&quot;套接字名&quot;——IP地址和端口号。服务器通过该套接字来接受连接请求。但是套接字不能用于发送或接受任何数据，也不表示任何实际的网络会话，而是由服务器指示被动套接字通知操作系统优先使用哪个特定的 TCP 端口号来接受连接请求。 主动套接字（active socket）又叫做连接套接字（connected socket），他将一个特定的IP地址以及端口号与某个正在进行远程会话的主机绑定。连接套接字只用于与该特定远程主机进行通信。可以通过该套接字发送或接收数据，可以将 TCP 的连接套接字传给另一个接受普通文件作为输入的程序，该程序可能永远也不会知道它正在进行网络通信。 被动套接字有接口 IP 地址和正在监听的端口号来唯一表示，即任何程序都无法再使用。而多个主动套接字是可以共享同一个本地套接字名的。例如有1000个客户端与一台繁忙的网络服务器都在进行 HTTP 连接。就会有1000个主动套接字都绑定到了服务器的公共 IP 地址和 TCP 的80端口，唯一表示主动套接字是如下的四元组: (local_ip, local_port, remote_ip, remote_port) 操作系统是通过这个四元组来为主动 TCP 连接命名的，接到数据包是，操作系统会检查源地址和目标地址是否与系统中某一个主动套接字相符。 一个简单的 TCP 客户端和服务端的例子： tcp_sixteen.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import argparse, socketdef recv_all(sock, length): data = b'' while len(data) &lt; length: more = sock.recv(length - len(data)) if not more: raise IOError(&quot;was expecting %d bytes but only received %d bytes before the socket closed&quot; % (length, len(data))) data += more return datadef server(interface, port): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((interface, port)) sock.listen(1) # 1? print(&quot;Listening at&quot;, sock.getsockname()) while True: sc, sockname = sock.accept() print(&quot;We have accepted a connection from&quot;, sockname) print(&quot;socket name:&quot;, sc.getsockname()) print(&quot;socket peer:&quot;, sc.getpeername()) message = recv_all(sc, 16) print(&quot;Incoming sixteen-octet message:&quot;, repr(message)) sc.sendall(b&quot;Farewell, client&quot;) sc.close() print(&quot;Reply sent, socket closed&quot;)def client(host, port): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect((host, port)) print(&quot;Client has been assigned socket name &quot;, sock.getsockname()) sock.sendall(b&quot;Hi there, server&quot;) reply = recv_all(sock, 16) print(&quot;The server said &quot;, repr(reply)) sock.close()if __name__ == &quot;__main__&quot;: choices = {&quot;client&quot;: client, &quot;server&quot;: server} parser = argparse.ArgumentParser(description=&quot;Send and receive over TCP&quot;) parser.add_argument(&quot;role&quot;, choices=choices.keys(), help=&quot;which role to take&quot;) parser.add_argument(&quot;host&quot;, help=&quot;interface the server listens at / host the client sends to&quot;) parser.add_argument(&quot;-p&quot;, metavar=&quot;PORT&quot;, type=int, default=1060, help=&quot;TCP port (default 1060)&quot;) args = parser.parse_args() func = choices[args.role] func(args.host, args.p) 看上去和 UDP 客户端和服务器程序很像，但 TCP 的 connect() 调用与 UDP 不同，UDP 的 connect 调用只是对绑定套接字进行了配置，设置了后续的 send(), recv() 调用锁需要的默认的远程地址，不会导致任何错误。而例子中的 connect() 调用则是真实的网络操作，会在要通信的客户端和服务端进行3次握手，这意味这 connect() 有可能失败，比如说没有运行服务器时运行客户端: ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 TCP 把发送的数据简单的看做流，而流是没有开始和结束标志，TCP 会将这些流分为多个数据包。而与之相比，UDP 的意义很简单，要么是发送一个数据报，要么是接收一个数据报，每个数据报都是原子的。TCP 可能会在传输过程中把数据流分为多个大小不同的数据包，然后在接受器端将这些数据包逐步重组。调用 send() 和 recv() 对 TCP 流会有什么效果？ send() 发生时，操作系统的网络栈可能会碰到下述3种情况： 要发送的数据被立即被网络栈接收，这时可能由于网卡正好空闲，可以用于立即发送数据，也可能因为系统还有空间，可以将数据复制到临时发送缓冲区，这样程序就能继续运行。这些情况下，send() 会立即返回，由于发送的是整个串，返回值是整个数据串的长度。 另一种可能性是，网卡很忙，该套接字的发送缓冲区已满，而系统也无法或不愿为其分配更多的空间，此时 send() 默认情况下会直接阻塞进程，暂停应用程序，直到本地网络栈能够接受并传输数据。 最后一种情况介于2者之间，发送缓冲区几乎满了，但尚有空间，因此想要发送的部分数据可以进入发送缓冲区的队列等待发送，但剩余的数据块则必须等待。这种情况下 send() 会立即返回从数据串开始处起已经发送被接收的字节数，剩余尚未处理。 由于这个原因，有时会在网络程序的代码中看到如下方式的循环: 1234bytes_sent = 0while bytes_sent &lt; len(message): message_remaining = message[bytes_sent:] bytes_sent += s.send(message_remaining) Python socket标准库实现了 sendall() 方法，比上述有更高的效率。另外它在循环中释放了全局解释锁，因此其他的 Python 线程在所有数据完成之前不会竞争资源。 而对于 recv()，由于收到的字节不定长，Python 并没有标准库方法，操作系统内部的 recv() 实现的逻辑和发送相似： 如果没有任何数据，那么 recv() 会阻塞程序直到数据到达 如果缓冲区里只有 recv() 需要返回的部分数据，那么即使这并非全部内容，也会立即返回缓冲区中已有的数据 如果缓冲区内的数据已经完整就绪，那么 recv() 收到所需的全部数据 死锁 典型的 TCP 栈使用了缓冲区，这样就可以在应用程序准备好读取数据前存放到的接收到的数据，也可以在网络硬件准备好发送数据包前存放的数据。这些缓冲区的大小是有限制的，系统一般不会想让程序使用未发送的网络数据将 RAM 填满。毕竟，如果另一方尚未准备好处理数据，那么增加系统资源用于更大的缓冲区是没有意义的。 下面这个TCP服务器和客户端可能会造成死锁: tcp_deadlock.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import argparseimport socketimport sysdef server(host, port, bytecount): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((host, port)) sock.listen(1) # 1? print(&quot;Listening at&quot;, sock.getsockname()) while True: sc, sockname = sock.accept() print(&quot;Processing up to 1024 bytes at a time from &quot;, sockname) n = 0 while True: data = sock.recv(1024) if not data: break output = data.decode(&quot;ascii&quot;).upper().encode(&quot;ascii&quot;) sc.sendall(output) # send it back uppercase n += len(data) print(&quot;\\r %d bytes processed so far&quot; % (n, ), end=&quot;&quot;) sys.stdout.flush() print() sc.close() print(&quot;Socket closed&quot;)def client(host, port, bytecount): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) bytecount = (bytecount + 15) // 16 * 16 # round up to a multiple of 16 message = b'capitalize this!' # 16-bytes message to repeat over and over print(&quot;Sending &quot;, bytecount, &quot; bytes of data, in chunks of 16 bytes&quot;) sock.connect((host, port)) sent = 0 while sent &lt; bytecount: sock.sendall(message) sent += len(message) # repeat the same content print(&quot;\\r %d bytes sent &quot; % (sent, ), end=&quot;&quot;) sys.stdout.flush() print() sock.shutdown(socket.SHUT_WR) print(&quot;Receiving all the data tje sends back&quot;) received = 0 while True: data = sock.recv(42) if not received: print(&quot;The first data received says &quot;, repr(data)) if not data: break received += len(data) print(&quot;\\r %d bytes received&quot; % (received, ), end=&quot;&quot;) print() sock.close()if __name__ == &quot;__main__&quot;: choices = {&quot;client&quot;: client, &quot;server&quot;: server} parser = argparse.ArgumentParser(description=&quot;Get deadlock over TCP&quot;) parser.add_argument(&quot;role&quot;, choices=choices.keys(), help=&quot;which role to take&quot;) parser.add_argument(&quot;host&quot;, help=&quot;interface the server listens at / host the client sends to&quot;) parser.add_argument(&quot;bytecount&quot;, type=int, nargs=&quot;?&quot;, default=16, help=&quot;number of bytes for client to send (default=16)&quot;) parser.add_argument(&quot;-p&quot;, metavar=&quot;PORT&quot;, type=int, default=1060, help=&quot;TCP port (default 1060)&quot;) args = parser.parse_args() func = choices[args.role] func(args.host, args.p, args.bytecount) 1234567891011121314(venv) D:\\my_py36\\Python-Web\\tcp&gt;python tcp_deadlock.py client 127.0.0.1 32Sending 32 bytes of data, in chunks of 16 bytes 32 bytes sentReceiving all the data tje sends backThe first data received says b'CAPITALIZE THIS!CAPITALIZE THIS!' 32 bytes received(venv) D:\\my_py36\\Python-Web\\tcp&gt;python tcp_deadlock.py server 0.0.0.0Listening at ('0.0.0.0', 1060)Processing up to 1024 bytes at a time from ('127.0.0.1', 63331) 32 bytes processed so farSocket closed 运行一下，达到了我们的预期。在任何情况下像这样处理输入每次只处理一个数据块对于服务器来说是一个明智的选择，通过分块处理程序并及时发回响应，服务器限制了其任意时刻需要保存在内存中的数据量。如果服务器这样设计，即使每个客户端发送的数据多达几兆字节，服务器也能在同一时刻处理数百个客户端，而且不会使内存或者其他硬件资源难堪重负。 但当我们尝试发送大到一定程度的数据量的时候: 1234567(venv) D:\\my_py36\\Python-Web\\tcp&gt;python tcp_deadlock.py client 127.0.0.1 1073741824Sending 1073741824 bytes of data, in chunks of 16 bytes 5435120 bytes sentProcessing up to 1024 bytes at a time from ('127.0.0.1', 63395) 2750112 bytes processed so far 送到一定大小的时候，就卡死了，客户端要比服务端多发送一些数据。为什么会停止呢？，因为服务器的输出缓冲区和客户端的输入缓冲区都会被填满，然后 TCP 就会使用滑动窗口协议而来处理这种情况，套接字会停止发送更多的数据，因为即使发送这些数据都会丢失。 为什么会导致死锁呢？考虑一下每个数据块的传输过程中都发送了什么。客户端使用 sendall() 发送数据块，然后服务端使用 recv() 来接收，处理，接着转为大写，再次使用 sendall() 发回去。由于还有数据需要发送，客户端并没有运行任何 recv() 调用，因此越来越大的数据填满了操作系统的缓冲区，导致无法接收更多的数据。 怎么解决？首先客户端和服务端可以通过套接字选项将阻塞关闭，这样像 send() 和 recv() 这样的调用在得知还不能发送数据时就会返回。第二种方法，程序可以使用某种技术同时处理来自多个输入的数据，可以采用多线程或进程，也可以采用 select() 或 poll() 等系统调用，这样当程序在接收或者发送套接字繁忙的时候等待，当他们任意一个空闲时做出响应。 告诉我们了什么呢？ UDP 是不会发生这种事情，因为 UDP 并没有实现流量控制，当传达的数据量超出接收端的处理能力时，UDP 就会直接丢弃这些数据，由应用程序来发现数据报的丢失。 网络连接的每一段 TCP 栈中都有缓冲区，这些缓冲区能够暂时保存数据，这样一来当数据包传到接收端时，即使接收端没有运行 recv() 调用，也不需要丢弃这些数据包。当然缓冲区的大小是有限的，当不断尝试写入的数据始终没有被接受或处理，次数就无法再写数据，直到数据被读取出来前，即缓冲区有空余空间后，写数据操作才可以继续进行。 没有采用锁的协议的可能涉及的危险情况之一，如果一个协议并没有严格要求服务器在客户端请求发送完成后才读取完整的请求，然后再返回完整的响应，那么就有可能发生上述的死锁情况。 半开连接 例子中在客户端套接字完成发生之后使用了 shutdown()，这解决了一个重要的问题。如果服务器在遇到文件结束符之前一直永远的读数据，那么客户端如果避免在套接字上进行完整的 close() 操作。客户端如果防止运行很多 recv() 来接收服务器的响应呢？解决方法就是将套接字&quot;半关&quot;，即在一个方向上永久关闭，但并不销毁，在这种情况下服务器不会再读任何数据，但仍能向客户端发送剩余的响应。SHUT_WR 表示不知道通信对方何的输出何时结束，表示调用方不再向套接字写数据。而通信对方也会不再读取任何数据并且认为遇到了文件结束符。 有时当需要创建单向的套接字，往往会先创建双向套接字然后当套接字连接后立马运行 shutdown() 来关闭不需要的连接方向，这样操作系统的缓冲区也不会被无意义的填充。立即运行 shutdown() 也能够为通信对方提供更加清晰的错误信息，这样对方也不会混淆，也不会尝试在不需要发送数据的方向上发，否则意外数据可能会将缓冲区填满，由于这些数据永远不会被读取，导致无法写入，导致死锁。 UDP 和 TCP 可以绑定在同一个端口吗? 可以的。 首先，一个 UDP 应用是可以在不同的 IP 上绑定同一个端口，如绑定在127.0.0.1:1060 和 本机的 IP 地址下的 1060 端口的。无论任何时候，IP 网络栈都不会把 UDP 端口看作是一个可以连接或者正在使用的单独实体。相反，IP 网络栈关注的是 UDP “套接字名”，这是由 IP 接口和 UDP 端口号组成的二元组。如果只是端口号冲突无伤大雅。需要留意的是，客户端发送数据只会被一个服务器接受，这个服务器就是你 UDP 客户端指定的那个。 而对于 TCP 连接需要由四元组来形成，即(src_ip, src_port, dst_ip, dst_port)，当连接请求来了之后，服务器调用 accept 函数生成了一个新的 socket 这个端口占用的仍是 80（假设这个应用监控着 80）这些新的 socket 本地的 ip 和 port 都相同，远程的不同。这就是它可以建立很多很多的连接的原因。 最后 UDP 和 TCP 都可以绑定在同一个端口。再想想端口的定义：端口是一种抽象的软件结构（包括一些数据结构和 I/O 缓冲区）。应用程序通过系统调用与某端口建立连接（binding）后，传输层传给该端口的数据都被相应进程所接收，相应进程发给传输层的数据都通过该端口输出。在TCP/IP协议的实现中，端口操作类似于一般的 I/O 操作，进程获取一个端口，相当于获取本地唯一的 I/O 文件，可以用一般的读写原语访问之。 而端口号类似于文件描述符，用于区别不同端口。由于 TCP/IP 传输层的两个协议 TCP 和 UDP 是完全独立的两个软件模块（操作系统提供的），因此各自的端口号也相互独立，如 TCP有一个255号端口，UDP 也可以有一个255号端口，二者并不冲突。","link":"/2020/10/20/python-web-3/"},{"title":"probabilistic-methods","text":"概率方法 Monte Carlo Simulation General 我们需要定量分析我们的模型预测结果的可靠性，而蒙特卡洛方法就是可以预测概率，评估风险的一个方法。当我们需要计算，测量不确定性对模型的影响，模特卡洛方法是首先考虑的。简单来说，蒙特卡洛方法就是用不确定的参数反复评估模型，研究模型输出的不确定性。 蒙特卡洛方法的主要好处就在于它的鲁棒性和多功能性，不好之处在于它的收敛速度很慢并且计算量很大。 Mathematical Representation 我们用服从某个概率分布的随机变量来模型化不确定性，假设我们想要研究随机变量 X 的不确定性是如何影响模型输出 Y 的，先选择一些输入 $[X_1, X_2, \\cdots, X_n]$，我们可以得到一组模型 f 的输出： $$ [Y_1, \\cdots, Y_n] = [f(X_1), \\cdots, f(X_n)] $$ 我们可以估计出输出的不确定性的平均值，比如说使用大数定律。根据大数定律（算数平均值依概率收敛于数学期望）。 $$ E[Y] = \\frac{1}{N} \\sum_{i=1}^{N} f(X_i) $$ 根据中心极限定理：（当 n 足够大的时候，我们可以把任何一个奇奇怪怪（期望方差要存在）的分布，近似成一个正态分布）$\\sum_{i=1}^{N} X_i ~ N(n\\mu , n\\sigma ^2)$ probabilistic forcasting 蒙特卡洛方法可以被应用于一个动态模型的概率预测上，如下： $$ x_{t+1} = f(x_t, \\epsilon _t) $$ $x_t$ 表示状态，$\\epsilon _t$ 表示在 t 时间的噪声。噪声可以表示我们不确定的输入，随机性使我们能够以定量的方式在我们缺乏一些知识下模拟场景并帮我们推理这些这些知识。 在动态模型上使用蒙特卡洛方法被称为集合预测（ensemble forecasting），这涉及模拟系统的许多独立轨迹（trajectory），以便对系统行为进行预测。每个轨迹就是一个集合成员（ensemble member） 假设我们想要得到再时间 $t=1$ 时的预测值，用 M 条轨迹描述初始条件 $x_0$，则从 1 到 M，有： $$ x_1^{(i)}=f(x_0, \\epsilon _0^{(i)}) $$ 这样我们就可以预测将来某个时间系统状态的均值和方差，并计算系统可能处于不安全区域的概率或风险。 Simulating Rare Event 蒙特卡洛方法也可以用于模拟罕见的事件的发生： 地震 洋流转变 极端天气 股票市场崩溃 但问题是效率太差，想要得到一个比较小的蒙特卡洛观测误差值比较困难，但我们可以通过修改蒙特卡洛方法来提升效率，比如说重要性采样（Importance Sampling）。 我们假设 Y 是根据概率分布 $p(y)$ 分布的随机变量，我们想要估计 Y 超过某个特定的阈值 a 的概率，一个简单的蒙特卡洛估算方法如下： $$ \\hat{\\rho } = \\frac{1}{N} \\sum_{i=1}^{N} 1_{Y&gt;a} (Y^i) Y^i \\sim p(y) \\\\ 1_{Y&gt;a}(y) = \\left{\\begin{matrix} 1 &amp; y&gt;a\\ 0 &amp; y&lt;a \\end{matrix}\\right. $$ 这样就有一个问题，对于概率很小很小的事件，我们模拟使用的 N 会非常的大，造成计算开销很大。 重要性采样使用了另一种分布——偏差分布（biasing distribution） $q(y)$，修改上面的模型为： $$ \\hat{\\rho }{IS} = \\frac{1}{N} \\sum{i=1}^{N} 1_{Y&gt;a} (\\tilde{Y}^i) \\frac{p(\\tilde{Y}i)}{q(\\tilde{Y}i)} \\\\ \\tilde{Y}^i \\sim q(y) $$ Sensitivity Analysis 当我们有这样一个式子： $$ Y = f(X_1, \\vdots, X_n) $$ Y 的值取决于一系列的 X，如果我们想要知道那个输入对结果的影响更大，即输入的敏感度（Sensitivity ），就需要敏感度分析（Sensitivity analysis），通过这种方法，我们可以降低投资决策中的不确定性，或者在预测值时忽略一些不重要的输入。 敏感性分析有以下方法： Local sensitivity analysis 敏感度系数定义为： $$ s_i = \\frac{\\partial y}{\\partial x_i} $$ 对于每个输入 $x_i$，计算 $s_i$ 来衡量。 问题是，我们应该用那个位置的点 x 来计算偏导？如果模型是一个非线性模型，在不同 x 处得到敏感度系数会有很大的差异。这个方法还忽略了几点：如果 x 是非常不确定变化的变量呢？如果 x 的分布范围很广泛，它可能会比窄的分布范围对输出的 Y 有更大的影响。 Averaged derivative 对局部敏感度在输入上求积分来表示敏感度： $$ \\int_{D} (\\frac{\\partial y}{\\partial x_i})^2 dx_i $$ 但依旧有问题，如周期函数，会导致结果不准确。 Variance based global sensitivity analysis 就像我们使用蒙特卡洛方法来通过 x 的分布估测 y 的分布，我们通过输出 y 的方差值，该方差来自于每个输入的不确定性。我们将对 y 的方差的影响看成一个饼，不同的变量组合对结果的影响可以从饼中划分出来一部分。 为什么这样是正确的呢？我们来看背后的数学推导。 我们假设输出 Y 受到 $X_1$ 和 $X_2$ 的影响，它们以不同的形式影响这 Y 值，我们现在想要知道它们哪个对 Y 的影响更大，基于方差的全局敏感性分析给出的方法是：如果 $X_1$ 对 Y 的方差值贡献的更多，那么 Y 对 $X_1$ 更加敏感。 $$ Var[Y]=Var_{x_1}[\\Bbb E_{x_2}[Y|X_1] ] + \\Bbb E_{x_1}[Var_{x_2}[Y|X_1] ] $$ 上面的式子是方差的一个性质，$\\Bbb E_{x_2} [Y| X_1]$ 项代表固定 x 下的条件均值，直观来看，这是 Y 在给定 x 下的最好的观察值，我们可以用它来代表 Y 由于 $X_1$ 而产生的方差。后面的部分就是 Y 在 非 $X_1$ 影响下产生的方差，影响它的可能包括 $X_1 X_2$ 我们在以 $X_2$ 为计算对象来写另外一个相似的计算公式： $$ Var[Y]=Var_{x_2}[\\Bbb E_{x_1}[Y|X_2] ] + \\Bbb E_{x_2}[Var_{x_1}[Y|X_2] ] $$ 仅仅由 $X_1$ 对方差的影响的占比为 $$ s_1 = \\frac{Var_{x_1}[\\Bbb E_{x_2}[Y|X_1] ]}{Var[Y]} $$ 由包含 $X_1$ 的项（只含$X_1$和交叉项）对方差的贡献为： $$ s_{T_1} = \\frac{\\Bbb E_{x_2}[Var_{x_1}[Y|X_2] ]}{Var[Y]} $$ 当有两个以上变量的时候，上面两个公式需要归一化。 例子","link":"/2021/03/13/probabilistic-methods/"}],"tags":[{"name":"AssemblyLanguage","slug":"AssemblyLanguage","link":"/tags/AssemblyLanguage/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"Linkers&amp;Loaders","slug":"Linkers-Loaders","link":"/tags/Linkers-Loaders/"},{"name":"Scientific Calculate","slug":"Scientific-Calculate","link":"/tags/Scientific-Calculate/"},{"name":"basis","slug":"basis","link":"/tags/basis/"},{"name":"Web Crawler","slug":"Web-Crawler","link":"/tags/Web-Crawler/"},{"name":"Process&amp;Threading","slug":"Process-Threading","link":"/tags/Process-Threading/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"automation","slug":"automation","link":"/tags/automation/"},{"name":"OperatingSystems","slug":"OperatingSystems","link":"/tags/OperatingSystems/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"cuda","slug":"cuda","link":"/tags/cuda/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"AI+X Blending","slug":"AI-X-Blending","link":"/tags/AI-X-Blending/"},{"name":"Internet Programming","slug":"Internet-Programming","link":"/tags/Internet-Programming/"},{"name":"unittest","slug":"unittest","link":"/tags/unittest/"},{"name":"essay","slug":"essay","link":"/tags/essay/"},{"name":"Win32 API","slug":"Win32-API","link":"/tags/Win32-API/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"}],"categories":[{"name":"essay","slug":"essay","link":"/categories/essay/"},{"name":"ComputerOrganization","slug":"ComputerOrganization","link":"/categories/ComputerOrganization/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Web FrameWork","slug":"Python/Web-FrameWork","link":"/categories/Python/Web-FrameWork/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"server","slug":"server","link":"/categories/server/"},{"name":"C++&#x2F;C","slug":"C-C","link":"/categories/C-C/"}]}