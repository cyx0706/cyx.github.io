<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>bird-identify - Ctwo&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Ctwo&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Ctwo&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="软件工程炼丹心得与体会 其实就是深度学习入门吧 大三上软工项目：鸟类识别与分享平台，项目传送门iBird 在充分了解了深度学习（指前两周看了老师发的视频）后开始尝试构建鸟类识别模型，这篇博客用于记录自己在学习中的一点点收获。 ps:基础太差了，感觉好多时候都是在瞎炼。"><meta property="og:type" content="blog"><meta property="og:title" content="bird-identify"><meta property="og:url" content="http://cyx0706.github.io/2020/12/31/bird-identify/"><meta property="og:site_name" content="Ctwo&#039;s Blog"><meta property="og:description" content="软件工程炼丹心得与体会 其实就是深度学习入门吧 大三上软工项目：鸟类识别与分享平台，项目传送门iBird 在充分了解了深度学习（指前两周看了老师发的视频）后开始尝试构建鸟类识别模型，这篇博客用于记录自己在学习中的一点点收获。 ps:基础太差了，感觉好多时候都是在瞎炼。"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://cyx0706.github.io/gallery/thumbnails/deep-learning.jpg"><meta property="article:published_time" content="2020-12-31T11:37:00.000Z"><meta property="article:modified_time" content="2020-12-31T13:18:03.327Z"><meta property="article:author" content="Ctwo"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/thumbnails/deep-learning.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://cyx0706.github.io/2020/12/31/bird-identify/"},"headline":"Ctwo's Blog","image":["http://cyx0706.github.io/gallery/thumbnails/deep-learning.jpg"],"datePublished":"2020-12-31T11:37:00.000Z","dateModified":"2020-12-31T13:18:03.327Z","author":{"@type":"Person","name":"Ctwo"},"description":"软件工程炼丹心得与体会 其实就是深度学习入门吧 大三上软工项目：鸟类识别与分享平台，项目传送门iBird 在充分了解了深度学习（指前两周看了老师发的视频）后开始尝试构建鸟类识别模型，这篇博客用于记录自己在学习中的一点点收获。 ps:基础太差了，感觉好多时候都是在瞎炼。"}</script><link rel="canonical" href="http://cyx0706.github.io/2020/12/31/bird-identify/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/5.13.0/css/all.css"><link rel="stylesheet" href="https://at.alicdn.com/t/font_1216726_izwtvafdd5o.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/railscasts.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Ctwo&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/gallery/thumbnails/deep-learning.jpg" alt="bird-identify"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-31T11:37:00.000Z" title="2020-12-31T11:37:00.000Z">2020-12-31</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-12-31T13:18:03.327Z" title="2020-12-31T13:18:03.327Z">2020-12-31</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a></span></div></div><h1 class="title is-3 is-size-4-mobile">bird-identify</h1><div class="content"><h1>软件工程炼丹心得与体会</h1>
<p><s>其实就是深度学习入门吧</s></p>
<p>大三上软工项目：鸟类识别与分享平台，项目传送门<a target="_blank" rel="noopener" href="https://github.com/OUC-iBird">iBird</a></p>
<p>在充分了解了深度学习（指前两周看了老师发的视频）后开始尝试构建鸟类识别模型，这篇博客用于记录自己在学习中的一点点收获。</p>
<p>ps:基础太差了，感觉好多时候都是在瞎炼。</p>
<a id="more"></a>
<h2 id="一点点准备">一点点准备</h2>
<ul>
<li>
<p><a href="https://cyx0706.github.io/2020/11/20/cuda-disaster/">Pytorch + Cuda</a></p>
</li>
<li>
<p>我的电脑GPU内存不咋够用，所以训练主要放在了 <a target="_blank" rel="noopener" href="https://www.google.com/intl/zh-CN/drive/">Colab</a> 上</p>
</li>
<li>
<p>模型训练的数据源于<a target="_blank" rel="noopener" href="https://god.yanxishe.com/4?from=god_home_list">AI 研习社-200种鸟类识别分类</a></p>
</li>
</ul>
<h2 id="模型的构建">模型的构建</h2>
<h3 id="细粒度图像识别">细粒度图像识别</h3>
<p>200 种鸟类识别其实是一个细粒度图像识别问题(fine-grained image recognition)</p>
<p>对于现在的模型，识别出物体的大类别（比如：猫，狗，手机，车）比较容易，但如果要进一步去更细的划分物体的类别和名称，难度就大了很多，在这其中，有一些子类别的差异十分的小，如何区分布他们是比较困难的。</p>
<p>目前，精细化分类的方法主要有以下两类：</p>
<ul>
<li>基于图像重要区域定位的方法：该方法集中探讨如何利用弱监督的信息自动找到图像中有判别力的区域，从而达到精细化分类的目的。</li>
<li>基于图像精细化特征表达的方法：该方法提出使用高维度的图像特征（如：bilinear vector）对图像信息进行高阶编码，以达到准确分类的目的。</li>
</ul>
<p>举我看的论文里面的例子吧：</p>
<p>在 <a target="_blank" rel="noopener" href="http://vis-www.cs.umass.edu/bcnn/">Bilinear CNN Models for Fine-grained Visual Recognition</a> 这篇论文里提到了：</p>
<blockquote>
<p>Fine-grained recognition tasks such as identifying the species of a bird … are quite challenging because the visual differences between the categories are small and can be easily overwhelmed by those caused by factors such as pose, viewpoint, or location of the object in the image.</p>
</blockquote>
<p>这里提到了，细粒度识别的一个很大的难度在于&quot;细小的差别会被鸟的姿势，视角，拍摄的位置给掩盖掉&quot;（这里是以鸟为例）</p>
<blockquote>
<p>For example, the inter-category variation(类别间的变化) between “Ringed-beak gull” and a “California gull” due to the differences in the pattern on their beaks(喙) is significantly smaller than the inter-category variation on a popular fine-grained recognition dataset for birds.</p>
</blockquote>
<p>论文中举了环嘴鸥（Ringed-beak gull）和加州鸥（California gull）在喙上的差别要明显小于细粒度分别的数据集中的差别。</p>
<p>为了解决这个问题，这篇论文中提出了一个 BCNN 模型来解决，我主要学习的也是这个模型，不过这是后面要说的了。</p>
<h3 id="预处理">预处理</h3>
<p>在正式写我们的模型前，要先写好读取数据的方法，数据集就用 AI 研习社上的了，先在本地下一份。</p>
<p>对于数据，我们交给模型训练的时候，一般都会进行预处理，预处理的方法有很多，最常用的如下：</p>
<ul>
<li>平移：一定尺度内平移</li>
<li>旋转：一定角度内旋转</li>
<li>翻转：水平或者上下翻转</li>
<li>裁剪：在原有图像上裁剪一部分</li>
<li>颜色变化：rgb 颜色空间进行一些变换（亮度对比度等）</li>
<li>噪声扰动：给图像加入一些人工生产的噪声</li>
</ul>
<p>说的高级点好像叫<strong>数据增强</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="comment"># 随机比例缩放</span></span><br><span class="line">transforms.Resize((<span class="number">100</span>, <span class="number">200</span>))</span><br><span class="line"><span class="comment"># 随机位置裁剪</span></span><br><span class="line">transforms.RandomCrop(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 中心裁剪</span></span><br><span class="line">transforms.CenterCrop(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 随机垂直水平翻转</span></span><br><span class="line">transforms.RandomVerticalFlip(p=<span class="number">1</span>)</span><br><span class="line">transforms.RandomHorizontalFlip(p=<span class="number">1</span>)   <span class="comment"># p表示概率</span></span><br><span class="line"><span class="comment"># 随机角度旋转</span></span><br><span class="line">transforms.RandomRotation(<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 色度，亮度，饱和度，对比度</span></span><br><span class="line">transforms.ColorJitter(brightness=<span class="number">1</span>)  <span class="comment"># 亮度</span></span><br><span class="line">transforms.ColorJitter(contrast=<span class="number">1</span>)  <span class="comment"># 对比度</span></span><br><span class="line">transforms.ColorJitter(saturation=<span class="number">0.5</span>)  <span class="comment"># 饱和度</span></span><br><span class="line">transforms.ColorJitter(hue=<span class="number">0.5</span>)  <span class="comment"># 色度</span></span><br></pre></td></tr></table></figure>
<h3 id="数据集">数据集</h3>
<p>Pytorch 提供内置的图片数据集 ImageFolder，它有一个通用的数据加载器，它加载的数据要求以下面的方式组织：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">base_dir = <span class="string">&quot;xxx/xxx&quot;</span></span><br><span class="line"><span class="comment"># data_dir 中的图片这样组织</span></span><br><span class="line"><span class="comment"># data_dir/dog/xxx1.png</span></span><br><span class="line"><span class="comment"># data_dir/dog/xxx2.png</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data_dir/cat/xxx1.png</span></span><br><span class="line"><span class="comment"># data_dir/cat/xxx2.png</span></span><br><span class="line"></span><br><span class="line">predict_sets = torchvision.datasets.ImageFolder(os.path.join(base_dir, <span class="string">&quot;data_dir&quot;</span>), transform=your_trans)</span><br></pre></td></tr></table></figure>
<p>这时读入的数据所有在 dog 文件夹下的都被打上了 dog 的标签，同理 cat。简单来说，你要将一类的图片全部放入一个以这个类别命名的文件夹下才能正常的读取。</p>
<p>这对于我们这个显然不太方面，所以就要自己写数据集的加载方式了</p>
<blockquote>
<p>All datasets are subclasses of torch.utils.data.Dataset i.e, they have __getitem__ and __len__ methods implemented. Hence, they can all be passed to a torch. utils.data.DataLoader which can load multiple samples parallelly using torch.multiprocessing workers.</p>
</blockquote>
<p>就是要我们实现两个函数<code>__getitem__()</code> 和 <code>__len__()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FirstDataset</span>(<span class="params">data.Dataset</span>):</span><span class="comment">#需要继承data.Dataset</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment">#在这里初始化</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#1 读取一个数据和标签</span></span><br><span class="line">        <span class="comment">#2 预处理数据（例如 torchvision.transform）</span></span><br><span class="line">        <span class="comment">#3 返回数据对（例如图像和标签）</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 数据集的大小</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>有了这个我们思路就很清晰了，由于我们的标签都在一个 .csv 文件中，里面包括图片名对应的标签号，我们用 Pandas 读入然后分列，在我们的__getitem__() 函数里一次取一个就好了（取第 item 个）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets.folder <span class="keyword">import</span> accimage_loader, pil_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">default_loader</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">from</span> torchvision <span class="keyword">import</span> get_image_backend</span><br><span class="line">    <span class="keyword">if</span> get_image_backend() == <span class="string">&#x27;accimage&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> accimage_loader(path)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> pil_loader(path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span>(<span class="params">torch.utils.data.Dataset</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_path, data_label_path, data_transform, data_loader=default_loader</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data_path: 要读取的文件的路径</span></span><br><span class="line"><span class="string">        :param data_label_path: 标签数据的路径</span></span><br><span class="line"><span class="string">        :param data_transform: 数据变换模式</span></span><br><span class="line"><span class="string">        :param data_loader: 加载方法</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 在 label文件中注意不要加上第一行列名行</span></span><br><span class="line">        df = pd.read_csv(data_label_path, header=<span class="literal">None</span>)</span><br><span class="line">        self.data_loader = data_loader</span><br><span class="line">        self.data_transform = data_transform</span><br><span class="line">        self.data_path = data_path</span><br><span class="line">        </span><br><span class="line">        self.img_names = <span class="built_in">list</span>(df[<span class="number">0</span>])</span><br><span class="line">        self.labels = <span class="built_in">list</span>(df[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_names)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型训练的时候调用，返回一组图片和标签用于训练</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, item</span>):</span></span><br><span class="line">        img_name = self.img_names[item]</span><br><span class="line">        img_path = os.path.join(self.data_path, img_name)</span><br><span class="line">        label = self.labels[item]</span><br><span class="line">        img = self.data_loader(img_path)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            img = self.data_transform(img)</span><br><span class="line">            <span class="keyword">return</span> img, label-<span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;cannot transform image: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(img_name))</span><br></pre></td></tr></table></figure>
<h3 id="训练函数">训练函数</h3>
<p>Tranier 的写法比较固定，网上有各种各样的，贴一个我找到~~（自己写不来，但改了一下）~~</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module</span><br><span class="line"><span class="keyword">from</span> torch.optim.optimizer <span class="keyword">import</span> Optimizer</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> ReduceLROnPlateau</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trainer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">            self,</span></span></span><br><span class="line"><span class="function"><span class="params">            model: Module,</span></span></span><br><span class="line"><span class="function"><span class="params">            criterion: Module,</span></span></span><br><span class="line"><span class="function"><span class="params">            optimizer: Optimizer,</span></span></span><br><span class="line"><span class="function"><span class="params">            device: torch.device</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>(Trainer, self).__init__()</span><br><span class="line">        self.model: Module = model</span><br><span class="line">        self.criterion: Module = criterion</span><br><span class="line">        self.optimizer: Optimizer = optimizer</span><br><span class="line">        self.device: torch.device = device</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self, loader: DataLoader</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]:</span></span><br><span class="line">        </span><br><span class="line">        total_loss, total_acc = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        self.model.train()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> tqdm(<span class="built_in">enumerate</span>(loader), total=<span class="built_in">len</span>(loader), desc=<span class="string">&#x27;Training&#x27;</span>) <span class="keyword">as</span> proc:</span><br><span class="line">                <span class="keyword">for</span> _, (inputs, targets) <span class="keyword">in</span> proc:</span><br><span class="line">                    inputs = inputs.to(self.device)</span><br><span class="line">                    targets = targets.to(self.device)</span><br><span class="line">                    outputs = self.model(inputs)</span><br><span class="line">                    loss = self.criterion(outputs, targets)</span><br><span class="line">                    self.optimizer.zero_grad()</span><br><span class="line">                    loss.backward()</span><br><span class="line">                    self.optimizer.step()</span><br><span class="line">                    _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                    total_loss += loss.item()</span><br><span class="line">                    total_acc += (predicted == targets).<span class="built_in">float</span>().<span class="built_in">sum</span>().item() / targets.numel()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 异常情况关闭</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Running Error in training, &quot;</span>, e)</span><br><span class="line">            proc.close()</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>, -<span class="number">1</span></span><br><span class="line">        proc.close()</span><br><span class="line">        <span class="keyword">return</span> total_loss / <span class="built_in">len</span>(loader), <span class="number">100.0</span> * total_acc / <span class="built_in">len</span>(loader)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self, loader: DataLoader</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]:</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            total_loss, total_acc = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">            self.model.<span class="built_in">eval</span>()</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">with</span> tqdm(<span class="built_in">enumerate</span>(loader), total=<span class="built_in">len</span>(loader), desc=<span class="string">&#x27;Testing &#x27;</span>) <span class="keyword">as</span> proc:</span><br><span class="line">                    <span class="keyword">for</span> _, (inputs, targets) <span class="keyword">in</span> proc:</span><br><span class="line">                        inputs = inputs.to(self.device)</span><br><span class="line">                        targets = targets.to(self.device)</span><br><span class="line">                        outputs = self.model(inputs)</span><br><span class="line">                        loss = self.criterion(outputs, targets)</span><br><span class="line">                        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                        total_loss += loss.item()</span><br><span class="line">                        total_acc += (predicted == targets).<span class="built_in">float</span>().<span class="built_in">sum</span>().item() / targets.numel()</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                proc.close()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Running Error in validating,&quot;</span>, e)</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span>, -<span class="number">1</span></span><br><span class="line">            proc.close()</span><br><span class="line">        <span class="keyword">return</span> total_loss / <span class="built_in">len</span>(loader), <span class="number">100.0</span> * total_acc / <span class="built_in">len</span>(loader)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>比较喜欢这个写法，tqdm 是一个 Python 的进度条库，它有个问题是如果代码异常结束，它有时不会被停止，这样在第二次运行时会无法刷新输出窗口，导致看上去就不是一个进度条了，而是进度条每更新一次就打印出来一个新的，原来的还在。我们在套一个 try-catch 在异常的时候正确的关闭这个进度条进程就好了，用 close() 函数。</p>
</li>
<li>
<p>model.eval() 和 model.train()这两个必须要搞明白</p>
<ul>
<li>model.train() 会启用 BatchNormalization 和 Dropout 而 model.eval() 不启用 BatchNormalization 和 Dropout。</li>
<li>否则的话，有输入数据，即使不训练，它也会改变权值。这是 model 中含有 batch normalization 层和 dropout所带来的的性质。</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2020/12/31/riJ1FKxGcNa3MXA.png" alt="dropout.png"></p>
<ul>
<li>想象一下，如果被删除的神经元是唯一促成正确结果的神经元。一旦我们不激活它，其他神经元就需要学习如何在没有这些神经元的情况下保持准确。这种 dropout 提高了最终测试的性能。但它对训练期间的性能产生了负面影响，因为网络是不全的。</li>
</ul>
<h3 id="数据集加载">数据集加载</h3>
<p>用 <code>torch.utils.data.DataLoader</code> 就可以，需要注意的是 Windows 下需要将 num_workers 设置为 0。</p>
<p>dataloader 一次性创建 num_worker 个 worker，他们负责将数据提前读入好内存。num_worker 设置得大，好处是寻 batch 速度快，因为下一轮迭代的 batch 很可能在前面几轮的迭代时已经加载好了。坏处是内存开销大，也加重了 CPU 的负担。num_workers 的经验设置看自己的 CPU 和 RAM 吧，如果 CPU 处理强，内存大，就可以设置得更大些。如果 num_worker 设为 0，意味着每一轮迭代时，dataloader 不再有自主加载数据到 RAM 这一步骤（没有worker了），而是在RAM 中找 batch，找不到时再加载相应的 batch。这样当然是速度慢。</p>
<h3 id="模型">模型</h3>
<p>我鸟类识别的模型实现了两个（<s>还有一个出问题了先不管他</s>）</p>
<h4 id="BCNN">BCNN</h4>
<p><a target="_blank" rel="noopener" href="http://vis-www.cs.umass.edu/bcnn/">Bilinear CNN Models for Fine-grained Visual Recognition</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BilinearModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Load model with pretrained weights and initialise new layers.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes: <span class="built_in">int</span> = <span class="number">200</span>, pretrained=<span class="literal">True</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Load pretrained model, set new layers with specified number of layers.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(BilinearModel, self).__init__()</span><br><span class="line">        model: nn.Module = models.vgg16(pretrained)</span><br><span class="line">        self.features: nn.Module = nn.Sequential(*<span class="built_in">list</span>(model.features)[:-<span class="number">1</span>])</span><br><span class="line">        self.classifier: nn.Module = nn.Linear(<span class="number">512</span> ** <span class="number">2</span>, num_classes)</span><br><span class="line">        self.dropout: nn.Module = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">        nn.init.kaiming_normal_(self.classifier.weight.data)</span><br><span class="line">        <span class="keyword">if</span> self.classifier.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.constant_(self.classifier.bias.data, val=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @overrides</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs: torch.Tensor</span>) -&gt; torch.Tensor:</span></span><br><span class="line">        outputs: torch.Tensor = self.features(inputs)</span><br><span class="line">        outputs = outputs.view(-<span class="number">1</span>, <span class="number">512</span>, <span class="number">28</span> ** <span class="number">2</span>)</span><br><span class="line">        outputs = self.dropout(outputs)</span><br><span class="line">        outputs = torch.bmm(outputs, outputs.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>))      <span class="comment"># bilinear product</span></span><br><span class="line">        outputs = torch.div(outputs, <span class="number">28</span> ** <span class="number">2</span>)                       <span class="comment"># normalize</span></span><br><span class="line">        outputs = outputs.view(-<span class="number">1</span>, <span class="number">512</span> ** <span class="number">2</span>) </span><br><span class="line">        outputs = torch.sign(outputs) * torch.sqrt(outputs + <span class="number">1e-5</span>)  <span class="comment"># signed square root normalization</span></span><br><span class="line">        outputs = nn.functional.normalize(outputs, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">        outputs = self.dropout(outputs)</span><br><span class="line">        outputs = self.classifier(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<p>论文中原本推荐使用两个不同的模型来提取特征值然后使用一个双线性函数来进一步处理提取的特征值，后来又有人指出，使用同源的模型也可以得到不错的效果，所以我就尝试使用了 VGG 作为提取层，然后将处理好的结果使用一个全连接层对应 200 种鸟类。最后正确率在 75% 左右。</p>
<h4 id="EfficientNet-With-Attention">EfficientNet With Attention</h4>
<p>Attention机制还没咋看的（有空再补了），看别人这么用我也就瞎几把组合了一下。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lukemelas/EfficientNet-PyTorch">Pytorch 实现的 EfficientNet</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.11946">论文在此</a></p>
<p>这个我看懂了（震声！），论文对现有模型提出了反思：如果只是增加模型的深度（有多少层）（depth），宽度（每一层的参数数）（width），还有图像的解析度（输入的大小）（resolution）其中之一对模型的提升不完全而且有时还会导致准确率下降。Google 的研究员们发现当按照一个比率（ratio）同时提升这 3 个值，会让模型更好的提高准确度，也变得更加精简。它通过（经验？）发现这样的原则:</p>
<p style="filter: opacity(95%);transform:scale(0.85);text-align:center;"><img src="https://math.now.sh?from=depth%3A%20d%20%3D%20%5Calpha%5E%5Cphi%20%20%5C%5C%0Awidth%3A%20w%20%3D%20%5Cbeta%5E%5Cphi%20%5C%5C%0Aresolution%3A%20r%20%3D%20%5Cgamma%5E%5Cphi%20%5C%5C%0As.t.%20%5Cquad%20%20%5Calpha%20*%20%5Cbeta%5E2%20*%20%5Cgamma%5E2%20%5Capprox%202%20%5C%5C%0A%5Cquad%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cquad%20%5Calpha%20%5Cgeqslant%201%2C%20%5Cbeta%20%5Cgeqslant%201%2C%5Cgamma%20%5Cgeqslant%201%20%5C%5C%0A" /></p><p>按照这个原则，Google 提出了 EfficientNet 系列，非常精简并且准确率高的模型。</p>
<p>关于 Attention 机制，还没咋看呢，等待看完了加上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> efficientnet_pytorch <span class="keyword">import</span> EfficientNet</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv3x3</span>(<span class="params">in_planes, out_planes, stride=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="comment"># &quot;3x3 convolution with padding&quot;</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                     padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_planes, ratio=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)  <span class="comment"># 压缩空间</span></span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Conv2d(in_planes, in_planes // <span class="number">16</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2 = nn.Conv2d(in_planes // <span class="number">16</span>, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))</span><br><span class="line">        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))</span><br><span class="line">        out = avg_out + max_out  <span class="comment"># [b, C, 1, 1]</span></span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">&#x27;kernel size must be 3 or 7&#x27;</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># 压缩通道</span></span><br><span class="line">        max_out, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)   <span class="comment"># 压缩通道</span></span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)  <span class="comment"># [b, 1, h, w]</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EfficientNetWithAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes: <span class="built_in">int</span> = <span class="number">200</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(EfficientNetWithAttention, self).__init__()</span><br><span class="line">        self.eff_model = EfficientNet.from_pretrained(<span class="string">&quot;efficientnet-b7&quot;</span>)</span><br><span class="line">        self._avg_pooling = nn.AdaptiveAvgPool2d(output_size=<span class="number">1</span>)</span><br><span class="line">        self._dropout = nn.Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Linear(in_features=<span class="number">2560</span>, out_features=num_classes, bias=<span class="literal">True</span>)</span><br><span class="line">        self.ca_head = ChannelAttention(<span class="number">64</span>)</span><br><span class="line">        self.sa = SpatialAttention()</span><br><span class="line">        self.ca_tail = ChannelAttention(<span class="number">2560</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.eff_model.extract_features(x)</span><br><span class="line">        <span class="comment"># 最后一层加入 Attention 机制</span></span><br><span class="line">        x = self.ca_tail(x) * x</span><br><span class="line">        x = self.sa(x) * x</span><br><span class="line">        x = self._avg_pooling(x)</span><br><span class="line">        <span class="keyword">if</span> self.eff_model._global_params.include_top:</span><br><span class="line">            x = x.flatten(start_dim=<span class="number">1</span>)</span><br><span class="line">            x = self._dropout(x)</span><br><span class="line">            x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>最后准确率在 81% 左右，大小仅仅需要 200+MB，比前一个小多了！</p>
<h3 id="学习率调整函数">学习率调整函数</h3>
<p>一般来说，我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，使得网络更好的收敛到最优解。</p>
<h4 id="固定步长衰减">固定步长衰减</h4>
<ul>
<li>使用 <code>torch.optim.lr_scheduler.StepLR</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer_StepLR = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">StepLR = torch.optim.lr_scheduler.StepLR(optimizer_StepLR, step_size=step_size, gamma=<span class="number">0.65</span>)</span><br></pre></td></tr></table></figure>
<p>其中gamma参数表示衰减的程度，step_size参数表示每隔多少个step进行一次学习率调整</p>
<h4 id="ReduceLROnPlateau">ReduceLROnPlateau</h4>
<ul>
<li>使用 <code>torch.optim.lr_scheduler.ReduceLROnPlateau</code></li>
</ul>
<p>他可以基于训练中的某些测量值对学习率进行动态下降。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">10</span>,</span><br><span class="line"> verbose=<span class="literal">False</span>, threshold=<span class="number">0.0001</span>, threshold_mode=<span class="string">&#x27;rel&#x27;</span>, cooldown=<span class="number">0</span>, min_lr=<span class="number">0</span>, eps=<span class="number">1e-08</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>mode 可选择 min 或者 max ，min 表示当监控量停止下降的时候，学习率将减小，max 表示当监控量停止上升的时候，学习率将减小。</li>
<li>factor 学习率每次降低多少。new_lr = old_lr * factor</li>
<li>min_lr,学习率的下限</li>
</ul>
<h2 id="写在最后">写在最后</h2>
<p>感觉软工这个项目确实学到了点深度学习和人工智能的东西，但又说不上来（还是太菜了）。2020 年要结束了，今年的工作绝不拖到明年做！先这样子了，忙去复习期末了，等有空了还会捡起来接着做的！<s>数学不好感觉学不明白…</s></p>
<p>下一步大概是尝试异元的 BCNN，一个用 EfficientNet 和另一个用 EfficientNet + Attention。还有就是提取特征后使用 SVM 或者一些拟合函数来训练，希望能突破85% 的准确率吧。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1347752">腾讯云：细粒度图像识别概述</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/mind_programmonkey/article/details/104354525">实战200类鸟类细粒度图像分类</a>|这个我虽然没看懂代码，但学习了点方法</li>
<li><a target="_blank" rel="noopener" href="http://vis-www.cs.umass.edu/bcnn/">Bilinear CNN Models for Fine-grained Visual Recognition</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/dasguptar/bcnn.pytorch/tree/master/bcnn">dasguptar/bcnn.pytorch</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/lukemelas/EfficientNet-PyTorch/">lukemelas/EfficientNet-PyTorch </a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/93624972">pytorch必须掌握的的4种学习率衰减策略</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>bird-identify</p><p><a href="http://cyx0706.github.io/2020/12/31/bird-identify/">http://cyx0706.github.io/2020/12/31/bird-identify/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Ctwo</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-12-31</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2020-12-31</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Deep-Learning/">Deep Learning</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/01/28/ode/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">aix</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/12/26/pre-learn-of-aix-2/"><span class="level-item">pre-learn-of-aix-week-2/3</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "f6b50699edf1558f6f8dd1d493d74cf0",
            repo: "cyx0706.github.io",
            owner: "cyx0706",
            clientID: "4d458c0d13a2c2157dbd",
            clientSecret: "99a8159ca4a12d236f888be149168b92808a4e29",
            admin: ["cyx0706"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#"><span class="level-left"><span class="level-item">1</span><span class="level-item">软件工程炼丹心得与体会</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#一点点准备"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">一点点准备</span></span></a></li><li><a class="level is-mobile" href="#模型的构建"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">模型的构建</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#细粒度图像识别"><span class="level-left"><span class="level-item">1.2.1</span><span class="level-item">细粒度图像识别</span></span></a></li><li><a class="level is-mobile" href="#预处理"><span class="level-left"><span class="level-item">1.2.2</span><span class="level-item">预处理</span></span></a></li><li><a class="level is-mobile" href="#数据集"><span class="level-left"><span class="level-item">1.2.3</span><span class="level-item">数据集</span></span></a></li><li><a class="level is-mobile" href="#训练函数"><span class="level-left"><span class="level-item">1.2.4</span><span class="level-item">训练函数</span></span></a></li><li><a class="level is-mobile" href="#数据集加载"><span class="level-left"><span class="level-item">1.2.5</span><span class="level-item">数据集加载</span></span></a></li><li><a class="level is-mobile" href="#模型"><span class="level-left"><span class="level-item">1.2.6</span><span class="level-item">模型</span></span></a></li><li><a class="level is-mobile" href="#学习率调整函数"><span class="level-left"><span class="level-item">1.2.7</span><span class="level-item">学习率调整函数</span></span></a></li></ul></li><li><a class="level is-mobile" href="#写在最后"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">写在最后</span></span></a></li><li><a class="level is-mobile" href="#参考"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">参考</span></span></a></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Ctwo&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Ctwo</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>